{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775fead-7675-42b0-8d73-cfeab9873874",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb10567-0129-47e4-8132-d202844b1789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7d37fe-62a0-4709-bc92-71a780b3f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yqzheng/semeval2014_restaurants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4597e50-b7dc-4e19-9f50-d28bb2e3ee72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3608, 5), (1120, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.DataFrame(dataset['train'])\n",
    "test = pd.DataFrame(dataset['test'])\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85272749-ebc6-40b2-a323-756d6f8fca44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'aspect', 'start', 'end', 'label'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff109a4b-ce29-4594-897c-7b9820d45774",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a25a3c6-f612-48b9-8e44-b8c886f43b8e",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9781889e-951c-4219-a123-f6fca4ea07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(df):\n",
    "    df['json'] = df.apply(lambda row: {'aspect': row['aspect'], 'label': row['label']} , axis=1)\n",
    "    return df.groupby('text')['json'].agg(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7419bdee-3fe0-4d7c-9eca-43221f366b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$160 for 2 filets, 2 sides, an appetizer and d...</td>\n",
       "      <td>[{'aspect': 'filets', 'label': 0}, {'aspect': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$20 for all you can eat sushi cannot be beaten.</td>\n",
       "      <td>[{'aspect': 'sushi', 'label': 0}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$20 gets you unlimited sushi of a very high qu...</td>\n",
       "      <td>[{'aspect': 'sushi', 'label': 1}, {'aspect': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$6 and there is much tasty food, all of it fre...</td>\n",
       "      <td>[{'aspect': 'food', 'label': 1}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>($200 for 2 glasses of champagne, not too expe...</td>\n",
       "      <td>[{'aspect': 'glasses of champagne', 'label': -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Always ask the bartender for the SEASONAL bee...</td>\n",
       "      <td>[{'aspect': 'SEASONAL beer', 'label': 1}, {'as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(and I have eaten my share) Which impresses me...</td>\n",
       "      <td>[{'aspect': 'serve', 'label': 1}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(food was delivered by a busboy, not waiter) W...</td>\n",
       "      <td>[{'aspect': 'food', 'label': 0}, {'aspect': 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>- the bread at the beginning is super tasty an...</td>\n",
       "      <td>[{'aspect': 'bread', 'label': 1}, {'aspect': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20 minutes for our reservation but it gave us ...</td>\n",
       "      <td>[{'aspect': 'reservation', 'label': -1}, {'asp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  $160 for 2 filets, 2 sides, an appetizer and d...   \n",
       "1    $20 for all you can eat sushi cannot be beaten.   \n",
       "2  $20 gets you unlimited sushi of a very high qu...   \n",
       "3  $6 and there is much tasty food, all of it fre...   \n",
       "4  ($200 for 2 glasses of champagne, not too expe...   \n",
       "5  (Always ask the bartender for the SEASONAL bee...   \n",
       "6  (and I have eaten my share) Which impresses me...   \n",
       "7  (food was delivered by a busboy, not waiter) W...   \n",
       "8  - the bread at the beginning is super tasty an...   \n",
       "9  20 minutes for our reservation but it gave us ...   \n",
       "\n",
       "                                                json  \n",
       "0  [{'aspect': 'filets', 'label': 0}, {'aspect': ...  \n",
       "1                  [{'aspect': 'sushi', 'label': 0}]  \n",
       "2  [{'aspect': 'sushi', 'label': 1}, {'aspect': '...  \n",
       "3                   [{'aspect': 'food', 'label': 1}]  \n",
       "4  [{'aspect': 'glasses of champagne', 'label': -...  \n",
       "5  [{'aspect': 'SEASONAL beer', 'label': 1}, {'as...  \n",
       "6                  [{'aspect': 'serve', 'label': 1}]  \n",
       "7  [{'aspect': 'food', 'label': 0}, {'aspect': 'b...  \n",
       "8  [{'aspect': 'bread', 'label': 1}, {'aspect': '...  \n",
       "9  [{'aspect': 'reservation', 'label': -1}, {'asp...  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = create_list(train)\n",
    "test_list = create_list(test)\n",
    "train_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01c0734-9c80-45d5-bcce-37dd7a0cb9fc",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99e576b7-022e-46ad-97a9-55d6a8b3add3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22fbdeae-fb15-4fee-99cd-24de67ac38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_instructor(review: str, model: str=\"gpt-3.5-turbo\"):\n",
    "    class AspectInfo(BaseModel):\n",
    "        aspect: str\n",
    "        label: int\n",
    "\n",
    "    example_review = train_df.loc[5, 'text']\n",
    "    example_label = train_df.loc[5, 'json']\n",
    "    prompt = dedent(\"\"\"\n",
    "                Please help me extract the aspects in the following customer review, and for each aspect, \n",
    "                label it as 1 for positive, 0 for neutral, or -1 for negative.\n",
    "\n",
    "                Customer Review: Always ask the bartender for the SEASONAL beer!!!\n",
    "\n",
    "                AspectInfo: [{'aspect': 'SEASONAL beer', 'label': 1}, {'aspect': 'bartender', 'label': 0}]\n",
    "\n",
    "                Customer Review: \n",
    "                \"\"\")\n",
    "\n",
    "    client = instructor.from_openai(OpenAI())\n",
    "    aspects = client.chat.completions.create_iterable(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_model=AspectInfo,\n",
    "    )\n",
    "    return [{\"aspect\": aspect.aspect, \"label\": aspect.label} for aspect in aspects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ca6af51-0026-4566-a00a-05e9e8b576c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Always ask the bartender for the SEASONAL beer!!!\n",
      "[{'aspect': 'SEASONAL beer', 'label': 1}, {'aspect': 'bartender', 'label': 0}]\n",
      "A beautiful atmosphere, perfect for drinks and/or appetizers.\n",
      "[{'aspect': 'atmosphere', 'label': 1}, {'aspect': 'drinks', 'label': 0}, {'aspect': 'appetizers', 'label': 0}]\n"
     ]
    }
   ],
   "source": [
    "example_review = train_df.loc[5, 'text']\n",
    "example_label = train_df.loc[5, 'json']\n",
    "test_review = test_df.loc[4, 'text']\n",
    "test_label = test_df.loc[4, 'json']\n",
    "\n",
    "print(example_review)\n",
    "print(example_label)\n",
    "print(test_review)\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ceee145-aa31-456d-8665-006cb45e6d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'aspect': 'SEASONAL beer', 'label': 1}, {'aspect': 'bartender', 'label': 0}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = use_instructor(test_review)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bdc69c44-1e4c-4cfb-aeac-582b4410be8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "comp = [{'aspect': 'bartender', 'label': 0}, {'aspect': 'SEASONAL beer', 'label': 1}]\n",
    "\n",
    "sorted(comp, key=lambda x: json.dumps(x, sort_keys=True)) == sorted(res, key=lambda x: json.dumps(x, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ea0206e-3d1c-476c-ac95-834625ed8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing import List, Iterable\n",
    "\n",
    "class AspectInfo(BaseModel):\n",
    "    aspect: str\n",
    "    label: int\n",
    "\n",
    "    model_config = ConfigDict(\n",
    "            json_schema_extra={\n",
    "                \"examples\": [json for i in range(5) for json in train_df.loc[i, 'json']]\n",
    "            }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8947908a-9b2b-408b-ba45-4097f97b7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = dedent(f\"\"\"\n",
    "                Please help me extract the aspects in the following customer review, and for each aspect, \n",
    "                label it as 1 for positive, 0 for neutral, or -1 for negative. The response should be a valid Python\n",
    "                list of JSON objects, and each JSON object contains an aspect and a label. \n",
    "\n",
    "                Customer Review: {example_review}\n",
    "\n",
    "                Entities: {example_label}\n",
    "\n",
    "                Customer Review: {test_review}\n",
    "                \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1c50b571-3d38-4e7f-94b2-b1fdd991e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "# client = Groq(\n",
    "#     api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    "# )\n",
    "\n",
    "# client = instructor.from_groq(client, mode=instructor.Mode.JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a7e5fadc-4f3c-4bf1-89e6-b87165e4b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    # model=\"llama3-70b-8192\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "    response_model=Iterable[AspectInfo],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cd598165-db16-4d77-aa7f-774f991338a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AspectInfo(aspect='atmosphere', label=1),\n",
       " AspectInfo(aspect='drinks', label=1),\n",
       " AspectInfo(aspect='appetizers', label=1)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b73361-21c8-4483-a8c6-40d20f734f50",
   "metadata": {},
   "source": [
    "# DSPY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e819b-4cce-4c50-8ff0-022183a905d2",
   "metadata": {},
   "source": [
    "## DSPY Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d4182f-5fb8-4b4d-9759-16bb2ae9811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌍 To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "📺 To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "📖 For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "phoenix_session = px.launch_app()\n",
    "\n",
    "from openinference.instrumentation.dspy import DSPyInstrumentor\n",
    "from opentelemetry import trace as trace_api\n",
    "from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter\n",
    "from opentelemetry.sdk import trace as trace_sdk\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace.export import SimpleSpanProcessor\n",
    "\n",
    "endpoint = \"http://127.0.0.1:6006/v1/traces\"\n",
    "resource = Resource(attributes={})\n",
    "tracer_provider = trace_sdk.TracerProvider(resource=resource)\n",
    "span_otlp_exporter = OTLPSpanExporter(endpoint=endpoint)\n",
    "tracer_provider.add_span_processor(SimpleSpanProcessor(span_exporter=span_otlp_exporter))\n",
    "\n",
    "trace_api.set_tracer_provider(tracer_provider=tracer_provider)\n",
    "DSPyInstrumentor().instrument()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa13a2c-5a47-4b52-8241-9714b59336ab",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5649dcca-d0bf-47e8-8cf3-952a34d98f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_jsons(json_list):\n",
    "    result = {}\n",
    "    for j in json_list:\n",
    "        result.update(j)\n",
    "    return result\n",
    "\n",
    "def create_json(df):\n",
    "    df['json'] = df.apply(lambda row: {row['aspect']: row['label']} , axis=1)\n",
    "    return df.groupby('text')['json'].agg(merge_jsons).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec4b41e-ffa9-4408-a883-947ac505309a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$160 for 2 filets, 2 sides, an appetizer and d...</td>\n",
       "      <td>{'filets': 0, 'sides': 0, 'appetizer': 0, 'dri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$20 for all you can eat sushi cannot be beaten.</td>\n",
       "      <td>{'sushi': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$20 gets you unlimited sushi of a very high qu...</td>\n",
       "      <td>{'sushi': 1, 'sushi places': 1, 'quality': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$6 and there is much tasty food, all of it fre...</td>\n",
       "      <td>{'food': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>($200 for 2 glasses of champagne, not too expe...</td>\n",
       "      <td>{'glasses of champagne': -1, 'bottle of wine':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Always ask the bartender for the SEASONAL bee...</td>\n",
       "      <td>{'SEASONAL beer': 1, 'bartender': 0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(and I have eaten my share) Which impresses me...</td>\n",
       "      <td>{'serve': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(food was delivered by a busboy, not waiter) W...</td>\n",
       "      <td>{'food': 0, 'busboy': -1, 'waiter': -1, 'chees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>- the bread at the beginning is super tasty an...</td>\n",
       "      <td>{'bread': 1, 'pizza': 1, 'margarite pizza with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20 minutes for our reservation but it gave us ...</td>\n",
       "      <td>{'reservation': -1, 'cocktails': 1, 'surroundi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  $160 for 2 filets, 2 sides, an appetizer and d...   \n",
       "1    $20 for all you can eat sushi cannot be beaten.   \n",
       "2  $20 gets you unlimited sushi of a very high qu...   \n",
       "3  $6 and there is much tasty food, all of it fre...   \n",
       "4  ($200 for 2 glasses of champagne, not too expe...   \n",
       "5  (Always ask the bartender for the SEASONAL bee...   \n",
       "6  (and I have eaten my share) Which impresses me...   \n",
       "7  (food was delivered by a busboy, not waiter) W...   \n",
       "8  - the bread at the beginning is super tasty an...   \n",
       "9  20 minutes for our reservation but it gave us ...   \n",
       "\n",
       "                                                json  \n",
       "0  {'filets': 0, 'sides': 0, 'appetizer': 0, 'dri...  \n",
       "1                                       {'sushi': 0}  \n",
       "2      {'sushi': 1, 'sushi places': 1, 'quality': 1}  \n",
       "3                                        {'food': 1}  \n",
       "4  {'glasses of champagne': -1, 'bottle of wine':...  \n",
       "5               {'SEASONAL beer': 1, 'bartender': 0}  \n",
       "6                                       {'serve': 1}  \n",
       "7  {'food': 0, 'busboy': -1, 'waiter': -1, 'chees...  \n",
       "8  {'bread': 1, 'pizza': 1, 'margarite pizza with...  \n",
       "9  {'reservation': -1, 'cocktails': 1, 'surroundi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_json = create_json(train)\n",
    "test_json = create_json(test)\n",
    "train_json.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f40f17a-4d94-498a-9da6-9868c17e970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "gpt = dspy.OpenAI(model=\"gpt-3.5-turbo\", max_tokens=1000)\n",
    "dspy.settings.configure(lm=gpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12926387-cfad-4035-982f-65940f9cb81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dspy_train = [dspy.Example(review=row['text'], aspects_with_label=row['json'], aspects_list=str(row['json'].keys())).with_inputs('review') for _, row in train_json.iterrows()]\n",
    "dspy_test = [dspy.Example(review=row['text'], aspects_with_label=row['json'], aspects_list=str(row['json'].keys())).with_inputs('review') for _, row in test_json.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3929a85-4752-4e1b-a7d1-57a2ad6addca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "evaluate_test = Evaluate(devset=dspy_test[:100], num_threads=10, display_progress=True, display_table=5, max_errors=99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130bbdde-2c98-4227-9688-e2cd72a04a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_venn(example, pred, trace=None):\n",
    "    total_count = len(merge_jsons([example.aspects_with_label, pred.aspects_with_label]).keys())\n",
    "    accurate_count = sum(1 for k, v in example.aspects_with_label.items() if pred.aspects_with_label.get(k) == v)\n",
    "    if trace is None:\n",
    "        return float(accurate_count) / total_count\n",
    "    else:\n",
    "        return accurate_count > total_count * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87bc870e-2ef5-4519-a13a-0e2ed717f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_f1(example, pred, trace=None):\n",
    "    tp = sum(1 for k, v in example.aspects_with_label.items() if pred.aspects_with_label.get(k) == v)\n",
    "    fp = sum(1 for k, v in pred.aspects_with_label.items() if example.aspects_with_label.get(k) != v)\n",
    "    fn = sum(1 for k, v in example.aspects_with_label.items() if k not in pred.aspects_with_label.keys())\n",
    "    if (0.5 * (fp + fn) + tp) == 0:\n",
    "        return 0\n",
    "    f1 = float(tp) / (0.5 * (fp + fn) + tp)\n",
    "    if trace is None:\n",
    "        return f1\n",
    "    else:\n",
    "        return f1 >= 0.8\n",
    "\n",
    "# def validate_f1(example, pred, trace=None):\n",
    "#     tp = sum(1 for k, v in example.aspects_with_label.items() if v == 1 and pred.aspects_with_label.get(k) == v)\n",
    "#     fp = sum(1 for k, v in pred.aspects_with_label.items() if v == 1 and example.aspects_with_label.get(k) != v)\n",
    "#     fn = sum(1 for k, v in pred.aspects_with_label.items() if v == -1 and example.aspects_with_label.get(k) != v)\n",
    "#     if (0.5 * (fp + fn) + tp) == 0:\n",
    "#         return 0\n",
    "#     f1 = float(tp) / (0.5 * (fp + fn) + tp)\n",
    "#     if trace is None:\n",
    "#         return f1\n",
    "#     else:\n",
    "#         return f1 >= 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a638fb5-33ea-4edc-9320-4bb8ad31f06d",
   "metadata": {},
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "501c51e6-afe8-4f84-84d6-94e39be6c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review2Aspects(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Identify aspects and their sentiments from a customer review. The aspects must be words or phrases in the review.\n",
    "    The response should be a Python dictionary, where each key is an aspect and the value is a sentiment label.\n",
    "    A label of 1 indicates positive sentiment, 0 indicates neutral sentiment, and -1 indicates negative sentiment.\n",
    "    \"\"\"\n",
    "\n",
    "    review: str = dspy.InputField(desc=\"a customer review\")\n",
    "    aspects_with_label: dict = dspy.OutputField(format=dict, desc=dedent(\"\"\"\n",
    "        a single Python dictionary, where each key is an aspect and the value is the label,\n",
    "        with label 1 indicating positive sentiment, 0 indicating neutral sentiment, and -1\n",
    "        indicating negative sentiment.\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36b3b5c3-2a59-4e13-8a73-f5a138719d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dspy_test[0].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef1e492b-c68f-49a1-9528-694e6a1d03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABSAPipeline(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_aspects = dspy.TypedChainOfThought(Review2Aspects)\n",
    "\n",
    "    def forward(self, review):\n",
    "        pred = self.generate_aspects(review=review)\n",
    "        return dspy.Prediction(aspects_with_label=pred.aspects_with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16c4d10a-88ec-458d-9ac4-477ba5a03c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompiled_pipeline = ABSAPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f8c1350-2527-43e3-a929-7812da2dc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = uncompiled_pipeline(dspy_test[0].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a175ba0-0990-4b80-b95f-323701f67178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    aspects_with_label={'menu': 1, 'pub fare': 1, 'burgers': 1, 'steaks': 1, 'shepherds pie': 1, 'portabella lasagna': 1, 'vegetarians': 1}\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "09817285-3099-4cc5-8df1-dd3ba9e903c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to train 16 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 2  (12.5):   1%|▏            | 1/100 [00:00<00:08, 12.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 3  (16.7):   2%|▎             | 2/100 [00:00<00:04, 21.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 4  (12.5):   3%|▍             | 3/100 [00:00<00:03, 26.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 4  (12.5):   4%|▌             | 4/100 [00:00<00:02, 32.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 5  (10.0):   4%|▌             | 4/100 [00:00<00:02, 32.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 6  (8.3):   5%|▊              | 5/100 [00:00<00:02, 32.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.75 / 7  (10.7):   6%|▊            | 6/100 [00:00<00:02, 32.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.0833333333333333 / 8  (13.5):   7%| | 7/100 [00:00<00:02, 32.27it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.0833333333333333 / 9  (12.0):   8%| | 8/100 [00:00<00:02, 32.27it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.0833333333333333 / 10  (10.8):   9%| | 9/100 [00:00<00:02, 32.27it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.0833333333333333 / 10  (10.8):  10%| | 10/100 [00:00<00:02, 43.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.0833333333333333 / 11  (9.8):  10%| | 10/100 [00:00<00:02, 43.23it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.0833333333333333 / 12  (9.0):  11%| | 11/100 [00:00<00:02, 43.23it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.3333333333333333 / 13  (10.3):  12%| | 12/100 [00:00<00:02, 43.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.6666666666666665 / 14  (11.9):  13%|▏| 13/100 [00:00<00:02, 43.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.6666666666666665 / 15  (17.8):  14%|▏| 14/100 [00:00<00:01, 43.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.6666666666666665 / 16  (22.9):  15%|▏| 15/100 [00:00<00:01, 43.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.6666666666666665 / 16  (22.9):  16%|▏| 16/100 [00:00<00:01, 46.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.6666666666666665 / 17  (21.6):  16%|▏| 16/100 [00:00<00:01, 46.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.833333333333333 / 18  (21.3):  17%|▏| 17/100 [00:00<00:01, 46.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.833333333333333 / 19  (20.2):  18%|▏| 18/100 [00:00<00:01, 46.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.833333333333333 / 20  (19.2):  19%|▏| 19/100 [00:00<00:01, 46.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.166666666666666 / 21  (19.8):  20%|▏| 20/100 [00:00<00:01, 46.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.166666666666666 / 22  (18.9):  21%|▏| 21/100 [00:00<00:01, 46.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.166666666666666 / 22  (18.9):  22%|▏| 22/100 [00:00<00:01, 50.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.166666666666666 / 23  (18.1):  22%|▏| 22/100 [00:00<00:01, 50.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.166666666666666 / 24  (17.4):  23%|▏| 23/100 [00:00<00:01, 50.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.166666666666666 / 25  (16.7):  24%|▏| 24/100 [00:00<00:01, 50.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.166666666666666 / 26  (16.0):  25%|▎| 25/100 [00:00<00:01, 50.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.666666666666666 / 27  (17.3):  26%|▎| 26/100 [00:00<00:01, 50.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.666666666666666 / 28  (20.2):  27%|▎| 27/100 [00:00<00:01, 50.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.666666666666666 / 28  (20.2):  28%|▎| 28/100 [00:00<00:01, 49.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 9  (0.0):   9%|█▎             | 9/100 [00:17<00:03, 26.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.666666666666666 / 29  (23.0):  28%|▎| 28/100 [00:00<00:01, 49.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.666666666666666 / 30  (22.2):  29%|▎| 29/100 [00:00<00:01, 49.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.666666666666666 / 31  (21.5):  30%|▎| 30/100 [00:00<00:01, 49.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.166666666666666 / 32  (22.4):  31%|▎| 31/100 [00:00<00:01, 49.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.166666666666666 / 33  (21.7):  32%|▎| 32/100 [00:00<00:01, 49.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.166666666666666 / 34  (21.1):  33%|▎| 33/100 [00:00<00:01, 49.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.166666666666666 / 34  (21.1):  34%|▎| 34/100 [00:00<00:01, 49.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.166666666666666 / 35  (20.5):  34%|▎| 34/100 [00:00<00:01, 49.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.166666666666666 / 36  (19.9):  35%|▎| 35/100 [00:00<00:01, 49.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.166666666666666 / 37  (19.4):  36%|▎| 36/100 [00:00<00:01, 49.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.366666666666666 / 38  (19.4):  37%|▎| 37/100 [00:00<00:01, 49.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.616666666666666 / 39  (19.5):  38%|▍| 38/100 [00:00<00:01, 49.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.116666666666667 / 40  (20.3):  39%|▍| 39/100 [00:00<00:01, 49.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.116666666666667 / 40  (20.3):  40%|▍| 40/100 [00:00<00:01, 49.30it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.116666666666667 / 41  (19.8):  40%|▍| 40/100 [00:00<00:01, 49.30it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.783333333333333 / 42  (20.9):  41%|▍| 41/100 [00:00<00:01, 49.30it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.116666666666667 / 43  (21.2):  42%|▍| 42/100 [00:00<00:01, 49.30it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.116666666666667 / 44  (20.7):  43%|▍| 43/100 [00:00<00:01, 49.30it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666667 / 45  (22.5):  44%|▍| 44/100 [00:00<00:01, 49.30i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666667 / 46  (22.0):  45%|▍| 45/100 [00:00<00:01, 49.30i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666667 / 47  (21.5):  46%|▍| 46/100 [00:00<00:01, 49.30i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666667 / 47  (21.5):  47%|▍| 47/100 [00:00<00:01, 51.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666667 / 48  (21.1):  47%|▍| 47/100 [00:00<00:01, 51.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666667 / 49  (20.6):  48%|▍| 48/100 [00:01<00:01, 51.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666667 / 50  (20.2):  49%|▍| 49/100 [00:01<00:00, 51.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.450000000000001 / 51  (20.5):  50%|▌| 50/100 [00:01<00:00, 51.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.450000000000001 / 52  (22.0):  51%|▌| 51/100 [00:01<00:00, 51.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.783333333333335 / 53  (22.2):  52%|▌| 52/100 [00:01<00:00, 51.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.783333333333335 / 53  (22.2):  53%|▌| 53/100 [00:01<00:00, 49.82i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.183333333333335 / 54  (22.6):  53%|▌| 53/100 [00:01<00:00, 49.82i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.183333333333335 / 55  (24.0):  54%|▌| 54/100 [00:01<00:00, 49.82i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.683333333333335 / 56  (24.4):  55%|▌| 55/100 [00:01<00:00, 49.82i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.683333333333335 / 57  (25.8):  56%|▌| 56/100 [00:01<00:00, 49.82i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 58  (26.2):  57%|▌| 57/100 [00:01<00:00, 49.82i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 59  (25.7):  58%|▌| 58/100 [00:01<00:00, 49.82i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 59  (25.7):  59%|▌| 59/100 [00:01<00:00, 48.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 60  (25.3):  59%|▌| 59/100 [00:01<00:00, 48.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 61  (24.9):  60%|▌| 60/100 [00:01<00:00, 48.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 62  (24.5):  61%|▌| 61/100 [00:01<00:00, 48.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 63  (24.1):  62%|▌| 62/100 [00:01<00:00, 48.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.183333333333335 / 64  (23.7):  63%|▋| 63/100 [00:01<00:00, 48.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.433333333333335 / 65  (23.7):  64%|▋| 64/100 [00:01<00:00, 48.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.433333333333335 / 65  (23.7):  65%|▋| 65/100 [00:01<00:00, 45.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.683333333333335 / 66  (23.8):  65%|▋| 65/100 [00:01<00:00, 45.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.183333333333337 / 67  (24.2):  66%|▋| 66/100 [00:01<00:00, 45.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.933333333333337 / 68  (24.9):  67%|▋| 67/100 [00:01<00:00, 45.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.933333333333337 / 69  (24.5):  68%|▋| 68/100 [00:01<00:00, 45.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.133333333333336 / 70  (24.5):  69%|▋| 69/100 [00:01<00:00, 45.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.133333333333336 / 70  (24.5):  70%|▋| 70/100 [00:01<00:00, 41.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.46666666666667 / 71  (24.6):  70%|▋| 70/100 [00:01<00:00, 41.23it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.46666666666667 / 72  (24.3):  71%|▋| 71/100 [00:01<00:00, 41.23it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.46666666666667 / 73  (25.3):  72%|▋| 72/100 [00:01<00:00, 41.23it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.8 / 74  (25.4):  73%|████████   | 73/100 [00:01<00:00, 41.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.133333333333333 / 75  (25.5):  74%|▋| 74/100 [00:01<00:00, 41.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.133333333333333 / 75  (25.5):  75%|▊| 75/100 [00:01<00:00, 35.77i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.133333333333333 / 76  (25.2):  75%|▊| 75/100 [00:01<00:00, 35.77i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.466666666666665 / 77  (25.3):  76%|▊| 76/100 [00:01<00:00, 35.77i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.466666666666665 / 78  (26.2):  77%|▊| 77/100 [00:01<00:00, 35.77i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.466666666666665 / 79  (25.9):  78%|▊| 78/100 [00:01<00:00, 35.77i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.466666666666665 / 79  (25.9):  79%|▊| 79/100 [00:01<00:00, 35.20i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.799999999999997 / 80  (26.0):  79%|▊| 79/100 [00:01<00:00, 35.20i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.13333333333333 / 81  (26.1):  80%|▊| 80/100 [00:01<00:00, 35.20it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.13333333333333 / 82  (27.0):  81%|▊| 81/100 [00:01<00:00, 35.20it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.35555555555555 / 83  (26.9):  82%|▊| 82/100 [00:01<00:00, 35.20it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.35555555555555 / 83  (26.9):  83%|▊| 83/100 [00:01<00:00, 35.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.35555555555555 / 84  (26.6):  83%|▊| 83/100 [00:01<00:00, 35.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.35555555555555 / 85  (27.5):  84%|▊| 84/100 [00:01<00:00, 35.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.35555555555555 / 86  (28.3):  85%|▊| 85/100 [00:01<00:00, 35.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.35555555555555 / 87  (28.0):  86%|▊| 86/100 [00:01<00:00, 35.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.35555555555555 / 88  (27.7):  87%|▊| 87/100 [00:02<00:00, 35.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.60555555555555 / 89  (27.6):  88%|▉| 88/100 [00:02<00:00, 35.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.60555555555555 / 89  (27.6):  89%|▉| 89/100 [00:02<00:00, 38.88it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.60555555555555 / 90  (27.3):  89%|▉| 89/100 [00:02<00:00, 38.88it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.60555555555555 / 91  (28.1):  90%|▉| 90/100 [00:02<00:00, 38.88it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.60555555555555 / 92  (28.9):  91%|▉| 91/100 [00:02<00:00, 38.88it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.60555555555555 / 93  (29.7):  92%|▉| 92/100 [00:02<00:00, 38.88it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.10555555555555 / 94  (29.9):  93%|▉| 93/100 [00:02<00:00, 38.88it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.10555555555555 / 94  (29.9):  94%|▉| 94/100 [00:02<00:00, 41.36it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.60555555555555 / 95  (30.1):  94%|▉| 94/100 [00:02<00:00, 41.36it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.60555555555555 / 96  (30.8):  95%|▉| 95/100 [00:02<00:00, 41.36it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.60555555555555 / 97  (31.6):  96%|▉| 96/100 [00:02<00:00, 41.36it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.60555555555555 / 98  (31.2):  97%|▉| 97/100 [00:02<00:00, 41.36it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.60555555555555 / 99  (30.9):  98%|▉| 98/100 [00:02<00:00, 41.36it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.60555555555555 / 100  (30.6): 100%|█| 100/100 [00:02<00:00, 44.43\u001b[A\u001b[A\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 30.60555555555555 / 100  (30.6%)\n",
      "Score: 30.61 for set: [0]\n",
      "New best score: 30.61 for seed -3\n",
      "Scores so far: [30.61]\n",
      "Best score: 30.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                      | 0/100 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   1%|▏             | 1/100 [00:01<02:00,  1.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 2  (25.0):   1%|▏             | 1/100 [00:01<02:00,  1.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 3  (16.7):   2%|▎             | 2/100 [00:01<01:59,  1.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5 / 3  (16.7):   3%|▍             | 3/100 [00:02<00:59,  1.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.8333333333333333 / 4  (20.8):   3%| | 3/100 [00:02<00:59,  1.63it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):   4%| | 4/100 [00:02<00:58,  1.63it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 6  (30.6):   5%| | 5/100 [00:02<00:58,  1.63it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 6  (30.6):   6%| | 6/100 [00:02<00:31,  2.97it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 7  (26.2):   6%| | 6/100 [00:03<00:31,  2.97it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 7  (26.2):   7%| | 7/100 [00:03<00:44,  2.11it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.833333333333333 / 8  (35.4):   7%| | 7/100 [00:03<00:44,  2.11it/s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.1666666666666665 / 9  (35.2):   8%| | 8/100 [00:04<00:43,  2.11it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.1666666666666665 / 9  (35.2):   9%| | 9/100 [00:04<00:41,  2.19it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.4166666666666665 / 10  (34.2):   9%| | 9/100 [00:04<00:41,  2.19it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.416666666666666 / 11  (40.2):  10%| | 10/100 [00:04<00:41,  2.19it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.416666666666666 / 11  (40.2):  11%| | 11/100 [00:04<00:37,  2.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.416666666666666 / 12  (45.1):  11%| | 11/100 [00:05<00:37,  2.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.749999999999999 / 13  (44.2):  12%| | 12/100 [00:05<00:36,  2.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.749999999999999 / 13  (44.2):  13%|▏| 13/100 [00:05<00:29,  2.98it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.749999999999999 / 14  (41.1):  13%|▏| 13/100 [00:05<00:29,  2.98it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.749999999999999 / 14  (41.1):  14%|▏| 14/100 [00:05<00:31,  2.71it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.499999999999999 / 15  (43.3):  14%|▏| 14/100 [00:05<00:31,  2.71it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.499999999999999 / 16  (46.9):  15%|▏| 15/100 [00:05<00:31,  2.71it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.999999999999999 / 17  (47.1):  16%|▏| 16/100 [00:06<00:30,  2.71it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.999999999999999 / 17  (47.1):  17%|▏| 17/100 [00:06<00:23,  3.55it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.333333333333332 / 18  (46.3):  17%|▏| 17/100 [00:06<00:23,  3.55it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.333333333333332 / 18  (46.3):  18%|▏| 18/100 [00:06<00:20,  3.97it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.333333333333332 / 19  (49.1):  18%|▏| 18/100 [00:06<00:20,  3.97it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.333333333333332 / 19  (49.1):  19%|▏| 19/100 [00:06<00:19,  4.12it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.333333333333332 / 20  (46.7):  19%|▏| 19/100 [00:07<00:19,  4.12it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.333333333333332 / 20  (46.7):  20%|▏| 20/100 [00:07<00:20,  3.86it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.833333333333332 / 21  (46.8):  20%|▏| 20/100 [00:07<00:20,  3.86it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.833333333333332 / 22  (44.7):  21%|▏| 21/100 [00:07<00:20,  3.86it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.833333333333332 / 22  (44.7):  22%|▏| 22/100 [00:07<00:21,  3.59it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.833333333333332 / 23  (42.8):  22%|▏| 22/100 [00:07<00:21,  3.59it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.583333333333332 / 24  (44.1):  23%|▏| 23/100 [00:08<00:21,  3.59i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.583333333333332 / 24  (44.1):  24%|▏| 24/100 [00:08<00:20,  3.78i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.583333333333332 / 25  (46.3):  24%|▏| 24/100 [00:08<00:20,  3.78i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.249999999999998 / 26  (47.1):  25%|▎| 25/100 [00:08<00:19,  3.78i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.749999999999998 / 27  (47.2):  26%|▎| 26/100 [00:08<00:19,  3.78i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.749999999999998 / 27  (47.2):  27%|▎| 27/100 [00:08<00:13,  5.43i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.749999999999998 / 28  (45.5):  27%|▎| 27/100 [00:08<00:13,  5.43i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.749999999999998 / 28  (45.5):  28%|▎| 28/100 [00:08<00:13,  5.22i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.749999999999998 / 29  (47.4):  28%|▎| 28/100 [00:08<00:13,  5.22i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.749999999999998 / 29  (47.4):  29%|▎| 29/100 [00:08<00:14,  4.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.249999999999998 / 30  (47.5):  29%|▎| 29/100 [00:09<00:14,  4.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.249999999999998 / 30  (47.5):  30%|▎| 30/100 [00:09<00:17,  3.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.249999999999998 / 31  (49.2):  30%|▎| 30/100 [00:09<00:17,  3.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.249999999999998 / 31  (49.2):  31%|▎| 31/100 [00:09<00:15,  4.44i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.25 / 32  (50.8):  31%|███       | 31/100 [00:09<00:15,  4.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.25 / 32  (50.8):  32%|███▏      | 32/100 [00:09<00:14,  4.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.65 / 33  (50.5):  32%|███▏      | 32/100 [00:09<00:14,  4.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.65 / 34  (49.0):  33%|███▎      | 33/100 [00:10<00:13,  4.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.65 / 34  (49.0):  34%|███▍      | 34/100 [00:10<00:16,  4.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.65 / 35  (47.6):  34%|███▍      | 34/100 [00:10<00:16,  4.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.65 / 35  (47.6):  35%|███▌      | 35/100 [00:10<00:20,  3.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.65 / 36  (49.0):  35%|███▌      | 35/100 [00:11<00:20,  3.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.65 / 36  (49.0):  36%|███▌      | 36/100 [00:11<00:21,  2.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.65 / 37  (50.4):  36%|███▌      | 36/100 [00:11<00:21,  2.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.65 / 37  (50.4):  37%|███▋      | 37/100 [00:11<00:19,  3.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.65 / 38  (51.7):  37%|███▋      | 37/100 [00:11<00:19,  3.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.65 / 39  (50.4):  38%|███▊      | 38/100 [00:11<00:19,  3.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.65 / 39  (50.4):  39%|███▉      | 39/100 [00:11<00:15,  3.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.15 / 40  (50.4):  39%|███▉      | 39/100 [00:12<00:15,  3.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.15 / 40  (50.4):  40%|████      | 40/100 [00:12<00:15,  3.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.15 / 41  (51.6):  40%|████      | 40/100 [00:12<00:15,  3.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.15 / 41  (51.6):  41%|████      | 41/100 [00:12<00:21,  2.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.15 / 42  (52.7):  41%|████      | 41/100 [00:12<00:21,  2.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.48333333333333 / 43  (52.3):  42%|▍| 42/100 [00:12<00:20,  2.78it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.48333333333333 / 43  (52.3):  43%|▍| 43/100 [00:12<00:13,  4.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.48333333333333 / 44  (53.4):  43%|▍| 43/100 [00:13<00:13,  4.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.48333333333333 / 44  (53.4):  44%|▍| 44/100 [00:13<00:18,  3.01it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.48333333333333 / 45  (52.2):  44%|▍| 44/100 [00:13<00:18,  3.01it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.48333333333333 / 45  (52.2):  45%|▍| 45/100 [00:13<00:17,  3.13it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.73333333333333 / 46  (51.6):  45%|▍| 45/100 [00:14<00:17,  3.13it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.73333333333333 / 46  (51.6):  46%|▍| 46/100 [00:14<00:18,  2.94it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.73333333333333 / 47  (50.5):  46%|▍| 46/100 [00:14<00:18,  2.94it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.066666666666663 / 48  (50.1):  47%|▍| 47/100 [00:14<00:18,  2.94i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.066666666666663 / 48  (50.1):  48%|▍| 48/100 [00:14<00:16,  3.20i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.73333333333333 / 49  (50.5):  48%|▍| 48/100 [00:14<00:16,  3.20it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.73333333333333 / 50  (51.5):  49%|▍| 49/100 [00:14<00:15,  3.20it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.73333333333333 / 50  (51.5):  50%|▌| 50/100 [00:14<00:11,  4.22it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.73333333333333 / 51  (52.4):  50%|▌| 50/100 [00:15<00:11,  4.22it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.73333333333333 / 51  (52.4):  51%|▌| 51/100 [00:15<00:17,  2.85it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 27.066666666666663 / 52  (52.1):  51%|▌| 51/100 [00:15<00:17,  2.85i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.066666666666663 / 52  (52.1):  52%|▌| 52/100 [00:15<00:14,  3.21i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.066666666666663 / 53  (53.0):  52%|▌| 52/100 [00:16<00:14,  3.21i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.066666666666663 / 53  (53.0):  53%|▌| 53/100 [00:16<00:13,  3.46i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.566666666666663 / 54  (52.9):  53%|▌| 53/100 [00:16<00:13,  3.46i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.566666666666663 / 54  (52.9):  54%|▌| 54/100 [00:16<00:11,  3.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.566666666666663 / 55  (53.8):  54%|▌| 54/100 [00:16<00:11,  3.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.566666666666663 / 56  (54.6):  55%|▌| 55/100 [00:17<00:11,  3.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.566666666666663 / 56  (54.6):  56%|▌| 56/100 [00:17<00:15,  2.88i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.066666666666663 / 57  (54.5):  56%|▌| 56/100 [00:17<00:15,  2.88i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.066666666666663 / 57  (54.5):  57%|▌| 57/100 [00:17<00:13,  3.10i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.06666666666666 / 58  (55.3):  57%|▌| 57/100 [00:18<00:13,  3.10it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.06666666666666 / 58  (55.3):  58%|▌| 58/100 [00:18<00:22,  1.89it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 32.06666666666666 / 59  (54.4):  58%|▌| 58/100 [00:21<00:22,  1.89it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.06666666666666 / 59  (54.4):  59%|▌| 59/100 [00:21<00:46,  1.13s/\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 32.06666666666666 / 60  (53.4):  59%|▌| 59/100 [00:21<00:46,  1.13s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.06666666666666 / 60  (53.4):  60%|▌| 60/100 [00:21<00:34,  1.17it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 33.06666666666666 / 61  (54.2):  60%|▌| 60/100 [00:23<00:34,  1.17it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.06666666666666 / 61  (54.2):  61%|▌| 61/100 [00:23<00:46,  1.19s/\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.06666666666666 / 62  (54.9):  61%|▌| 61/100 [00:25<00:46,  1.19s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.06666666666666 / 62  (54.9):  62%|▌| 62/100 [00:25<00:50,  1.32s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.56666666666666 / 63  (54.9):  62%|▌| 62/100 [00:25<00:50,  1.32s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.56666666666666 / 63  (54.9):  63%|▋| 63/100 [00:25<00:37,  1.00s/\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.56666666666666 / 64  (54.0):  63%|▋| 63/100 [00:26<00:37,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.56666666666666 / 64  (54.0):  64%|▋| 64/100 [00:26<00:40,  1.12s/\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.81666666666666 / 65  (53.6):  64%|▋| 64/100 [00:29<00:40,  1.12s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.81666666666666 / 65  (53.6):  65%|▋| 65/100 [00:29<00:54,  1.56s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.81666666666666 / 66  (52.8):  65%|▋| 65/100 [00:29<00:54,  1.56s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.81666666666666 / 66  (52.8):  66%|▋| 66/100 [00:29<00:39,  1.15s/\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 35.15 / 67  (52.5):  66%|██████▌   | 66/100 [00:30<00:39,  1.15s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.15 / 67  (52.5):  67%|██████▋   | 67/100 [00:30<00:39,  1.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.65 / 68  (52.4):  67%|██████▋   | 67/100 [00:32<00:39,  1.19s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.65 / 68  (52.4):  68%|██████▊   | 68/100 [00:32<00:39,  1.23s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 35.65 / 69  (51.7):  68%|██████▊   | 68/100 [00:33<00:39,  1.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.65 / 69  (51.7):  69%|██████▉   | 69/100 [00:33<00:38,  1.24s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 36.65 / 70  (52.4):  69%|██████▉   | 69/100 [00:35<00:38,  1.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 36.65 / 70  (52.4):  70%|███████   | 70/100 [00:35<00:41,  1.40s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 37.65 / 71  (53.0):  70%|███████   | 70/100 [00:36<00:41,  1.40s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.65 / 71  (53.0):  71%|███████   | 71/100 [00:36<00:38,  1.34s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 38.65 / 72  (53.7):  71%|███████   | 71/100 [00:37<00:38,  1.34s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 38.65 / 72  (53.7):  72%|███████▏  | 72/100 [00:37<00:34,  1.23s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 39.65 / 73  (54.3):  72%|███████▏  | 72/100 [00:39<00:34,  1.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 39.65 / 73  (54.3):  73%|███████▎  | 73/100 [00:39<00:36,  1.36s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 40.65 / 74  (54.9):  73%|███████▎  | 73/100 [00:39<00:36,  1.36s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.65 / 74  (54.9):  74%|███████▍  | 74/100 [00:39<00:31,  1.21s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 40.65 / 75  (54.2):  74%|███████▍  | 74/100 [00:41<00:31,  1.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.65 / 75  (54.2):  75%|███████▌  | 75/100 [00:41<00:32,  1.32s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 41.65 / 76  (54.8):  75%|███████▌  | 75/100 [00:43<00:32,  1.32s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.65 / 76  (54.8):  76%|███████▌  | 76/100 [00:43<00:35,  1.47s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 31.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 41.983333333333334 / 77  (54.5):  76%|▊| 76/100 [00:45<00:35,  1.47s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.983333333333334 / 77  (54.5):  77%|▊| 77/100 [00:45<00:39,  1.70s\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 42.983333333333334 / 78  (55.1):  77%|▊| 77/100 [00:45<00:39,  1.70s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 42.983333333333334 / 78  (55.1):  78%|▊| 78/100 [00:45<00:27,  1.26s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.233333333333334 / 79  (54.7):  78%|▊| 78/100 [00:46<00:27,  1.26s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.233333333333334 / 79  (54.7):  79%|▊| 79/100 [00:46<00:24,  1.18s\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 43.233333333333334 / 80  (54.0):  79%|▊| 79/100 [00:47<00:24,  1.18s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.233333333333334 / 80  (54.0):  80%|▊| 80/100 [00:47<00:23,  1.17s\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 43.9 / 81  (54.2):  80%|████████▊  | 80/100 [00:50<00:23,  1.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.9 / 81  (54.2):  81%|████████▉  | 81/100 [00:50<00:28,  1.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.4 / 82  (54.1):  81%|████████▉  | 81/100 [00:50<00:28,  1.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.4 / 82  (54.1):  82%|█████████  | 82/100 [00:50<00:21,  1.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.4 / 83  (54.7):  82%|█████████  | 82/100 [00:51<00:21,  1.21s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.4 / 83  (54.7):  83%|█████████▏ | 83/100 [00:51<00:20,  1.23s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 45.65 / 84  (54.3):  83%|████████▎ | 83/100 [00:53<00:20,  1.23s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.65 / 84  (54.3):  84%|████████▍ | 84/100 [00:53<00:22,  1.39s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 45.9 / 85  (54.0):  84%|█████████▏ | 84/100 [00:55<00:22,  1.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.9 / 85  (54.0):  85%|█████████▎ | 85/100 [00:55<00:20,  1.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 46.9 / 86  (54.5):  85%|█████████▎ | 85/100 [00:56<00:20,  1.35s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 46.9 / 86  (54.5):  86%|█████████▍ | 86/100 [00:56<00:17,  1.24s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 47.9 / 87  (55.1):  86%|█████████▍ | 86/100 [00:56<00:17,  1.24s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.9 / 87  (55.1):  87%|█████████▌ | 87/100 [00:56<00:14,  1.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 48.9 / 88  (55.6):  87%|█████████▌ | 87/100 [00:58<00:14,  1.14s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.9 / 88  (55.6):  88%|█████████▋ | 88/100 [00:58<00:14,  1.20s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 49.9 / 89  (56.1):  88%|█████████▋ | 88/100 [01:01<00:14,  1.20s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 49.9 / 89  (56.1):  89%|█████████▊ | 89/100 [01:01<00:21,  1.93s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.9 / 90  (56.6):  89%|█████████▊ | 89/100 [01:03<00:21,  1.93s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.9 / 90  (56.6):  90%|█████████▉ | 90/100 [01:03<00:17,  1.79s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 31.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 51.9 / 91  (57.0):  90%|█████████▉ | 90/100 [01:04<00:17,  1.79s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 51.9 / 91  (57.0):  91%|██████████ | 91/100 [01:04<00:13,  1.46s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 52.4 / 92  (57.0):  91%|██████████ | 91/100 [01:04<00:13,  1.46s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 52.4 / 92  (57.0):  92%|██████████ | 92/100 [01:04<00:09,  1.22s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 53.4 / 93  (57.4):  92%|██████████ | 92/100 [01:06<00:09,  1.22s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 53.4 / 93  (57.4):  93%|██████████▏| 93/100 [01:06<00:09,  1.36s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 53.62222222222222 / 94  (57.0):  93%|▉| 93/100 [01:07<00:09,  1.36s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 53.62222222222222 / 94  (57.0):  94%|▉| 94/100 [01:07<00:07,  1.27s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 54.62222222222222 / 95  (57.5):  94%|▉| 94/100 [01:07<00:07,  1.27s/\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 55.62222222222222 / 96  (57.9):  95%|▉| 95/100 [01:08<00:06,  1.27s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 55.62222222222222 / 96  (57.9):  96%|▉| 96/100 [01:08<00:03,  1.06it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 55.62222222222222 / 97  (57.3):  96%|▉| 96/100 [01:10<00:03,  1.06it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 55.62222222222222 / 97  (57.3):  97%|▉| 97/100 [01:10<00:03,  1.07s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 56.62222222222222 / 98  (57.8):  97%|▉| 97/100 [01:11<00:03,  1.07s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 56.62222222222222 / 98  (57.8):  98%|▉| 98/100 [01:11<00:02,  1.14s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 56.955555555555556 / 99  (57.5):  98%|▉| 98/100 [01:18<00:02,  1.14s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 56.955555555555556 / 99  (57.5):  99%|▉| 99/100 [01:18<00:02,  2.89s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 57.955555555555556 / 100  (58.0):  99%|▉| 99/100 [01:35<00:02,  2.89\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 57.955555555555556 / 100  (58.0): 100%|█| 100/100 [01:35<00:00,  1.0\u001b[A\u001b[A\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.955555555555556 / 100  (58.0%)\n",
      "Score: 57.96 for set: [16]\n",
      "New best score: 57.96 for seed -2\n",
      "Scores so far: [30.61, 57.96]\n",
      "Best score: 57.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▊                                            | 6/100 [00:01<00:19,  4.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|███████▎                                      | 16/100 [00:01<00:07, 11.78it/s]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:01<01:45,  1.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|▏              | 1/100 [00:01<01:45,  1.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 3  (8.3):   2%|▎             | 2/100 [00:01<01:44,  1.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 3  (8.3):   3%|▍             | 3/100 [00:01<00:35,  2.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.25 / 4  (31.2):   3%|▍            | 3/100 [00:01<00:35,  2.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.25 / 4  (31.2):   4%|▌            | 4/100 [00:01<00:28,  3.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.65 / 5  (33.0):   4%|▌            | 4/100 [00:01<00:28,  3.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.65 / 6  (44.2):   5%|▋            | 5/100 [00:01<00:27,  3.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.65 / 6  (44.2):   6%|▊            | 6/100 [00:01<00:16,  5.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.65 / 7  (37.9):   6%|▊            | 6/100 [00:02<00:16,  5.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.65 / 8  (45.6):   7%|▉            | 7/100 [00:02<00:16,  5.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.65 / 8  (45.6):   8%|█            | 8/100 [00:02<00:30,  3.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.9833333333333334 / 9  (44.3):   8%| | 8/100 [00:02<00:30,  3.01it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.074242424242424 / 10  (40.7):   9%| | 9/100 [00:02<00:30,  3.01it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.074242424242424 / 10  (40.7):  10%| | 10/100 [00:02<00:22,  3.92it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.074242424242424 / 11  (37.0):  10%| | 10/100 [00:02<00:22,  3.92it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.324242424242424 / 12  (36.0):  11%| | 11/100 [00:03<00:22,  3.92it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.324242424242424 / 12  (36.0):  12%| | 12/100 [00:03<00:26,  3.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.324242424242424 / 13  (41.0):  12%| | 12/100 [00:03<00:26,  3.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.574242424242424 / 14  (39.8):  13%|▏| 13/100 [00:04<00:26,  3.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.574242424242424 / 14  (39.8):  14%|▏| 14/100 [00:04<00:23,  3.62it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.574242424242424 / 15  (43.8):  14%|▏| 14/100 [00:04<00:23,  3.62it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.574242424242424 / 15  (43.8):  15%|▏| 15/100 [00:04<00:24,  3.53it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.174242424242424 / 16  (44.8):  15%|▏| 15/100 [00:04<00:24,  3.53it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.674242424242424 / 17  (45.1):  16%|▏| 16/100 [00:04<00:23,  3.53it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.007575757575758 / 18  (44.5):  17%|▏| 17/100 [00:04<00:23,  3.53it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.007575757575758 / 18  (44.5):  18%|▏| 18/100 [00:04<00:16,  4.83it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.007575757575758 / 19  (47.4):  18%|▏| 18/100 [00:05<00:16,  4.83it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.007575757575758 / 19  (47.4):  19%|▏| 19/100 [00:05<00:20,  3.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.007575757575758 / 20  (45.0):  19%|▏| 19/100 [00:05<00:20,  3.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.007575757575758 / 21  (42.9):  20%|▏| 20/100 [00:06<00:20,  3.93it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.007575757575758 / 21  (42.9):  21%|▏| 21/100 [00:06<00:24,  3.18it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.757575757575758 / 22  (44.4):  21%|▏| 21/100 [00:06<00:24,  3.18it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.257575757575758 / 23  (44.6):  22%|▏| 22/100 [00:06<00:24,  3.18i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.257575757575758 / 23  (44.6):  23%|▏| 23/100 [00:06<00:17,  4.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.257575757575758 / 24  (42.7):  23%|▏| 23/100 [00:07<00:17,  4.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.257575757575758 / 24  (42.7):  24%|▏| 24/100 [00:07<00:27,  2.78i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.257575757575758 / 25  (45.0):  24%|▏| 24/100 [00:07<00:27,  2.78i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.257575757575758 / 26  (43.3):  25%|▎| 25/100 [00:08<00:26,  2.78i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.257575757575758 / 26  (43.3):  26%|▎| 26/100 [00:08<00:28,  2.61i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.257575757575758 / 27  (45.4):  26%|▎| 26/100 [00:08<00:28,  2.61i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.257575757575758 / 27  (45.4):  27%|▎| 27/100 [00:08<00:25,  2.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.590909090909092 / 28  (45.0):  27%|▎| 27/100 [00:08<00:25,  2.90i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.590909090909092 / 28  (45.0):  28%|▎| 28/100 [00:08<00:21,  3.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.590909090909092 / 29  (46.9):  28%|▎| 28/100 [00:08<00:21,  3.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.590909090909092 / 30  (45.3):  29%|▎| 29/100 [00:08<00:21,  3.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.757575757575758 / 31  (44.4):  30%|▎| 30/100 [00:08<00:21,  3.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.757575757575758 / 31  (44.4):  31%|▎| 31/100 [00:08<00:15,  4.51i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.757575757575758 / 32  (46.1):  31%|▎| 31/100 [00:09<00:15,  4.51i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.757575757575758 / 32  (46.1):  32%|▎| 32/100 [00:09<00:17,  3.84i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.257575757575758 / 33  (46.2):  32%|▎| 32/100 [00:09<00:17,  3.84i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.257575757575758 / 33  (46.2):  33%|▎| 33/100 [00:09<00:16,  3.96i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.657575757575758 / 34  (46.1):  33%|▎| 33/100 [00:09<00:16,  3.96i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.657575757575758 / 34  (46.1):  34%|▎| 34/100 [00:09<00:15,  4.18i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 15.824242424242424 / 35  (45.2):  34%|▎| 34/100 [00:10<00:15,  4.18i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.824242424242424 / 35  (45.2):  35%|▎| 35/100 [00:10<00:21,  3.01i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 16.324242424242424 / 36  (45.3):  35%|▎| 35/100 [00:10<00:21,  3.01i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.324242424242424 / 36  (45.3):  36%|▎| 36/100 [00:10<00:21,  3.02i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.657575757575756 / 37  (45.0):  36%|▎| 36/100 [00:10<00:21,  3.02i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 17.157575757575756 / 38  (45.2):  37%|▎| 37/100 [00:11<00:20,  3.02i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.157575757575756 / 38  (45.2):  38%|▍| 38/100 [00:11<00:21,  2.91i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.49090909090909 / 39  (44.8):  38%|▍| 38/100 [00:11<00:21,  2.91it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.49090909090909 / 39  (44.8):  39%|▍| 39/100 [00:11<00:22,  2.76it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.99090909090909 / 40  (45.0):  39%|▍| 39/100 [00:12<00:22,  2.76it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.99090909090909 / 40  (45.0):  40%|▍| 40/100 [00:12<00:24,  2.41it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.49090909090909 / 41  (45.1):  40%|▍| 40/100 [00:12<00:24,  2.41it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.49090909090909 / 41  (45.1):  41%|▍| 41/100 [00:12<00:25,  2.29it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.49090909090909 / 42  (44.0):  41%|▍| 41/100 [00:13<00:25,  2.29it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.49090909090909 / 42  (44.0):  42%|▍| 42/100 [00:13<00:27,  2.13it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 18.82424242424242 / 43  (43.8):  42%|▍| 42/100 [00:14<00:27,  2.13it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.82424242424242 / 43  (43.8):  43%|▍| 43/100 [00:14<00:37,  1.50it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 19.82424242424242 / 44  (45.1):  43%|▍| 43/100 [00:15<00:37,  1.50it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.82424242424242 / 44  (45.1):  44%|▍| 44/100 [00:15<00:39,  1.42it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 20.32424242424242 / 45  (45.2):  44%|▍| 44/100 [00:16<00:39,  1.42it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.32424242424242 / 45  (45.2):  45%|▍| 45/100 [00:16<00:52,  1.04it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.32424242424242 / 46  (46.4):  45%|▍| 45/100 [00:17<00:52,  1.04it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.32424242424242 / 46  (46.4):  46%|▍| 46/100 [00:17<00:43,  1.25it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.32424242424242 / 47  (47.5):  46%|▍| 46/100 [00:18<00:43,  1.25it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.32424242424242 / 47  (47.5):  47%|▍| 47/100 [00:18<00:42,  1.25it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 23.32424242424242 / 48  (48.6):  47%|▍| 47/100 [00:19<00:42,  1.25it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.32424242424242 / 48  (48.6):  48%|▍| 48/100 [00:19<00:49,  1.05it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.32424242424242 / 49  (47.6):  48%|▍| 48/100 [00:19<00:49,  1.05it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.32424242424242 / 49  (47.6):  49%|▍| 49/100 [00:19<00:38,  1.34it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 24.32424242424242 / 50  (48.6):  49%|▍| 49/100 [00:20<00:38,  1.34it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.32424242424242 / 50  (48.6):  50%|▌| 50/100 [00:20<00:39,  1.25it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 24.82424242424242 / 51  (48.7):  50%|▌| 50/100 [00:22<00:39,  1.25it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.82424242424242 / 51  (48.7):  51%|▌| 51/100 [00:22<00:50,  1.02s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.32424242424242 / 52  (48.7):  51%|▌| 51/100 [00:23<00:50,  1.02s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.32424242424242 / 52  (48.7):  52%|▌| 52/100 [00:23<00:50,  1.06s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.32424242424242 / 53  (49.7):  52%|▌| 52/100 [00:23<00:50,  1.06s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.32424242424242 / 53  (49.7):  53%|▌| 53/100 [00:23<00:37,  1.26it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 27.32424242424242 / 54  (50.6):  53%|▌| 53/100 [00:25<00:37,  1.26it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.32424242424242 / 54  (50.6):  54%|▌| 54/100 [00:25<00:59,  1.28s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.657575757575753 / 55  (50.3):  54%|▌| 54/100 [00:25<00:59,  1.28s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.657575757575753 / 56  (49.4):  55%|▌| 55/100 [00:27<00:57,  1.28s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.657575757575753 / 56  (49.4):  56%|▌| 56/100 [00:27<00:41,  1.05i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 28.657575757575753 / 57  (50.3):  56%|▌| 56/100 [00:27<00:41,  1.05i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.657575757575753 / 57  (50.3):  57%|▌| 57/100 [00:28<00:41,  1.04i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.657575757575753 / 58  (49.4):  57%|▌| 57/100 [00:28<00:41,  1.04i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 29.657575757575753 / 59  (50.3):  58%|▌| 58/100 [00:28<00:40,  1.04i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.657575757575753 / 59  (50.3):  59%|▌| 59/100 [00:28<00:31,  1.31i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 30.657575757575753 / 60  (51.1):  59%|▌| 59/100 [00:29<00:31,  1.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.657575757575753 / 60  (51.1):  60%|▌| 60/100 [00:29<00:29,  1.38i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 30.990909090909085 / 61  (50.8):  60%|▌| 60/100 [00:30<00:29,  1.38i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.990909090909085 / 61  (50.8):  61%|▌| 61/100 [00:30<00:33,  1.15i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.990909090909085 / 62  (50.0):  61%|▌| 61/100 [00:31<00:33,  1.15i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.990909090909085 / 62  (50.0):  62%|▌| 62/100 [00:31<00:28,  1.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.490909090909085 / 63  (50.0):  62%|▌| 62/100 [00:32<00:28,  1.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.490909090909085 / 63  (50.0):  63%|▋| 63/100 [00:32<00:28,  1.31i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 31.490909090909085 / 64  (49.2):  63%|▋| 63/100 [00:32<00:28,  1.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.490909090909085 / 64  (49.2):  64%|▋| 64/100 [00:32<00:27,  1.29i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 31.824242424242417 / 65  (49.0):  64%|▋| 64/100 [00:33<00:27,  1.29i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.824242424242417 / 65  (49.0):  65%|▋| 65/100 [00:33<00:28,  1.21i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.074242424242414 / 66  (48.6):  65%|▋| 65/100 [00:34<00:28,  1.21i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.074242424242414 / 66  (48.6):  66%|▋| 66/100 [00:34<00:27,  1.26i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.074242424242414 / 67  (49.4):  66%|▋| 66/100 [00:35<00:27,  1.26i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.074242424242414 / 67  (49.4):  67%|▋| 67/100 [00:35<00:30,  1.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.824242424242414 / 68  (49.7):  67%|▋| 67/100 [00:35<00:30,  1.08i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 33.824242424242414 / 69  (49.0):  68%|▋| 68/100 [00:36<00:29,  1.08i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.824242424242414 / 69  (49.0):  69%|▋| 69/100 [00:36<00:23,  1.33i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.824242424242414 / 70  (48.3):  69%|▋| 69/100 [00:37<00:23,  1.33i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.824242424242414 / 70  (48.3):  70%|▋| 70/100 [00:37<00:21,  1.40i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.15757575757575 / 71  (48.1):  70%|▋| 70/100 [00:38<00:21,  1.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.15757575757575 / 71  (48.1):  71%|▋| 71/100 [00:38<00:20,  1.41it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.490909090909085 / 72  (47.9):  71%|▋| 71/100 [00:39<00:20,  1.41i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.490909090909085 / 72  (47.9):  72%|▋| 72/100 [00:39<00:22,  1.22i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.82424242424242 / 73  (47.7):  72%|▋| 72/100 [00:39<00:22,  1.22it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.82424242424242 / 73  (47.7):  73%|▋| 73/100 [00:39<00:21,  1.28it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.157575757575756 / 74  (47.5):  73%|▋| 73/100 [00:40<00:21,  1.28i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.157575757575756 / 74  (47.5):  74%|▋| 74/100 [00:40<00:19,  1.36i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 20.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 35.157575757575756 / 75  (46.9):  74%|▋| 74/100 [00:41<00:19,  1.36i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.157575757575756 / 75  (46.9):  75%|▊| 75/100 [00:41<00:17,  1.43i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 35.407575757575756 / 76  (46.6):  75%|▊| 75/100 [00:42<00:17,  1.43i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.407575757575756 / 76  (46.6):  76%|▊| 76/100 [00:42<00:20,  1.18i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.407575757575756 / 77  (46.0):  76%|▊| 76/100 [00:43<00:20,  1.18i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.407575757575756 / 77  (46.0):  77%|▊| 77/100 [00:43<00:17,  1.28i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 36.407575757575756 / 78  (46.7):  77%|▊| 77/100 [00:43<00:17,  1.28i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 36.407575757575756 / 78  (46.7):  78%|▊| 78/100 [00:43<00:14,  1.48i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 37.407575757575756 / 79  (47.4):  78%|▊| 78/100 [00:44<00:14,  1.48i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.407575757575756 / 79  (47.4):  79%|▊| 79/100 [00:44<00:15,  1.34i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 37.60757575757576 / 80  (47.0):  79%|▊| 79/100 [00:45<00:15,  1.34it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.60757575757576 / 80  (47.0):  80%|▊| 80/100 [00:45<00:18,  1.07it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 38.60757575757576 / 81  (47.7):  80%|▊| 80/100 [00:46<00:18,  1.07it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 38.60757575757576 / 81  (47.7):  81%|▊| 81/100 [00:46<00:14,  1.34it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 39.60757575757576 / 82  (48.3):  81%|▊| 81/100 [00:46<00:14,  1.34it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 39.60757575757576 / 82  (48.3):  82%|▊| 82/100 [00:46<00:13,  1.33it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 40.60757575757576 / 83  (48.9):  82%|▊| 82/100 [00:47<00:13,  1.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.60757575757576 / 83  (48.9):  83%|▊| 83/100 [00:47<00:14,  1.19it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 41.60757575757576 / 84  (49.5):  83%|▊| 83/100 [00:48<00:14,  1.19it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.60757575757576 / 84  (49.5):  84%|▊| 84/100 [00:48<00:13,  1.15it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 42.60757575757576 / 85  (50.1):  84%|▊| 84/100 [00:49<00:13,  1.15it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 42.60757575757576 / 85  (50.1):  85%|▊| 85/100 [00:49<00:12,  1.20it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 43.60757575757576 / 86  (50.7):  85%|▊| 85/100 [00:50<00:12,  1.20it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.60757575757576 / 86  (50.7):  86%|▊| 86/100 [00:50<00:12,  1.15it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.60757575757576 / 87  (50.1):  86%|▊| 86/100 [00:51<00:12,  1.15it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.60757575757576 / 87  (50.1):  87%|▊| 87/100 [00:51<00:13,  1.02s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.60757575757576 / 88  (50.7):  87%|▊| 87/100 [00:51<00:13,  1.02s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.60757575757576 / 89  (50.1):  88%|▉| 88/100 [00:53<00:12,  1.02s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.60757575757576 / 89  (50.1):  89%|▉| 89/100 [00:53<00:09,  1.18it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.85757575757576 / 90  (49.8):  89%|▉| 89/100 [00:54<00:09,  1.18it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.85757575757576 / 90  (49.8):  90%|▉| 90/100 [00:54<00:08,  1.17it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 45.85757575757576 / 91  (50.4):  90%|▉| 90/100 [00:54<00:08,  1.17it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.85757575757576 / 91  (50.4):  91%|▉| 91/100 [00:54<00:06,  1.31it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 46.85757575757576 / 92  (50.9):  91%|▉| 91/100 [00:55<00:06,  1.31it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 46.85757575757576 / 92  (50.9):  92%|▉| 92/100 [00:55<00:07,  1.12it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 46.85757575757576 / 93  (50.4):  92%|▉| 92/100 [00:56<00:07,  1.12it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 46.85757575757576 / 93  (50.4):  93%|▉| 93/100 [00:56<00:06,  1.10it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 47.85757575757576 / 94  (50.9):  93%|▉| 93/100 [00:57<00:06,  1.10it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.85757575757576 / 94  (50.9):  94%|▉| 94/100 [00:57<00:05,  1.11it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 48.85757575757576 / 95  (51.4):  94%|▉| 94/100 [00:58<00:05,  1.11it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.85757575757576 / 95  (51.4):  95%|▉| 95/100 [00:58<00:04,  1.22it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 49.85757575757576 / 96  (51.9):  95%|▉| 95/100 [00:59<00:04,  1.22it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 49.85757575757576 / 96  (51.9):  96%|▉| 96/100 [00:59<00:03,  1.13it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 50.85757575757576 / 97  (52.4):  96%|▉| 96/100 [01:00<00:03,  1.13it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.85757575757576 / 97  (52.4):  97%|▉| 97/100 [01:00<00:03,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 51.52424242424242 / 98  (52.6):  97%|▉| 97/100 [01:01<00:03,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 51.52424242424242 / 98  (52.6):  98%|▉| 98/100 [01:01<00:02,  1.11s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 52.52424242424242 / 99  (53.1):  98%|▉| 98/100 [01:02<00:02,  1.11s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 52.52424242424242 / 99  (53.1):  99%|▉| 99/100 [01:02<00:01,  1.03s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 53.19090909090909 / 100  (53.2):  99%|▉| 99/100 [01:04<00:01,  1.03s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 53.19090909090909 / 100  (53.2): 100%|█| 100/100 [01:04<00:00,  1.56\u001b[A\u001b[A\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 53.19090909090909 / 100  (53.2%)\n",
      "Score: 53.19 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19]\n",
      "Best score: 57.96\n",
      "Average of max per entry across top 1 scores: 0.5795555555555556\n",
      "Average of max per entry across top 2 scores: 0.7768333333333334\n",
      "Average of max per entry across top 3 scores: 0.804\n",
      "Average of max per entry across top 5 scores: 0.804\n",
      "Average of max per entry across top 8 scores: 0.804\n",
      "Average of max per entry across top 9999 scores: 0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▍                                              | 1/100 [00:01<02:46,  1.68s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▉                                              | 2/100 [00:03<02:39,  1.62s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▍                                             | 3/100 [00:04<02:25,  1.50s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▉                                             | 4/100 [00:09<04:15,  2.66s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|██▎                                            | 5/100 [00:10<03:36,  2.28s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▊                                            | 6/100 [00:11<03:01,  1.93s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|███▎                                           | 7/100 [00:13<02:38,  1.70s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███▊                                           | 8/100 [00:16<03:11,  2.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|████▏                                          | 9/100 [00:17<02:41,  1.78s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|████▌                                         | 10/100 [00:19<02:55,  1.94s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:01<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:01<01:50,  1.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|▏              | 1/100 [00:01<01:50,  1.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 3  (8.3):   2%|▎             | 2/100 [00:01<01:49,  1.11s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 3  (8.3):   3%|▍             | 3/100 [00:01<00:38,  2.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 4  (6.2):   3%|▍             | 3/100 [00:01<00:38,  2.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 4  (6.2):   4%|▌             | 4/100 [00:01<00:33,  2.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.5833333333333333 / 5  (11.7):   4%| | 4/100 [00:01<00:33,  2.91it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.3833333333333333 / 6  (23.1):   5%| | 5/100 [00:01<00:32,  2.91it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.3833333333333333 / 7  (19.8):   6%| | 6/100 [00:02<00:32,  2.91it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.3833333333333333 / 7  (19.8):   7%| | 7/100 [00:02<00:20,  4.50it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.3833333333333333 / 8  (29.8):   7%| | 7/100 [00:03<00:20,  4.50it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.3833333333333333 / 8  (29.8):   8%| | 8/100 [00:03<00:45,  2.03it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.6333333333333333 / 9  (29.3):   8%| | 8/100 [00:03<00:45,  2.03it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.8833333333333333 / 10  (28.8):   9%| | 9/100 [00:03<00:44,  2.03it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.8833333333333333 / 11  (26.2):  10%| | 10/100 [00:03<00:44,  2.03i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.8833333333333333 / 11  (26.2):  11%| | 11/100 [00:03<00:24,  3.68i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 3.8833333333333333 / 12  (32.4):  11%| | 11/100 [00:04<00:24,  3.68i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.883333333333333 / 13  (37.6):  12%| | 12/100 [00:04<00:23,  3.68it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.883333333333333 / 13  (37.6):  13%|▏| 13/100 [00:04<00:29,  3.00it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.883333333333333 / 14  (42.0):  13%|▏| 13/100 [00:04<00:29,  3.00it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.883333333333333 / 14  (42.0):  14%|▏| 14/100 [00:04<00:28,  2.99it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 15  (41.4):  14%|▏| 14/100 [00:05<00:28,  2.99it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 15  (41.4):  15%|▏| 15/100 [00:05<00:35,  2.38it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 16  (38.9):  15%|▏| 15/100 [00:06<00:35,  2.38it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 16  (38.9):  16%|▏| 16/100 [00:06<00:39,  2.11it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 17  (36.6):  16%|▏| 16/100 [00:06<00:39,  2.11it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 17  (36.6):  17%|▏| 17/100 [00:06<00:41,  2.01it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 18  (34.5):  17%|▏| 17/100 [00:07<00:41,  2.01it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.216666666666666 / 18  (34.5):  18%|▏| 18/100 [00:07<00:45,  1.79it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 6.966666666666666 / 19  (36.7):  18%|▏| 18/100 [00:08<00:45,  1.79it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.966666666666666 / 19  (36.7):  19%|▏| 19/100 [00:08<00:56,  1.43it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.299999999999999 / 20  (36.5):  19%|▏| 19/100 [00:09<00:56,  1.43it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.299999999999999 / 20  (36.5):  20%|▏| 20/100 [00:09<00:54,  1.47it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.299999999999999 / 21  (34.8):  20%|▏| 20/100 [00:09<00:54,  1.47it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.299999999999999 / 21  (34.8):  21%|▏| 21/100 [00:09<00:48,  1.63it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 7.499999999999999 / 22  (34.1):  21%|▏| 21/100 [00:11<00:48,  1.63it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.499999999999999 / 22  (34.1):  22%|▏| 22/100 [00:11<01:08,  1.15it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.5 / 23  (37.0):  22%|██▋         | 22/100 [00:11<01:08,  1.15it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 8.5 / 24  (35.4):  23%|██▊         | 23/100 [00:12<01:07,  1.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.5 / 24  (35.4):  24%|██▉         | 24/100 [00:12<00:58,  1.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.5 / 25  (38.0):  24%|██▉         | 24/100 [00:12<00:58,  1.30it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 10.5 / 26  (40.4):  25%|██▊        | 25/100 [00:14<00:57,  1.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.5 / 26  (40.4):  26%|██▊        | 26/100 [00:14<00:59,  1.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.75 / 27  (39.8):  26%|██▌       | 26/100 [00:14<00:59,  1.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.75 / 27  (39.8):  27%|██▋       | 27/100 [00:14<00:52,  1.40it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 11.083333333333334 / 28  (39.6):  27%|▎| 27/100 [00:16<00:52,  1.40i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.083333333333334 / 28  (39.6):  28%|▎| 28/100 [00:16<01:03,  1.14i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.583333333333334 / 29  (39.9):  28%|▎| 28/100 [00:16<01:03,  1.14i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.583333333333334 / 29  (39.9):  29%|▎| 29/100 [00:16<01:02,  1.13i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 11.583333333333334 / 30  (38.6):  29%|▎| 29/100 [00:18<01:02,  1.13i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.583333333333334 / 30  (38.6):  30%|▎| 30/100 [00:18<01:06,  1.05i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.083333333333334 / 31  (39.0):  30%|▎| 30/100 [00:18<01:06,  1.05i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.083333333333334 / 31  (39.0):  31%|▎| 31/100 [00:18<00:56,  1.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.583333333333334 / 32  (39.3):  31%|▎| 31/100 [00:19<00:56,  1.23i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.583333333333334 / 32  (39.3):  32%|▎| 32/100 [00:19<01:00,  1.12i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 13.583333333333334 / 33  (41.2):  32%|▎| 32/100 [00:20<01:00,  1.12i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.583333333333334 / 33  (41.2):  33%|▎| 33/100 [00:20<00:59,  1.12i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 13.833333333333334 / 34  (40.7):  33%|▎| 33/100 [00:20<00:59,  1.12i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.833333333333334 / 34  (40.7):  34%|▎| 34/100 [00:20<00:46,  1.41i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 14.333333333333334 / 35  (41.0):  34%|▎| 34/100 [00:22<00:46,  1.41i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.333333333333334 / 35  (41.0):  35%|▎| 35/100 [00:22<01:03,  1.02i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.333333333333334 / 36  (42.6):  35%|▎| 35/100 [00:22<01:03,  1.02i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.333333333333334 / 36  (42.6):  36%|▎| 36/100 [00:22<00:53,  1.19i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.333333333333334 / 37  (41.4):  36%|▎| 36/100 [00:23<00:53,  1.19i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.333333333333334 / 37  (41.4):  37%|▎| 37/100 [00:23<00:48,  1.29i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.733333333333334 / 38  (41.4):  37%|▎| 37/100 [00:24<00:48,  1.29i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.733333333333334 / 38  (41.4):  38%|▍| 38/100 [00:24<00:54,  1.14i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 16.483333333333334 / 39  (42.3):  38%|▍| 38/100 [00:25<00:54,  1.14i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.483333333333334 / 39  (42.3):  39%|▍| 39/100 [00:25<01:00,  1.01i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 17.483333333333334 / 40  (43.7):  39%|▍| 39/100 [00:27<01:00,  1.01i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.483333333333334 / 40  (43.7):  40%|▍| 40/100 [00:27<01:04,  1.07s\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 17.816666666666666 / 41  (43.5):  40%|▍| 40/100 [00:29<01:04,  1.07s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.816666666666666 / 41  (43.5):  41%|▍| 41/100 [00:29<01:24,  1.43s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.15 / 42  (43.2):  41%|████      | 41/100 [00:30<01:24,  1.43s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.15 / 42  (43.2):  42%|████▏     | 42/100 [00:30<01:08,  1.18s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 18.349999999999998 / 43  (42.7):  42%|▍| 42/100 [00:31<01:08,  1.18s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.349999999999998 / 43  (42.7):  43%|▍| 43/100 [00:31<01:15,  1.33s\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 18.849999999999998 / 44  (42.8):  43%|▍| 43/100 [00:32<01:15,  1.33s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.849999999999998 / 44  (42.8):  44%|▍| 44/100 [00:32<01:06,  1.18s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.849999999999998 / 45  (44.1):  44%|▍| 44/100 [00:33<01:06,  1.18s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.849999999999998 / 45  (44.1):  45%|▍| 45/100 [00:33<00:58,  1.06s\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 20.18333333333333 / 46  (43.9):  45%|▍| 45/100 [00:34<00:58,  1.06s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.18333333333333 / 46  (43.9):  46%|▍| 46/100 [00:34<00:56,  1.06s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.18333333333333 / 47  (45.1):  46%|▍| 46/100 [00:35<00:56,  1.06s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.18333333333333 / 47  (45.1):  47%|▍| 47/100 [00:35<01:01,  1.15s/\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 21.18333333333333 / 48  (44.1):  47%|▍| 47/100 [00:35<01:01,  1.15s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.18333333333333 / 48  (44.1):  48%|▍| 48/100 [00:35<00:45,  1.15it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 21.516666666666662 / 49  (43.9):  48%|▍| 48/100 [00:37<00:45,  1.15i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.516666666666662 / 49  (43.9):  49%|▍| 49/100 [00:37<00:50,  1.01i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 22.516666666666662 / 50  (45.0):  49%|▍| 49/100 [00:38<00:50,  1.01i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.516666666666662 / 50  (45.0):  50%|▌| 50/100 [00:38<00:50,  1.01s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.516666666666662 / 51  (46.1):  50%|▌| 50/100 [00:38<00:50,  1.01s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.516666666666662 / 51  (46.1):  51%|▌| 51/100 [00:38<00:38,  1.27i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.516666666666662 / 52  (47.1):  51%|▌| 51/100 [00:39<00:38,  1.27i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.516666666666662 / 52  (47.1):  52%|▌| 52/100 [00:39<00:36,  1.30i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.516666666666662 / 53  (48.1):  52%|▌| 52/100 [00:40<00:36,  1.30i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.516666666666662 / 53  (48.1):  53%|▌| 53/100 [00:40<00:39,  1.19i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.516666666666662 / 54  (49.1):  53%|▌| 53/100 [00:41<00:39,  1.19i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.516666666666662 / 54  (49.1):  54%|▌| 54/100 [00:41<00:38,  1.18i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.516666666666662 / 55  (48.2):  54%|▌| 54/100 [00:41<00:38,  1.18i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.516666666666662 / 55  (48.2):  55%|▌| 55/100 [00:41<00:29,  1.50i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 31.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 26.516666666666662 / 56  (47.4):  55%|▌| 55/100 [00:42<00:29,  1.50i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.516666666666662 / 56  (47.4):  56%|▌| 56/100 [00:42<00:36,  1.19i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.516666666666662 / 57  (48.3):  56%|▌| 56/100 [00:42<00:36,  1.19i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.516666666666662 / 57  (48.3):  57%|▌| 57/100 [00:42<00:27,  1.54i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 27.516666666666662 / 58  (47.4):  57%|▌| 57/100 [00:43<00:27,  1.54i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.516666666666662 / 58  (47.4):  58%|▌| 58/100 [00:43<00:31,  1.35i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 28.516666666666662 / 59  (48.3):  58%|▌| 58/100 [00:44<00:31,  1.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.516666666666662 / 59  (48.3):  59%|▌| 59/100 [00:44<00:29,  1.39i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 28.71666666666666 / 60  (47.9):  59%|▌| 59/100 [00:46<00:29,  1.39it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.71666666666666 / 60  (47.9):  60%|▌| 60/100 [00:46<00:40,  1.02s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.71666666666666 / 61  (47.1):  60%|▌| 60/100 [00:46<00:40,  1.02s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.71666666666666 / 61  (47.1):  61%|▌| 61/100 [00:46<00:29,  1.31it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 29.049999999999994 / 62  (46.9):  61%|▌| 61/100 [00:47<00:29,  1.31i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.049999999999994 / 62  (46.9):  62%|▌| 62/100 [00:47<00:34,  1.10i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.549999999999994 / 63  (46.9):  62%|▌| 62/100 [00:48<00:34,  1.10i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.549999999999994 / 63  (46.9):  63%|▋| 63/100 [00:48<00:29,  1.26i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 30.299999999999994 / 64  (47.3):  63%|▋| 63/100 [00:50<00:29,  1.26i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.299999999999994 / 64  (47.3):  64%|▋| 64/100 [00:50<00:40,  1.12s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.299999999999994 / 65  (46.6):  64%|▋| 64/100 [00:50<00:40,  1.12s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.299999999999994 / 65  (46.6):  65%|▋| 65/100 [00:50<00:36,  1.06s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.633333333333326 / 66  (46.4):  65%|▋| 65/100 [00:52<00:36,  1.06s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.633333333333326 / 66  (46.4):  66%|▋| 66/100 [00:52<00:37,  1.11s\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 10.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 31.633333333333326 / 67  (47.2):  66%|▋| 66/100 [00:52<00:37,  1.11s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.633333333333326 / 67  (47.2):  67%|▋| 67/100 [00:52<00:29,  1.13i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.633333333333326 / 68  (46.5):  67%|▋| 67/100 [00:52<00:29,  1.13i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.633333333333326 / 69  (47.3):  68%|▋| 68/100 [00:53<00:28,  1.13i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.633333333333326 / 69  (47.3):  69%|▋| 69/100 [00:53<00:20,  1.53i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.633333333333326 / 70  (48.0):  69%|▋| 69/100 [00:53<00:20,  1.53i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.96666666666666 / 71  (47.8):  70%|▋| 70/100 [00:54<00:19,  1.53it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.96666666666666 / 71  (47.8):  71%|▋| 71/100 [00:54<00:16,  1.73it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.21666666666666 / 72  (47.5):  71%|▋| 71/100 [00:54<00:16,  1.73it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.21666666666666 / 72  (47.5):  72%|▋| 72/100 [00:54<00:15,  1.79it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.21666666666666 / 73  (46.9):  72%|▋| 72/100 [00:55<00:15,  1.79it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.21666666666666 / 73  (46.9):  73%|▋| 73/100 [00:55<00:13,  1.94it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.55 / 74  (46.7):  73%|███████▎  | 73/100 [00:55<00:13,  1.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.55 / 74  (46.7):  74%|███████▍  | 74/100 [00:55<00:15,  1.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.55 / 75  (46.1):  74%|███████▍  | 74/100 [00:56<00:15,  1.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.55 / 75  (46.1):  75%|███████▌  | 75/100 [00:56<00:16,  1.53it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.55 / 76  (45.5):  75%|███████▌  | 75/100 [00:57<00:16,  1.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.55 / 76  (45.5):  76%|███████▌  | 76/100 [00:57<00:17,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.55 / 77  (46.2):  76%|███████▌  | 76/100 [00:58<00:17,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.55 / 77  (46.2):  77%|███████▋  | 77/100 [00:58<00:15,  1.47it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 36.55 / 78  (46.9):  77%|███████▋  | 77/100 [00:59<00:15,  1.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 36.55 / 78  (46.9):  78%|███████▊  | 78/100 [00:59<00:16,  1.33it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 37.05 / 79  (46.9):  78%|███████▊  | 78/100 [01:00<00:16,  1.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.05 / 79  (46.9):  79%|███████▉  | 79/100 [01:00<00:19,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.3 / 80  (46.6):  79%|████████▋  | 79/100 [01:01<00:19,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.3 / 80  (46.6):  80%|████████▊  | 80/100 [01:01<00:17,  1.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 38.3 / 81  (47.3):  80%|████████▊  | 80/100 [01:01<00:17,  1.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 38.3 / 81  (47.3):  81%|████████▉  | 81/100 [01:01<00:14,  1.28it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 39.3 / 82  (47.9):  81%|████████▉  | 81/100 [01:02<00:14,  1.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 39.3 / 82  (47.9):  82%|█████████  | 82/100 [01:02<00:14,  1.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.3 / 83  (48.6):  82%|█████████  | 82/100 [01:03<00:14,  1.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.3 / 83  (48.6):  83%|█████████▏ | 83/100 [01:03<00:14,  1.19it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 14.8 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 40.3 / 84  (48.0):  83%|█████████▏ | 83/100 [01:05<00:14,  1.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.3 / 84  (48.0):  84%|█████████▏ | 84/100 [01:05<00:16,  1.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.3 / 85  (48.6):  84%|█████████▏ | 84/100 [01:05<00:16,  1.04s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.3 / 85  (48.6):  85%|█████████▎ | 85/100 [01:05<00:14,  1.04it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 41.55 / 86  (48.3):  85%|████████▌ | 85/100 [01:06<00:14,  1.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.55 / 86  (48.3):  86%|████████▌ | 86/100 [01:06<00:12,  1.10it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 42.55 / 87  (48.9):  86%|████████▌ | 86/100 [01:06<00:12,  1.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 42.55 / 87  (48.9):  87%|████████▋ | 87/100 [01:06<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.55 / 88  (49.5):  87%|████████▋ | 87/100 [01:07<00:09,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.55 / 88  (49.5):  88%|████████▊ | 88/100 [01:07<00:07,  1.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.55 / 89  (50.1):  88%|████████▊ | 88/100 [01:07<00:07,  1.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.55 / 89  (50.1):  89%|████████▉ | 89/100 [01:07<00:06,  1.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.55 / 90  (50.6):  89%|████████▉ | 89/100 [01:08<00:06,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.55 / 90  (50.6):  90%|█████████ | 90/100 [01:08<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 45.55 / 91  (50.1):  90%|█████████ | 90/100 [01:10<00:07,  1.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.55 / 91  (50.1):  91%|█████████ | 91/100 [01:10<00:08,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 46.55 / 92  (50.6):  91%|█████████ | 91/100 [01:10<00:08,  1.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 46.55 / 92  (50.6):  92%|█████████▏| 92/100 [01:10<00:06,  1.30it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 47.38333333333333 / 93  (50.9):  92%|▉| 92/100 [01:12<00:06,  1.30it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.38333333333333 / 93  (50.9):  93%|▉| 93/100 [01:12<00:07,  1.07s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.63333333333333 / 94  (50.7):  93%|▉| 93/100 [01:12<00:07,  1.07s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.63333333333333 / 94  (50.7):  94%|▉| 94/100 [01:12<00:04,  1.22it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.63333333333333 / 95  (51.2):  94%|▉| 94/100 [01:13<00:04,  1.22it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.63333333333333 / 95  (51.2):  95%|▉| 95/100 [01:13<00:03,  1.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.63333333333333 / 96  (50.7):  95%|▉| 95/100 [01:13<00:03,  1.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.63333333333333 / 96  (50.7):  96%|▉| 96/100 [01:13<00:02,  1.36it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 41.0 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 49.63333333333333 / 97  (51.2):  96%|▉| 96/100 [01:15<00:02,  1.36it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 49.63333333333333 / 97  (51.2):  97%|▉| 97/100 [01:15<00:03,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.63333333333333 / 98  (51.7):  97%|▉| 97/100 [01:15<00:03,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.63333333333333 / 98  (51.7):  98%|▉| 98/100 [01:15<00:01,  1.27it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.63333333333333 / 99  (51.1):  98%|▉| 98/100 [01:20<00:01,  1.27it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.63333333333333 / 99  (51.1):  99%|▉| 99/100 [01:20<00:01,  1.85s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 51.3 / 100  (51.3):  99%|█████████▉| 99/100 [01:56<00:01,  1.85s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 51.3 / 100  (51.3): 100%|█████████| 100/100 [01:56<00:00,  1.17s/it]\u001b[A\u001b[A\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.3 / 100  (51.3%)\n",
      "Score: 51.3 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3]\n",
      "Best score: 57.96\n",
      "Average of max per entry across top 1 scores: 0.5795555555555556\n",
      "Average of max per entry across top 2 scores: 0.7768333333333334\n",
      "Average of max per entry across top 3 scores: 0.8490000000000001\n",
      "Average of max per entry across top 5 scores: 0.8648333333333333\n",
      "Average of max per entry across top 8 scores: 0.8648333333333333\n",
      "Average of max per entry across top 9999 scores: 0.8648333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▍                                              | 1/100 [00:01<02:47,  1.69s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▉                                              | 2/100 [00:03<03:17,  2.01s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▍                                             | 3/100 [00:05<03:00,  1.86s/it]\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dsp/modules/gpt3.py:264: UserWarning: Persisting input arguments took 1.82s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.\n",
      "  return v1_cached_gpt3_turbo_request_v2(**kwargs)\n",
      "\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 1  (25.0):   0%|                     | 0/100 [00:02<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 0.25 / 1  (25.0):   1%|▏            | 1/100 [00:02<04:39,  2.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.25 / 2  (62.5):   1%|▏            | 1/100 [00:02<04:39,  2.82s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.5833333333333333 / 3  (52.8):   2%| | 2/100 [00:02<04:36,  2.82s/i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 1.5833333333333333 / 4  (39.6):   3%| | 3/100 [00:02<04:33,  2.82s/i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.583333333333333 / 5  (51.7):   4%| | 4/100 [00:02<04:30,  2.82s/it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.583333333333333 / 6  (43.1):   5%| | 5/100 [00:03<04:28,  2.82s/it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.583333333333333 / 6  (43.1):   6%| | 6/100 [00:03<00:44,  2.13it/s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 2.583333333333333 / 7  (36.9):   6%| | 6/100 [00:03<00:44,  2.13it/s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.2499999999999996 / 8  (40.6):   7%| | 7/100 [00:04<00:43,  2.13it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 3.2499999999999996 / 8  (40.6):   8%| | 8/100 [00:04<00:36,  2.51it/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.25 / 9  (47.2):   8%|█            | 8/100 [00:04<00:36,  2.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.25 / 9  (47.2):   9%|█▏           | 9/100 [00:04<00:34,  2.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.5 / 10  (45.0):   9%|█▏           | 9/100 [00:04<00:34,  2.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.5 / 10  (45.0):  10%|█▏          | 10/100 [00:04<00:37,  2.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 4.833333333333333 / 11  (43.9):  10%| | 10/100 [00:04<00:37,  2.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 5.083333333333333 / 12  (42.4):  11%| | 11/100 [00:04<00:37,  2.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.083333333333333 / 13  (46.8):  12%| | 12/100 [00:05<00:36,  2.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.083333333333333 / 13  (46.8):  13%|▏| 13/100 [00:05<00:22,  3.87it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.183333333333333 / 14  (44.2):  13%|▏| 13/100 [00:05<00:22,  3.87it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.183333333333333 / 14  (44.2):  14%|▏| 14/100 [00:05<00:21,  3.91it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.783333333333332 / 15  (45.2):  14%|▏| 14/100 [00:05<00:21,  3.91it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 6.783333333333332 / 15  (45.2):  15%|▏| 15/100 [00:05<00:26,  3.21it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.283333333333332 / 16  (45.5):  15%|▏| 15/100 [00:06<00:26,  3.21it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 7.283333333333332 / 16  (45.5):  16%|▏| 16/100 [00:06<00:25,  3.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.283333333333331 / 17  (48.7):  16%|▏| 16/100 [00:06<00:25,  3.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 8.283333333333331 / 17  (48.7):  17%|▏| 17/100 [00:06<00:22,  3.75it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.283333333333331 / 18  (51.6):  17%|▏| 17/100 [00:06<00:22,  3.75it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.283333333333331 / 18  (51.6):  18%|▏| 18/100 [00:06<00:18,  4.46it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.616666666666665 / 19  (50.6):  18%|▏| 18/100 [00:07<00:18,  4.46it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 9.616666666666665 / 19  (50.6):  19%|▏| 19/100 [00:07<00:26,  3.09it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666665 / 20  (50.6):  19%|▏| 19/100 [00:07<00:26,  3.09i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 10.116666666666665 / 21  (48.2):  20%|▏| 20/100 [00:07<00:25,  3.09i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.116666666666665 / 22  (50.5):  21%|▏| 21/100 [00:07<00:25,  3.09i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.116666666666665 / 22  (50.5):  22%|▏| 22/100 [00:07<00:22,  3.54i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.116666666666665 / 23  (48.3):  22%|▏| 22/100 [00:07<00:22,  3.54i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.116666666666665 / 24  (46.3):  23%|▏| 23/100 [00:07<00:21,  3.54i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.116666666666665 / 24  (46.3):  24%|▏| 24/100 [00:07<00:15,  4.89i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.45 / 25  (45.8):  24%|██▍       | 24/100 [00:08<00:15,  4.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.45 / 25  (45.8):  25%|██▌       | 25/100 [00:08<00:15,  4.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 11.95 / 26  (46.0):  25%|██▌       | 25/100 [00:08<00:15,  4.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.95 / 27  (48.0):  26%|██▌       | 26/100 [00:08<00:15,  4.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.95 / 27  (48.0):  27%|██▋       | 27/100 [00:08<00:15,  4.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.95 / 28  (49.8):  27%|██▋       | 27/100 [00:08<00:15,  4.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.95 / 28  (49.8):  28%|██▊       | 28/100 [00:08<00:15,  4.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 13.95 / 29  (48.1):  28%|██▊       | 28/100 [00:08<00:15,  4.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.95 / 30  (49.8):  29%|██▉       | 29/100 [00:09<00:15,  4.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 14.95 / 30  (49.8):  30%|███       | 30/100 [00:09<00:15,  4.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.283333333333333 / 31  (49.3):  30%|▎| 30/100 [00:09<00:15,  4.46i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.283333333333333 / 31  (49.3):  31%|▎| 31/100 [00:09<00:14,  4.73i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.483333333333333 / 32  (48.4):  31%|▎| 31/100 [00:09<00:14,  4.73i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.483333333333333 / 32  (48.4):  32%|▎| 32/100 [00:09<00:15,  4.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.883333333333333 / 33  (48.1):  32%|▎| 32/100 [00:09<00:15,  4.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.883333333333333 / 33  (48.1):  33%|▎| 33/100 [00:09<00:15,  4.24i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.883333333333333 / 34  (46.7):  33%|▎| 33/100 [00:10<00:15,  4.24i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 15.883333333333333 / 34  (46.7):  34%|▎| 34/100 [00:10<00:25,  2.57i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.28333333333333 / 35  (46.5):  34%|▎| 34/100 [00:11<00:25,  2.57it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.28333333333333 / 35  (46.5):  35%|▎| 35/100 [00:11<00:22,  2.90it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.53333333333333 / 36  (45.9):  35%|▎| 35/100 [00:11<00:22,  2.90it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 16.53333333333333 / 36  (45.9):  36%|▎| 36/100 [00:11<00:19,  3.32it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.03333333333333 / 37  (46.0):  36%|▎| 36/100 [00:11<00:19,  3.32it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.03333333333333 / 37  (46.0):  37%|▎| 37/100 [00:11<00:16,  3.82it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.03333333333333 / 38  (44.8):  37%|▎| 37/100 [00:11<00:16,  3.82it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.03333333333333 / 38  (44.8):  38%|▍| 38/100 [00:11<00:17,  3.51it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.53333333333333 / 39  (45.0):  38%|▍| 38/100 [00:11<00:17,  3.51it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.53333333333333 / 39  (45.0):  39%|▍| 39/100 [00:11<00:16,  3.72it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.53333333333333 / 40  (43.8):  39%|▍| 39/100 [00:12<00:16,  3.72it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 17.53333333333333 / 40  (43.8):  40%|▍| 40/100 [00:12<00:14,  4.21it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.2 / 41  (44.4):  40%|████▍      | 40/100 [00:12<00:14,  4.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 18.2 / 41  (44.4):  41%|████▌      | 41/100 [00:12<00:13,  4.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.2 / 42  (45.7):  41%|████▌      | 41/100 [00:12<00:13,  4.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 19.53333333333333 / 43  (45.4):  42%|▍| 42/100 [00:12<00:13,  4.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.53333333333333 / 44  (46.7):  43%|▍| 43/100 [00:12<00:13,  4.33it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 20.53333333333333 / 44  (46.7):  44%|▍| 44/100 [00:12<00:10,  5.49it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 21.53333333333333 / 45  (47.9):  44%|▍| 44/100 [00:12<00:10,  5.49it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.53333333333333 / 46  (49.0):  45%|▍| 45/100 [00:13<00:10,  5.49it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.53333333333333 / 46  (49.0):  46%|▍| 46/100 [00:13<00:10,  5.19it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.866666666666664 / 47  (48.7):  46%|▍| 46/100 [00:13<00:10,  5.19i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 22.866666666666664 / 47  (48.7):  47%|▍| 47/100 [00:13<00:09,  5.63i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.366666666666664 / 48  (48.7):  47%|▍| 47/100 [00:13<00:09,  5.63i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.366666666666664 / 48  (48.7):  48%|▍| 48/100 [00:13<00:12,  4.24i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.699999999999996 / 49  (48.4):  48%|▍| 48/100 [00:13<00:12,  4.24i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.699999999999996 / 49  (48.4):  49%|▍| 49/100 [00:13<00:10,  4.80i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 23.699999999999996 / 50  (47.4):  49%|▍| 49/100 [00:13<00:10,  4.80i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.699999999999996 / 51  (48.4):  50%|▌| 50/100 [00:14<00:10,  4.80i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 24.699999999999996 / 51  (48.4):  51%|▌| 51/100 [00:14<00:08,  6.01i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.699999999999996 / 52  (49.4):  51%|▌| 51/100 [00:14<00:08,  6.01i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.699999999999996 / 52  (49.4):  52%|▌| 52/100 [00:14<00:13,  3.65i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 25.899999999999995 / 53  (48.9):  52%|▌| 52/100 [00:14<00:13,  3.65i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.233333333333327 / 54  (48.6):  53%|▌| 53/100 [00:14<00:12,  3.65i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.233333333333327 / 54  (48.6):  54%|▌| 54/100 [00:14<00:08,  5.25i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.733333333333327 / 55  (48.6):  54%|▌| 54/100 [00:14<00:08,  5.25i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 26.733333333333327 / 55  (48.6):  55%|▌| 55/100 [00:14<00:08,  5.34i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 27.733333333333327 / 56  (49.5):  55%|▌| 55/100 [00:15<00:08,  5.34i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.233333333333327 / 57  (49.5):  56%|▌| 56/100 [00:15<00:08,  5.34i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.233333333333327 / 58  (50.4):  57%|▌| 57/100 [00:15<00:08,  5.34i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.233333333333327 / 58  (50.4):  58%|▌| 58/100 [00:15<00:09,  4.67i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.56666666666666 / 59  (50.1):  58%|▌| 58/100 [00:15<00:09,  4.67it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.56666666666666 / 60  (49.3):  59%|▌| 59/100 [00:15<00:08,  4.67it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.56666666666666 / 61  (48.5):  60%|▌| 60/100 [00:15<00:08,  4.67it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.56666666666666 / 61  (48.5):  61%|▌| 61/100 [00:15<00:05,  6.98it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.56666666666666 / 62  (47.7):  61%|▌| 61/100 [00:16<00:05,  6.98it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.56666666666666 / 63  (46.9):  62%|▌| 62/100 [00:16<00:05,  6.98it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.56666666666666 / 63  (46.9):  63%|▋| 63/100 [00:16<00:04,  7.45it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 30.56666666666666 / 64  (47.8):  63%|▋| 63/100 [00:16<00:04,  7.45it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.06666666666666 / 65  (47.8):  64%|▋| 64/100 [00:17<00:04,  7.45it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.06666666666666 / 65  (47.8):  65%|▋| 65/100 [00:17<00:08,  4.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.39999999999999 / 66  (47.6):  65%|▋| 65/100 [00:17<00:08,  4.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.39999999999999 / 67  (46.9):  66%|▋| 66/100 [00:17<00:08,  4.08it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 31.39999999999999 / 67  (46.9):  67%|▋| 67/100 [00:17<00:06,  4.92it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.39999999999999 / 68  (47.6):  67%|▋| 67/100 [00:17<00:06,  4.92it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 32.39999999999999 / 68  (47.6):  68%|▋| 68/100 [00:17<00:06,  4.63it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 33.14999999999999 / 69  (48.0):  68%|▋| 68/100 [00:17<00:06,  4.63it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.14999999999999 / 70  (48.8):  69%|▋| 69/100 [00:18<00:06,  4.63it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.14999999999999 / 70  (48.8):  70%|▋| 70/100 [00:18<00:06,  4.29it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 34.14999999999999 / 71  (48.1):  70%|▋| 70/100 [00:18<00:06,  4.29it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.14999999999999 / 71  (48.1):  71%|▋| 71/100 [00:18<00:09,  3.03it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.64999999999999 / 72  (48.1):  71%|▋| 71/100 [00:19<00:09,  3.03it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 34.64999999999999 / 72  (48.1):  72%|▋| 72/100 [00:19<00:08,  3.17it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.64999999999999 / 73  (48.8):  72%|▋| 72/100 [00:19<00:08,  3.17it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 35.64999999999999 / 73  (48.8):  73%|▋| 73/100 [00:19<00:09,  2.79it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 36.64999999999999 / 74  (49.5):  73%|▋| 73/100 [00:19<00:09,  2.79it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 36.64999999999999 / 74  (49.5):  74%|▋| 74/100 [00:20<00:09,  2.77it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.04999999999999 / 75  (49.4):  74%|▋| 74/100 [00:20<00:09,  2.77it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 37.383333333333326 / 76  (49.2):  75%|▊| 75/100 [00:21<00:09,  2.77i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.383333333333326 / 76  (49.2):  76%|▊| 76/100 [00:21<00:10,  2.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.383333333333326 / 77  (48.5):  76%|▊| 76/100 [00:21<00:10,  2.35i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 37.383333333333326 / 77  (48.5):  77%|▊| 77/100 [00:21<00:08,  2.61i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 38.383333333333326 / 78  (49.2):  77%|▊| 77/100 [00:22<00:08,  2.61i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 38.383333333333326 / 78  (49.2):  78%|▊| 78/100 [00:22<00:10,  2.12i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 39.383333333333326 / 79  (49.9):  78%|▊| 78/100 [00:22<00:10,  2.12i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 39.383333333333326 / 79  (49.9):  79%|▊| 79/100 [00:22<00:08,  2.41i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 39.383333333333326 / 80  (49.2):  79%|▊| 79/100 [00:23<00:08,  2.41i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 39.383333333333326 / 80  (49.2):  80%|▊| 80/100 [00:23<00:10,  1.89i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.383333333333326 / 81  (49.9):  80%|▊| 80/100 [00:23<00:10,  1.89i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 40.383333333333326 / 81  (49.9):  81%|▊| 81/100 [00:23<00:10,  1.87i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 41.04999999999999 / 82  (50.1):  81%|▊| 81/100 [00:24<00:10,  1.87it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.04999999999999 / 82  (50.1):  82%|▊| 82/100 [00:24<00:12,  1.42it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 41.383333333333326 / 83  (49.9):  82%|▊| 82/100 [00:25<00:12,  1.42i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.383333333333326 / 83  (49.9):  83%|▊| 83/100 [00:25<00:13,  1.24i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.383333333333326 / 84  (49.3):  83%|▊| 83/100 [00:26<00:13,  1.24i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.383333333333326 / 84  (49.3):  84%|▊| 84/100 [00:26<00:10,  1.52i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 41.633333333333326 / 85  (49.0):  84%|▊| 84/100 [00:27<00:10,  1.52i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 41.633333333333326 / 85  (49.0):  85%|▊| 85/100 [00:27<00:11,  1.32i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 42.633333333333326 / 86  (49.6):  85%|▊| 85/100 [00:27<00:11,  1.32i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 42.633333333333326 / 86  (49.6):  86%|▊| 86/100 [00:27<00:08,  1.73i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 43.633333333333326 / 87  (50.2):  86%|▊| 86/100 [00:28<00:08,  1.73i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 43.633333333333326 / 87  (50.2):  87%|▊| 87/100 [00:28<00:08,  1.52i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 44.633333333333326 / 88  (50.7):  87%|▊| 87/100 [00:28<00:08,  1.52i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 44.633333333333326 / 88  (50.7):  88%|▉| 88/100 [00:28<00:07,  1.54i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.633333333333326 / 89  (51.3):  88%|▉| 88/100 [00:29<00:07,  1.54i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 45.633333333333326 / 89  (51.3):  89%|▉| 89/100 [00:29<00:07,  1.56i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 46.133333333333326 / 90  (51.3):  89%|▉| 89/100 [00:30<00:07,  1.56i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 46.133333333333326 / 90  (51.3):  90%|▉| 90/100 [00:30<00:07,  1.37i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.133333333333326 / 91  (51.8):  90%|▉| 90/100 [00:31<00:07,  1.37i\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.133333333333326 / 91  (51.8):  91%|▉| 91/100 [00:31<00:08,  1.11i\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 14.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 47.35555555555555 / 92  (51.5):  91%|▉| 91/100 [00:31<00:08,  1.11it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 47.35555555555555 / 92  (51.5):  92%|▉| 92/100 [00:31<00:05,  1.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.35555555555555 / 93  (52.0):  92%|▉| 92/100 [00:32<00:05,  1.40it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 48.35555555555555 / 93  (52.0):  93%|▉| 93/100 [00:32<00:04,  1.41it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 49.35555555555555 / 94  (52.5):  93%|▉| 93/100 [00:33<00:04,  1.41it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 49.35555555555555 / 94  (52.5):  94%|▉| 94/100 [00:33<00:04,  1.38it\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Average Metric: 50.35555555555555 / 95  (53.0):  94%|▉| 94/100 [00:34<00:04,  1.38it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.35555555555555 / 95  (53.0):  95%|▉| 95/100 [00:34<00:04,  1.24it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.35555555555555 / 96  (52.5):  95%|▉| 95/100 [00:34<00:04,  1.24it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 50.35555555555555 / 96  (52.5):  96%|▉| 96/100 [00:34<00:02,  1.34it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 51.35555555555555 / 97  (52.9):  96%|▉| 96/100 [00:36<00:02,  1.34it\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 51.35555555555555 / 97  (52.9):  97%|▉| 97/100 [00:36<00:03,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 52.35555555555555 / 98  (53.4):  97%|▉| 97/100 [00:36<00:03,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 53.02222222222221 / 99  (53.6):  98%|▉| 98/100 [00:39<00:02,  1.00s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 53.02222222222221 / 99  (53.6):  99%|▉| 99/100 [00:39<00:01,  1.26s/\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 54.02222222222221 / 100  (54.0):  99%|▉| 99/100 [00:47<00:01,  1.26s\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 54.02222222222221 / 100  (54.0): 100%|█| 100/100 [00:47<00:00,  2.10\u001b[A\u001b[A\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.02222222222221 / 100  (54.0%)\n",
      "Score: 54.02 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02]\n",
      "Best score: 57.96\n",
      "Average of max per entry across top 1 scores: 0.5795555555555556\n",
      "Average of max per entry across top 2 scores: 0.7613333333333334\n",
      "Average of max per entry across top 3 scores: 0.8656666666666666\n",
      "Average of max per entry across top 5 scores: 0.9079999999999999\n",
      "Average of max per entry across top 8 scores: 0.9079999999999999\n",
      "Average of max per entry across top 9999 scores: 0.9079999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<03:08,  1.91s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:03<02:27,  1.51s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:04<02:19,  1.44s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:05<02:09,  1.35s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:06<02:01,  1.28s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:08<01:55,  1.23s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:09<02:01,  1.30s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:10<01:51,  1.21s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:11<01:48,  1.20s/it]\u001b[A\n",
      " 10%|████▌                                         | 10/100 [00:13<02:02,  1.36s/it]\u001b[A\n",
      " 11%|█████                                         | 11/100 [00:15<02:01,  1.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                      | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   1%|▏             | 1/100 [00:01<02:17,  1.39s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   1%|▏             | 1/100 [00:01<02:17,  1.39s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   2%|▎             | 2/100 [00:01<01:02,  1.56it/s]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   2%|▎             | 2/100 [00:01<01:02,  1.56it/s]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   3%|▍             | 3/100 [00:01<00:41,  2.34it/s]\u001b[A\n",
      "Average Metric: 1.75 / 4  (43.8):   3%|▍            | 3/100 [00:01<00:41,  2.34it/s]\u001b[A\n",
      "Average Metric: 1.75 / 4  (43.8):   4%|▌            | 4/100 [00:01<00:29,  3.22it/s]\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 5  (41.7):   4%| | 4/100 [00:02<00:29,  3.22it/\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 5  (41.7):   5%| | 5/100 [00:02<00:33,  2.83it/\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 6  (34.7):   5%| | 5/100 [00:02<00:33,  2.83it/\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 7  (29.8):   6%| | 6/100 [00:02<00:33,  2.83it/\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 7  (29.8):   7%| | 7/100 [00:02<00:21,  4.23it/\u001b[A\n",
      "Average Metric: 3.0833333333333335 / 8  (38.5):   7%| | 7/100 [00:03<00:21,  4.23it/\u001b[A\n",
      "Average Metric: 3.0833333333333335 / 8  (38.5):   8%| | 8/100 [00:03<00:34,  2.68it/\u001b[A\n",
      "Average Metric: 4.083333333333334 / 9  (45.4):   8%| | 8/100 [00:03<00:34,  2.68it/s\u001b[A\n",
      "Average Metric: 4.083333333333334 / 9  (45.4):   9%| | 9/100 [00:03<00:30,  2.95it/s\u001b[A\n",
      "Average Metric: 4.083333333333334 / 10  (40.8):   9%| | 9/100 [00:03<00:30,  2.95it/\u001b[A\n",
      "Average Metric: 4.333333333333334 / 11  (39.4):  10%| | 10/100 [00:04<00:30,  2.95it\u001b[A\n",
      "Average Metric: 4.333333333333334 / 11  (39.4):  11%| | 11/100 [00:04<00:30,  2.87it\u001b[A\n",
      "Average Metric: 5.333333333333334 / 12  (44.4):  11%| | 11/100 [00:04<00:30,  2.87it\u001b[A\n",
      "Average Metric: 5.333333333333334 / 12  (44.4):  12%| | 12/100 [00:04<00:30,  2.86it\u001b[A\n",
      "Average Metric: 6.333333333333334 / 13  (48.7):  12%| | 12/100 [00:04<00:30,  2.86it\u001b[A\n",
      "Average Metric: 6.333333333333334 / 13  (48.7):  13%|▏| 13/100 [00:04<00:25,  3.36it\u001b[A\n",
      "Average Metric: 6.583333333333334 / 14  (47.0):  13%|▏| 13/100 [00:04<00:25,  3.36it\u001b[A\n",
      "Average Metric: 7.583333333333334 / 15  (50.6):  14%|▏| 14/100 [00:05<00:25,  3.36it\u001b[A\n",
      "Average Metric: 7.583333333333334 / 15  (50.6):  15%|▏| 15/100 [00:05<00:22,  3.81it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.183333333333334 / 16  (51.1):  15%|▏| 15/100 [00:05<00:22,  3.81it\u001b[A\n",
      "Average Metric: 8.183333333333334 / 16  (51.1):  16%|▏| 16/100 [00:05<00:26,  3.13it\u001b[A\n",
      "Average Metric: 8.516666666666667 / 17  (50.1):  16%|▏| 16/100 [00:06<00:26,  3.13it\u001b[A\n",
      "Average Metric: 8.516666666666667 / 17  (50.1):  17%|▏| 17/100 [00:06<00:30,  2.69it\u001b[A\n",
      "Average Metric: 8.683333333333334 / 18  (48.2):  17%|▏| 17/100 [00:06<00:30,  2.69it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.683333333333334 / 19  (45.7):  18%|▏| 18/100 [00:06<00:30,  2.69it\u001b[A\n",
      "Average Metric: 8.683333333333334 / 19  (45.7):  19%|▏| 19/100 [00:06<00:25,  3.20it\u001b[A\n",
      "Average Metric: 8.683333333333334 / 20  (43.4):  19%|▏| 19/100 [00:06<00:25,  3.20it\u001b[A\n",
      "Average Metric: 8.683333333333334 / 20  (43.4):  20%|▏| 20/100 [00:06<00:22,  3.55it\u001b[A\n",
      "Average Metric: 8.683333333333334 / 21  (41.3):  20%|▏| 20/100 [00:08<00:22,  3.55it\u001b[A\n",
      "Average Metric: 8.683333333333334 / 21  (41.3):  21%|▏| 21/100 [00:08<00:46,  1.69it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.85 / 22  (40.2):  21%|██▎        | 21/100 [00:08<00:46,  1.69it/s]\u001b[A\n",
      "Average Metric: 8.85 / 22  (40.2):  22%|██▍        | 22/100 [00:08<00:42,  1.84it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.516666666666666 / 23  (41.4):  22%|▏| 22/100 [00:09<00:42,  1.84it\u001b[A\n",
      "Average Metric: 9.516666666666666 / 23  (41.4):  23%|▏| 23/100 [00:09<00:43,  1.79it\u001b[A\n",
      "Average Metric: 10.516666666666666 / 24  (43.8):  23%|▏| 23/100 [00:09<00:43,  1.79i\u001b[A\n",
      "Average Metric: 11.516666666666666 / 25  (46.1):  24%|▏| 24/100 [00:10<00:42,  1.79i\u001b[A\n",
      "Average Metric: 11.516666666666666 / 25  (46.1):  25%|▎| 25/100 [00:10<00:38,  1.95i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.516666666666666 / 26  (48.1):  25%|▎| 25/100 [00:11<00:38,  1.95i\u001b[A\n",
      "Average Metric: 12.516666666666666 / 26  (48.1):  26%|▎| 26/100 [00:11<00:43,  1.72i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.766666666666666 / 27  (47.3):  26%|▎| 26/100 [00:12<00:43,  1.72i\u001b[A\n",
      "Average Metric: 12.766666666666666 / 27  (47.3):  27%|▎| 27/100 [00:12<00:49,  1.47i\u001b[A\n",
      "Average Metric: 12.766666666666666 / 28  (45.6):  27%|▎| 27/100 [00:12<00:49,  1.47i\u001b[A\n",
      "Average Metric: 12.766666666666666 / 28  (45.6):  28%|▎| 28/100 [00:12<00:46,  1.56i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.166666666666666 / 29  (45.4):  28%|▎| 28/100 [00:14<00:46,  1.56i\u001b[A\n",
      "Average Metric: 13.166666666666666 / 29  (45.4):  29%|▎| 29/100 [00:14<01:13,  1.03s\u001b[A\n",
      "Average Metric: 13.916666666666666 / 30  (46.4):  29%|▎| 29/100 [00:14<01:13,  1.03s\u001b[A\n",
      "Average Metric: 13.916666666666666 / 30  (46.4):  30%|▎| 30/100 [00:14<00:54,  1.28i\u001b[A\n",
      "Average Metric: 14.416666666666666 / 31  (46.5):  30%|▎| 30/100 [00:16<00:54,  1.28i\u001b[A\n",
      "Average Metric: 14.416666666666666 / 31  (46.5):  31%|▎| 31/100 [00:16<01:05,  1.06i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.416666666666666 / 32  (45.1):  31%|▎| 31/100 [00:17<01:05,  1.06i\u001b[A\n",
      "Average Metric: 14.416666666666666 / 32  (45.1):  32%|▎| 32/100 [00:17<01:13,  1.08s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.916666666666666 / 33  (45.2):  32%|▎| 32/100 [00:18<01:13,  1.08s\u001b[A\n",
      "Average Metric: 14.916666666666666 / 33  (45.2):  33%|▎| 33/100 [00:18<01:18,  1.17s\u001b[A\n",
      "Average Metric: 15.316666666666666 / 34  (45.0):  33%|▎| 33/100 [00:19<01:18,  1.17s\u001b[A\n",
      "Average Metric: 15.316666666666666 / 34  (45.0):  34%|▎| 34/100 [00:19<00:59,  1.11i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.816666666666666 / 35  (45.2):  34%|▎| 34/100 [00:20<00:59,  1.11i\u001b[A\n",
      "Average Metric: 15.816666666666666 / 35  (45.2):  35%|▎| 35/100 [00:20<01:07,  1.03s\u001b[A\n",
      "Average Metric: 16.316666666666666 / 36  (45.3):  35%|▎| 35/100 [00:21<01:07,  1.03s\u001b[A\n",
      "Average Metric: 16.316666666666666 / 36  (45.3):  36%|▎| 36/100 [00:21<01:04,  1.01s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.316666666666666 / 37  (44.1):  36%|▎| 36/100 [00:22<01:04,  1.01s\u001b[A\n",
      "Average Metric: 16.316666666666666 / 37  (44.1):  37%|▎| 37/100 [00:22<01:01,  1.03i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.65 / 38  (43.8):  37%|███▋      | 37/100 [00:23<01:01,  1.03it/s]\u001b[A\n",
      "Average Metric: 16.65 / 38  (43.8):  38%|███▊      | 38/100 [00:23<01:01,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.65 / 39  (42.7):  38%|███▊      | 38/100 [00:25<01:01,  1.01it/s]\u001b[A\n",
      "Average Metric: 16.65 / 39  (42.7):  39%|███▉      | 39/100 [00:25<01:23,  1.37s/it]\u001b[A\n",
      "Average Metric: 17.65 / 40  (44.1):  39%|███▉      | 39/100 [00:25<01:23,  1.37s/it]\u001b[A\n",
      "Average Metric: 17.65 / 40  (44.1):  40%|████      | 40/100 [00:25<01:00,  1.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.15 / 41  (44.3):  40%|████      | 40/100 [00:27<01:00,  1.00s/it]\u001b[A\n",
      "Average Metric: 18.15 / 41  (44.3):  41%|████      | 41/100 [00:27<01:12,  1.24s/it]\u001b[A\n",
      "Average Metric: 19.15 / 42  (45.6):  41%|████      | 41/100 [00:27<01:12,  1.24s/it]\u001b[A\n",
      "Average Metric: 19.15 / 42  (45.6):  42%|████▏     | 42/100 [00:27<00:57,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.15 / 43  (46.9):  42%|████▏     | 42/100 [00:29<00:57,  1.01it/s]\u001b[A\n",
      "Average Metric: 20.15 / 43  (46.9):  43%|████▎     | 43/100 [00:29<01:00,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.15 / 44  (45.8):  43%|████▎     | 43/100 [00:29<01:00,  1.06s/it]\u001b[A\n",
      "Average Metric: 20.15 / 44  (45.8):  44%|████▍     | 44/100 [00:29<00:44,  1.25it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.65 / 45  (45.9):  44%|████▍     | 44/100 [00:31<00:44,  1.25it/s]\u001b[A\n",
      "Average Metric: 20.65 / 45  (45.9):  45%|████▌     | 45/100 [00:31<01:03,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.65 / 46  (47.1):  45%|████▌     | 45/100 [00:32<01:03,  1.16s/it]\u001b[A\n",
      "Average Metric: 21.65 / 46  (47.1):  46%|████▌     | 46/100 [00:32<01:06,  1.24s/it]\u001b[A\n",
      "Average Metric: 22.65 / 47  (48.2):  46%|████▌     | 46/100 [00:34<01:06,  1.24s/it]\u001b[A\n",
      "Average Metric: 22.65 / 47  (48.2):  47%|████▋     | 47/100 [00:34<01:05,  1.23s/it]\u001b[A\n",
      "Average Metric: 22.65 / 48  (47.2):  47%|████▋     | 47/100 [00:34<01:05,  1.23s/it]\u001b[A\n",
      "Average Metric: 22.65 / 48  (47.2):  48%|████▊     | 48/100 [00:34<00:47,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 27.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.65 / 49  (48.3):  48%|████▊     | 48/100 [00:35<00:47,  1.09it/s]\u001b[A\n",
      "Average Metric: 23.65 / 49  (48.3):  49%|████▉     | 49/100 [00:35<00:50,  1.00it/s]\u001b[A\n",
      "Average Metric: 24.65 / 50  (49.3):  49%|████▉     | 49/100 [00:36<00:50,  1.00it/s]\u001b[A\n",
      "Average Metric: 24.65 / 50  (49.3):  50%|█████     | 50/100 [00:36<00:51,  1.04s/it]\u001b[A\n",
      "Average Metric: 25.65 / 51  (50.3):  50%|█████     | 50/100 [00:36<00:51,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.98333333333333 / 52  (50.0):  51%|▌| 51/100 [00:38<00:50,  1.04s/\u001b[A\n",
      "Average Metric: 25.98333333333333 / 52  (50.0):  52%|▌| 52/100 [00:38<00:44,  1.07it\u001b[A\n",
      "Average Metric: 26.48333333333333 / 53  (50.0):  52%|▌| 52/100 [00:38<00:44,  1.07it\u001b[A\n",
      "Average Metric: 26.48333333333333 / 53  (50.0):  53%|▌| 53/100 [00:38<00:40,  1.16it\u001b[A\n",
      "Average Metric: 26.816666666666663 / 54  (49.7):  53%|▌| 53/100 [00:39<00:40,  1.16i\u001b[A\n",
      "Average Metric: 26.816666666666663 / 54  (49.7):  54%|▌| 54/100 [00:39<00:42,  1.07i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.816666666666663 / 55  (48.8):  54%|▌| 54/100 [00:41<00:42,  1.07i\u001b[A\n",
      "Average Metric: 26.816666666666663 / 55  (48.8):  55%|▌| 55/100 [00:41<00:47,  1.06s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.816666666666663 / 56  (49.7):  55%|▌| 55/100 [00:42<00:47,  1.06s\u001b[A\n",
      "Average Metric: 27.816666666666663 / 56  (49.7):  56%|▌| 56/100 [00:42<00:47,  1.08s\u001b[A\n",
      "Average Metric: 27.816666666666663 / 57  (48.8):  56%|▌| 56/100 [00:42<00:47,  1.08s\u001b[A\n",
      "Average Metric: 27.816666666666663 / 57  (48.8):  57%|▌| 57/100 [00:42<00:34,  1.24i\u001b[A\n",
      "Average Metric: 28.816666666666663 / 58  (49.7):  57%|▌| 57/100 [00:43<00:34,  1.24i\u001b[A\n",
      "Average Metric: 28.816666666666663 / 58  (49.7):  58%|▌| 58/100 [00:43<00:36,  1.16i\u001b[A\n",
      "Average Metric: 28.816666666666663 / 59  (48.8):  58%|▌| 58/100 [00:43<00:36,  1.16i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 28.816666666666663 / 59  (48.8):  59%|▌| 59/100 [00:43<00:28,  1.43i\u001b[A\n",
      "Average Metric: 29.816666666666663 / 60  (49.7):  59%|▌| 59/100 [00:44<00:28,  1.43i\u001b[A\n",
      "Average Metric: 29.816666666666663 / 60  (49.7):  60%|▌| 60/100 [00:44<00:29,  1.36i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.816666666666663 / 61  (50.5):  60%|▌| 60/100 [00:45<00:29,  1.36i\u001b[A\n",
      "Average Metric: 30.816666666666663 / 61  (50.5):  61%|▌| 61/100 [00:45<00:34,  1.11i\u001b[A\n",
      "Average Metric: 31.149999999999995 / 62  (50.2):  61%|▌| 61/100 [00:46<00:34,  1.11i\u001b[A\n",
      "Average Metric: 31.149999999999995 / 62  (50.2):  62%|▌| 62/100 [00:46<00:28,  1.35i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 24.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.649999999999995 / 63  (50.2):  62%|▌| 62/100 [00:47<00:28,  1.35i\u001b[A\n",
      "Average Metric: 31.649999999999995 / 63  (50.2):  63%|▋| 63/100 [00:47<00:35,  1.05i\u001b[A\n",
      "Average Metric: 31.899999999999995 / 64  (49.8):  63%|▋| 63/100 [00:48<00:35,  1.05i\u001b[A\n",
      "Average Metric: 31.899999999999995 / 64  (49.8):  64%|▋| 64/100 [00:48<00:35,  1.01i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.89999999999999 / 65  (50.6):  64%|▋| 64/100 [00:52<00:35,  1.01it\u001b[A\n",
      "Average Metric: 32.89999999999999 / 65  (50.6):  65%|▋| 65/100 [00:52<00:57,  1.65s/\u001b[A\n",
      "Average Metric: 33.23333333333333 / 66  (50.4):  65%|▋| 65/100 [00:52<00:57,  1.65s/\u001b[A\n",
      "Average Metric: 33.23333333333333 / 66  (50.4):  66%|▋| 66/100 [00:52<00:43,  1.29s/\u001b[A\n",
      "Average Metric: 34.23333333333333 / 67  (51.1):  66%|▋| 66/100 [00:53<00:43,  1.29s/\u001b[A\n",
      "Average Metric: 34.23333333333333 / 67  (51.1):  67%|▋| 67/100 [00:53<00:39,  1.21s/\u001b[A\n",
      "Average Metric: 34.633333333333326 / 68  (50.9):  67%|▋| 67/100 [00:53<00:39,  1.21s\u001b[A\n",
      "Average Metric: 35.133333333333326 / 69  (50.9):  68%|▋| 68/100 [00:54<00:38,  1.21s\u001b[A\n",
      "Average Metric: 35.133333333333326 / 69  (50.9):  69%|▋| 69/100 [00:54<00:25,  1.20i\u001b[A\n",
      "Average Metric: 36.133333333333326 / 70  (51.6):  69%|▋| 69/100 [00:54<00:25,  1.20i\u001b[A\n",
      "Average Metric: 36.133333333333326 / 70  (51.6):  70%|▋| 70/100 [00:54<00:19,  1.50i\u001b[A\n",
      "Average Metric: 37.133333333333326 / 71  (52.3):  70%|▋| 70/100 [00:55<00:19,  1.50i\u001b[A\n",
      "Average Metric: 37.133333333333326 / 71  (52.3):  71%|▋| 71/100 [00:55<00:23,  1.22i\u001b[A\n",
      "Average Metric: 37.46666666666666 / 72  (52.0):  71%|▋| 71/100 [00:55<00:23,  1.22it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.46666666666666 / 73  (52.7):  72%|▋| 72/100 [00:56<00:23,  1.22it\u001b[A\n",
      "Average Metric: 38.46666666666666 / 73  (52.7):  73%|▋| 73/100 [00:56<00:18,  1.49it\u001b[A\n",
      "Average Metric: 39.46666666666666 / 74  (53.3):  73%|▋| 73/100 [00:57<00:18,  1.49it\u001b[A\n",
      "Average Metric: 39.46666666666666 / 74  (53.3):  74%|▋| 74/100 [00:57<00:16,  1.61it\u001b[A\n",
      "Average Metric: 39.8 / 75  (53.1):  74%|████████▏  | 74/100 [00:58<00:16,  1.61it/s]\u001b[A\n",
      "Average Metric: 39.8 / 75  (53.1):  75%|████████▎  | 75/100 [00:58<00:19,  1.30it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.8 / 76  (52.4):  75%|████████▎  | 75/100 [00:59<00:19,  1.30it/s]\u001b[A\n",
      "Average Metric: 39.8 / 76  (52.4):  76%|████████▎  | 76/100 [00:59<00:19,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.13333333333333 / 77  (52.1):  76%|▊| 76/100 [01:00<00:19,  1.23it\u001b[A\n",
      "Average Metric: 40.13333333333333 / 77  (52.1):  77%|▊| 77/100 [01:00<00:23,  1.00s/\u001b[A\n",
      "Average Metric: 41.13333333333333 / 78  (52.7):  77%|▊| 77/100 [01:00<00:23,  1.00s/\u001b[A\n",
      "Average Metric: 42.13333333333333 / 79  (53.3):  78%|▊| 78/100 [01:02<00:22,  1.00s/\u001b[A\n",
      "Average Metric: 42.13333333333333 / 79  (53.3):  79%|▊| 79/100 [01:02<00:20,  1.03it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.13333333333333 / 80  (53.9):  79%|▊| 79/100 [01:03<00:20,  1.03it\u001b[A\n",
      "Average Metric: 43.13333333333333 / 80  (53.9):  80%|▊| 80/100 [01:03<00:20,  1.02s/\u001b[A\n",
      "Average Metric: 43.355555555555554 / 81  (53.5):  80%|▊| 80/100 [01:03<00:20,  1.02s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 10.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.355555555555554 / 82  (54.1):  81%|▊| 81/100 [01:05<00:19,  1.02s\u001b[A\n",
      "Average Metric: 44.355555555555554 / 82  (54.1):  82%|▊| 82/100 [01:05<00:15,  1.17i\u001b[A\n",
      "Average Metric: 44.355555555555554 / 83  (53.4):  82%|▊| 82/100 [01:06<00:15,  1.17i\u001b[A\n",
      "Average Metric: 44.355555555555554 / 83  (53.4):  83%|▊| 83/100 [01:06<00:15,  1.07i\u001b[A\n",
      "Average Metric: 45.355555555555554 / 84  (54.0):  83%|▊| 83/100 [01:06<00:15,  1.07i\u001b[A\n",
      "Average Metric: 45.355555555555554 / 84  (54.0):  84%|▊| 84/100 [01:06<00:11,  1.34i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.605555555555554 / 85  (53.7):  84%|▊| 84/100 [01:07<00:11,  1.34i\u001b[A\n",
      "Average Metric: 45.605555555555554 / 85  (53.7):  85%|▊| 85/100 [01:07<00:14,  1.07i\u001b[A\n",
      "Average Metric: 46.605555555555554 / 86  (54.2):  85%|▊| 85/100 [01:08<00:14,  1.07i\u001b[A\n",
      "Average Metric: 46.605555555555554 / 86  (54.2):  86%|▊| 86/100 [01:08<00:10,  1.28i\u001b[A\n",
      "Average Metric: 47.605555555555554 / 87  (54.7):  86%|▊| 86/100 [01:08<00:10,  1.28i\u001b[A\n",
      "Average Metric: 47.605555555555554 / 87  (54.7):  87%|▊| 87/100 [01:08<00:09,  1.36i\u001b[A\n",
      "Average Metric: 48.605555555555554 / 88  (55.2):  87%|▊| 87/100 [01:09<00:09,  1.36i\u001b[A\n",
      "Average Metric: 48.605555555555554 / 88  (55.2):  88%|▉| 88/100 [01:09<00:08,  1.38i\u001b[A\n",
      "Average Metric: 49.605555555555554 / 89  (55.7):  88%|▉| 88/100 [01:10<00:08,  1.38i\u001b[A\n",
      "Average Metric: 49.605555555555554 / 89  (55.7):  89%|▉| 89/100 [01:10<00:07,  1.42i\u001b[A\n",
      "Average Metric: 50.105555555555554 / 90  (55.7):  89%|▉| 89/100 [01:11<00:07,  1.42i\u001b[A\n",
      "Average Metric: 50.105555555555554 / 90  (55.7):  90%|▉| 90/100 [01:11<00:07,  1.35i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.105555555555554 / 91  (56.2):  90%|▉| 90/100 [01:12<00:07,  1.35i\u001b[A\n",
      "Average Metric: 51.105555555555554 / 91  (56.2):  91%|▉| 91/100 [01:12<00:07,  1.17i\u001b[A\n",
      "Average Metric: 52.105555555555554 / 92  (56.6):  91%|▉| 91/100 [01:12<00:07,  1.17i\u001b[A\n",
      "Average Metric: 52.105555555555554 / 92  (56.6):  92%|▉| 92/100 [01:12<00:05,  1.37i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 28.8 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.605555555555554 / 93  (56.6):  92%|▉| 92/100 [01:13<00:05,  1.37i\u001b[A\n",
      "Average Metric: 52.605555555555554 / 93  (56.6):  93%|▉| 93/100 [01:13<00:05,  1.25i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 53.605555555555554 / 94  (57.0):  93%|▉| 93/100 [01:14<00:05,  1.25i\u001b[A\n",
      "Average Metric: 53.605555555555554 / 94  (57.0):  94%|▉| 94/100 [01:14<00:05,  1.05i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 75.3 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 53.605555555555554 / 95  (56.4):  94%|▉| 94/100 [01:16<00:05,  1.05i\u001b[A\n",
      "Average Metric: 53.605555555555554 / 95  (56.4):  95%|▉| 95/100 [01:16<00:06,  1.21s\u001b[A\n",
      "Average Metric: 53.93888888888889 / 96  (56.2):  95%|▉| 95/100 [01:17<00:06,  1.21s/\u001b[A\n",
      "Average Metric: 53.93888888888889 / 96  (56.2):  96%|▉| 96/100 [01:17<00:04,  1.13s/\u001b[A\n",
      "Average Metric: 54.43888888888889 / 97  (56.1):  96%|▉| 96/100 [01:19<00:04,  1.13s/\u001b[A\n",
      "Average Metric: 54.43888888888889 / 97  (56.1):  97%|▉| 97/100 [01:19<00:04,  1.36s/\u001b[A\n",
      "Average Metric: 55.43888888888889 / 98  (56.6):  97%|▉| 97/100 [01:19<00:04,  1.36s/\u001b[A\n",
      "Average Metric: 56.105555555555554 / 99  (56.7):  98%|▉| 98/100 [01:43<00:02,  1.36s\u001b[A\n",
      "Average Metric: 56.105555555555554 / 99  (56.7):  99%|▉| 99/100 [01:43<00:06,  6.28s\u001b[A\n",
      "Average Metric: 56.30555555555556 / 100  (56.3):  99%|▉| 99/100 [02:34<00:06,  6.28s\u001b[A\n",
      "Average Metric: 56.30555555555556 / 100  (56.3): 100%|█| 100/100 [02:34<00:00,  1.54\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.30555555555556 / 100  (56.3%)\n",
      "Score: 56.31 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31]\n",
      "Best score: 57.96\n",
      "Average of max per entry across top 1 scores: 0.5795555555555556\n",
      "Average of max per entry across top 2 scores: 0.7615000000000002\n",
      "Average of max per entry across top 3 scores: 0.8596666666666668\n",
      "Average of max per entry across top 5 scores: 0.9363333333333334\n",
      "Average of max per entry across top 8 scores: 0.9388333333333334\n",
      "Average of max per entry across top 9999 scores: 0.9388333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:02<04:21,  2.64s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:04<03:12,  1.97s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:06<03:09,  1.95s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:07<02:58,  1.86s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:09<02:44,  1.73s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:10<02:37,  1.67s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:12<02:35,  1.67s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:14<02:35,  1.69s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:16<02:45,  1.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                      | 0/100 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   1%|▏             | 1/100 [00:02<03:31,  2.14s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   1%|▏             | 1/100 [00:02<03:31,  2.14s/it]\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   2%| | 2/100 [00:02<03:29,  2.14s/i\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):   3%| | 3/100 [00:02<03:27,  2.14s/i\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):   4%| | 4/100 [00:02<00:51,  1.88it/\u001b[A\n",
      "Average Metric: 2.833333333333333 / 5  (56.7):   4%| | 4/100 [00:02<00:51,  1.88it/s\u001b[A\n",
      "Average Metric: 2.833333333333333 / 5  (56.7):   5%| | 5/100 [00:02<00:46,  2.03it/s\u001b[A\n",
      "Average Metric: 3.833333333333333 / 6  (63.9):   5%| | 5/100 [00:03<00:46,  2.03it/s\u001b[A\n",
      "Average Metric: 3.833333333333333 / 6  (63.9):   6%| | 6/100 [00:03<00:41,  2.29it/s\u001b[A\n",
      "Average Metric: 4.833333333333333 / 7  (69.0):   6%| | 6/100 [00:04<00:41,  2.29it/s\u001b[A\n",
      "Average Metric: 4.833333333333333 / 7  (69.0):   7%| | 7/100 [00:04<00:48,  1.94it/s\u001b[A\n",
      "Average Metric: 4.833333333333333 / 8  (60.4):   7%| | 7/100 [00:04<00:48,  1.94it/s\u001b[A\n",
      "Average Metric: 4.833333333333333 / 8  (60.4):   8%| | 8/100 [00:04<00:48,  1.88it/s\u001b[A\n",
      "Average Metric: 5.1060606060606055 / 9  (56.7):   8%| | 8/100 [00:04<00:48,  1.88it/\u001b[A\n",
      "Average Metric: 5.1060606060606055 / 9  (56.7):   9%| | 9/100 [00:04<00:37,  2.45it/\u001b[A\n",
      "Average Metric: 5.1060606060606055 / 10  (51.1):   9%| | 9/100 [00:05<00:37,  2.45it\u001b[A\n",
      "Average Metric: 5.1060606060606055 / 10  (51.1):  10%| | 10/100 [00:05<00:35,  2.53i\u001b[A\n",
      "Average Metric: 5.1060606060606055 / 11  (46.4):  10%| | 10/100 [00:05<00:35,  2.53i\u001b[A\n",
      "Average Metric: 5.1060606060606055 / 11  (46.4):  11%| | 11/100 [00:05<00:45,  1.98i\u001b[A\n",
      "Average Metric: 5.439393939393939 / 12  (45.3):  11%| | 11/100 [00:06<00:45,  1.98it\u001b[A\n",
      "Average Metric: 5.439393939393939 / 12  (45.3):  12%| | 12/100 [00:06<00:38,  2.27it\u001b[A\n",
      "Average Metric: 5.689393939393939 / 13  (43.8):  12%| | 12/100 [00:06<00:38,  2.27it\u001b[A\n",
      "Average Metric: 5.689393939393939 / 13  (43.8):  13%|▏| 13/100 [00:06<00:33,  2.57it\u001b[A\n",
      "Average Metric: 6.689393939393939 / 14  (47.8):  13%|▏| 13/100 [00:06<00:33,  2.57it\u001b[A\n",
      "Average Metric: 6.689393939393939 / 14  (47.8):  14%|▏| 14/100 [00:06<00:35,  2.45it\u001b[A\n",
      "Average Metric: 7.439393939393939 / 15  (49.6):  14%|▏| 14/100 [00:07<00:35,  2.45it\u001b[A\n",
      "Average Metric: 7.439393939393939 / 15  (49.6):  15%|▏| 15/100 [00:07<00:42,  2.01it\u001b[A\n",
      "Average Metric: 8.439393939393938 / 16  (52.7):  15%|▏| 15/100 [00:08<00:42,  2.01it\u001b[A\n",
      "Average Metric: 8.439393939393938 / 16  (52.7):  16%|▏| 16/100 [00:08<00:43,  1.93it\u001b[A\n",
      "Average Metric: 8.439393939393938 / 17  (49.6):  16%|▏| 16/100 [00:08<00:43,  1.93it\u001b[A\n",
      "Average Metric: 8.939393939393938 / 18  (49.7):  17%|▏| 17/100 [00:08<00:42,  1.93it\u001b[A\n",
      "Average Metric: 8.939393939393938 / 18  (49.7):  18%|▏| 18/100 [00:08<00:31,  2.57it\u001b[A\n",
      "Average Metric: 9.272727272727272 / 19  (48.8):  18%|▏| 18/100 [00:08<00:31,  2.57it\u001b[A\n",
      "Average Metric: 9.439393939393938 / 20  (47.2):  19%|▏| 19/100 [00:08<00:31,  2.57it\u001b[A\n",
      "Average Metric: 9.439393939393938 / 20  (47.2):  20%|▏| 20/100 [00:08<00:23,  3.41it\u001b[A\n",
      "Average Metric: 9.639393939393937 / 21  (45.9):  20%|▏| 20/100 [00:09<00:23,  3.41it\u001b[A\n",
      "Average Metric: 9.639393939393937 / 21  (45.9):  21%|▏| 21/100 [00:09<00:20,  3.79it\u001b[A\n",
      "Average Metric: 9.639393939393937 / 22  (43.8):  21%|▏| 21/100 [00:09<00:20,  3.79it\u001b[A\n",
      "Average Metric: 9.639393939393937 / 22  (43.8):  22%|▏| 22/100 [00:09<00:31,  2.45it\u001b[A\n",
      "Average Metric: 10.639393939393937 / 23  (46.3):  22%|▏| 22/100 [00:10<00:31,  2.45i\u001b[A\n",
      "Average Metric: 10.639393939393937 / 23  (46.3):  23%|▏| 23/100 [00:10<00:31,  2.48i\u001b[A\n",
      "Average Metric: 11.639393939393937 / 24  (48.5):  23%|▏| 23/100 [00:10<00:31,  2.48i\u001b[A\n",
      "Average Metric: 11.639393939393937 / 24  (48.5):  24%|▏| 24/100 [00:10<00:27,  2.76i\u001b[A\n",
      "Average Metric: 12.139393939393937 / 25  (48.6):  24%|▏| 24/100 [00:11<00:27,  2.76i\u001b[A\n",
      "Average Metric: 12.139393939393937 / 25  (48.6):  25%|▎| 25/100 [00:11<00:29,  2.56i\u001b[A\n",
      "Average Metric: 12.139393939393937 / 26  (46.7):  25%|▎| 25/100 [00:11<00:29,  2.56i\u001b[A\n",
      "Average Metric: 13.139393939393937 / 27  (48.7):  26%|▎| 26/100 [00:11<00:28,  2.56i\u001b[A\n",
      "Average Metric: 13.139393939393937 / 27  (48.7):  27%|▎| 27/100 [00:11<00:28,  2.56i\u001b[A\n",
      "Average Metric: 14.139393939393937 / 28  (50.5):  27%|▎| 27/100 [00:11<00:28,  2.56i\u001b[A\n",
      "Average Metric: 14.250505050505048 / 29  (49.1):  28%|▎| 28/100 [00:11<00:28,  2.56i\u001b[A\n",
      "Average Metric: 14.250505050505048 / 29  (49.1):  29%|▎| 29/100 [00:11<00:18,  3.78i\u001b[A\n",
      "Average Metric: 15.250505050505048 / 30  (50.8):  29%|▎| 29/100 [00:12<00:18,  3.78i\u001b[A\n",
      "Average Metric: 15.250505050505048 / 30  (50.8):  30%|▎| 30/100 [00:12<00:30,  2.33i\u001b[A\n",
      "Average Metric: 16.250505050505048 / 31  (52.4):  30%|▎| 30/100 [00:13<00:30,  2.33i\u001b[A\n",
      "Average Metric: 16.250505050505048 / 31  (52.4):  31%|▎| 31/100 [00:13<00:26,  2.65i\u001b[A\n",
      "Average Metric: 16.750505050505048 / 32  (52.3):  31%|▎| 31/100 [00:13<00:26,  2.65i\u001b[A\n",
      "Average Metric: 17.750505050505048 / 33  (53.8):  32%|▎| 32/100 [00:13<00:25,  2.65i\u001b[A\n",
      "Average Metric: 17.750505050505048 / 33  (53.8):  33%|▎| 33/100 [00:13<00:18,  3.57i\u001b[A\n",
      "Average Metric: 17.750505050505048 / 34  (52.2):  33%|▎| 33/100 [00:14<00:18,  3.57i\u001b[A\n",
      "Average Metric: 17.750505050505048 / 34  (52.2):  34%|▎| 34/100 [00:14<00:27,  2.42i\u001b[A\n",
      "Average Metric: 18.150505050505046 / 35  (51.9):  34%|▎| 34/100 [00:14<00:27,  2.42i\u001b[A\n",
      "Average Metric: 18.150505050505046 / 35  (51.9):  35%|▎| 35/100 [00:14<00:27,  2.37i\u001b[A\n",
      "Average Metric: 18.817171717171714 / 36  (52.3):  35%|▎| 35/100 [00:15<00:27,  2.37i\u001b[A\n",
      "Average Metric: 18.817171717171714 / 36  (52.3):  36%|▎| 36/100 [00:15<00:27,  2.34i\u001b[A\n",
      "Average Metric: 18.817171717171714 / 37  (50.9):  36%|▎| 36/100 [00:15<00:27,  2.34i\u001b[A\n",
      "Average Metric: 18.817171717171714 / 37  (50.9):  37%|▎| 37/100 [00:15<00:25,  2.44i\u001b[A\n",
      "Average Metric: 19.483838383838382 / 38  (51.3):  37%|▎| 37/100 [00:15<00:25,  2.44i\u001b[A\n",
      "Average Metric: 19.483838383838382 / 38  (51.3):  38%|▍| 38/100 [00:15<00:24,  2.54i\u001b[A\n",
      "Average Metric: 19.983838383838382 / 39  (51.2):  38%|▍| 38/100 [00:16<00:24,  2.54i\u001b[A\n",
      "Average Metric: 19.983838383838382 / 39  (51.2):  39%|▍| 39/100 [00:16<00:21,  2.79i\u001b[A\n",
      "Average Metric: 20.317171717171714 / 40  (50.8):  39%|▍| 39/100 [00:16<00:21,  2.79i\u001b[A\n",
      "Average Metric: 20.317171717171714 / 40  (50.8):  40%|▍| 40/100 [00:16<00:22,  2.70i\u001b[A\n",
      "Average Metric: 20.817171717171714 / 41  (50.8):  40%|▍| 40/100 [00:16<00:22,  2.70i\u001b[A\n",
      "Average Metric: 20.817171717171714 / 41  (50.8):  41%|▍| 41/100 [00:16<00:18,  3.14i\u001b[A\n",
      "Average Metric: 21.817171717171714 / 42  (51.9):  41%|▍| 41/100 [00:17<00:18,  3.14i\u001b[A\n",
      "Average Metric: 21.817171717171714 / 42  (51.9):  42%|▍| 42/100 [00:17<00:27,  2.11i\u001b[A\n",
      "Average Metric: 22.817171717171714 / 43  (53.1):  42%|▍| 42/100 [00:17<00:27,  2.11i\u001b[A\n",
      "Average Metric: 23.817171717171714 / 44  (54.1):  43%|▍| 43/100 [00:17<00:26,  2.11i\u001b[A\n",
      "Average Metric: 23.817171717171714 / 45  (52.9):  44%|▍| 44/100 [00:17<00:26,  2.11i\u001b[A\n",
      "Average Metric: 23.817171717171714 / 45  (52.9):  45%|▍| 45/100 [00:17<00:12,  4.26i\u001b[A\n",
      "Average Metric: 23.817171717171714 / 46  (51.8):  45%|▍| 45/100 [00:18<00:12,  4.26i\u001b[A\n",
      "Average Metric: 23.817171717171714 / 46  (51.8):  46%|▍| 46/100 [00:18<00:16,  3.24i\u001b[A\n",
      "Average Metric: 24.817171717171714 / 47  (52.8):  46%|▍| 46/100 [00:19<00:16,  3.24i\u001b[A\n",
      "Average Metric: 24.817171717171714 / 47  (52.8):  47%|▍| 47/100 [00:19<00:21,  2.50i\u001b[A\n",
      "Average Metric: 25.817171717171714 / 48  (53.8):  47%|▍| 47/100 [00:19<00:21,  2.50i\u001b[A\n",
      "Average Metric: 25.817171717171714 / 48  (53.8):  48%|▍| 48/100 [00:19<00:17,  2.94i\u001b[A\n",
      "Average Metric: 26.317171717171714 / 49  (53.7):  48%|▍| 48/100 [00:19<00:17,  2.94i\u001b[A\n",
      "Average Metric: 26.317171717171714 / 49  (53.7):  49%|▍| 49/100 [00:19<00:16,  3.04i\u001b[A\n",
      "Average Metric: 27.317171717171714 / 50  (54.6):  49%|▍| 49/100 [00:19<00:16,  3.04i\u001b[A\n",
      "Average Metric: 27.317171717171714 / 51  (53.6):  50%|▌| 50/100 [00:19<00:16,  3.04i\u001b[A\n",
      "Average Metric: 27.317171717171714 / 51  (53.6):  51%|▌| 51/100 [00:19<00:13,  3.60i\u001b[A\n",
      "Average Metric: 28.317171717171714 / 52  (54.5):  51%|▌| 51/100 [00:20<00:13,  3.60i\u001b[A\n",
      "Average Metric: 28.317171717171714 / 52  (54.5):  52%|▌| 52/100 [00:20<00:13,  3.53i\u001b[A\n",
      "Average Metric: 29.317171717171714 / 53  (55.3):  52%|▌| 52/100 [00:20<00:13,  3.53i\u001b[A\n",
      "Average Metric: 29.317171717171714 / 53  (55.3):  53%|▌| 53/100 [00:20<00:17,  2.63i\u001b[A\n",
      "Average Metric: 30.317171717171714 / 54  (56.1):  53%|▌| 53/100 [00:21<00:17,  2.63i\u001b[A\n",
      "Average Metric: 30.317171717171714 / 54  (56.1):  54%|▌| 54/100 [00:21<00:14,  3.15i\u001b[A\n",
      "Average Metric: 30.817171717171714 / 55  (56.0):  54%|▌| 54/100 [00:21<00:14,  3.15i\u001b[A\n",
      "Average Metric: 31.317171717171714 / 56  (55.9):  55%|▌| 55/100 [00:22<00:14,  3.15i\u001b[A\n",
      "Average Metric: 31.317171717171714 / 56  (55.9):  56%|▌| 56/100 [00:22<00:18,  2.36i\u001b[A\n",
      "Average Metric: 32.31717171717172 / 57  (56.7):  56%|▌| 56/100 [00:22<00:18,  2.36it\u001b[A\n",
      "Average Metric: 32.31717171717172 / 57  (56.7):  57%|▌| 57/100 [00:22<00:15,  2.81it\u001b[A\n",
      "Average Metric: 33.31717171717172 / 58  (57.4):  57%|▌| 57/100 [00:22<00:15,  2.81it\u001b[A\n",
      "Average Metric: 33.31717171717172 / 58  (57.4):  58%|▌| 58/100 [00:22<00:13,  3.21it\u001b[A\n",
      "Average Metric: 33.31717171717172 / 59  (56.5):  58%|▌| 58/100 [00:22<00:13,  3.21it\u001b[A\n",
      "Average Metric: 33.31717171717172 / 60  (55.5):  59%|▌| 59/100 [00:22<00:12,  3.21it\u001b[A\n",
      "Average Metric: 33.31717171717172 / 60  (55.5):  60%|▌| 60/100 [00:22<00:08,  4.79it\u001b[A\n",
      "Average Metric: 33.31717171717172 / 61  (54.6):  60%|▌| 60/100 [00:23<00:08,  4.79it\u001b[A\n",
      "Average Metric: 33.31717171717172 / 61  (54.6):  61%|▌| 61/100 [00:23<00:13,  2.98it\u001b[A\n",
      "Average Metric: 34.31717171717172 / 62  (55.4):  61%|▌| 61/100 [00:23<00:13,  2.98it\u001b[A\n",
      "Average Metric: 34.31717171717172 / 62  (55.4):  62%|▌| 62/100 [00:23<00:13,  2.84it\u001b[A\n",
      "Average Metric: 34.81717171717172 / 63  (55.3):  62%|▌| 62/100 [00:23<00:13,  2.84it\u001b[A\n",
      "Average Metric: 34.81717171717172 / 64  (54.4):  63%|▋| 63/100 [00:24<00:13,  2.84it\u001b[A\n",
      "Average Metric: 34.81717171717172 / 64  (54.4):  64%|▋| 64/100 [00:24<00:11,  3.17it\u001b[A\n",
      "Average Metric: 35.31717171717172 / 65  (54.3):  64%|▋| 64/100 [00:24<00:11,  3.17it\u001b[A\n",
      "Average Metric: 35.31717171717172 / 65  (54.3):  65%|▋| 65/100 [00:24<00:09,  3.55it\u001b[A\n",
      "Average Metric: 36.31717171717172 / 66  (55.0):  65%|▋| 65/100 [00:25<00:09,  3.55it\u001b[A\n",
      "Average Metric: 36.31717171717172 / 66  (55.0):  66%|▋| 66/100 [00:25<00:12,  2.64it\u001b[A\n",
      "Average Metric: 37.31717171717172 / 67  (55.7):  66%|▋| 66/100 [00:25<00:12,  2.64it\u001b[A\n",
      "Average Metric: 37.31717171717172 / 67  (55.7):  67%|▋| 67/100 [00:25<00:11,  2.88it\u001b[A\n",
      "Average Metric: 37.81717171717172 / 68  (55.6):  67%|▋| 67/100 [00:25<00:11,  2.88it\u001b[A\n",
      "Average Metric: 37.81717171717172 / 68  (55.6):  68%|▋| 68/100 [00:25<00:09,  3.20it\u001b[A\n",
      "Average Metric: 37.81717171717172 / 69  (54.8):  68%|▋| 68/100 [00:26<00:09,  3.20it\u001b[A\n",
      "Average Metric: 37.81717171717172 / 69  (54.8):  69%|▋| 69/100 [00:26<00:10,  2.84it\u001b[A\n",
      "Average Metric: 38.56717171717172 / 70  (55.1):  69%|▋| 69/100 [00:27<00:10,  2.84it\u001b[A\n",
      "Average Metric: 38.56717171717172 / 70  (55.1):  70%|▋| 70/100 [00:27<00:15,  1.92it\u001b[A\n",
      "Average Metric: 39.56717171717172 / 71  (55.7):  70%|▋| 70/100 [00:27<00:15,  1.92it\u001b[A\n",
      "Average Metric: 40.56717171717172 / 72  (56.3):  71%|▋| 71/100 [00:27<00:15,  1.92it\u001b[A\n",
      "Average Metric: 41.06717171717172 / 73  (56.3):  72%|▋| 72/100 [00:27<00:14,  1.92it\u001b[A\n",
      "Average Metric: 41.06717171717172 / 73  (56.3):  73%|▋| 73/100 [00:27<00:08,  3.25it\u001b[A\n",
      "Average Metric: 41.40050505050505 / 74  (55.9):  73%|▋| 73/100 [00:27<00:08,  3.25it\u001b[A\n",
      "Average Metric: 41.40050505050505 / 74  (55.9):  74%|▋| 74/100 [00:27<00:08,  3.03it\u001b[A\n",
      "Average Metric: 42.40050505050505 / 75  (56.5):  74%|▋| 74/100 [00:27<00:08,  3.03it\u001b[A\n",
      "Average Metric: 43.40050505050505 / 76  (57.1):  75%|▊| 75/100 [00:28<00:08,  3.03it\u001b[A\n",
      "Average Metric: 43.40050505050505 / 76  (57.1):  76%|▊| 76/100 [00:28<00:08,  2.92it\u001b[A\n",
      "Average Metric: 43.73383838383839 / 77  (56.8):  76%|▊| 76/100 [00:28<00:08,  2.92it\u001b[A\n",
      "Average Metric: 43.73383838383839 / 77  (56.8):  77%|▊| 77/100 [00:28<00:07,  3.07it\u001b[A\n",
      "Average Metric: 43.73383838383839 / 78  (56.1):  77%|▊| 77/100 [00:28<00:07,  3.07it\u001b[A\n",
      "Average Metric: 43.73383838383839 / 78  (56.1):  78%|▊| 78/100 [00:28<00:06,  3.57it\u001b[A\n",
      "Average Metric: 43.73383838383839 / 79  (55.4):  78%|▊| 78/100 [00:29<00:06,  3.57it\u001b[A\n",
      "Average Metric: 43.73383838383839 / 79  (55.4):  79%|▊| 79/100 [00:29<00:07,  2.77it\u001b[A\n",
      "Average Metric: 43.73383838383839 / 80  (54.7):  79%|▊| 79/100 [00:29<00:07,  2.77it\u001b[A\n",
      "Average Metric: 44.73383838383839 / 81  (55.2):  80%|▊| 80/100 [00:30<00:07,  2.77it\u001b[A\n",
      "Average Metric: 44.73383838383839 / 81  (55.2):  81%|▊| 81/100 [00:30<00:06,  3.04it\u001b[A\n",
      "Average Metric: 44.98383838383839 / 82  (54.9):  81%|▊| 81/100 [00:30<00:06,  3.04it\u001b[A\n",
      "Average Metric: 44.98383838383839 / 82  (54.9):  82%|▊| 82/100 [00:30<00:05,  3.07it\u001b[A\n",
      "Average Metric: 45.98383838383839 / 83  (55.4):  82%|▊| 82/100 [00:30<00:05,  3.07it\u001b[A\n",
      "Average Metric: 45.98383838383839 / 83  (55.4):  83%|▊| 83/100 [00:30<00:05,  3.25it\u001b[A\n",
      "Average Metric: 46.98383838383839 / 84  (55.9):  83%|▊| 83/100 [00:30<00:05,  3.25it\u001b[A\n",
      "Average Metric: 46.98383838383839 / 84  (55.9):  84%|▊| 84/100 [00:30<00:04,  3.46it\u001b[A\n",
      "Average Metric: 47.98383838383839 / 85  (56.5):  84%|▊| 84/100 [00:31<00:04,  3.46it\u001b[A\n",
      "Average Metric: 47.98383838383839 / 85  (56.5):  85%|▊| 85/100 [00:31<00:05,  2.54it\u001b[A\n",
      "Average Metric: 48.98383838383839 / 86  (57.0):  85%|▊| 85/100 [00:31<00:05,  2.54it\u001b[A\n",
      "Average Metric: 48.98383838383839 / 86  (57.0):  86%|▊| 86/100 [00:31<00:05,  2.60it\u001b[A\n",
      "Average Metric: 48.98383838383839 / 87  (56.3):  86%|▊| 86/100 [00:32<00:05,  2.60it\u001b[A\n",
      "Average Metric: 48.98383838383839 / 87  (56.3):  87%|▊| 87/100 [00:32<00:04,  2.81it\u001b[A\n",
      "Average Metric: 49.98383838383839 / 88  (56.8):  87%|▊| 87/100 [00:32<00:04,  2.81it\u001b[A\n",
      "Average Metric: 49.98383838383839 / 88  (56.8):  88%|▉| 88/100 [00:32<00:03,  3.21it\u001b[A\n",
      "Average Metric: 50.48383838383839 / 89  (56.7):  88%|▉| 88/100 [00:32<00:03,  3.21it\u001b[A\n",
      "Average Metric: 50.48383838383839 / 89  (56.7):  89%|▉| 89/100 [00:32<00:02,  3.70it\u001b[A\n",
      "Average Metric: 51.48383838383839 / 90  (57.2):  89%|▉| 89/100 [00:32<00:02,  3.70it\u001b[A\n",
      "Average Metric: 51.48383838383839 / 90  (57.2):  90%|▉| 90/100 [00:32<00:02,  4.17it\u001b[A\n",
      "Average Metric: 51.48383838383839 / 91  (56.6):  90%|▉| 90/100 [00:32<00:02,  4.17it\u001b[A\n",
      "Average Metric: 51.48383838383839 / 91  (56.6):  91%|▉| 91/100 [00:32<00:01,  4.71it\u001b[A\n",
      "Average Metric: 52.48383838383839 / 92  (57.0):  91%|▉| 91/100 [00:33<00:01,  4.71it\u001b[A\n",
      "Average Metric: 52.48383838383839 / 92  (57.0):  92%|▉| 92/100 [00:33<00:02,  2.75it\u001b[A\n",
      "Average Metric: 53.48383838383839 / 93  (57.5):  92%|▉| 92/100 [00:33<00:02,  2.75it\u001b[A\n",
      "Average Metric: 53.48383838383839 / 93  (57.5):  93%|▉| 93/100 [00:33<00:02,  2.81it\u001b[A\n",
      "Average Metric: 54.48383838383839 / 94  (58.0):  93%|▉| 93/100 [00:34<00:02,  2.81it\u001b[A\n",
      "Average Metric: 54.48383838383839 / 94  (58.0):  94%|▉| 94/100 [00:34<00:01,  3.46it\u001b[A\n",
      "Average Metric: 55.48383838383839 / 95  (58.4):  94%|▉| 94/100 [00:34<00:01,  3.46it\u001b[A\n",
      "Average Metric: 56.48383838383839 / 96  (58.8):  95%|▉| 95/100 [00:34<00:01,  3.46it\u001b[A\n",
      "Average Metric: 56.48383838383839 / 96  (58.8):  96%|▉| 96/100 [00:34<00:00,  4.32it\u001b[A\n",
      "Average Metric: 57.48383838383839 / 97  (59.3):  96%|▉| 96/100 [00:34<00:00,  4.32it\u001b[A\n",
      "Average Metric: 57.48383838383839 / 97  (59.3):  97%|▉| 97/100 [00:34<00:00,  4.45it\u001b[A\n",
      "Average Metric: 58.48383838383839 / 98  (59.7):  97%|▉| 97/100 [00:35<00:00,  4.45it\u001b[A\n",
      "Average Metric: 58.48383838383839 / 98  (59.7):  98%|▉| 98/100 [00:35<00:00,  2.48it\u001b[A\n",
      "Average Metric: 58.817171717171725 / 99  (59.4):  98%|▉| 98/100 [00:35<00:00,  2.48i\u001b[A\n",
      "Average Metric: 58.817171717171725 / 99  (59.4):  99%|▉| 99/100 [00:35<00:00,  2.95i\u001b[A\n",
      "Average Metric: 59.317171717171725 / 100  (59.3):  99%|▉| 99/100 [00:35<00:00,  2.95\u001b[A\n",
      "Average Metric: 59.317171717171725 / 100  (59.3): 100%|█| 100/100 [00:35<00:00,  2.7\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 59.317171717171725 / 100  (59.3%)\n",
      "Score: 59.32 for set: [16]\n",
      "New best score: 59.32 for seed 3\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8823333333333333\n",
      "Average of max per entry across top 5 scores: 0.9473333333333334\n",
      "Average of max per entry across top 8 scores: 0.9590000000000001\n",
      "Average of max per entry across top 9999 scores: 0.9590000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:19,  1.41s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:04<03:43,  2.28s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:06<03:44,  2.31s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:08<03:20,  2.09s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:09<02:41,  1.70s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:10<02:28,  1.58s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:12<02:49,  1.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:01<01:49,  1.11s/it]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   1%| | 1/100 [00:01<01:49,  1.11s/i\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   2%| | 2/100 [00:01<01:02,  1.57it/\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   2%| | 2/100 [00:01<01:02,  1.57it/\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):   3%| | 3/100 [00:01<01:01,  1.57it/\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):   4%| | 4/100 [00:01<00:32,  2.93it/\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 5  (43.3):   4%| | 4/100 [00:01<00:32,  2.93it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 6  (44.4):   5%| | 5/100 [00:01<00:32,  2.93it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 7  (38.1):   6%| | 6/100 [00:02<00:32,  2.93it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 7  (38.1):   7%| | 7/100 [00:02<00:21,  4.41it/\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 8  (39.6):   7%| | 7/100 [00:03<00:21,  4.41it/\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 8  (39.6):   8%| | 8/100 [00:03<00:38,  2.39it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.5666666666666664 / 9  (39.6):   8%| | 8/100 [00:03<00:38,  2.39it/\u001b[A\n",
      "Average Metric: 3.5666666666666664 / 9  (39.6):   9%| | 9/100 [00:03<00:42,  2.15it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8166666666666664 / 10  (38.2):   9%| | 9/100 [00:06<00:42,  2.15it\u001b[A\n",
      "Average Metric: 3.8166666666666664 / 10  (38.2):  10%| | 10/100 [00:06<01:23,  1.08i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.816666666666666 / 11  (43.8):  10%| | 10/100 [00:07<01:23,  1.08it\u001b[A\n",
      "Average Metric: 4.816666666666666 / 11  (43.8):  11%| | 11/100 [00:07<01:37,  1.09s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.816666666666666 / 12  (48.5):  11%| | 11/100 [00:08<01:37,  1.09s/\u001b[A\n",
      "Average Metric: 5.816666666666666 / 12  (48.5):  12%| | 12/100 [00:08<01:31,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.566666666666666 / 13  (50.5):  12%| | 12/100 [00:10<01:31,  1.03s/\u001b[A\n",
      "Average Metric: 6.566666666666666 / 13  (50.5):  13%|▏| 13/100 [00:10<01:42,  1.18s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.766666666666667 / 14  (48.3):  13%|▏| 13/100 [00:10<01:42,  1.18s/\u001b[A\n",
      "Average Metric: 6.766666666666667 / 14  (48.3):  14%|▏| 14/100 [00:10<01:21,  1.06it\u001b[A\n",
      "Average Metric: 7.766666666666667 / 15  (51.8):  14%|▏| 14/100 [00:11<01:21,  1.06it\u001b[A\n",
      "Average Metric: 7.766666666666667 / 15  (51.8):  15%|▏| 15/100 [00:11<01:24,  1.01it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.1 / 16  (50.6):  15%|█▊          | 15/100 [00:13<01:24,  1.01it/s]\u001b[A\n",
      "Average Metric: 8.1 / 16  (50.6):  16%|█▉          | 16/100 [00:13<01:46,  1.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.1 / 17  (47.6):  16%|█▉          | 16/100 [00:15<01:46,  1.27s/it]\u001b[A\n",
      "Average Metric: 8.1 / 17  (47.6):  17%|██          | 17/100 [00:15<01:52,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.6 / 18  (47.8):  17%|██          | 17/100 [00:16<01:52,  1.35s/it]\u001b[A\n",
      "Average Metric: 8.6 / 18  (47.8):  18%|██▏         | 18/100 [00:16<01:55,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.6 / 19  (45.3):  18%|██▏         | 18/100 [00:18<01:55,  1.41s/it]\u001b[A\n",
      "Average Metric: 8.6 / 19  (45.3):  19%|██▎         | 19/100 [00:18<02:11,  1.62s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.1 / 20  (45.5):  19%|██▎         | 19/100 [00:20<02:11,  1.62s/it]\u001b[A\n",
      "Average Metric: 9.1 / 20  (45.5):  20%|██▍         | 20/100 [00:20<02:14,  1.68s/it]\u001b[A\n",
      "Average Metric: 10.1 / 21  (48.1):  20%|██▏        | 20/100 [00:21<02:14,  1.68s/it]\u001b[A\n",
      "Average Metric: 10.1 / 21  (48.1):  21%|██▎        | 21/100 [00:21<01:51,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.6 / 22  (48.2):  21%|██▎        | 21/100 [00:22<01:51,  1.41s/it]\u001b[A\n",
      "Average Metric: 10.6 / 22  (48.2):  22%|██▍        | 22/100 [00:22<01:48,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.1 / 23  (48.3):  22%|██▍        | 22/100 [00:23<01:48,  1.40s/it]\u001b[A\n",
      "Average Metric: 11.1 / 23  (48.3):  23%|██▌        | 23/100 [00:23<01:32,  1.20s/it]\u001b[A\n",
      "Average Metric: 11.1 / 24  (46.2):  23%|██▌        | 23/100 [00:25<01:32,  1.20s/it]\u001b[A\n",
      "Average Metric: 11.1 / 24  (46.2):  24%|██▋        | 24/100 [00:25<01:38,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.1 / 25  (48.4):  24%|██▋        | 24/100 [00:27<01:38,  1.30s/it]\u001b[A\n",
      "Average Metric: 12.1 / 25  (48.4):  25%|██▊        | 25/100 [00:27<01:55,  1.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.1 / 26  (50.4):  25%|██▊        | 25/100 [00:28<01:55,  1.53s/it]\u001b[A\n",
      "Average Metric: 13.1 / 26  (50.4):  26%|██▊        | 26/100 [00:28<01:52,  1.52s/it]\u001b[A\n",
      "Average Metric: 14.1 / 27  (52.2):  26%|██▊        | 26/100 [00:28<01:52,  1.52s/it]\u001b[A\n",
      "Average Metric: 14.1 / 27  (52.2):  27%|██▉        | 27/100 [00:28<01:22,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 24.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.6 / 28  (52.1):  27%|██▉        | 27/100 [00:33<01:22,  1.13s/it]\u001b[A\n",
      "Average Metric: 14.6 / 28  (52.1):  28%|███        | 28/100 [00:33<02:43,  2.27s/it]\u001b[A\n",
      "Average Metric: 15.6 / 29  (53.8):  28%|███        | 28/100 [00:33<02:43,  2.27s/it]\u001b[A\n",
      "Average Metric: 15.6 / 29  (53.8):  29%|███▏       | 29/100 [00:33<01:56,  1.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.6 / 30  (52.0):  29%|███▏       | 29/100 [00:34<01:56,  1.65s/it]\u001b[A\n",
      "Average Metric: 15.6 / 30  (52.0):  30%|███▎       | 30/100 [00:34<01:42,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.6 / 31  (50.3):  30%|███▎       | 30/100 [00:36<01:42,  1.47s/it]\u001b[A\n",
      "Average Metric: 15.6 / 31  (50.3):  31%|███▍       | 31/100 [00:36<01:43,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.0 / 32  (50.0):  31%|███▍       | 31/100 [00:37<01:43,  1.50s/it]\u001b[A\n",
      "Average Metric: 16.0 / 32  (50.0):  32%|███▌       | 32/100 [00:37<01:24,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.333333333333332 / 33  (49.5):  32%|▎| 32/100 [00:40<01:24,  1.24s\u001b[A\n",
      "Average Metric: 16.333333333333332 / 33  (49.5):  33%|▎| 33/100 [00:40<02:04,  1.85s\u001b[A\n",
      "Average Metric: 17.333333333333332 / 34  (51.0):  33%|▎| 33/100 [00:40<02:04,  1.85s\u001b[A\n",
      "Average Metric: 17.333333333333332 / 34  (51.0):  34%|▎| 34/100 [00:40<01:30,  1.38s\u001b[A\n",
      "Average Metric: 17.833333333333332 / 35  (51.0):  34%|▎| 34/100 [00:41<01:30,  1.38s\u001b[A\n",
      "Average Metric: 17.833333333333332 / 35  (51.0):  35%|▎| 35/100 [00:41<01:10,  1.09s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.333333333333332 / 36  (50.9):  35%|▎| 35/100 [00:43<01:10,  1.09s\u001b[A\n",
      "Average Metric: 18.333333333333332 / 36  (50.9):  36%|▎| 36/100 [00:43<01:39,  1.55s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.0 / 37  (51.4):  36%|███▉       | 36/100 [00:44<01:39,  1.55s/it]\u001b[A\n",
      "Average Metric: 19.0 / 37  (51.4):  37%|████       | 37/100 [00:44<01:28,  1.41s/it]\u001b[A\n",
      "Average Metric: 19.666666666666668 / 38  (51.8):  37%|▎| 37/100 [00:45<01:28,  1.41s\u001b[A\n",
      "Average Metric: 19.666666666666668 / 38  (51.8):  38%|▍| 38/100 [00:45<01:11,  1.15s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.666666666666668 / 39  (50.4):  38%|▍| 38/100 [00:46<01:11,  1.15s\u001b[A\n",
      "Average Metric: 19.666666666666668 / 39  (50.4):  39%|▍| 39/100 [00:46<01:13,  1.21s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.0 / 40  (50.0):  39%|████▎      | 39/100 [00:48<01:13,  1.21s/it]\u001b[A\n",
      "Average Metric: 20.0 / 40  (50.0):  40%|████▍      | 40/100 [00:48<01:21,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.0 / 41  (51.2):  40%|████▍      | 40/100 [00:50<01:21,  1.37s/it]\u001b[A\n",
      "Average Metric: 21.0 / 41  (51.2):  41%|████▌      | 41/100 [00:50<01:32,  1.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.166666666666668 / 42  (50.4):  41%|▍| 41/100 [00:50<01:32,  1.57s\u001b[A\n",
      "Average Metric: 21.166666666666668 / 42  (50.4):  42%|▍| 42/100 [00:50<01:10,  1.21s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.166666666666668 / 43  (51.6):  42%|▍| 42/100 [00:52<01:10,  1.21s\u001b[A\n",
      "Average Metric: 22.166666666666668 / 43  (51.6):  43%|▍| 43/100 [00:52<01:16,  1.34s\u001b[A\n",
      "Average Metric: 23.166666666666668 / 44  (52.7):  43%|▍| 43/100 [00:52<01:16,  1.34s\u001b[A\n",
      "Average Metric: 23.166666666666668 / 44  (52.7):  44%|▍| 44/100 [00:52<00:57,  1.02s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.166666666666668 / 45  (53.7):  44%|▍| 44/100 [00:54<00:57,  1.02s\u001b[A\n",
      "Average Metric: 24.166666666666668 / 45  (53.7):  45%|▍| 45/100 [00:54<01:07,  1.23s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.166666666666668 / 46  (54.7):  45%|▍| 45/100 [00:56<01:07,  1.23s\u001b[A\n",
      "Average Metric: 25.166666666666668 / 46  (54.7):  46%|▍| 46/100 [00:56<01:18,  1.45s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.666666666666668 / 47  (54.6):  46%|▍| 46/100 [00:58<01:18,  1.45s\u001b[A\n",
      "Average Metric: 25.666666666666668 / 47  (54.6):  47%|▍| 47/100 [00:58<01:25,  1.61s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.666666666666668 / 48  (53.5):  47%|▍| 47/100 [01:00<01:25,  1.61s\u001b[A\n",
      "Average Metric: 25.666666666666668 / 48  (53.5):  48%|▍| 48/100 [01:00<01:23,  1.61s\u001b[A\n",
      "Average Metric: 26.666666666666668 / 49  (54.4):  48%|▍| 48/100 [01:00<01:23,  1.61s\u001b[A\n",
      "Average Metric: 26.666666666666668 / 49  (54.4):  49%|▍| 49/100 [01:00<01:02,  1.23s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.666666666666668 / 50  (55.3):  49%|▍| 49/100 [01:02<01:02,  1.23s\u001b[A\n",
      "Average Metric: 27.666666666666668 / 50  (55.3):  50%|▌| 50/100 [01:02<01:19,  1.60s\u001b[A\n",
      "Average Metric: 28.666666666666668 / 51  (56.2):  50%|▌| 50/100 [01:02<01:19,  1.60s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.666666666666668 / 52  (57.1):  51%|▌| 51/100 [01:04<01:18,  1.60s\u001b[A\n",
      "Average Metric: 29.666666666666668 / 52  (57.1):  52%|▌| 52/100 [01:04<00:59,  1.23s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.666666666666668 / 53  (56.0):  52%|▌| 52/100 [01:06<00:59,  1.23s\u001b[A\n",
      "Average Metric: 29.666666666666668 / 53  (56.0):  53%|▌| 53/100 [01:06<01:01,  1.30s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.666666666666668 / 54  (56.8):  53%|▌| 53/100 [01:07<01:01,  1.30s\u001b[A\n",
      "Average Metric: 30.666666666666668 / 54  (56.8):  54%|▌| 54/100 [01:07<01:04,  1.41s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.666666666666668 / 55  (57.6):  54%|▌| 54/100 [01:09<01:04,  1.41s\u001b[A\n",
      "Average Metric: 31.666666666666668 / 55  (57.6):  55%|▌| 55/100 [01:09<01:06,  1.48s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 15.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.666666666666668 / 56  (56.5):  55%|▌| 55/100 [01:10<01:06,  1.48s\u001b[A\n",
      "Average Metric: 31.666666666666668 / 56  (56.5):  56%|▌| 56/100 [01:10<01:05,  1.50s\u001b[A\n",
      "Average Metric: 32.0 / 57  (56.1):  56%|██████▏    | 56/100 [01:11<01:05,  1.50s/it]\u001b[A\n",
      "Average Metric: 32.0 / 57  (56.1):  57%|██████▎    | 57/100 [01:11<00:57,  1.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 13.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.0 / 58  (56.9):  57%|██████▎    | 57/100 [01:13<00:57,  1.33s/it]\u001b[A\n",
      "Average Metric: 33.0 / 58  (56.9):  58%|██████▍    | 58/100 [01:13<01:04,  1.55s/it]\u001b[A\n",
      "Average Metric: 33.0 / 59  (55.9):  58%|██████▍    | 58/100 [01:14<01:04,  1.55s/it]\u001b[A\n",
      "Average Metric: 33.0 / 59  (55.9):  59%|██████▍    | 59/100 [01:14<00:52,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.0 / 60  (55.0):  59%|██████▍    | 59/100 [01:15<00:52,  1.29s/it]\u001b[A\n",
      "Average Metric: 33.0 / 60  (55.0):  60%|██████▌    | 60/100 [01:15<00:46,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.0 / 61  (55.7):  60%|██████▌    | 60/100 [01:18<00:46,  1.15s/it]\u001b[A\n",
      "Average Metric: 34.0 / 61  (55.7):  61%|██████▋    | 61/100 [01:18<01:10,  1.81s/it]\u001b[A\n",
      "Average Metric: 34.333333333333336 / 62  (55.4):  61%|▌| 61/100 [01:19<01:10,  1.81s\u001b[A\n",
      "Average Metric: 34.333333333333336 / 62  (55.4):  62%|▌| 62/100 [01:19<00:52,  1.38s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.333333333333336 / 63  (54.5):  62%|▌| 62/100 [01:21<00:52,  1.38s\u001b[A\n",
      "Average Metric: 34.333333333333336 / 63  (54.5):  63%|▋| 63/100 [01:21<00:59,  1.62s\u001b[A\n",
      "Average Metric: 34.333333333333336 / 64  (53.6):  63%|▋| 63/100 [01:21<00:59,  1.62s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 34.333333333333336 / 64  (53.6):  64%|▋| 64/100 [01:21<00:47,  1.32s\u001b[A\n",
      "Average Metric: 34.833333333333336 / 65  (53.6):  64%|▋| 64/100 [01:23<00:47,  1.32s\u001b[A\n",
      "Average Metric: 34.833333333333336 / 65  (53.6):  65%|▋| 65/100 [01:23<00:52,  1.50s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.833333333333336 / 66  (54.3):  65%|▋| 65/100 [01:25<00:52,  1.50s\u001b[A\n",
      "Average Metric: 35.833333333333336 / 66  (54.3):  66%|▋| 66/100 [01:25<00:55,  1.62s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.833333333333336 / 67  (55.0):  66%|▋| 66/100 [01:27<00:55,  1.62s\u001b[A\n",
      "Average Metric: 36.833333333333336 / 67  (55.0):  67%|▋| 67/100 [01:27<00:54,  1.64s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 31.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.833333333333336 / 68  (55.6):  67%|▋| 67/100 [01:29<00:54,  1.64s\u001b[A\n",
      "Average Metric: 37.833333333333336 / 68  (55.6):  68%|▋| 68/100 [01:29<00:56,  1.76s\u001b[A\n",
      "Average Metric: 38.16666666666667 / 69  (55.3):  68%|▋| 68/100 [01:30<00:56,  1.76s/\u001b[A\n",
      "Average Metric: 38.16666666666667 / 69  (55.3):  69%|▋| 69/100 [01:30<00:50,  1.62s/\u001b[A\n",
      "Average Metric: 38.50000000000001 / 70  (55.0):  69%|▋| 69/100 [01:31<00:50,  1.62s/\u001b[A\n",
      "Average Metric: 38.50000000000001 / 70  (55.0):  70%|▋| 70/100 [01:31<00:39,  1.30s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.50000000000001 / 71  (54.2):  70%|▋| 70/100 [01:32<00:39,  1.30s/\u001b[A\n",
      "Average Metric: 38.50000000000001 / 71  (54.2):  71%|▋| 71/100 [01:32<00:39,  1.35s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.75000000000001 / 72  (53.8):  71%|▋| 71/100 [01:34<00:39,  1.35s/\u001b[A\n",
      "Average Metric: 38.75000000000001 / 72  (53.8):  72%|▋| 72/100 [01:34<00:39,  1.40s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.08333333333334 / 73  (53.5):  72%|▋| 72/100 [01:35<00:39,  1.40s/\u001b[A\n",
      "Average Metric: 39.08333333333334 / 73  (53.5):  73%|▋| 73/100 [01:35<00:39,  1.46s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.41666666666668 / 74  (53.3):  73%|▋| 73/100 [01:38<00:39,  1.46s/\u001b[A\n",
      "Average Metric: 39.41666666666668 / 74  (53.3):  74%|▋| 74/100 [01:38<00:42,  1.64s/\u001b[A\n",
      "Average Metric: 39.750000000000014 / 75  (53.0):  74%|▋| 74/100 [01:38<00:42,  1.64s\u001b[A\n",
      "Average Metric: 39.750000000000014 / 76  (52.3):  75%|▊| 75/100 [01:39<00:40,  1.64s\u001b[A\n",
      "Average Metric: 39.750000000000014 / 76  (52.3):  76%|▊| 76/100 [01:39<00:29,  1.22s\u001b[A\n",
      "Average Metric: 39.750000000000014 / 77  (51.6):  76%|▊| 76/100 [01:40<00:29,  1.22s\u001b[A\n",
      "Average Metric: 39.750000000000014 / 77  (51.6):  77%|▊| 77/100 [01:40<00:27,  1.20s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.750000000000014 / 78  (51.0):  77%|▊| 77/100 [01:41<00:27,  1.20s\u001b[A\n",
      "Average Metric: 39.750000000000014 / 78  (51.0):  78%|▊| 78/100 [01:41<00:27,  1.24s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.750000000000014 / 79  (50.3):  78%|▊| 78/100 [01:44<00:27,  1.24s\u001b[A\n",
      "Average Metric: 39.750000000000014 / 79  (50.3):  79%|▊| 79/100 [01:44<00:34,  1.63s\u001b[A\n",
      "Average Metric: 40.750000000000014 / 80  (50.9):  79%|▊| 79/100 [01:45<00:34,  1.63s\u001b[A\n",
      "Average Metric: 40.750000000000014 / 80  (50.9):  80%|▊| 80/100 [01:45<00:26,  1.31s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.750000000000014 / 81  (51.5):  80%|▊| 80/100 [01:46<00:26,  1.31s\u001b[A\n",
      "Average Metric: 41.750000000000014 / 81  (51.5):  81%|▊| 81/100 [01:46<00:23,  1.26s\u001b[A\n",
      "Average Metric: 42.750000000000014 / 82  (52.1):  81%|▊| 81/100 [01:47<00:23,  1.26s\u001b[A\n",
      "Average Metric: 42.750000000000014 / 82  (52.1):  82%|▊| 82/100 [01:47<00:23,  1.31s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.41666666666668 / 83  (52.3):  82%|▊| 82/100 [01:49<00:23,  1.31s/\u001b[A\n",
      "Average Metric: 43.41666666666668 / 83  (52.3):  83%|▊| 83/100 [01:49<00:26,  1.56s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.66666666666668 / 84  (52.0):  83%|▊| 83/100 [01:51<00:26,  1.56s/\u001b[A\n",
      "Average Metric: 43.66666666666668 / 84  (52.0):  84%|▊| 84/100 [01:51<00:25,  1.61s/\u001b[A\n",
      "Average Metric: 44.66666666666668 / 85  (52.5):  84%|▊| 84/100 [01:52<00:25,  1.61s/\u001b[A\n",
      "Average Metric: 44.66666666666668 / 85  (52.5):  85%|▊| 85/100 [01:52<00:21,  1.46s/\u001b[A\n",
      "Average Metric: 45.66666666666668 / 86  (53.1):  85%|▊| 85/100 [01:54<00:21,  1.46s/\u001b[A\n",
      "Average Metric: 45.66666666666668 / 86  (53.1):  86%|▊| 86/100 [01:54<00:19,  1.42s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46.66666666666668 / 87  (53.6):  86%|▊| 86/100 [01:55<00:19,  1.42s/\u001b[A\n",
      "Average Metric: 46.66666666666668 / 87  (53.6):  87%|▊| 87/100 [01:55<00:19,  1.50s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 21.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.66666666666668 / 88  (54.2):  87%|▊| 87/100 [01:57<00:19,  1.50s/\u001b[A\n",
      "Average Metric: 47.66666666666668 / 88  (54.2):  88%|▉| 88/100 [01:57<00:18,  1.52s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 48.66666666666668 / 89  (54.7):  88%|▉| 88/100 [01:59<00:18,  1.52s/\u001b[A\n",
      "Average Metric: 48.66666666666668 / 89  (54.7):  89%|▉| 89/100 [01:59<00:18,  1.65s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.66666666666668 / 90  (55.2):  89%|▉| 89/100 [02:00<00:18,  1.65s/\u001b[A\n",
      "Average Metric: 49.66666666666668 / 90  (55.2):  90%|▉| 90/100 [02:00<00:14,  1.45s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.000000000000014 / 91  (54.9):  90%|▉| 90/100 [02:01<00:14,  1.45s\u001b[A\n",
      "Average Metric: 50.000000000000014 / 91  (54.9):  91%|▉| 91/100 [02:01<00:13,  1.49s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.20000000000002 / 92  (54.6):  91%|▉| 91/100 [02:04<00:13,  1.49s/\u001b[A\n",
      "Average Metric: 50.20000000000002 / 92  (54.6):  92%|▉| 92/100 [02:04<00:13,  1.73s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.20000000000002 / 93  (55.1):  92%|▉| 92/100 [02:04<00:13,  1.73s/\u001b[A\n",
      "Average Metric: 51.20000000000002 / 93  (55.1):  93%|▉| 93/100 [02:04<00:09,  1.36s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.20000000000002 / 94  (55.5):  93%|▉| 93/100 [02:06<00:09,  1.36s/\u001b[A\n",
      "Average Metric: 52.20000000000002 / 94  (55.5):  94%|▉| 94/100 [02:06<00:08,  1.42s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 22.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 53.20000000000002 / 95  (56.0):  94%|▉| 94/100 [02:07<00:08,  1.42s/\u001b[A\n",
      "Average Metric: 53.20000000000002 / 95  (56.0):  95%|▉| 95/100 [02:07<00:07,  1.54s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 54.20000000000002 / 96  (56.5):  95%|▉| 95/100 [02:09<00:07,  1.54s/\u001b[A\n",
      "Average Metric: 54.20000000000002 / 96  (56.5):  96%|▉| 96/100 [02:09<00:06,  1.68s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 54.20000000000002 / 97  (55.9):  96%|▉| 96/100 [02:11<00:06,  1.68s/\u001b[A\n",
      "Average Metric: 54.20000000000002 / 97  (55.9):  97%|▉| 97/100 [02:11<00:04,  1.60s/\u001b[A\n",
      "Average Metric: 54.20000000000002 / 98  (55.3):  97%|▉| 97/100 [02:12<00:04,  1.60s/\u001b[A\n",
      "Average Metric: 54.20000000000002 / 98  (55.3):  98%|▉| 98/100 [02:12<00:03,  1.57s/\u001b[A\n",
      "Average Metric: 54.70000000000002 / 99  (55.3):  98%|▉| 98/100 [02:20<00:03,  1.57s/\u001b[A\n",
      "Average Metric: 54.70000000000002 / 99  (55.3):  99%|▉| 99/100 [02:20<00:03,  3.35s/\u001b[A\n",
      "Average Metric: 54.70000000000002 / 100  (54.7):  99%|▉| 99/100 [02:30<00:03,  3.35s\u001b[A\n",
      "Average Metric: 54.70000000000002 / 100  (54.7): 100%|█| 100/100 [02:30<00:00,  1.51\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.70000000000002 / 100  (54.7%)\n",
      "Score: 54.7 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8823333333333333\n",
      "Average of max per entry across top 5 scores: 0.9483333333333335\n",
      "Average of max per entry across top 8 scores: 0.97\n",
      "Average of max per entry across top 9999 scores: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<01:52,  1.14s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:03<02:46,  1.69s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:04<02:36,  1.62s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:06<02:32,  1.59s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:07<02:25,  1.53s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:09<02:33,  1.64s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:11<02:32,  1.64s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:14<03:12,  2.09s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:15<02:44,  1.81s/it]\u001b[A\n",
      " 10%|████▌                                         | 10/100 [00:16<02:31,  1.68s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:00<01:38,  1.00it/s]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   1%| | 1/100 [00:01<01:38,  1.00it/\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   2%| | 2/100 [00:01<00:59,  1.65it/\u001b[A\n",
      "Average Metric: 0.7333333333333334 / 3  (24.4):   2%| | 2/100 [00:01<00:59,  1.65it/\u001b[A\n",
      "Average Metric: 0.7333333333333334 / 3  (24.4):   3%| | 3/100 [00:01<00:38,  2.52it/\u001b[A\n",
      "Average Metric: 1.0666666666666667 / 4  (26.7):   3%| | 3/100 [00:01<00:38,  2.52it/\u001b[A\n",
      "Average Metric: 1.0666666666666667 / 5  (21.3):   4%| | 4/100 [00:01<00:38,  2.52it/\u001b[A\n",
      "Average Metric: 1.0666666666666667 / 5  (21.3):   5%| | 5/100 [00:01<00:22,  4.20it/\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 6  (34.4):   5%| | 5/100 [00:01<00:22,  4.20it/\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 6  (34.4):   6%| | 6/100 [00:01<00:23,  4.06it/\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 7  (29.5):   6%| | 6/100 [00:02<00:23,  4.06it/\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 7  (29.5):   7%| | 7/100 [00:02<00:20,  4.53it/\u001b[A\n",
      "Average Metric: 3.0666666666666664 / 8  (38.3):   7%| | 7/100 [00:02<00:20,  4.53it/\u001b[A\n",
      "Average Metric: 3.0666666666666664 / 8  (38.3):   8%| | 8/100 [00:02<00:28,  3.21it/\u001b[A\n",
      "Average Metric: 4.066666666666666 / 9  (45.2):   8%| | 8/100 [00:02<00:28,  3.21it/s\u001b[A\n",
      "Average Metric: 4.066666666666666 / 9  (45.2):   9%| | 9/100 [00:02<00:25,  3.59it/s\u001b[A\n",
      "Average Metric: 4.3999999999999995 / 10  (44.0):   9%| | 9/100 [00:03<00:25,  3.59it\u001b[A\n",
      "Average Metric: 4.3999999999999995 / 10  (44.0):  10%| | 10/100 [00:03<00:27,  3.33i\u001b[A\n",
      "Average Metric: 4.6499999999999995 / 11  (42.3):  10%| | 10/100 [00:03<00:27,  3.33i\u001b[A\n",
      "Average Metric: 5.6499999999999995 / 12  (47.1):  11%| | 11/100 [00:03<00:26,  3.33i\u001b[A\n",
      "Average Metric: 5.6499999999999995 / 12  (47.1):  12%| | 12/100 [00:03<00:25,  3.47i\u001b[A\n",
      "Average Metric: 5.749999999999999 / 13  (44.2):  12%| | 12/100 [00:03<00:25,  3.47it\u001b[A\n",
      "Average Metric: 5.749999999999999 / 13  (44.2):  13%|▏| 13/100 [00:03<00:22,  3.80it\u001b[A\n",
      "Average Metric: 6.349999999999999 / 14  (45.4):  13%|▏| 13/100 [00:04<00:22,  3.80it\u001b[A\n",
      "Average Metric: 6.349999999999999 / 14  (45.4):  14%|▏| 14/100 [00:04<00:29,  2.94it\u001b[A\n",
      "Average Metric: 6.599999999999999 / 15  (44.0):  14%|▏| 14/100 [00:04<00:29,  2.94it\u001b[A\n",
      "Average Metric: 7.599999999999999 / 16  (47.5):  15%|▏| 15/100 [00:04<00:28,  2.94it\u001b[A\n",
      "Average Metric: 7.599999999999999 / 16  (47.5):  16%|▏| 16/100 [00:04<00:19,  4.29it\u001b[A\n",
      "Average Metric: 8.099999999999998 / 17  (47.6):  16%|▏| 16/100 [00:04<00:19,  4.29it\u001b[A\n",
      "Average Metric: 8.099999999999998 / 17  (47.6):  17%|▏| 17/100 [00:04<00:20,  4.06it\u001b[A\n",
      "Average Metric: 8.433333333333332 / 18  (46.9):  17%|▏| 17/100 [00:04<00:20,  4.06it\u001b[A\n",
      "Average Metric: 8.633333333333331 / 19  (45.4):  18%|▏| 18/100 [00:05<00:20,  4.06it\u001b[A\n",
      "Average Metric: 8.633333333333331 / 19  (45.4):  19%|▏| 19/100 [00:05<00:17,  4.75it\u001b[A\n",
      "Average Metric: 8.633333333333331 / 20  (43.2):  19%|▏| 19/100 [00:05<00:17,  4.75it\u001b[A\n",
      "Average Metric: 8.633333333333331 / 20  (43.2):  20%|▏| 20/100 [00:05<00:23,  3.47it\u001b[A\n",
      "Average Metric: 8.966666666666665 / 21  (42.7):  20%|▏| 20/100 [00:05<00:23,  3.47it\u001b[A\n",
      "Average Metric: 9.133333333333331 / 22  (41.5):  21%|▏| 21/100 [00:06<00:22,  3.47it\u001b[A\n",
      "Average Metric: 9.133333333333331 / 22  (41.5):  22%|▏| 22/100 [00:06<00:24,  3.22it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.133333333333331 / 23  (39.7):  22%|▏| 22/100 [00:06<00:24,  3.22it\u001b[A\n",
      "Average Metric: 10.133333333333331 / 24  (42.2):  23%|▏| 23/100 [00:07<00:23,  3.22i\u001b[A\n",
      "Average Metric: 10.133333333333331 / 24  (42.2):  24%|▏| 24/100 [00:07<00:22,  3.32i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.133333333333331 / 25  (44.5):  24%|▏| 24/100 [00:08<00:22,  3.32i\u001b[A\n",
      "Average Metric: 11.133333333333331 / 25  (44.5):  25%|▎| 25/100 [00:08<00:35,  2.11i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.466666666666665 / 26  (44.1):  25%|▎| 25/100 [00:09<00:35,  2.11i\u001b[A\n",
      "Average Metric: 11.466666666666665 / 26  (44.1):  26%|▎| 26/100 [00:09<00:48,  1.52i\u001b[A\n",
      "Average Metric: 12.466666666666665 / 27  (46.2):  26%|▎| 26/100 [00:09<00:48,  1.52i\u001b[A\n",
      "Average Metric: 12.466666666666665 / 27  (46.2):  27%|▎| 27/100 [00:09<00:44,  1.65i\u001b[A\n",
      "Average Metric: 12.466666666666665 / 28  (44.5):  27%|▎| 27/100 [00:10<00:44,  1.65i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.866666666666665 / 29  (44.4):  28%|▎| 28/100 [00:11<00:43,  1.65i\u001b[A\n",
      "Average Metric: 12.866666666666665 / 29  (44.4):  29%|▎| 29/100 [00:11<00:45,  1.57i\u001b[A\n",
      "Average Metric: 12.866666666666665 / 30  (42.9):  29%|▎| 29/100 [00:11<00:45,  1.57i\u001b[A\n",
      "Average Metric: 12.866666666666665 / 30  (42.9):  30%|▎| 30/100 [00:11<00:38,  1.84i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.866666666666665 / 31  (41.5):  30%|▎| 30/100 [00:13<00:38,  1.84i\u001b[A\n",
      "Average Metric: 12.866666666666665 / 31  (41.5):  31%|▎| 31/100 [00:13<00:59,  1.16i\u001b[A\n",
      "Average Metric: 13.116666666666665 / 32  (41.0):  31%|▎| 31/100 [00:14<00:59,  1.16i\u001b[A\n",
      "Average Metric: 13.116666666666665 / 32  (41.0):  32%|▎| 32/100 [00:14<00:53,  1.27i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.45 / 33  (40.8):  32%|███▏      | 32/100 [00:15<00:53,  1.27it/s]\u001b[A\n",
      "Average Metric: 13.45 / 33  (40.8):  33%|███▎      | 33/100 [00:15<01:00,  1.11it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.45 / 34  (42.5):  33%|███▎      | 33/100 [00:15<01:00,  1.11it/s]\u001b[A\n",
      "Average Metric: 14.45 / 34  (42.5):  34%|███▍      | 34/100 [00:15<00:54,  1.20it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.116666666666665 / 35  (43.2):  34%|▎| 34/100 [00:16<00:54,  1.20i\u001b[A\n",
      "Average Metric: 15.116666666666665 / 35  (43.2):  35%|▎| 35/100 [00:16<00:59,  1.10i\u001b[A\n",
      "Average Metric: 15.616666666666665 / 36  (43.4):  35%|▎| 35/100 [00:17<00:59,  1.10i\u001b[A\n",
      "Average Metric: 15.616666666666665 / 36  (43.4):  36%|▎| 36/100 [00:17<00:53,  1.21i\u001b[A\n",
      "Average Metric: 16.116666666666667 / 37  (43.6):  36%|▎| 36/100 [00:18<00:53,  1.21i\u001b[A\n",
      "Average Metric: 16.116666666666667 / 37  (43.6):  37%|▎| 37/100 [00:18<00:49,  1.27i\u001b[A\n",
      "Average Metric: 17.116666666666667 / 38  (45.0):  37%|▎| 37/100 [00:19<00:49,  1.27i\u001b[A\n",
      "Average Metric: 17.116666666666667 / 38  (45.0):  38%|▍| 38/100 [00:19<00:53,  1.17i\u001b[A\n",
      "Average Metric: 17.45 / 39  (44.7):  38%|███▊      | 38/100 [00:19<00:53,  1.17it/s]\u001b[A\n",
      "Average Metric: 17.45 / 39  (44.7):  39%|███▉      | 39/100 [00:19<00:40,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.45 / 40  (46.1):  39%|███▉      | 39/100 [00:20<00:40,  1.52it/s]\u001b[A\n",
      "Average Metric: 18.45 / 40  (46.1):  40%|████      | 40/100 [00:20<00:42,  1.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.95 / 41  (46.2):  40%|████      | 40/100 [00:22<00:42,  1.42it/s]\u001b[A\n",
      "Average Metric: 18.95 / 41  (46.2):  41%|████      | 41/100 [00:22<01:07,  1.14s/it]\u001b[A\n",
      "Average Metric: 19.95 / 42  (47.5):  41%|████      | 41/100 [00:22<01:07,  1.14s/it]\u001b[A\n",
      "Average Metric: 19.95 / 42  (47.5):  42%|████▏     | 42/100 [00:22<00:49,  1.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.45 / 43  (47.6):  42%|████▏     | 42/100 [00:24<00:49,  1.18it/s]\u001b[A\n",
      "Average Metric: 20.45 / 43  (47.6):  43%|████▎     | 43/100 [00:24<01:05,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.45 / 44  (46.5):  43%|████▎     | 43/100 [00:26<01:05,  1.15s/it]\u001b[A\n",
      "Average Metric: 20.45 / 44  (46.5):  44%|████▍     | 44/100 [00:26<01:10,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.95 / 45  (46.6):  44%|████▍     | 44/100 [00:26<01:10,  1.26s/it]\u001b[A\n",
      "Average Metric: 20.95 / 45  (46.6):  45%|████▌     | 45/100 [00:26<01:00,  1.10s/it]\u001b[A\n",
      "Average Metric: 20.95 / 46  (45.5):  45%|████▌     | 45/100 [00:27<01:00,  1.10s/it]\u001b[A\n",
      "Average Metric: 20.95 / 46  (45.5):  46%|████▌     | 46/100 [00:27<00:56,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.95 / 47  (46.7):  46%|████▌     | 46/100 [00:28<00:56,  1.04s/it]\u001b[A\n",
      "Average Metric: 21.95 / 47  (46.7):  47%|████▋     | 47/100 [00:28<00:59,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.28333333333333 / 48  (46.4):  47%|▍| 47/100 [00:30<00:59,  1.13s/\u001b[A\n",
      "Average Metric: 22.28333333333333 / 48  (46.4):  48%|▍| 48/100 [00:30<00:59,  1.15s/\u001b[A\n",
      "Average Metric: 23.28333333333333 / 49  (47.5):  48%|▍| 48/100 [00:31<00:59,  1.15s/\u001b[A\n",
      "Average Metric: 23.28333333333333 / 49  (47.5):  49%|▍| 49/100 [00:31<00:59,  1.16s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.616666666666664 / 50  (47.2):  49%|▍| 49/100 [00:32<00:59,  1.16s\u001b[A\n",
      "Average Metric: 23.616666666666664 / 50  (47.2):  50%|▌| 50/100 [00:32<00:55,  1.11s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 21.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 23.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.616666666666664 / 51  (48.3):  50%|▌| 50/100 [00:33<00:55,  1.11s\u001b[A\n",
      "Average Metric: 24.616666666666664 / 51  (48.3):  51%|▌| 51/100 [00:33<01:00,  1.24s\u001b[A\n",
      "Average Metric: 25.616666666666664 / 52  (49.3):  51%|▌| 51/100 [00:33<01:00,  1.24s\u001b[A\n",
      "Average Metric: 26.616666666666664 / 53  (50.2):  52%|▌| 52/100 [00:35<00:59,  1.24s\u001b[A\n",
      "Average Metric: 26.616666666666664 / 53  (50.2):  53%|▌| 53/100 [00:35<00:43,  1.08i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.949999999999996 / 54  (49.9):  53%|▌| 53/100 [00:36<00:43,  1.08i\u001b[A\n",
      "Average Metric: 26.949999999999996 / 54  (49.9):  54%|▌| 54/100 [00:36<00:48,  1.05s\u001b[A\n",
      "Average Metric: 27.449999999999996 / 55  (49.9):  54%|▌| 54/100 [00:37<00:48,  1.05s\u001b[A\n",
      "Average Metric: 27.449999999999996 / 55  (49.9):  55%|▌| 55/100 [00:37<00:47,  1.05s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.449999999999996 / 56  (49.0):  55%|▌| 55/100 [00:38<00:47,  1.05s\u001b[A\n",
      "Average Metric: 27.449999999999996 / 56  (49.0):  56%|▌| 56/100 [00:38<00:47,  1.07s\u001b[A\n",
      "Average Metric: 27.449999999999996 / 57  (48.2):  56%|▌| 56/100 [00:38<00:47,  1.07s\u001b[A\n",
      "Average Metric: 27.449999999999996 / 57  (48.2):  57%|▌| 57/100 [00:38<00:36,  1.17i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.449999999999996 / 58  (49.1):  57%|▌| 57/100 [00:40<00:36,  1.17i\u001b[A\n",
      "Average Metric: 28.449999999999996 / 58  (49.1):  58%|▌| 58/100 [00:40<00:41,  1.00i\u001b[A\n",
      "Average Metric: 28.449999999999996 / 59  (48.2):  58%|▌| 58/100 [00:40<00:41,  1.00i\u001b[A\n",
      "Average Metric: 28.449999999999996 / 59  (48.2):  59%|▌| 59/100 [00:40<00:30,  1.35i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.783333333333328 / 60  (48.0):  59%|▌| 59/100 [00:41<00:30,  1.35i\u001b[A\n",
      "Average Metric: 28.783333333333328 / 60  (48.0):  60%|▌| 60/100 [00:41<00:35,  1.14i\u001b[A\n",
      "Average Metric: 29.283333333333328 / 61  (48.0):  60%|▌| 60/100 [00:43<00:35,  1.14i\u001b[A\n",
      "Average Metric: 29.283333333333328 / 61  (48.0):  61%|▌| 61/100 [00:43<00:42,  1.08s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.283333333333328 / 62  (48.8):  61%|▌| 61/100 [00:43<00:42,  1.08s\u001b[A\n",
      "Average Metric: 30.283333333333328 / 62  (48.8):  62%|▌| 62/100 [00:43<00:30,  1.26i\u001b[A\n",
      "Average Metric: 30.283333333333328 / 63  (48.1):  62%|▌| 62/100 [00:44<00:30,  1.26i\u001b[A\n",
      "Average Metric: 30.283333333333328 / 63  (48.1):  63%|▋| 63/100 [00:44<00:33,  1.10i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.283333333333328 / 64  (48.9):  63%|▋| 63/100 [00:45<00:33,  1.10i\u001b[A\n",
      "Average Metric: 31.283333333333328 / 64  (48.9):  64%|▋| 64/100 [00:45<00:34,  1.06i\u001b[A\n",
      "Average Metric: 31.783333333333328 / 65  (48.9):  64%|▋| 64/100 [00:46<00:34,  1.06i\u001b[A\n",
      "Average Metric: 31.783333333333328 / 65  (48.9):  65%|▋| 65/100 [00:46<00:29,  1.20i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.28333333333333 / 66  (48.9):  65%|▋| 65/100 [00:46<00:29,  1.20it\u001b[A\n",
      "Average Metric: 32.28333333333333 / 66  (48.9):  66%|▋| 66/100 [00:46<00:27,  1.25it\u001b[A\n",
      "Average Metric: 33.28333333333333 / 67  (49.7):  66%|▋| 66/100 [00:47<00:27,  1.25it\u001b[A\n",
      "Average Metric: 33.28333333333333 / 67  (49.7):  67%|▋| 67/100 [00:47<00:28,  1.14it\u001b[A\n",
      "Average Metric: 33.78333333333333 / 68  (49.7):  67%|▋| 67/100 [00:48<00:28,  1.14it\u001b[A\n",
      "Average Metric: 33.78333333333333 / 68  (49.7):  68%|▋| 68/100 [00:48<00:21,  1.49it\u001b[A\n",
      "Average Metric: 34.78333333333333 / 69  (50.4):  68%|▋| 68/100 [00:48<00:21,  1.49it\u001b[A\n",
      "Average Metric: 34.78333333333333 / 69  (50.4):  69%|▋| 69/100 [00:48<00:18,  1.63it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 17.1 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.78333333333333 / 70  (49.7):  69%|▋| 69/100 [00:49<00:18,  1.63it\u001b[A\n",
      "Average Metric: 34.78333333333333 / 70  (49.7):  70%|▋| 70/100 [00:49<00:21,  1.40it\u001b[A\n",
      "Average Metric: 35.78333333333333 / 71  (50.4):  70%|▋| 70/100 [00:49<00:21,  1.40it\u001b[A\n",
      "Average Metric: 35.78333333333333 / 71  (50.4):  71%|▋| 71/100 [00:49<00:19,  1.51it\u001b[A\n",
      "Average Metric: 36.53333333333333 / 72  (50.7):  71%|▋| 71/100 [00:51<00:19,  1.51it\u001b[A\n",
      "Average Metric: 36.53333333333333 / 72  (50.7):  72%|▋| 72/100 [00:51<00:22,  1.23it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.86666666666667 / 73  (50.5):  72%|▋| 72/100 [00:51<00:22,  1.23it\u001b[A\n",
      "Average Metric: 36.86666666666667 / 73  (50.5):  73%|▋| 73/100 [00:51<00:19,  1.41it\u001b[A\n",
      "Average Metric: 37.86666666666667 / 74  (51.2):  73%|▋| 73/100 [00:52<00:19,  1.41it\u001b[A\n",
      "Average Metric: 37.86666666666667 / 74  (51.2):  74%|▋| 74/100 [00:52<00:17,  1.46it\u001b[A\n",
      "Average Metric: 38.2 / 75  (50.9):  74%|████████▏  | 74/100 [00:53<00:17,  1.46it/s]\u001b[A\n",
      "Average Metric: 38.2 / 75  (50.9):  75%|████████▎  | 75/100 [00:53<00:18,  1.38it/s]\u001b[A\n",
      "Average Metric: 39.2 / 76  (51.6):  75%|████████▎  | 75/100 [00:53<00:18,  1.38it/s]\u001b[A\n",
      "Average Metric: 39.2 / 76  (51.6):  76%|████████▎  | 76/100 [00:53<00:14,  1.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.45 / 77  (51.2):  76%|███████▌  | 76/100 [00:54<00:14,  1.69it/s]\u001b[A\n",
      "Average Metric: 39.45 / 77  (51.2):  77%|███████▋  | 77/100 [00:54<00:17,  1.28it/s]\u001b[A\n",
      "Average Metric: 40.45 / 78  (51.9):  77%|███████▋  | 77/100 [00:54<00:17,  1.28it/s]\u001b[A\n",
      "Average Metric: 41.45 / 79  (52.5):  78%|███████▊  | 78/100 [00:56<00:17,  1.28it/s]\u001b[A\n",
      "Average Metric: 41.45 / 79  (52.5):  79%|███████▉  | 79/100 [00:56<00:16,  1.26it/s]\u001b[A\n",
      "Average Metric: 41.825 / 80  (52.3):  79%|███████  | 79/100 [00:56<00:16,  1.26it/s]\u001b[A\n",
      "Average Metric: 41.825 / 80  (52.3):  80%|███████▏ | 80/100 [00:56<00:14,  1.36it/s]\u001b[A\n",
      "Average Metric: 42.825 / 81  (52.9):  80%|███████▏ | 80/100 [00:57<00:14,  1.36it/s]\u001b[A\n",
      "Average Metric: 42.825 / 81  (52.9):  81%|███████▎ | 81/100 [00:57<00:11,  1.60it/s]\u001b[A\n",
      "Average Metric: 43.49166666666667 / 82  (53.0):  81%|▊| 81/100 [00:57<00:11,  1.60it\u001b[A\n",
      "Average Metric: 43.49166666666667 / 82  (53.0):  82%|▊| 82/100 [00:57<00:12,  1.50it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 44.0 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.49166666666667 / 83  (52.4):  82%|▊| 82/100 [00:58<00:12,  1.50it\u001b[A\n",
      "Average Metric: 43.49166666666667 / 83  (52.4):  83%|▊| 83/100 [00:58<00:11,  1.46it\u001b[A\n",
      "Average Metric: 44.49166666666667 / 84  (53.0):  83%|▊| 83/100 [00:59<00:11,  1.46it\u001b[A\n",
      "Average Metric: 44.49166666666667 / 84  (53.0):  84%|▊| 84/100 [00:59<00:10,  1.53it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 21.8 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.49166666666667 / 85  (53.5):  84%|▊| 84/100 [01:00<00:10,  1.53it\u001b[A\n",
      "Average Metric: 45.49166666666667 / 85  (53.5):  85%|▊| 85/100 [01:01<00:15,  1.01s/\u001b[A\n",
      "Average Metric: 45.74166666666667 / 86  (53.2):  85%|▊| 85/100 [01:01<00:15,  1.01s/\u001b[A\n",
      "Average Metric: 45.74166666666667 / 86  (53.2):  86%|▊| 86/100 [01:01<00:12,  1.15it\u001b[A\n",
      "Average Metric: 46.74166666666667 / 87  (53.7):  86%|▊| 86/100 [01:01<00:12,  1.15it\u001b[A\n",
      "Average Metric: 46.74166666666667 / 87  (53.7):  87%|▊| 87/100 [01:01<00:09,  1.41it\u001b[A\n",
      "Average Metric: 47.74166666666667 / 88  (54.3):  87%|▊| 87/100 [01:02<00:09,  1.41it\u001b[A\n",
      "Average Metric: 47.74166666666667 / 88  (54.3):  88%|▉| 88/100 [01:03<00:10,  1.20it\u001b[A\n",
      "Average Metric: 48.74166666666667 / 89  (54.8):  88%|▉| 88/100 [01:03<00:10,  1.20it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.74166666666667 / 90  (55.3):  89%|▉| 89/100 [01:04<00:09,  1.20it\u001b[A\n",
      "Average Metric: 49.74166666666667 / 90  (55.3):  90%|▉| 90/100 [01:04<00:07,  1.38it\u001b[A\n",
      "Average Metric: 50.74166666666667 / 91  (55.8):  90%|▉| 90/100 [01:05<00:07,  1.38it\u001b[A\n",
      "Average Metric: 50.74166666666667 / 91  (55.8):  91%|▉| 91/100 [01:05<00:06,  1.29it\u001b[A\n",
      "Average Metric: 51.74166666666667 / 92  (56.2):  91%|▉| 91/100 [01:06<00:06,  1.29it\u001b[A\n",
      "Average Metric: 51.74166666666667 / 92  (56.2):  92%|▉| 92/100 [01:06<00:07,  1.06it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 101.7 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.24166666666667 / 93  (56.2):  92%|▉| 92/100 [01:07<00:07,  1.06it\u001b[A\n",
      "Average Metric: 52.24166666666667 / 93  (56.2):  93%|▉| 93/100 [01:07<00:07,  1.04s/\u001b[A\n",
      "Average Metric: 52.575 / 94  (55.9):  93%|████████▎| 93/100 [01:08<00:07,  1.04s/it]\u001b[A\n",
      "Average Metric: 52.575 / 94  (55.9):  94%|████████▍| 94/100 [01:08<00:06,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 53.575 / 95  (56.4):  94%|████████▍| 94/100 [01:09<00:06,  1.04s/it]\u001b[A\n",
      "Average Metric: 53.575 / 95  (56.4):  95%|████████▌| 95/100 [01:09<00:04,  1.01it/s]\u001b[A\n",
      "Average Metric: 54.075 / 96  (56.3):  95%|████████▌| 95/100 [01:10<00:04,  1.01it/s]\u001b[A\n",
      "Average Metric: 54.075 / 96  (56.3):  96%|████████▋| 96/100 [01:10<00:04,  1.06s/it]\u001b[A\n",
      "Average Metric: 55.075 / 97  (56.8):  96%|████████▋| 96/100 [01:11<00:04,  1.06s/it]\u001b[A\n",
      "Average Metric: 55.075 / 97  (56.8):  97%|████████▋| 97/100 [01:11<00:02,  1.02it/s]\u001b[A\n",
      "Average Metric: 55.575 / 98  (56.7):  97%|████████▋| 97/100 [01:22<00:02,  1.02it/s]\u001b[A\n",
      "Average Metric: 55.575 / 98  (56.7):  98%|████████▊| 98/100 [01:22<00:07,  3.90s/it]\u001b[A\n",
      "Average Metric: 55.90833333333334 / 99  (56.5):  98%|▉| 98/100 [01:43<00:07,  3.90s/\u001b[A\n",
      "Average Metric: 55.90833333333334 / 99  (56.5):  99%|▉| 99/100 [01:43<00:08,  8.89s/\u001b[A\n",
      "Average Metric: 56.90833333333334 / 100  (56.9):  99%|▉| 99/100 [02:50<00:08,  8.89s\u001b[A\n",
      "Average Metric: 56.90833333333334 / 100  (56.9): 100%|█| 100/100 [02:50<00:00,  1.71\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.90833333333334 / 100  (56.9%)\n",
      "Score: 56.91 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8560833333333333\n",
      "Average of max per entry across top 5 scores: 0.9283333333333332\n",
      "Average of max per entry across top 8 scores: 0.9725\n",
      "Average of max per entry across top 9999 scores: 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:13,  1.35s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:02<02:15,  1.38s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:04<02:30,  1.55s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:05<02:19,  1.46s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                      | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   1%|▏             | 1/100 [00:01<01:57,  1.18s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   1%|▏             | 1/100 [00:01<01:57,  1.18s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   2%|▎             | 2/100 [00:01<01:04,  1.53it/s]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   2%|▎             | 2/100 [00:01<01:04,  1.53it/s]\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):   3%| | 3/100 [00:01<01:03,  1.53it/\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):   4%| | 4/100 [00:01<01:02,  1.53it/\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):   5%| | 5/100 [00:01<00:21,  4.38it/\u001b[A\n",
      "Average Metric: 2.6333333333333333 / 6  (43.9):   5%| | 5/100 [00:01<00:21,  4.38it/\u001b[A\n",
      "Average Metric: 2.6333333333333333 / 6  (43.9):   6%| | 6/100 [00:01<00:21,  4.39it/\u001b[A\n",
      "Average Metric: 2.6333333333333333 / 7  (37.6):   6%| | 6/100 [00:02<00:21,  4.39it/\u001b[A\n",
      "Average Metric: 2.6333333333333333 / 7  (37.6):   7%| | 7/100 [00:02<00:20,  4.53it/\u001b[A\n",
      "Average Metric: 3.3 / 8  (41.2):   7%|▉             | 7/100 [00:02<00:20,  4.53it/s]\u001b[A\n",
      "Average Metric: 3.3 / 8  (41.2):   8%|█             | 8/100 [00:02<00:37,  2.45it/s]\u001b[A\n",
      "Average Metric: 3.6333333333333333 / 9  (40.4):   8%| | 8/100 [00:02<00:37,  2.45it/\u001b[A\n",
      "Average Metric: 4.633333333333333 / 10  (46.3):   9%| | 9/100 [00:03<00:37,  2.45it/\u001b[A\n",
      "Average Metric: 4.633333333333333 / 10  (46.3):  10%| | 10/100 [00:03<00:24,  3.75it\u001b[A\n",
      "Average Metric: 4.883333333333333 / 11  (44.4):  10%| | 10/100 [00:03<00:24,  3.75it\u001b[A\n",
      "Average Metric: 4.883333333333333 / 11  (44.4):  11%| | 11/100 [00:03<00:26,  3.38it\u001b[A\n",
      "Average Metric: 5.105555555555555 / 12  (42.5):  11%| | 11/100 [00:03<00:26,  3.38it\u001b[A\n",
      "Average Metric: 5.105555555555555 / 12  (42.5):  12%| | 12/100 [00:03<00:22,  3.87it\u001b[A\n",
      "Average Metric: 5.305555555555555 / 13  (40.8):  12%| | 12/100 [00:04<00:22,  3.87it\u001b[A\n",
      "Average Metric: 5.305555555555555 / 13  (40.8):  13%|▏| 13/100 [00:04<00:24,  3.56it\u001b[A\n",
      "Average Metric: 6.305555555555555 / 14  (45.0):  13%|▏| 13/100 [00:04<00:24,  3.56it\u001b[A\n",
      "Average Metric: 7.305555555555555 / 15  (48.7):  14%|▏| 14/100 [00:04<00:24,  3.56it\u001b[A\n",
      "Average Metric: 7.305555555555555 / 15  (48.7):  15%|▏| 15/100 [00:04<00:28,  2.93it\u001b[A\n",
      "Average Metric: 7.905555555555555 / 16  (49.4):  15%|▏| 15/100 [00:04<00:28,  2.93it\u001b[A\n",
      "Average Metric: 8.238888888888889 / 17  (48.5):  16%|▏| 16/100 [00:05<00:28,  2.93it\u001b[A\n",
      "Average Metric: 8.238888888888889 / 17  (48.5):  17%|▏| 17/100 [00:05<00:21,  3.92it\u001b[A\n",
      "Average Metric: 8.572222222222223 / 18  (47.6):  17%|▏| 17/100 [00:05<00:21,  3.92it\u001b[A\n",
      "Average Metric: 8.572222222222223 / 18  (47.6):  18%|▏| 18/100 [00:05<00:20,  3.96it\u001b[A\n",
      "Average Metric: 8.772222222222222 / 19  (46.2):  18%|▏| 18/100 [00:05<00:20,  3.96it\u001b[A\n",
      "Average Metric: 8.772222222222222 / 19  (46.2):  19%|▏| 19/100 [00:05<00:20,  3.97it\u001b[A\n",
      "Average Metric: 8.772222222222222 / 20  (43.9):  19%|▏| 19/100 [00:05<00:20,  3.97it\u001b[A\n",
      "Average Metric: 9.772222222222222 / 21  (46.5):  20%|▏| 20/100 [00:05<00:20,  3.97it\u001b[A\n",
      "Average Metric: 9.772222222222222 / 21  (46.5):  21%|▏| 21/100 [00:05<00:18,  4.37it\u001b[A\n",
      "Average Metric: 9.772222222222222 / 22  (44.4):  21%|▏| 21/100 [00:06<00:18,  4.37it\u001b[A\n",
      "Average Metric: 10.772222222222222 / 23  (46.8):  22%|▏| 22/100 [00:06<00:17,  4.37i\u001b[A\n",
      "Average Metric: 10.772222222222222 / 23  (46.8):  23%|▏| 23/100 [00:06<00:19,  3.91i\u001b[A\n",
      "Average Metric: 11.772222222222222 / 24  (49.1):  23%|▏| 23/100 [00:06<00:19,  3.91i\u001b[A\n",
      "Average Metric: 11.772222222222222 / 24  (49.1):  24%|▏| 24/100 [00:06<00:17,  4.30i\u001b[A\n",
      "Average Metric: 12.272222222222222 / 25  (49.1):  24%|▏| 24/100 [00:06<00:17,  4.30i\u001b[A\n",
      "Average Metric: 13.272222222222222 / 26  (51.0):  25%|▎| 25/100 [00:07<00:17,  4.30i\u001b[A\n",
      "Average Metric: 13.272222222222222 / 26  (51.0):  26%|▎| 26/100 [00:07<00:16,  4.60i\u001b[A\n",
      "Average Metric: 13.272222222222222 / 27  (49.2):  26%|▎| 26/100 [00:07<00:16,  4.60i\u001b[A\n",
      "Average Metric: 13.272222222222222 / 27  (49.2):  27%|▎| 27/100 [00:07<00:15,  4.81i\u001b[A\n",
      "Average Metric: 13.272222222222222 / 28  (47.4):  27%|▎| 27/100 [00:07<00:15,  4.81i\u001b[A\n",
      "Average Metric: 13.938888888888888 / 29  (48.1):  28%|▎| 28/100 [00:07<00:14,  4.81i\u001b[A\n",
      "Average Metric: 14.438888888888888 / 30  (48.1):  29%|▎| 29/100 [00:08<00:14,  4.81i\u001b[A\n",
      "Average Metric: 14.438888888888888 / 30  (48.1):  30%|▎| 30/100 [00:08<00:17,  4.03i\u001b[A\n",
      "Average Metric: 14.438888888888888 / 31  (46.6):  30%|▎| 30/100 [00:08<00:17,  4.03i\u001b[A\n",
      "Average Metric: 14.438888888888888 / 31  (46.6):  31%|▎| 31/100 [00:08<00:22,  3.04i\u001b[A\n",
      "Average Metric: 14.938888888888888 / 32  (46.7):  31%|▎| 31/100 [00:08<00:22,  3.04i\u001b[A\n",
      "Average Metric: 15.338888888888889 / 33  (46.5):  32%|▎| 32/100 [00:09<00:22,  3.04i\u001b[A\n",
      "Average Metric: 15.338888888888889 / 33  (46.5):  33%|▎| 33/100 [00:09<00:17,  3.88i\u001b[A\n",
      "Average Metric: 15.538888888888888 / 34  (45.7):  33%|▎| 33/100 [00:09<00:17,  3.88i\u001b[A\n",
      "Average Metric: 16.538888888888888 / 35  (47.3):  34%|▎| 34/100 [00:10<00:17,  3.88i\u001b[A\n",
      "Average Metric: 16.538888888888888 / 35  (47.3):  35%|▎| 35/100 [00:10<00:21,  3.01i\u001b[A\n",
      "Average Metric: 16.87222222222222 / 36  (46.9):  35%|▎| 35/100 [00:10<00:21,  3.01it\u001b[A\n",
      "Average Metric: 17.37222222222222 / 37  (47.0):  36%|▎| 36/100 [00:10<00:21,  3.01it\u001b[A\n",
      "Average Metric: 17.37222222222222 / 37  (47.0):  37%|▎| 37/100 [00:10<00:15,  4.08it\u001b[A\n",
      "Average Metric: 17.87222222222222 / 38  (47.0):  37%|▎| 37/100 [00:10<00:15,  4.08it\u001b[A\n",
      "Average Metric: 17.87222222222222 / 38  (47.0):  38%|▍| 38/100 [00:10<00:15,  3.91it\u001b[A\n",
      "Average Metric: 18.538888888888888 / 39  (47.5):  38%|▍| 38/100 [00:10<00:15,  3.91i\u001b[A\n",
      "Average Metric: 18.538888888888888 / 40  (46.3):  39%|▍| 39/100 [00:10<00:15,  3.91i\u001b[A\n",
      "Average Metric: 18.538888888888888 / 40  (46.3):  40%|▍| 40/100 [00:10<00:14,  4.28i\u001b[A\n",
      "Average Metric: 19.038888888888888 / 41  (46.4):  40%|▍| 40/100 [00:11<00:14,  4.28i\u001b[A\n",
      "Average Metric: 19.038888888888888 / 41  (46.4):  41%|▍| 41/100 [00:11<00:14,  4.03i\u001b[A\n",
      "Average Metric: 19.37222222222222 / 42  (46.1):  41%|▍| 41/100 [00:11<00:14,  4.03it\u001b[A\n",
      "Average Metric: 19.37222222222222 / 42  (46.1):  42%|▍| 42/100 [00:11<00:14,  4.13it\u001b[A\n",
      "Average Metric: 20.37222222222222 / 43  (47.4):  42%|▍| 42/100 [00:11<00:14,  4.13it\u001b[A\n",
      "Average Metric: 20.37222222222222 / 43  (47.4):  43%|▍| 43/100 [00:11<00:12,  4.66it\u001b[A\n",
      "Average Metric: 20.87222222222222 / 44  (47.4):  43%|▍| 43/100 [00:11<00:12,  4.66it\u001b[A\n",
      "Average Metric: 21.87222222222222 / 45  (48.6):  44%|▍| 44/100 [00:11<00:12,  4.66it\u001b[A\n",
      "Average Metric: 21.87222222222222 / 45  (48.6):  45%|▍| 45/100 [00:11<00:10,  5.09it\u001b[A\n",
      "Average Metric: 21.87222222222222 / 46  (47.5):  45%|▍| 45/100 [00:12<00:10,  5.09it\u001b[A\n",
      "Average Metric: 21.87222222222222 / 46  (47.5):  46%|▍| 46/100 [00:12<00:13,  4.15it\u001b[A\n",
      "Average Metric: 22.87222222222222 / 47  (48.7):  46%|▍| 46/100 [00:12<00:13,  4.15it\u001b[A\n",
      "Average Metric: 22.87222222222222 / 47  (48.7):  47%|▍| 47/100 [00:12<00:13,  3.98it\u001b[A\n",
      "Average Metric: 23.37222222222222 / 48  (48.7):  47%|▍| 47/100 [00:12<00:13,  3.98it\u001b[A\n",
      "Average Metric: 23.37222222222222 / 48  (48.7):  48%|▍| 48/100 [00:12<00:11,  4.62it\u001b[A\n",
      "Average Metric: 23.87222222222222 / 49  (48.7):  48%|▍| 48/100 [00:12<00:11,  4.62it\u001b[A\n",
      "Average Metric: 23.87222222222222 / 49  (48.7):  49%|▍| 49/100 [00:12<00:10,  4.81it\u001b[A\n",
      "Average Metric: 23.87222222222222 / 50  (47.7):  49%|▍| 49/100 [00:12<00:10,  4.81it\u001b[A\n",
      "Average Metric: 24.205555555555552 / 51  (47.5):  50%|▌| 50/100 [00:13<00:10,  4.81i\u001b[A\n",
      "Average Metric: 24.205555555555552 / 51  (47.5):  51%|▌| 51/100 [00:13<00:08,  5.93i\u001b[A\n",
      "Average Metric: 25.205555555555552 / 52  (48.5):  51%|▌| 51/100 [00:13<00:08,  5.93i\u001b[A\n",
      "Average Metric: 25.205555555555552 / 52  (48.5):  52%|▌| 52/100 [00:13<00:10,  4.39i\u001b[A\n",
      "Average Metric: 26.205555555555552 / 53  (49.4):  52%|▌| 52/100 [00:13<00:10,  4.39i\u001b[A\n",
      "Average Metric: 26.205555555555552 / 53  (49.4):  53%|▌| 53/100 [00:13<00:12,  3.85i\u001b[A\n",
      "Average Metric: 26.705555555555552 / 54  (49.5):  53%|▌| 53/100 [00:13<00:12,  3.85i\u001b[A\n",
      "Average Metric: 26.705555555555552 / 54  (49.5):  54%|▌| 54/100 [00:13<00:10,  4.53i\u001b[A\n",
      "Average Metric: 27.038888888888884 / 55  (49.2):  54%|▌| 54/100 [00:13<00:10,  4.53i\u001b[A\n",
      "Average Metric: 28.038888888888884 / 56  (50.1):  55%|▌| 55/100 [00:14<00:09,  4.53i\u001b[A\n",
      "Average Metric: 28.038888888888884 / 56  (50.1):  56%|▌| 56/100 [00:14<00:08,  5.14i\u001b[A\n",
      "Average Metric: 29.038888888888884 / 57  (50.9):  56%|▌| 56/100 [00:14<00:08,  5.14i\u001b[A\n",
      "Average Metric: 29.038888888888884 / 57  (50.9):  57%|▌| 57/100 [00:14<00:07,  5.43i\u001b[A\n",
      "Average Metric: 29.038888888888884 / 58  (50.1):  57%|▌| 57/100 [00:14<00:07,  5.43i\u001b[A\n",
      "Average Metric: 29.038888888888884 / 58  (50.1):  58%|▌| 58/100 [00:14<00:09,  4.38i\u001b[A\n",
      "Average Metric: 30.038888888888884 / 59  (50.9):  58%|▌| 58/100 [00:14<00:09,  4.38i\u001b[A\n",
      "Average Metric: 30.038888888888884 / 60  (50.1):  59%|▌| 59/100 [00:15<00:09,  4.38i\u001b[A\n",
      "Average Metric: 30.038888888888884 / 60  (50.1):  60%|▌| 60/100 [00:15<00:07,  5.54i\u001b[A\n",
      "Average Metric: 30.538888888888884 / 61  (50.1):  60%|▌| 60/100 [00:15<00:07,  5.54i\u001b[A\n",
      "Average Metric: 30.538888888888884 / 61  (50.1):  61%|▌| 61/100 [00:15<00:07,  5.37i\u001b[A\n",
      "Average Metric: 30.538888888888884 / 62  (49.3):  61%|▌| 61/100 [00:15<00:07,  5.37i\u001b[A\n",
      "Average Metric: 30.538888888888884 / 62  (49.3):  62%|▌| 62/100 [00:15<00:06,  6.04i\u001b[A\n",
      "Average Metric: 30.538888888888884 / 63  (48.5):  62%|▌| 62/100 [00:15<00:06,  6.04i\u001b[A\n",
      "Average Metric: 30.872222222222216 / 64  (48.2):  63%|▋| 63/100 [00:15<00:06,  6.04i\u001b[A\n",
      "Average Metric: 30.872222222222216 / 64  (48.2):  64%|▋| 64/100 [00:15<00:08,  4.46i\u001b[A\n",
      "Average Metric: 31.372222222222216 / 65  (48.3):  64%|▋| 64/100 [00:16<00:08,  4.46i\u001b[A\n",
      "Average Metric: 31.372222222222216 / 65  (48.3):  65%|▋| 65/100 [00:16<00:10,  3.45i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.37222222222222 / 66  (49.0):  65%|▋| 65/100 [00:16<00:10,  3.45it\u001b[A\n",
      "Average Metric: 32.37222222222222 / 66  (49.0):  66%|▋| 66/100 [00:16<00:10,  3.14it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.37222222222222 / 67  (49.8):  66%|▋| 66/100 [00:18<00:10,  3.14it\u001b[A\n",
      "Average Metric: 33.37222222222222 / 67  (49.8):  67%|▋| 67/100 [00:18<00:17,  1.88it\u001b[A\n",
      "Average Metric: 33.87222222222222 / 68  (49.8):  67%|▋| 67/100 [00:18<00:17,  1.88it\u001b[A\n",
      "Average Metric: 34.87222222222222 / 69  (50.5):  68%|▋| 68/100 [00:18<00:17,  1.88it\u001b[A\n",
      "Average Metric: 34.87222222222222 / 69  (50.5):  69%|▋| 69/100 [00:18<00:14,  2.16it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.205555555555556 / 70  (50.3):  69%|▋| 69/100 [00:20<00:14,  2.16i\u001b[A\n",
      "Average Metric: 35.205555555555556 / 70  (50.3):  70%|▋| 70/100 [00:20<00:21,  1.38i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.455555555555556 / 71  (49.9):  70%|▋| 70/100 [00:21<00:21,  1.38i\u001b[A\n",
      "Average Metric: 35.455555555555556 / 71  (49.9):  71%|▋| 71/100 [00:21<00:23,  1.22i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.455555555555556 / 72  (49.2):  71%|▋| 71/100 [00:23<00:23,  1.22i\u001b[A\n",
      "Average Metric: 35.455555555555556 / 72  (49.2):  72%|▋| 72/100 [00:23<00:31,  1.13s\u001b[A\n",
      "Average Metric: 35.78888888888889 / 73  (49.0):  72%|▋| 72/100 [00:23<00:31,  1.13s/\u001b[A\n",
      "Average Metric: 35.78888888888889 / 73  (49.0):  73%|▋| 73/100 [00:23<00:23,  1.15it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.12222222222223 / 74  (48.8):  73%|▋| 73/100 [00:24<00:23,  1.15it\u001b[A\n",
      "Average Metric: 36.12222222222223 / 74  (48.8):  74%|▋| 74/100 [00:24<00:24,  1.05it\u001b[A\n",
      "Average Metric: 36.12222222222223 / 75  (48.2):  74%|▋| 74/100 [00:25<00:24,  1.05it\u001b[A\n",
      "Average Metric: 36.12222222222223 / 75  (48.2):  75%|▊| 75/100 [00:25<00:25,  1.01s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.37222222222223 / 76  (47.9):  75%|▊| 75/100 [00:28<00:25,  1.01s/\u001b[A\n",
      "Average Metric: 36.37222222222223 / 76  (47.9):  76%|▊| 76/100 [00:28<00:31,  1.32s/\u001b[A\n",
      "Average Metric: 36.37222222222223 / 77  (47.2):  76%|▊| 76/100 [00:28<00:31,  1.32s/\u001b[A\n",
      "Average Metric: 36.37222222222223 / 77  (47.2):  77%|▊| 77/100 [00:28<00:22,  1.01it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.37222222222223 / 78  (47.9):  77%|▊| 77/100 [00:30<00:22,  1.01it\u001b[A\n",
      "Average Metric: 37.37222222222223 / 78  (47.9):  78%|▊| 78/100 [00:30<00:27,  1.25s/\u001b[A\n",
      "Average Metric: 38.37222222222223 / 79  (48.6):  78%|▊| 78/100 [00:30<00:27,  1.25s/\u001b[A\n",
      "Average Metric: 38.37222222222223 / 79  (48.6):  79%|▊| 79/100 [00:30<00:20,  1.01it\u001b[A\n",
      "Average Metric: 39.37222222222223 / 80  (49.2):  79%|▊| 79/100 [00:31<00:20,  1.01it\u001b[A\n",
      "Average Metric: 39.37222222222223 / 80  (49.2):  80%|▊| 80/100 [00:31<00:19,  1.05it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.37222222222223 / 81  (49.8):  80%|▊| 80/100 [00:32<00:19,  1.05it\u001b[A\n",
      "Average Metric: 40.37222222222223 / 81  (49.8):  81%|▊| 81/100 [00:32<00:17,  1.11it\u001b[A\n",
      "Average Metric: 41.03888888888889 / 82  (50.0):  81%|▊| 81/100 [00:33<00:17,  1.11it\u001b[A\n",
      "Average Metric: 41.03888888888889 / 82  (50.0):  82%|▊| 82/100 [00:33<00:19,  1.06s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 15.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.03888888888889 / 83  (49.4):  82%|▊| 82/100 [00:34<00:19,  1.06s/\u001b[A\n",
      "Average Metric: 41.03888888888889 / 83  (49.4):  83%|▊| 83/100 [00:34<00:17,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.03888888888889 / 84  (50.0):  83%|▊| 83/100 [00:35<00:17,  1.05s/\u001b[A\n",
      "Average Metric: 42.03888888888889 / 84  (50.0):  84%|▊| 84/100 [00:35<00:14,  1.09it\u001b[A\n",
      "Average Metric: 42.03888888888889 / 85  (49.5):  84%|▊| 84/100 [00:36<00:14,  1.09it\u001b[A\n",
      "Average Metric: 42.03888888888889 / 85  (49.5):  85%|▊| 85/100 [00:36<00:13,  1.09it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.03888888888889 / 86  (50.0):  85%|▊| 85/100 [00:36<00:13,  1.09it\u001b[A\n",
      "Average Metric: 43.03888888888889 / 86  (50.0):  86%|▊| 86/100 [00:36<00:11,  1.21it\u001b[A\n",
      "Average Metric: 44.03888888888889 / 87  (50.6):  86%|▊| 86/100 [00:37<00:11,  1.21it\u001b[A\n",
      "Average Metric: 44.03888888888889 / 87  (50.6):  87%|▊| 87/100 [00:37<00:10,  1.24it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.03888888888889 / 88  (51.2):  87%|▊| 87/100 [00:38<00:10,  1.24it\u001b[A\n",
      "Average Metric: 45.03888888888889 / 88  (51.2):  88%|▉| 88/100 [00:38<00:09,  1.33it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46.03888888888889 / 89  (51.7):  88%|▉| 88/100 [00:39<00:09,  1.33it\u001b[A\n",
      "Average Metric: 46.03888888888889 / 89  (51.7):  89%|▉| 89/100 [00:39<00:11,  1.08s/\u001b[A\n",
      "Average Metric: 46.28888888888889 / 90  (51.4):  89%|▉| 89/100 [00:39<00:11,  1.08s/\u001b[A\n",
      "Average Metric: 46.53888888888889 / 91  (51.1):  90%|▉| 90/100 [00:41<00:10,  1.08s/\u001b[A\n",
      "Average Metric: 46.53888888888889 / 91  (51.1):  91%|▉| 91/100 [00:41<00:07,  1.13it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.53888888888889 / 92  (51.7):  91%|▉| 91/100 [00:42<00:07,  1.13it\u001b[A\n",
      "Average Metric: 47.53888888888889 / 92  (51.7):  92%|▉| 92/100 [00:42<00:07,  1.04it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 48.53888888888889 / 93  (52.2):  92%|▉| 92/100 [00:44<00:07,  1.04it\u001b[A\n",
      "Average Metric: 48.53888888888889 / 93  (52.2):  93%|▉| 93/100 [00:44<00:08,  1.18s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.28888888888889 / 94  (52.4):  93%|▉| 93/100 [00:44<00:08,  1.18s/\u001b[A\n",
      "Average Metric: 49.28888888888889 / 94  (52.4):  94%|▉| 94/100 [00:44<00:05,  1.08it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.78888888888889 / 95  (52.4):  94%|▉| 94/100 [00:46<00:05,  1.08it\u001b[A\n",
      "Average Metric: 49.78888888888889 / 95  (52.4):  95%|▉| 95/100 [00:46<00:06,  1.28s/\u001b[A\n",
      "Average Metric: 49.78888888888889 / 96  (51.9):  95%|▉| 95/100 [00:47<00:06,  1.28s/\u001b[A\n",
      "Average Metric: 49.78888888888889 / 96  (51.9):  96%|▉| 96/100 [00:47<00:04,  1.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.78888888888889 / 97  (52.4):  96%|▉| 96/100 [00:48<00:04,  1.02s/\u001b[A\n",
      "Average Metric: 50.78888888888889 / 97  (52.4):  97%|▉| 97/100 [00:48<00:03,  1.29s/\u001b[A\n",
      "Average Metric: 51.28888888888889 / 98  (52.3):  97%|▉| 97/100 [00:49<00:03,  1.29s/\u001b[A\n",
      "Average Metric: 51.28888888888889 / 98  (52.3):  98%|▉| 98/100 [00:49<00:02,  1.01s/\u001b[A\n",
      "Average Metric: 51.62222222222223 / 99  (52.1):  98%|▉| 98/100 [00:51<00:02,  1.01s/\u001b[A\n",
      "Average Metric: 51.62222222222223 / 99  (52.1):  99%|▉| 99/100 [00:51<00:01,  1.23s/\u001b[A\n",
      "Average Metric: 52.12222222222223 / 100  (52.1):  99%|▉| 99/100 [00:52<00:01,  1.23s\u001b[A\n",
      "Average Metric: 52.12222222222223 / 100  (52.1): 100%|█| 100/100 [00:52<00:00,  1.91\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 52.12222222222223 / 100  (52.1%)\n",
      "Score: 52.12 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8560833333333333\n",
      "Average of max per entry across top 5 scores: 0.9283333333333332\n",
      "Average of max per entry across top 8 scores: 0.9749999999999999\n",
      "Average of max per entry across top 9999 scores: 0.9825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:14,  1.35s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:03<03:25,  2.09s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:05<02:42,  1.67s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:06<02:30,  1.57s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:09<03:07,  1.97s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:10<02:39,  1.70s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:11<02:21,  1.52s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:12<02:09,  1.41s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:16<03:20,  2.20s/it]\u001b[A\n",
      " 10%|████▌                                         | 10/100 [00:17<02:52,  1.91s/it]\u001b[A\n",
      " 11%|█████                                         | 11/100 [00:20<02:56,  1.99s/it]\u001b[A\n",
      " 12%|█████▌                                        | 12/100 [00:21<02:40,  1.82s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                     | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   1%|▏            | 1/100 [00:01<01:47,  1.09s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   1%|▏             | 1/100 [00:01<01:47,  1.09s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   2%|▎             | 2/100 [00:01<01:46,  1.09s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   3%|▍             | 3/100 [00:01<00:36,  2.69it/s]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):   3%|▍             | 3/100 [00:01<00:36,  2.69it/s]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):   4%|▌             | 4/100 [00:01<00:29,  3.27it/s]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):   4%|▌             | 4/100 [00:01<00:29,  3.27it/s]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):   5%|▋             | 5/100 [00:01<00:32,  2.95it/s]\u001b[A\n",
      "Average Metric: 2.5 / 6  (41.7):   5%|▋             | 5/100 [00:02<00:32,  2.95it/s]\u001b[A\n",
      "Average Metric: 2.5 / 6  (41.7):   6%|▊             | 6/100 [00:02<00:31,  2.94it/s]\u001b[A\n",
      "Average Metric: 2.5 / 7  (35.7):   6%|▊             | 6/100 [00:03<00:31,  2.94it/s]\u001b[A\n",
      "Average Metric: 2.5 / 7  (35.7):   7%|▉             | 7/100 [00:03<00:49,  1.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.8333333333333335 / 8  (35.4):   7%| | 7/100 [00:03<00:49,  1.88it/\u001b[A\n",
      "Average Metric: 2.8333333333333335 / 8  (35.4):   8%| | 8/100 [00:03<00:46,  1.98it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8333333333333335 / 9  (42.6):   8%| | 8/100 [00:05<00:46,  1.98it/\u001b[A\n",
      "Average Metric: 3.8333333333333335 / 9  (42.6):   9%| | 9/100 [00:05<01:12,  1.25it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.833333333333334 / 10  (48.3):   9%| | 9/100 [00:05<01:12,  1.25it/\u001b[A\n",
      "Average Metric: 4.833333333333334 / 10  (48.3):  10%| | 10/100 [00:05<01:09,  1.30it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.833333333333334 / 11  (43.9):  10%| | 10/100 [00:06<01:09,  1.30it\u001b[A\n",
      "Average Metric: 4.833333333333334 / 11  (43.9):  11%| | 11/100 [00:06<01:05,  1.36it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.333333333333334 / 12  (44.4):  11%| | 11/100 [00:08<01:05,  1.36it\u001b[A\n",
      "Average Metric: 5.333333333333334 / 12  (44.4):  12%| | 12/100 [00:08<01:37,  1.10s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.333333333333334 / 13  (48.7):  12%| | 12/100 [00:09<01:37,  1.10s/\u001b[A\n",
      "Average Metric: 6.333333333333334 / 13  (48.7):  13%|▏| 13/100 [00:09<01:40,  1.16s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.533333333333334 / 14  (46.7):  13%|▏| 13/100 [00:11<01:40,  1.16s/\u001b[A\n",
      "Average Metric: 6.533333333333334 / 14  (46.7):  14%|▏| 14/100 [00:11<01:51,  1.29s/\u001b[A\n",
      "Average Metric: 6.866666666666667 / 15  (45.8):  14%|▏| 14/100 [00:11<01:51,  1.29s/\u001b[A\n",
      "Average Metric: 6.866666666666667 / 15  (45.8):  15%|▏| 15/100 [00:11<01:20,  1.06it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.366666666666667 / 16  (46.0):  15%|▏| 15/100 [00:12<01:20,  1.06it\u001b[A\n",
      "Average Metric: 7.366666666666667 / 16  (46.0):  16%|▏| 16/100 [00:12<01:28,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.366666666666667 / 17  (43.3):  16%|▏| 16/100 [00:13<01:28,  1.05s/\u001b[A\n",
      "Average Metric: 7.366666666666667 / 17  (43.3):  17%|▏| 17/100 [00:13<01:24,  1.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.866666666666667 / 18  (43.7):  17%|▏| 17/100 [00:15<01:24,  1.02s/\u001b[A\n",
      "Average Metric: 7.866666666666667 / 18  (43.7):  18%|▏| 18/100 [00:15<01:43,  1.26s/\u001b[A\n",
      "Average Metric: 8.116666666666667 / 19  (42.7):  18%|▏| 18/100 [00:16<01:43,  1.26s/\u001b[A\n",
      "Average Metric: 8.116666666666667 / 19  (42.7):  19%|▏| 19/100 [00:16<01:40,  1.25s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.116666666666667 / 20  (40.6):  19%|▏| 19/100 [00:18<01:40,  1.25s/\u001b[A\n",
      "Average Metric: 8.116666666666667 / 20  (40.6):  20%|▏| 20/100 [00:18<01:51,  1.40s/\u001b[A\n",
      "Average Metric: 8.866666666666667 / 21  (42.2):  20%|▏| 20/100 [00:18<01:51,  1.40s/\u001b[A\n",
      "Average Metric: 8.866666666666667 / 21  (42.2):  21%|▏| 21/100 [00:18<01:20,  1.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.866666666666667 / 22  (44.8):  21%|▏| 21/100 [00:20<01:20,  1.02s/\u001b[A\n",
      "Average Metric: 9.866666666666667 / 22  (44.8):  22%|▏| 22/100 [00:20<01:35,  1.22s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 9.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.366666666666667 / 23  (45.1):  22%|▏| 22/100 [00:22<01:35,  1.22s\u001b[A\n",
      "Average Metric: 10.366666666666667 / 23  (45.1):  23%|▏| 23/100 [00:22<01:53,  1.48s\u001b[A\n",
      "Average Metric: 11.366666666666667 / 24  (47.4):  23%|▏| 23/100 [00:22<01:53,  1.48s\u001b[A\n",
      "Average Metric: 11.366666666666667 / 24  (47.4):  24%|▏| 24/100 [00:22<01:30,  1.20s\u001b[A\n",
      "Average Metric: 12.366666666666667 / 25  (49.5):  24%|▏| 24/100 [00:24<01:30,  1.20s\u001b[A\n",
      "Average Metric: 12.366666666666667 / 25  (49.5):  25%|▎| 25/100 [00:24<01:31,  1.22s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.366666666666667 / 26  (47.6):  25%|▎| 25/100 [00:25<01:31,  1.22s\u001b[A\n",
      "Average Metric: 12.366666666666667 / 26  (47.6):  26%|▎| 26/100 [00:25<01:26,  1.16s\u001b[A\n",
      "Average Metric: 12.700000000000001 / 27  (47.0):  26%|▎| 26/100 [00:27<01:26,  1.16s\u001b[A\n",
      "Average Metric: 12.700000000000001 / 27  (47.0):  27%|▎| 27/100 [00:27<01:40,  1.38s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.700000000000001 / 28  (48.9):  27%|▎| 27/100 [00:28<01:40,  1.38s\u001b[A\n",
      "Average Metric: 13.700000000000001 / 28  (48.9):  28%|▎| 28/100 [00:28<01:40,  1.40s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.950000000000001 / 29  (48.1):  28%|▎| 28/100 [00:30<01:40,  1.40s\u001b[A\n",
      "Average Metric: 13.950000000000001 / 29  (48.1):  29%|▎| 29/100 [00:30<01:40,  1.42s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.450000000000001 / 30  (48.2):  29%|▎| 29/100 [00:31<01:40,  1.42s\u001b[A\n",
      "Average Metric: 14.450000000000001 / 30  (48.2):  30%|▎| 30/100 [00:31<01:34,  1.35s\u001b[A\n",
      "Average Metric: 14.450000000000001 / 31  (46.6):  30%|▎| 30/100 [00:32<01:34,  1.35s\u001b[A\n",
      "Average Metric: 14.450000000000001 / 31  (46.6):  31%|▎| 31/100 [00:32<01:37,  1.42s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 24.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 43.1 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.450000000000001 / 32  (45.2):  31%|▎| 31/100 [00:34<01:37,  1.42s\u001b[A\n",
      "Average Metric: 14.450000000000001 / 32  (45.2):  32%|▎| 32/100 [00:34<01:39,  1.46s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.850000000000001 / 33  (45.0):  32%|▎| 32/100 [00:36<01:39,  1.46s\u001b[A\n",
      "Average Metric: 14.850000000000001 / 33  (45.0):  33%|▎| 33/100 [00:36<01:43,  1.55s\u001b[A\n",
      "Average Metric: 15.183333333333335 / 34  (44.7):  33%|▎| 33/100 [00:37<01:43,  1.55s\u001b[A\n",
      "Average Metric: 15.183333333333335 / 34  (44.7):  34%|▎| 34/100 [00:37<01:34,  1.43s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.0 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.850000000000001 / 35  (45.3):  34%|▎| 34/100 [00:38<01:34,  1.43s\u001b[A\n",
      "Average Metric: 15.850000000000001 / 35  (45.3):  35%|▎| 35/100 [00:38<01:35,  1.47s\u001b[A\n",
      "Average Metric: 16.35 / 36  (45.4):  35%|███▌      | 35/100 [00:38<01:35,  1.47s/it]\u001b[A\n",
      "Average Metric: 16.85 / 37  (45.5):  36%|███▌      | 36/100 [00:40<01:34,  1.47s/it]\u001b[A\n",
      "Average Metric: 16.85 / 37  (45.5):  37%|███▋      | 37/100 [00:40<01:13,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.85 / 38  (47.0):  37%|███▋      | 37/100 [00:41<01:13,  1.16s/it]\u001b[A\n",
      "Average Metric: 17.85 / 38  (47.0):  38%|███▊      | 38/100 [00:41<01:14,  1.21s/it]\u001b[A\n",
      "Average Metric: 18.35 / 39  (47.1):  38%|███▊      | 38/100 [00:42<01:14,  1.21s/it]\u001b[A\n",
      "Average Metric: 18.35 / 39  (47.1):  39%|███▉      | 39/100 [00:42<01:10,  1.16s/it]\u001b[A\n",
      "Average Metric: 19.35 / 40  (48.4):  39%|███▉      | 39/100 [00:44<01:10,  1.16s/it]\u001b[A\n",
      "Average Metric: 19.35 / 40  (48.4):  40%|████      | 40/100 [00:44<01:18,  1.30s/it]\u001b[A\n",
      "Average Metric: 20.35 / 41  (49.6):  40%|████      | 40/100 [00:44<01:18,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 30.1 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.01666666666667 / 42  (50.0):  41%|▍| 41/100 [00:46<01:16,  1.30s/\u001b[A\n",
      "Average Metric: 21.01666666666667 / 42  (50.0):  42%|▍| 42/100 [00:46<01:04,  1.11s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.51666666666667 / 43  (50.0):  42%|▍| 42/100 [00:47<01:04,  1.11s/\u001b[A\n",
      "Average Metric: 21.51666666666667 / 43  (50.0):  43%|▍| 43/100 [00:47<01:09,  1.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.51666666666667 / 44  (48.9):  43%|▍| 43/100 [00:49<01:09,  1.23s/\u001b[A\n",
      "Average Metric: 21.51666666666667 / 44  (48.9):  44%|▍| 44/100 [00:49<01:11,  1.27s/\u001b[A\n",
      "Average Metric: 22.51666666666667 / 45  (50.0):  44%|▍| 44/100 [00:50<01:11,  1.27s/\u001b[A\n",
      "Average Metric: 22.51666666666667 / 45  (50.0):  45%|▍| 45/100 [00:50<01:04,  1.18s/\u001b[A\n",
      "Average Metric: 22.85 / 46  (49.7):  45%|████▌     | 45/100 [00:51<01:04,  1.18s/it]\u001b[A\n",
      "Average Metric: 22.85 / 46  (49.7):  46%|████▌     | 46/100 [00:51<01:12,  1.34s/it]\u001b[A\n",
      "Average Metric: 23.85 / 47  (50.7):  46%|████▌     | 46/100 [00:54<01:12,  1.34s/it]\u001b[A\n",
      "Average Metric: 23.85 / 47  (50.7):  47%|████▋     | 47/100 [00:54<01:35,  1.80s/it]\u001b[A\n",
      "Average Metric: 24.35 / 48  (50.7):  47%|████▋     | 47/100 [00:54<01:35,  1.80s/it]\u001b[A\n",
      "Average Metric: 24.35 / 48  (50.7):  48%|████▊     | 48/100 [00:54<01:08,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.35 / 49  (51.7):  48%|████▊     | 48/100 [00:56<01:08,  1.32s/it]\u001b[A\n",
      "Average Metric: 25.35 / 49  (51.7):  49%|████▉     | 49/100 [00:56<01:14,  1.46s/it]\u001b[A\n",
      "Average Metric: 26.35 / 50  (52.7):  49%|████▉     | 49/100 [00:57<01:14,  1.46s/it]\u001b[A\n",
      "Average Metric: 26.35 / 50  (52.7):  50%|█████     | 50/100 [00:57<01:06,  1.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.6 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.55 / 51  (52.1):  50%|█████     | 50/100 [00:59<01:06,  1.34s/it]\u001b[A\n",
      "Average Metric: 26.55 / 51  (52.1):  51%|█████     | 51/100 [00:59<01:11,  1.46s/it]\u001b[A\n",
      "Average Metric: 27.55 / 52  (53.0):  51%|█████     | 51/100 [00:59<01:11,  1.46s/it]\u001b[A\n",
      "Average Metric: 27.55 / 52  (53.0):  52%|█████▏    | 52/100 [00:59<00:52,  1.10s/it]\u001b[A\n",
      "Average Metric: 28.55 / 53  (53.9):  52%|█████▏    | 52/100 [01:01<00:52,  1.10s/it]\u001b[A\n",
      "Average Metric: 28.55 / 53  (53.9):  53%|█████▎    | 53/100 [01:01<00:54,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.55 / 54  (52.9):  53%|█████▎    | 53/100 [01:02<00:54,  1.15s/it]\u001b[A\n",
      "Average Metric: 28.55 / 54  (52.9):  54%|█████▍    | 54/100 [01:02<00:58,  1.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.55 / 55  (51.9):  54%|█████▍    | 54/100 [01:04<00:58,  1.27s/it]\u001b[A\n",
      "Average Metric: 28.55 / 55  (51.9):  55%|█████▌    | 55/100 [01:04<01:00,  1.34s/it]\u001b[A\n",
      "Average Metric: 28.55 / 56  (51.0):  55%|█████▌    | 55/100 [01:06<01:00,  1.34s/it]\u001b[A\n",
      "Average Metric: 28.55 / 56  (51.0):  56%|█████▌    | 56/100 [01:06<01:06,  1.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.994444444444444 / 57  (50.9):  56%|▌| 56/100 [01:07<01:06,  1.50s\u001b[A\n",
      "Average Metric: 28.994444444444444 / 57  (50.9):  57%|▌| 57/100 [01:07<00:57,  1.34s\u001b[A\n",
      "Average Metric: 28.994444444444444 / 58  (50.0):  57%|▌| 57/100 [01:08<00:57,  1.34s\u001b[A\n",
      "Average Metric: 28.994444444444444 / 58  (50.0):  58%|▌| 58/100 [01:08<00:54,  1.31s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.327777777777776 / 59  (49.7):  58%|▌| 58/100 [01:10<00:54,  1.31s\u001b[A\n",
      "Average Metric: 29.327777777777776 / 59  (49.7):  59%|▌| 59/100 [01:10<01:03,  1.54s\u001b[A\n",
      "Average Metric: 30.327777777777776 / 60  (50.5):  59%|▌| 59/100 [01:10<01:03,  1.54s\u001b[A\n",
      "Average Metric: 30.327777777777776 / 60  (50.5):  60%|▌| 60/100 [01:10<00:45,  1.14s\u001b[A\n",
      "Average Metric: 31.327777777777776 / 61  (51.4):  60%|▌| 60/100 [01:11<00:45,  1.14s\u001b[A\n",
      "Average Metric: 31.327777777777776 / 61  (51.4):  61%|▌| 61/100 [01:11<00:44,  1.15s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.577777777777776 / 62  (50.9):  61%|▌| 61/100 [01:13<00:44,  1.15s\u001b[A\n",
      "Average Metric: 31.577777777777776 / 62  (50.9):  62%|▌| 62/100 [01:13<00:52,  1.38s\u001b[A\n",
      "Average Metric: 32.077777777777776 / 63  (50.9):  62%|▌| 62/100 [01:13<00:52,  1.38s\u001b[A\n",
      "Average Metric: 33.077777777777776 / 64  (51.7):  63%|▋| 63/100 [01:15<00:51,  1.38s\u001b[A\n",
      "Average Metric: 33.077777777777776 / 64  (51.7):  64%|▋| 64/100 [01:15<00:41,  1.16s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 43.1 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.827777777777776 / 65  (52.0):  64%|▋| 64/100 [01:17<00:41,  1.16s\u001b[A\n",
      "Average Metric: 33.827777777777776 / 65  (52.0):  65%|▋| 65/100 [01:17<00:44,  1.27s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 109.6 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 60.0 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.827777777777776 / 66  (51.3):  65%|▋| 65/100 [01:18<00:44,  1.27s\u001b[A\n",
      "Average Metric: 33.827777777777776 / 66  (51.3):  66%|▋| 66/100 [01:18<00:43,  1.27s\u001b[A\n",
      "Average Metric: 34.827777777777776 / 67  (52.0):  66%|▋| 66/100 [01:19<00:43,  1.27s\u001b[A\n",
      "Average Metric: 34.827777777777776 / 67  (52.0):  67%|▋| 67/100 [01:19<00:40,  1.24s\u001b[A\n",
      "Average Metric: 35.827777777777776 / 68  (52.7):  67%|▋| 67/100 [01:20<00:40,  1.24s\u001b[A\n",
      "Average Metric: 35.827777777777776 / 68  (52.7):  68%|▋| 68/100 [01:20<00:42,  1.32s\u001b[A\n",
      "Average Metric: 36.327777777777776 / 69  (52.6):  68%|▋| 68/100 [01:21<00:42,  1.32s\u001b[A\n",
      "Average Metric: 36.327777777777776 / 69  (52.6):  69%|▋| 69/100 [01:21<00:30,  1.02i\u001b[A\n",
      "Average Metric: 36.66111111111111 / 70  (52.4):  69%|▋| 69/100 [01:22<00:30,  1.02it\u001b[A\n",
      "Average Metric: 36.66111111111111 / 70  (52.4):  70%|▋| 70/100 [01:22<00:30,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.91111111111111 / 71  (52.0):  70%|▋| 70/100 [01:23<00:30,  1.03s/\u001b[A\n",
      "Average Metric: 36.91111111111111 / 71  (52.0):  71%|▋| 71/100 [01:23<00:33,  1.16s/\u001b[A\n",
      "Average Metric: 36.91111111111111 / 72  (51.3):  71%|▋| 71/100 [01:24<00:33,  1.16s/\u001b[A\n",
      "Average Metric: 36.91111111111111 / 72  (51.3):  72%|▋| 72/100 [01:24<00:32,  1.16s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.24444444444445 / 73  (51.0):  72%|▋| 72/100 [01:25<00:32,  1.16s/\u001b[A\n",
      "Average Metric: 37.24444444444445 / 73  (51.0):  73%|▋| 73/100 [01:25<00:30,  1.11s/\u001b[A\n",
      "Average Metric: 37.24444444444445 / 74  (50.3):  73%|▋| 73/100 [01:27<00:30,  1.11s/\u001b[A\n",
      "Average Metric: 37.24444444444445 / 74  (50.3):  74%|▋| 74/100 [01:27<00:29,  1.15s/\u001b[A\n",
      "Average Metric: 37.24444444444445 / 75  (49.7):  74%|▋| 74/100 [01:28<00:29,  1.15s/\u001b[A\n",
      "Average Metric: 37.24444444444445 / 75  (49.7):  75%|▊| 75/100 [01:28<00:30,  1.23s/\u001b[A\n",
      "Average Metric: 38.24444444444445 / 76  (50.3):  75%|▊| 75/100 [01:29<00:30,  1.23s/\u001b[A\n",
      "Average Metric: 38.24444444444445 / 76  (50.3):  76%|▊| 76/100 [01:29<00:28,  1.17s/\u001b[A\n",
      "Average Metric: 38.24444444444445 / 77  (49.7):  76%|▊| 76/100 [01:29<00:28,  1.17s/\u001b[A\n",
      "Average Metric: 39.24444444444445 / 78  (50.3):  77%|▊| 77/100 [01:32<00:26,  1.17s/\u001b[A\n",
      "Average Metric: 39.24444444444445 / 78  (50.3):  78%|▊| 78/100 [01:32<00:27,  1.26s/\u001b[A\n",
      "Average Metric: 39.46666666666667 / 79  (50.0):  78%|▊| 78/100 [01:33<00:27,  1.26s/\u001b[A\n",
      "Average Metric: 39.46666666666667 / 79  (50.0):  79%|▊| 79/100 [01:33<00:24,  1.18s/\u001b[A\n",
      "Average Metric: 39.96666666666667 / 80  (50.0):  79%|▊| 79/100 [01:33<00:24,  1.18s/\u001b[A\n",
      "Average Metric: 39.96666666666667 / 80  (50.0):  80%|▊| 80/100 [01:33<00:19,  1.01it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.63333333333333 / 81  (50.2):  80%|▊| 80/100 [01:36<00:19,  1.01it\u001b[A\n",
      "Average Metric: 40.63333333333333 / 81  (50.2):  81%|▊| 81/100 [01:36<00:27,  1.46s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.63333333333333 / 82  (49.6):  81%|▊| 81/100 [01:38<00:27,  1.46s/\u001b[A\n",
      "Average Metric: 40.63333333333333 / 82  (49.6):  82%|▊| 82/100 [01:38<00:29,  1.66s/\u001b[A\n",
      "Average Metric: 41.63333333333333 / 83  (50.2):  82%|▊| 82/100 [01:39<00:29,  1.66s/\u001b[A\n",
      "Average Metric: 41.63333333333333 / 83  (50.2):  83%|▊| 83/100 [01:39<00:24,  1.44s/\u001b[A\n",
      "Average Metric: 42.13333333333333 / 84  (50.2):  83%|▊| 83/100 [01:40<00:24,  1.44s/\u001b[A\n",
      "Average Metric: 42.13333333333333 / 84  (50.2):  84%|▊| 84/100 [01:40<00:19,  1.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.38333333333333 / 85  (49.9):  84%|▊| 84/100 [01:41<00:19,  1.23s/\u001b[A\n",
      "Average Metric: 42.38333333333333 / 85  (49.9):  85%|▊| 85/100 [01:41<00:17,  1.18s/\u001b[A\n",
      "Average Metric: 43.38333333333333 / 86  (50.4):  85%|▊| 85/100 [01:41<00:17,  1.18s/\u001b[A\n",
      "Average Metric: 44.38333333333333 / 87  (51.0):  86%|▊| 86/100 [01:42<00:16,  1.18s/\u001b[A\n",
      "Average Metric: 44.38333333333333 / 87  (51.0):  87%|▊| 87/100 [01:42<00:10,  1.22it\u001b[A\n",
      "Average Metric: 45.38333333333333 / 88  (51.6):  87%|▊| 87/100 [01:42<00:10,  1.22it\u001b[A\n",
      "Average Metric: 45.38333333333333 / 88  (51.6):  88%|▉| 88/100 [01:42<00:10,  1.20it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46.38333333333333 / 89  (52.1):  88%|▉| 88/100 [01:44<00:10,  1.20it\u001b[A\n",
      "Average Metric: 46.38333333333333 / 89  (52.1):  89%|▉| 89/100 [01:44<00:11,  1.08s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.38333333333333 / 90  (52.6):  89%|▉| 89/100 [01:45<00:11,  1.08s/\u001b[A\n",
      "Average Metric: 47.38333333333333 / 90  (52.6):  90%|▉| 90/100 [01:45<00:11,  1.10s/\u001b[A\n",
      "Average Metric: 48.38333333333333 / 91  (53.2):  90%|▉| 90/100 [01:47<00:11,  1.10s/\u001b[A\n",
      "Average Metric: 48.38333333333333 / 91  (53.2):  91%|▉| 91/100 [01:47<00:11,  1.22s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.38333333333333 / 92  (53.7):  91%|▉| 91/100 [01:49<00:11,  1.22s/\u001b[A\n",
      "Average Metric: 49.38333333333333 / 92  (53.7):  92%|▉| 92/100 [01:49<00:10,  1.34s/\u001b[A\n",
      "Average Metric: 49.88333333333333 / 93  (53.6):  92%|▉| 92/100 [01:50<00:10,  1.34s/\u001b[A\n",
      "Average Metric: 49.88333333333333 / 93  (53.6):  93%|▉| 93/100 [01:50<00:09,  1.33s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.88333333333333 / 94  (54.1):  93%|▉| 93/100 [01:51<00:09,  1.33s/\u001b[A\n",
      "Average Metric: 50.88333333333333 / 94  (54.1):  94%|▉| 94/100 [01:51<00:07,  1.21s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.88333333333333 / 95  (53.6):  94%|▉| 94/100 [01:53<00:07,  1.21s/\u001b[A\n",
      "Average Metric: 50.88333333333333 / 95  (53.6):  95%|▉| 95/100 [01:53<00:07,  1.59s/\u001b[A\n",
      "Average Metric: 51.13333333333333 / 96  (53.3):  95%|▉| 95/100 [01:55<00:07,  1.59s/\u001b[A\n",
      "Average Metric: 51.13333333333333 / 96  (53.3):  96%|▉| 96/100 [01:55<00:06,  1.75s/\u001b[A\n",
      "Average Metric: 52.13333333333333 / 97  (53.7):  96%|▉| 96/100 [01:56<00:06,  1.75s/\u001b[A\n",
      "Average Metric: 52.13333333333333 / 97  (53.7):  97%|▉| 97/100 [01:56<00:04,  1.40s/\u001b[A\n",
      "Average Metric: 52.8 / 98  (53.9):  97%|██████████▋| 97/100 [02:00<00:04,  1.40s/it]\u001b[A\n",
      "Average Metric: 52.8 / 98  (53.9):  98%|██████████▊| 98/100 [02:00<00:04,  2.25s/it]\u001b[A\n",
      "Average Metric: 53.05 / 99  (53.6):  98%|█████████▊| 98/100 [02:19<00:04,  2.25s/it]\u001b[A\n",
      "Average Metric: 53.05 / 99  (53.6):  99%|█████████▉| 99/100 [02:19<00:07,  7.17s/it]\u001b[A\n",
      "Average Metric: 53.05 / 100  (53.0):  99%|████████▉| 99/100 [03:08<00:07,  7.17s/it]\u001b[A\n",
      "Average Metric: 53.05 / 100  (53.0): 100%|████████| 100/100 [03:08<00:00,  1.88s/it]\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 53.05 / 100  (53.0%)\n",
      "Score: 53.05 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8560833333333333\n",
      "Average of max per entry across top 5 scores: 0.9283333333333332\n",
      "Average of max per entry across top 8 scores: 0.9749999999999999\n",
      "Average of max per entry across top 9999 scores: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:03<05:38,  3.42s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:05<04:00,  2.46s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:06<02:58,  1.84s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:08<02:55,  1.83s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:09<02:47,  1.77s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:11<02:30,  1.60s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:13<03:09,  2.04s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:15<02:41,  1.76s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:16<02:34,  1.70s/it]\u001b[A\n",
      " 10%|████▌                                         | 10/100 [00:17<02:41,  1.79s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:00<01:30,  1.09it/s]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   1%|▏             | 1/100 [00:01<01:30,  1.09it/s]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   2%|▎             | 2/100 [00:01<00:48,  2.02it/s]\u001b[A\n",
      "Average Metric: 1.4 / 3  (46.7):   2%|▎             | 2/100 [00:01<00:48,  2.02it/s]\u001b[A\n",
      "Average Metric: 1.4 / 3  (46.7):   3%|▍             | 3/100 [00:01<00:39,  2.45it/s]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):   3%|▍             | 3/100 [00:01<00:39,  2.45it/s]\u001b[A\n",
      "Average Metric: 1.7333333333333332 / 5  (34.7):   4%| | 4/100 [00:01<00:39,  2.45it/\u001b[A\n",
      "Average Metric: 1.7333333333333332 / 5  (34.7):   5%| | 5/100 [00:01<00:28,  3.39it/\u001b[A\n",
      "Average Metric: 2.533333333333333 / 6  (42.2):   5%| | 5/100 [00:01<00:28,  3.39it/s\u001b[A\n",
      "Average Metric: 2.533333333333333 / 7  (36.2):   6%| | 6/100 [00:01<00:27,  3.39it/s\u001b[A\n",
      "Average Metric: 3.533333333333333 / 8  (44.2):   7%| | 7/100 [00:02<00:27,  3.39it/s\u001b[A\n",
      "Average Metric: 3.533333333333333 / 8  (44.2):   8%| | 8/100 [00:02<00:30,  3.01it/s\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 9  (43.0):   8%| | 8/100 [00:03<00:30,  3.01it/\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 9  (43.0):   9%| | 9/100 [00:03<00:28,  3.15it/\u001b[A\n",
      "Average Metric: 4.166666666666667 / 10  (41.7):   9%| | 9/100 [00:03<00:28,  3.15it/\u001b[A\n",
      "Average Metric: 4.166666666666667 / 10  (41.7):  10%| | 10/100 [00:03<00:25,  3.48it\u001b[A\n",
      "Average Metric: 4.416666666666667 / 11  (40.2):  10%| | 10/100 [00:03<00:25,  3.48it\u001b[A\n",
      "Average Metric: 4.416666666666667 / 12  (36.8):  11%| | 11/100 [00:04<00:25,  3.48it\u001b[A\n",
      "Average Metric: 4.416666666666667 / 12  (36.8):  12%| | 12/100 [00:04<00:30,  2.88it\u001b[A\n",
      "Average Metric: 5.416666666666667 / 13  (41.7):  12%| | 12/100 [00:04<00:30,  2.88it\u001b[A\n",
      "Average Metric: 5.416666666666667 / 13  (41.7):  13%|▏| 13/100 [00:04<00:25,  3.40it\u001b[A\n",
      "Average Metric: 5.666666666666667 / 14  (40.5):  13%|▏| 13/100 [00:04<00:25,  3.40it\u001b[A\n",
      "Average Metric: 5.666666666666667 / 14  (40.5):  14%|▏| 14/100 [00:04<00:22,  3.75it\u001b[A\n",
      "Average Metric: 6.416666666666667 / 15  (42.8):  14%|▏| 14/100 [00:04<00:22,  3.75it\u001b[A\n",
      "Average Metric: 7.416666666666667 / 16  (46.4):  15%|▏| 15/100 [00:04<00:22,  3.75it\u001b[A\n",
      "Average Metric: 7.416666666666667 / 16  (46.4):  16%|▏| 16/100 [00:04<00:19,  4.26it\u001b[A\n",
      "Average Metric: 7.616666666666667 / 17  (44.8):  16%|▏| 16/100 [00:04<00:19,  4.26it\u001b[A\n",
      "Average Metric: 7.95 / 18  (44.2):  17%|█▊         | 17/100 [00:05<00:19,  4.26it/s]\u001b[A\n",
      "Average Metric: 7.95 / 18  (44.2):  18%|█▉         | 18/100 [00:05<00:21,  3.75it/s]\u001b[A\n",
      "Average Metric: 7.95 / 19  (41.8):  18%|█▉         | 18/100 [00:05<00:21,  3.75it/s]\u001b[A\n",
      "Average Metric: 7.95 / 19  (41.8):  19%|██         | 19/100 [00:05<00:22,  3.65it/s]\u001b[A\n",
      "Average Metric: 8.283333333333333 / 20  (41.4):  19%|▏| 19/100 [00:05<00:22,  3.65it\u001b[A\n",
      "Average Metric: 8.283333333333333 / 21  (39.4):  20%|▏| 20/100 [00:06<00:21,  3.65it\u001b[A\n",
      "Average Metric: 8.283333333333333 / 21  (39.4):  21%|▏| 21/100 [00:06<00:16,  4.71it\u001b[A\n",
      "Average Metric: 9.283333333333333 / 22  (42.2):  21%|▏| 21/100 [00:06<00:16,  4.71it\u001b[A\n",
      "Average Metric: 9.283333333333333 / 22  (42.2):  22%|▏| 22/100 [00:06<00:15,  5.13it\u001b[A\n",
      "Average Metric: 9.783333333333333 / 23  (42.5):  22%|▏| 22/100 [00:06<00:15,  5.13it\u001b[A\n",
      "Average Metric: 9.783333333333333 / 23  (42.5):  23%|▏| 23/100 [00:06<00:20,  3.80it\u001b[A\n",
      "Average Metric: 10.783333333333333 / 24  (44.9):  23%|▏| 23/100 [00:06<00:20,  3.80i\u001b[A\n",
      "Average Metric: 11.283333333333333 / 25  (45.1):  24%|▏| 24/100 [00:06<00:20,  3.80i\u001b[A\n",
      "Average Metric: 11.283333333333333 / 25  (45.1):  25%|▎| 25/100 [00:06<00:14,  5.02i\u001b[A\n",
      "Average Metric: 12.283333333333333 / 26  (47.2):  25%|▎| 25/100 [00:06<00:14,  5.02i\u001b[A\n",
      "Average Metric: 13.283333333333333 / 27  (49.2):  26%|▎| 26/100 [00:07<00:14,  5.02i\u001b[A\n",
      "Average Metric: 13.283333333333333 / 27  (49.2):  27%|▎| 27/100 [00:07<00:12,  5.64i\u001b[A\n",
      "Average Metric: 13.283333333333333 / 28  (47.4):  27%|▎| 27/100 [00:07<00:12,  5.64i\u001b[A\n",
      "Average Metric: 13.283333333333333 / 28  (47.4):  28%|▎| 28/100 [00:07<00:12,  5.73i\u001b[A\n",
      "Average Metric: 13.283333333333333 / 29  (45.8):  28%|▎| 28/100 [00:07<00:12,  5.73i\u001b[A\n",
      "Average Metric: 14.283333333333333 / 30  (47.6):  29%|▎| 29/100 [00:07<00:12,  5.73i\u001b[A\n",
      "Average Metric: 14.283333333333333 / 30  (47.6):  30%|▎| 30/100 [00:07<00:14,  4.70i\u001b[A\n",
      "Average Metric: 15.283333333333333 / 31  (49.3):  30%|▎| 30/100 [00:08<00:14,  4.70i\u001b[A\n",
      "Average Metric: 15.283333333333333 / 31  (49.3):  31%|▎| 31/100 [00:08<00:16,  4.30i\u001b[A\n",
      "Average Metric: 15.533333333333333 / 32  (48.5):  31%|▎| 31/100 [00:08<00:16,  4.30i\u001b[A\n",
      "Average Metric: 15.783333333333333 / 33  (47.8):  32%|▎| 32/100 [00:08<00:15,  4.30i\u001b[A\n",
      "Average Metric: 15.783333333333333 / 33  (47.8):  33%|▎| 33/100 [00:08<00:12,  5.44i\u001b[A\n",
      "Average Metric: 16.183333333333334 / 34  (47.6):  33%|▎| 33/100 [00:08<00:12,  5.44i\u001b[A\n",
      "Average Metric: 16.183333333333334 / 34  (47.6):  34%|▎| 34/100 [00:08<00:12,  5.50i\u001b[A\n",
      "Average Metric: 16.183333333333334 / 35  (46.2):  34%|▎| 34/100 [00:08<00:12,  5.50i\u001b[A\n",
      "Average Metric: 16.183333333333334 / 35  (46.2):  35%|▎| 35/100 [00:08<00:12,  5.04i\u001b[A\n",
      "Average Metric: 16.683333333333334 / 36  (46.3):  35%|▎| 35/100 [00:09<00:12,  5.04i\u001b[A\n",
      "Average Metric: 16.683333333333334 / 36  (46.3):  36%|▎| 36/100 [00:09<00:17,  3.61i\u001b[A\n",
      "Average Metric: 17.683333333333334 / 37  (47.8):  36%|▎| 36/100 [00:09<00:17,  3.61i\u001b[A\n",
      "Average Metric: 17.683333333333334 / 37  (47.8):  37%|▎| 37/100 [00:09<00:14,  4.22i\u001b[A\n",
      "Average Metric: 18.35 / 38  (48.3):  37%|███▋      | 37/100 [00:09<00:14,  4.22it/s]\u001b[A\n",
      "Average Metric: 18.85 / 39  (48.3):  38%|███▊      | 38/100 [00:09<00:14,  4.22it/s]\u001b[A\n",
      "Average Metric: 19.183333333333334 / 40  (48.0):  39%|▍| 39/100 [00:09<00:14,  4.22i\u001b[A\n",
      "Average Metric: 19.183333333333334 / 40  (48.0):  40%|▍| 40/100 [00:09<00:08,  7.49i\u001b[A\n",
      "Average Metric: 19.683333333333334 / 41  (48.0):  40%|▍| 40/100 [00:10<00:08,  7.49i\u001b[A\n",
      "Average Metric: 20.683333333333334 / 42  (49.2):  41%|▍| 41/100 [00:10<00:07,  7.49i\u001b[A\n",
      "Average Metric: 20.683333333333334 / 42  (49.2):  42%|▍| 42/100 [00:10<00:11,  4.91i\u001b[A\n",
      "Average Metric: 21.683333333333334 / 43  (50.4):  42%|▍| 42/100 [00:10<00:11,  4.91i\u001b[A\n",
      "Average Metric: 21.683333333333334 / 43  (50.4):  43%|▍| 43/100 [00:10<00:11,  5.07i\u001b[A\n",
      "Average Metric: 22.683333333333334 / 44  (51.6):  43%|▍| 43/100 [00:10<00:11,  5.07i\u001b[A\n",
      "Average Metric: 23.016666666666666 / 45  (51.1):  44%|▍| 44/100 [00:10<00:11,  5.07i\u001b[A\n",
      "Average Metric: 23.016666666666666 / 45  (51.1):  45%|▍| 45/100 [00:10<00:08,  6.32i\u001b[A\n",
      "Average Metric: 23.016666666666666 / 46  (50.0):  45%|▍| 45/100 [00:11<00:08,  6.32i\u001b[A\n",
      "Average Metric: 23.016666666666666 / 46  (50.0):  46%|▍| 46/100 [00:11<00:11,  4.77i\u001b[A\n",
      "Average Metric: 24.016666666666666 / 47  (51.1):  46%|▍| 46/100 [00:11<00:11,  4.77i\u001b[A\n",
      "Average Metric: 24.016666666666666 / 47  (51.1):  47%|▍| 47/100 [00:11<00:14,  3.66i\u001b[A\n",
      "Average Metric: 24.266666666666666 / 48  (50.6):  47%|▍| 47/100 [00:11<00:14,  3.66i\u001b[A\n",
      "Average Metric: 24.266666666666666 / 49  (49.5):  48%|▍| 48/100 [00:11<00:14,  3.66i\u001b[A\n",
      "Average Metric: 24.466666666666665 / 50  (48.9):  49%|▍| 49/100 [00:12<00:13,  3.66i\u001b[A\n",
      "Average Metric: 24.466666666666665 / 50  (48.9):  50%|▌| 50/100 [00:12<00:12,  3.96i\u001b[A\n",
      "Average Metric: 25.466666666666665 / 51  (49.9):  50%|▌| 50/100 [00:12<00:12,  3.96i\u001b[A\n",
      "Average Metric: 25.466666666666665 / 51  (49.9):  51%|▌| 51/100 [00:12<00:12,  3.82i\u001b[A\n",
      "Average Metric: 25.966666666666665 / 52  (49.9):  51%|▌| 51/100 [00:12<00:12,  3.82i\u001b[A\n",
      "Average Metric: 25.966666666666665 / 52  (49.9):  52%|▌| 52/100 [00:12<00:14,  3.33i\u001b[A\n",
      "Average Metric: 26.299999999999997 / 53  (49.6):  52%|▌| 52/100 [00:13<00:14,  3.33i\u001b[A\n",
      "Average Metric: 27.299999999999997 / 54  (50.6):  53%|▌| 53/100 [00:13<00:14,  3.33i\u001b[A\n",
      "Average Metric: 27.299999999999997 / 54  (50.6):  54%|▌| 54/100 [00:13<00:09,  4.69i\u001b[A\n",
      "Average Metric: 28.299999999999997 / 55  (51.5):  54%|▌| 54/100 [00:13<00:09,  4.69i\u001b[A\n",
      "Average Metric: 29.299999999999997 / 56  (52.3):  55%|▌| 55/100 [00:13<00:09,  4.69i\u001b[A\n",
      "Average Metric: 29.299999999999997 / 56  (52.3):  56%|▌| 56/100 [00:13<00:07,  6.10i\u001b[A\n",
      "Average Metric: 30.299999999999997 / 57  (53.2):  56%|▌| 56/100 [00:13<00:07,  6.10i\u001b[A\n",
      "Average Metric: 30.299999999999997 / 57  (53.2):  57%|▌| 57/100 [00:13<00:08,  4.84i\u001b[A\n",
      "Average Metric: 30.299999999999997 / 58  (52.2):  57%|▌| 57/100 [00:13<00:08,  4.84i\u001b[A\n",
      "Average Metric: 30.299999999999997 / 58  (52.2):  58%|▌| 58/100 [00:13<00:09,  4.35i\u001b[A\n",
      "Average Metric: 30.299999999999997 / 59  (51.4):  58%|▌| 58/100 [00:14<00:09,  4.35i\u001b[A\n",
      "Average Metric: 30.299999999999997 / 59  (51.4):  59%|▌| 59/100 [00:14<00:10,  3.90i\u001b[A\n",
      "Average Metric: 30.299999999999997 / 60  (50.5):  59%|▌| 59/100 [00:14<00:10,  3.90i\u001b[A\n",
      "Average Metric: 30.63333333333333 / 61  (50.2):  60%|▌| 60/100 [00:14<00:10,  3.90it\u001b[A\n",
      "Average Metric: 31.63333333333333 / 62  (51.0):  61%|▌| 61/100 [00:14<00:10,  3.90it\u001b[A\n",
      "Average Metric: 32.633333333333326 / 63  (51.8):  62%|▌| 62/100 [00:14<00:09,  3.90i\u001b[A\n",
      "Average Metric: 32.633333333333326 / 63  (51.8):  63%|▋| 63/100 [00:14<00:05,  7.22i\u001b[A\n",
      "Average Metric: 33.133333333333326 / 64  (51.8):  63%|▋| 63/100 [00:15<00:05,  7.22i\u001b[A\n",
      "Average Metric: 33.133333333333326 / 64  (51.8):  64%|▋| 64/100 [00:15<00:07,  4.57i\u001b[A\n",
      "Average Metric: 33.633333333333326 / 65  (51.7):  64%|▋| 64/100 [00:15<00:07,  4.57i\u001b[A\n",
      "Average Metric: 33.633333333333326 / 65  (51.7):  65%|▋| 65/100 [00:15<00:07,  4.47i\u001b[A\n",
      "Average Metric: 34.133333333333326 / 66  (51.7):  65%|▋| 65/100 [00:15<00:07,  4.47i\u001b[A\n",
      "Average Metric: 34.46666666666666 / 67  (51.4):  66%|▋| 66/100 [00:15<00:07,  4.47it\u001b[A\n",
      "Average Metric: 34.46666666666666 / 67  (51.4):  67%|▋| 67/100 [00:15<00:08,  3.99it\u001b[A\n",
      "Average Metric: 34.46666666666666 / 68  (50.7):  67%|▋| 67/100 [00:15<00:08,  3.99it\u001b[A\n",
      "Average Metric: 35.46666666666666 / 69  (51.4):  68%|▋| 68/100 [00:15<00:08,  3.99it\u001b[A\n",
      "Average Metric: 35.96666666666666 / 70  (51.4):  69%|▋| 69/100 [00:16<00:07,  3.99it\u001b[A\n",
      "Average Metric: 35.96666666666666 / 70  (51.4):  70%|▋| 70/100 [00:16<00:05,  5.04it\u001b[A\n",
      "Average Metric: 36.166666666666664 / 71  (50.9):  70%|▋| 70/100 [00:16<00:05,  5.04i\u001b[A\n",
      "Average Metric: 36.166666666666664 / 71  (50.9):  71%|▋| 71/100 [00:16<00:05,  4.89i\u001b[A\n",
      "Average Metric: 37.166666666666664 / 72  (51.6):  71%|▋| 71/100 [00:16<00:05,  4.89i\u001b[A\n",
      "Average Metric: 37.166666666666664 / 72  (51.6):  72%|▋| 72/100 [00:16<00:05,  5.41i\u001b[A\n",
      "Average Metric: 38.166666666666664 / 73  (52.3):  72%|▋| 72/100 [00:16<00:05,  5.41i\u001b[A\n",
      "Average Metric: 38.166666666666664 / 73  (52.3):  73%|▋| 73/100 [00:16<00:04,  5.45i\u001b[A\n",
      "Average Metric: 38.5 / 74  (52.0):  73%|████████   | 73/100 [00:17<00:04,  5.45it/s]\u001b[A\n",
      "Average Metric: 38.5 / 74  (52.0):  74%|████████▏  | 74/100 [00:17<00:05,  4.56it/s]\u001b[A\n",
      "Average Metric: 39.166666666666664 / 75  (52.2):  74%|▋| 74/100 [00:17<00:05,  4.56i\u001b[A\n",
      "Average Metric: 39.166666666666664 / 75  (52.2):  75%|▊| 75/100 [00:17<00:06,  3.65i\u001b[A\n",
      "Average Metric: 40.166666666666664 / 76  (52.9):  75%|▊| 75/100 [00:17<00:06,  3.65i\u001b[A\n",
      "Average Metric: 40.166666666666664 / 76  (52.9):  76%|▊| 76/100 [00:17<00:06,  3.88i\u001b[A\n",
      "Average Metric: 41.166666666666664 / 77  (53.5):  76%|▊| 76/100 [00:17<00:06,  3.88i\u001b[A\n",
      "Average Metric: 41.166666666666664 / 78  (52.8):  77%|▊| 77/100 [00:18<00:05,  3.88i\u001b[A\n",
      "Average Metric: 41.166666666666664 / 78  (52.8):  78%|▊| 78/100 [00:18<00:06,  3.60i\u001b[A\n",
      "Average Metric: 42.166666666666664 / 79  (53.4):  78%|▊| 78/100 [00:18<00:06,  3.60i\u001b[A\n",
      "Average Metric: 43.166666666666664 / 80  (54.0):  79%|▊| 79/100 [00:18<00:05,  3.60i\u001b[A\n",
      "Average Metric: 43.166666666666664 / 80  (54.0):  80%|▊| 80/100 [00:18<00:03,  5.12i\u001b[A\n",
      "Average Metric: 43.5 / 81  (53.7):  80%|████████▊  | 80/100 [00:18<00:03,  5.12it/s]\u001b[A\n",
      "Average Metric: 43.5 / 81  (53.7):  81%|████████▉  | 81/100 [00:18<00:03,  5.51it/s]\u001b[A\n",
      "Average Metric: 44.5 / 82  (54.3):  81%|████████▉  | 81/100 [00:19<00:03,  5.51it/s]\u001b[A\n",
      "Average Metric: 44.5 / 82  (54.3):  82%|█████████  | 82/100 [00:19<00:05,  3.21it/s]\u001b[A\n",
      "Average Metric: 45.0 / 83  (54.2):  82%|█████████  | 82/100 [00:19<00:05,  3.21it/s]\u001b[A\n",
      "Average Metric: 45.0 / 83  (54.2):  83%|█████████▏ | 83/100 [00:19<00:04,  3.67it/s]\u001b[A\n",
      "Average Metric: 45.666666666666664 / 84  (54.4):  83%|▊| 83/100 [00:19<00:04,  3.67i\u001b[A\n",
      "Average Metric: 45.666666666666664 / 84  (54.4):  84%|▊| 84/100 [00:19<00:04,  3.50i\u001b[A\n",
      "Average Metric: 45.916666666666664 / 85  (54.0):  84%|▊| 84/100 [00:20<00:04,  3.50i\u001b[A\n",
      "Average Metric: 45.916666666666664 / 85  (54.0):  85%|▊| 85/100 [00:20<00:03,  4.07i\u001b[A\n",
      "Average Metric: 46.11666666666667 / 86  (53.6):  85%|▊| 85/100 [00:20<00:03,  4.07it\u001b[A\n",
      "Average Metric: 46.11666666666667 / 87  (53.0):  86%|▊| 86/100 [00:20<00:03,  4.07it\u001b[A\n",
      "Average Metric: 46.11666666666667 / 87  (53.0):  87%|▊| 87/100 [00:20<00:03,  3.87it\u001b[A\n",
      "Average Metric: 47.11666666666667 / 88  (53.5):  87%|▊| 87/100 [00:20<00:03,  3.87it\u001b[A\n",
      "Average Metric: 47.11666666666667 / 88  (53.5):  88%|▉| 88/100 [00:20<00:03,  3.77it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 48.11666666666667 / 89  (54.1):  88%|▉| 88/100 [00:20<00:03,  3.77it\u001b[A\n",
      "Average Metric: 48.36666666666667 / 90  (53.7):  89%|▉| 89/100 [00:20<00:02,  3.77it\u001b[A\n",
      "Average Metric: 49.36666666666667 / 91  (54.2):  90%|▉| 90/100 [00:21<00:02,  3.77it\u001b[A\n",
      "Average Metric: 49.36666666666667 / 91  (54.2):  91%|▉| 91/100 [00:21<00:02,  3.66it\u001b[A\n",
      "Average Metric: 49.86666666666667 / 92  (54.2):  91%|▉| 91/100 [00:21<00:02,  3.66it\u001b[A\n",
      "Average Metric: 49.86666666666667 / 92  (54.2):  92%|▉| 92/100 [00:21<00:02,  3.96it\u001b[A\n",
      "Average Metric: 50.86666666666667 / 93  (54.7):  92%|▉| 92/100 [00:22<00:02,  3.96it\u001b[A\n",
      "Average Metric: 50.86666666666667 / 93  (54.7):  93%|▉| 93/100 [00:22<00:02,  2.43it\u001b[A\n",
      "Average Metric: 51.86666666666667 / 94  (55.2):  93%|▉| 93/100 [00:22<00:02,  2.43it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.86666666666667 / 95  (55.6):  94%|▉| 94/100 [00:23<00:02,  2.43it\u001b[A\n",
      "Average Metric: 52.86666666666667 / 95  (55.6):  95%|▉| 95/100 [00:23<00:02,  2.16it\u001b[A\n",
      "Average Metric: 53.36666666666667 / 96  (55.6):  95%|▉| 95/100 [00:24<00:02,  2.16it\u001b[A\n",
      "Average Metric: 53.36666666666667 / 96  (55.6):  96%|▉| 96/100 [00:24<00:01,  2.06it\u001b[A\n",
      "Average Metric: 53.86666666666667 / 97  (55.5):  96%|▉| 96/100 [00:25<00:01,  2.06it\u001b[A\n",
      "Average Metric: 53.86666666666667 / 97  (55.5):  97%|▉| 97/100 [00:25<00:01,  1.53it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 54.86666666666667 / 98  (56.0):  97%|▉| 97/100 [00:26<00:01,  1.53it\u001b[A\n",
      "Average Metric: 54.86666666666667 / 98  (56.0):  98%|▉| 98/100 [00:26<00:01,  1.29it\u001b[A\n",
      "Average Metric: 55.86666666666667 / 99  (56.4):  98%|▉| 98/100 [00:27<00:01,  1.29it\u001b[A\n",
      "Average Metric: 55.86666666666667 / 99  (56.4):  99%|▉| 99/100 [00:27<00:00,  1.19it\u001b[A\n",
      "Average Metric: 56.86666666666667 / 100  (56.9):  99%|▉| 99/100 [00:30<00:00,  1.19i\u001b[A\n",
      "Average Metric: 56.86666666666667 / 100  (56.9): 100%|█| 100/100 [00:30<00:00,  3.25\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.86666666666667 / 100  (56.9%)\n",
      "Score: 56.87 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8560833333333333\n",
      "Average of max per entry across top 5 scores: 0.9383333333333335\n",
      "Average of max per entry across top 8 scores: 0.975\n",
      "Average of max per entry across top 9999 scores: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:47,  1.69s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:02<02:07,  1.30s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:03<02:00,  1.24s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:05<02:06,  1.32s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:07<02:19,  1.47s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:09<02:36,  1.66s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:12<03:23,  2.19s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:13<02:56,  1.92s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:14<02:36,  1.72s/it]\u001b[A\n",
      " 10%|████▌                                         | 10/100 [00:18<03:12,  2.14s/it]\u001b[A\n",
      " 11%|█████                                         | 11/100 [00:19<02:45,  1.86s/it]\u001b[A\n",
      " 12%|█████▌                                        | 12/100 [00:20<02:28,  1.68s/it]\u001b[A\n",
      " 13%|█████▉                                        | 13/100 [00:21<02:27,  1.69s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 14 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                     | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   1%|▏            | 1/100 [00:01<02:22,  1.43s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   1%|▏             | 1/100 [00:01<02:22,  1.43s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   2%|▎             | 2/100 [00:01<01:03,  1.53it/s]\u001b[A\n",
      "Average Metric: 1.75 / 3  (58.3):   2%|▎            | 2/100 [00:01<01:03,  1.53it/s]\u001b[A\n",
      "Average Metric: 1.75 / 4  (43.8):   3%|▍            | 3/100 [00:02<01:03,  1.53it/s]\u001b[A\n",
      "Average Metric: 1.75 / 4  (43.8):   4%|▌            | 4/100 [00:02<00:38,  2.49it/s]\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 5  (41.7):   4%| | 4/100 [00:02<00:38,  2.49it/\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 5  (41.7):   5%| | 5/100 [00:02<00:32,  2.92it/\u001b[A\n",
      "Average Metric: 2.0833333333333335 / 6  (34.7):   5%| | 5/100 [00:02<00:32,  2.92it/\u001b[A\n",
      "Average Metric: 2.2261904761904763 / 7  (31.8):   6%| | 6/100 [00:02<00:32,  2.92it/\u001b[A\n",
      "Average Metric: 2.2261904761904763 / 7  (31.8):   7%| | 7/100 [00:02<00:22,  4.12it/\u001b[A\n",
      "Average Metric: 2.2261904761904763 / 8  (27.8):   7%| | 7/100 [00:03<00:22,  4.12it/\u001b[A\n",
      "Average Metric: 2.2261904761904763 / 8  (27.8):   8%| | 8/100 [00:03<00:39,  2.34it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.2261904761904763 / 9  (35.8):   8%| | 8/100 [00:03<00:39,  2.34it/\u001b[A\n",
      "Average Metric: 3.2261904761904763 / 9  (35.8):   9%| | 9/100 [00:03<00:33,  2.70it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.4484126984126986 / 10  (34.5):   9%| | 9/100 [00:05<00:33,  2.70it\u001b[A\n",
      "Average Metric: 3.4484126984126986 / 10  (34.5):  10%| | 10/100 [00:05<01:19,  1.14i\u001b[A\n",
      "Average Metric: 3.6984126984126986 / 11  (33.6):  10%| | 10/100 [00:06<01:19,  1.14i\u001b[A\n",
      "Average Metric: 3.6984126984126986 / 11  (33.6):  11%| | 11/100 [00:06<01:10,  1.26i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.448412698412699 / 12  (37.1):  11%| | 11/100 [00:08<01:10,  1.26it\u001b[A\n",
      "Average Metric: 4.448412698412699 / 12  (37.1):  12%| | 12/100 [00:08<01:32,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.198412698412699 / 13  (40.0):  12%| | 12/100 [00:09<01:32,  1.05s/\u001b[A\n",
      "Average Metric: 5.198412698412699 / 13  (40.0):  13%|▏| 13/100 [00:09<01:40,  1.15s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.198412698412699 / 14  (44.3):  13%|▏| 13/100 [00:11<01:40,  1.15s/\u001b[A\n",
      "Average Metric: 6.198412698412699 / 14  (44.3):  14%|▏| 14/100 [00:11<01:45,  1.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.198412698412699 / 15  (48.0):  14%|▏| 14/100 [00:13<01:45,  1.23s/\u001b[A\n",
      "Average Metric: 7.198412698412699 / 15  (48.0):  15%|▏| 15/100 [00:13<02:09,  1.52s/\u001b[A\n",
      "Average Metric: 7.198412698412699 / 16  (45.0):  15%|▏| 15/100 [00:13<02:09,  1.52s/\u001b[A\n",
      "Average Metric: 7.198412698412699 / 16  (45.0):  16%|▏| 16/100 [00:13<01:40,  1.20s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.698412698412699 / 17  (45.3):  16%|▏| 16/100 [00:14<01:40,  1.20s/\u001b[A\n",
      "Average Metric: 7.698412698412699 / 17  (45.3):  17%|▏| 17/100 [00:14<01:32,  1.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.6984126984127 / 18  (48.3):  17%|▏| 17/100 [00:16<01:32,  1.12s/it\u001b[A\n",
      "Average Metric: 8.6984126984127 / 18  (48.3):  18%|▏| 18/100 [00:16<01:53,  1.38s/it\u001b[A\n",
      "Average Metric: 9.6984126984127 / 19  (51.0):  18%|▏| 18/100 [00:16<01:53,  1.38s/it\u001b[A\n",
      "Average Metric: 9.6984126984127 / 19  (51.0):  19%|▏| 19/100 [00:16<01:24,  1.04s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.6984126984127 / 20  (48.5):  19%|▏| 19/100 [00:19<01:24,  1.04s/it\u001b[A\n",
      "Average Metric: 9.6984126984127 / 20  (48.5):  20%|▏| 20/100 [00:19<01:56,  1.46s/it\u001b[A\n",
      "Average Metric: 10.1984126984127 / 21  (48.6):  20%|▏| 20/100 [00:19<01:56,  1.46s/i\u001b[A\n",
      "Average Metric: 10.1984126984127 / 21  (48.6):  21%|▏| 21/100 [00:19<01:32,  1.17s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.1984126984127 / 22  (50.9):  21%|▏| 21/100 [00:21<01:32,  1.17s/i\u001b[A\n",
      "Average Metric: 11.1984126984127 / 22  (50.9):  22%|▏| 22/100 [00:21<01:36,  1.23s/i\u001b[A\n",
      "Average Metric: 12.1984126984127 / 23  (53.0):  22%|▏| 22/100 [00:22<01:36,  1.23s/i\u001b[A\n",
      "Average Metric: 12.1984126984127 / 23  (53.0):  23%|▏| 23/100 [00:22<01:28,  1.15s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.6984126984127 / 24  (52.9):  23%|▏| 23/100 [00:22<01:28,  1.15s/i\u001b[A\n",
      "Average Metric: 12.6984126984127 / 24  (52.9):  24%|▏| 24/100 [00:22<01:19,  1.05s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.031746031746033 / 25  (52.1):  24%|▏| 24/100 [00:24<01:19,  1.05s\u001b[A\n",
      "Average Metric: 13.031746031746033 / 25  (52.1):  25%|▎| 25/100 [00:24<01:37,  1.31s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.231746031746033 / 26  (50.9):  25%|▎| 25/100 [00:25<01:37,  1.31s\u001b[A\n",
      "Average Metric: 13.231746031746033 / 26  (50.9):  26%|▎| 26/100 [00:25<01:28,  1.20s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.231746031746033 / 27  (52.7):  26%|▎| 26/100 [00:25<01:28,  1.20s\u001b[A\n",
      "Average Metric: 14.231746031746033 / 27  (52.7):  27%|▎| 27/100 [00:25<01:03,  1.15i\u001b[A\n",
      "Average Metric: 14.231746031746033 / 28  (50.8):  27%|▎| 27/100 [00:26<01:03,  1.15i\u001b[A\n",
      "Average Metric: 14.231746031746033 / 28  (50.8):  28%|▎| 28/100 [00:26<01:05,  1.10i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.231746031746033 / 29  (52.5):  28%|▎| 28/100 [00:27<01:05,  1.10i\u001b[A\n",
      "Average Metric: 15.231746031746033 / 29  (52.5):  29%|▎| 29/100 [00:27<01:09,  1.03i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.731746031746033 / 30  (52.4):  29%|▎| 29/100 [00:29<01:09,  1.03i\u001b[A\n",
      "Average Metric: 15.731746031746033 / 30  (52.4):  30%|▎| 30/100 [00:29<01:16,  1.10s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.731746031746033 / 31  (50.7):  30%|▎| 30/100 [00:30<01:16,  1.10s\u001b[A\n",
      "Average Metric: 15.731746031746033 / 31  (50.7):  31%|▎| 31/100 [00:30<01:21,  1.19s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.065079365079367 / 32  (50.2):  31%|▎| 31/100 [00:32<01:21,  1.19s\u001b[A\n",
      "Average Metric: 16.065079365079367 / 32  (50.2):  32%|▎| 32/100 [00:32<01:38,  1.45s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.065079365079367 / 33  (48.7):  32%|▎| 32/100 [00:33<01:38,  1.45s\u001b[A\n",
      "Average Metric: 16.065079365079367 / 33  (48.7):  33%|▎| 33/100 [00:33<01:22,  1.23s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.3984126984127 / 34  (48.2):  33%|▎| 33/100 [00:34<01:22,  1.23s/i\u001b[A\n",
      "Average Metric: 16.3984126984127 / 34  (48.2):  34%|▎| 34/100 [00:34<01:21,  1.23s/i\u001b[A\n",
      "Average Metric: 16.3984126984127 / 35  (46.9):  34%|▎| 34/100 [00:35<01:21,  1.23s/i\u001b[A\n",
      "Average Metric: 16.3984126984127 / 35  (46.9):  35%|▎| 35/100 [00:35<01:01,  1.05it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.3984126984127 / 36  (45.6):  35%|▎| 35/100 [00:36<01:01,  1.05it/\u001b[A\n",
      "Average Metric: 16.3984126984127 / 36  (45.6):  36%|▎| 36/100 [00:36<01:00,  1.05it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.065079365079367 / 37  (46.1):  36%|▎| 36/100 [00:37<01:00,  1.05i\u001b[A\n",
      "Average Metric: 17.065079365079367 / 37  (46.1):  37%|▎| 37/100 [00:37<01:07,  1.07s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.565079365079367 / 38  (46.2):  37%|▎| 37/100 [00:38<01:07,  1.07s\u001b[A\n",
      "Average Metric: 17.565079365079367 / 38  (46.2):  38%|▍| 38/100 [00:38<01:00,  1.03i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.565079365079367 / 39  (47.6):  38%|▍| 38/100 [00:39<01:00,  1.03i\u001b[A\n",
      "Average Metric: 18.565079365079367 / 39  (47.6):  39%|▍| 39/100 [00:39<01:00,  1.00i\u001b[A\n",
      "Average Metric: 19.565079365079367 / 40  (48.9):  39%|▍| 39/100 [00:40<01:00,  1.00i\u001b[A\n",
      "Average Metric: 19.565079365079367 / 40  (48.9):  40%|▍| 40/100 [00:40<01:00,  1.01s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.815079365079367 / 41  (48.3):  40%|▍| 40/100 [00:41<01:00,  1.01s\u001b[A\n",
      "Average Metric: 19.815079365079367 / 41  (48.3):  41%|▍| 41/100 [00:41<01:09,  1.17s\u001b[A\n",
      "Average Metric: 20.815079365079367 / 42  (49.6):  41%|▍| 41/100 [00:41<01:09,  1.17s\u001b[A\n",
      "Average Metric: 21.815079365079367 / 43  (50.7):  42%|▍| 42/100 [00:42<01:07,  1.17s\u001b[A\n",
      "Average Metric: 21.815079365079367 / 43  (50.7):  43%|▍| 43/100 [00:42<00:49,  1.15i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.481746031746034 / 44  (51.1):  43%|▍| 43/100 [00:44<00:49,  1.15i\u001b[A\n",
      "Average Metric: 22.481746031746034 / 44  (51.1):  44%|▍| 44/100 [00:44<00:58,  1.05s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.481746031746034 / 45  (52.2):  44%|▍| 44/100 [00:45<00:58,  1.05s\u001b[A\n",
      "Average Metric: 23.481746031746034 / 45  (52.2):  45%|▍| 45/100 [00:45<00:56,  1.04s\u001b[A\n",
      "Average Metric: 23.815079365079367 / 46  (51.8):  45%|▍| 45/100 [00:47<00:56,  1.04s\u001b[A\n",
      "Average Metric: 23.815079365079367 / 46  (51.8):  46%|▍| 46/100 [00:47<01:08,  1.28s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 23.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.815079365079367 / 47  (52.8):  46%|▍| 46/100 [00:50<01:08,  1.28s\u001b[A\n",
      "Average Metric: 24.815079365079367 / 47  (52.8):  47%|▍| 47/100 [00:50<01:34,  1.78s\u001b[A\n",
      "Average Metric: 24.815079365079367 / 48  (51.7):  47%|▍| 47/100 [00:50<01:34,  1.78s\u001b[A\n",
      "Average Metric: 24.815079365079367 / 48  (51.7):  48%|▍| 48/100 [00:50<01:09,  1.33s\u001b[A\n",
      "Average Metric: 25.315079365079367 / 49  (51.7):  48%|▍| 48/100 [00:52<01:09,  1.33s\u001b[A\n",
      "Average Metric: 25.315079365079367 / 49  (51.7):  49%|▍| 49/100 [00:52<01:14,  1.47s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.6484126984127 / 50  (51.3):  49%|▍| 49/100 [00:53<01:14,  1.47s/i\u001b[A\n",
      "Average Metric: 25.6484126984127 / 50  (51.3):  50%|▌| 50/100 [00:53<01:08,  1.38s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.6484126984127 / 51  (52.3):  50%|▌| 50/100 [00:55<01:08,  1.38s/i\u001b[A\n",
      "Average Metric: 26.6484126984127 / 51  (52.3):  51%|▌| 51/100 [00:55<01:18,  1.59s/i\u001b[A\n",
      "Average Metric: 27.315079365079367 / 52  (52.5):  51%|▌| 51/100 [00:56<01:18,  1.59s\u001b[A\n",
      "Average Metric: 27.315079365079367 / 52  (52.5):  52%|▌| 52/100 [00:56<00:58,  1.22s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 28.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.6484126984127 / 53  (52.2):  52%|▌| 52/100 [00:57<00:58,  1.22s/i\u001b[A\n",
      "Average Metric: 27.6484126984127 / 53  (52.2):  53%|▌| 53/100 [00:57<00:57,  1.22s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.6484126984127 / 54  (53.1):  53%|▌| 53/100 [00:59<00:57,  1.22s/i\u001b[A\n",
      "Average Metric: 28.6484126984127 / 54  (53.1):  54%|▌| 54/100 [00:59<01:05,  1.43s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.6484126984127 / 55  (53.9):  54%|▌| 54/100 [01:00<01:05,  1.43s/i\u001b[A\n",
      "Average Metric: 29.6484126984127 / 55  (53.9):  55%|▌| 55/100 [01:00<01:01,  1.37s/i\u001b[A\n",
      "Average Metric: 29.6484126984127 / 56  (52.9):  55%|▌| 55/100 [01:01<01:01,  1.37s/i\u001b[A\n",
      "Average Metric: 29.6484126984127 / 56  (52.9):  56%|▌| 56/100 [01:01<00:52,  1.19s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.6484126984127 / 57  (52.0):  56%|▌| 56/100 [01:01<00:52,  1.19s/i\u001b[A\n",
      "Average Metric: 29.6484126984127 / 57  (52.0):  57%|▌| 57/100 [01:01<00:46,  1.08s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.6484126984127 / 58  (51.1):  57%|▌| 57/100 [01:02<00:46,  1.08s/i\u001b[A\n",
      "Average Metric: 29.6484126984127 / 58  (51.1):  58%|▌| 58/100 [01:02<00:44,  1.05s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.6484126984127 / 59  (50.3):  58%|▌| 58/100 [01:05<00:44,  1.05s/i\u001b[A\n",
      "Average Metric: 29.6484126984127 / 59  (50.3):  59%|▌| 59/100 [01:05<00:57,  1.40s/i\u001b[A\n",
      "Average Metric: 29.98174603174603 / 60  (50.0):  59%|▌| 59/100 [01:05<00:57,  1.40s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.48174603174603 / 61  (50.0):  60%|▌| 60/100 [01:06<00:56,  1.40s/\u001b[A\n",
      "Average Metric: 30.48174603174603 / 61  (50.0):  61%|▌| 61/100 [01:06<00:41,  1.07s/\u001b[A\n",
      "Average Metric: 31.48174603174603 / 62  (50.8):  61%|▌| 61/100 [01:07<00:41,  1.07s/\u001b[A\n",
      "Average Metric: 31.48174603174603 / 62  (50.8):  62%|▌| 62/100 [01:07<00:42,  1.11s/\u001b[A\n",
      "Average Metric: 31.48174603174603 / 63  (50.0):  62%|▌| 62/100 [01:08<00:42,  1.11s/\u001b[A\n",
      "Average Metric: 31.48174603174603 / 63  (50.0):  63%|▋| 63/100 [01:08<00:41,  1.12s/\u001b[A\n",
      "Average Metric: 31.98174603174603 / 64  (50.0):  63%|▋| 63/100 [01:10<00:41,  1.12s/\u001b[A\n",
      "Average Metric: 31.98174603174603 / 64  (50.0):  64%|▋| 64/100 [01:10<00:43,  1.20s/\u001b[A\n",
      "Average Metric: 32.98174603174603 / 65  (50.7):  64%|▋| 64/100 [01:10<00:43,  1.20s/\u001b[A\n",
      "Average Metric: 32.98174603174603 / 65  (50.7):  65%|▋| 65/100 [01:10<00:32,  1.08it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.48174603174603 / 66  (50.7):  65%|▋| 65/100 [01:11<00:32,  1.08it\u001b[A\n",
      "Average Metric: 33.48174603174603 / 66  (50.7):  66%|▋| 66/100 [01:11<00:34,  1.01s/\u001b[A\n",
      "Average Metric: 33.881746031746026 / 67  (50.6):  66%|▋| 66/100 [01:13<00:34,  1.01s\u001b[A\n",
      "Average Metric: 33.881746031746026 / 67  (50.6):  67%|▋| 67/100 [01:13<00:44,  1.35s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.881746031746026 / 68  (51.3):  67%|▋| 67/100 [01:14<00:44,  1.35s\u001b[A\n",
      "Average Metric: 34.881746031746026 / 68  (51.3):  68%|▋| 68/100 [01:14<00:35,  1.12s\u001b[A\n",
      "Average Metric: 35.21507936507936 / 69  (51.0):  68%|▋| 68/100 [01:15<00:35,  1.12s/\u001b[A\n",
      "Average Metric: 35.21507936507936 / 69  (51.0):  69%|▋| 69/100 [01:15<00:34,  1.11s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.21507936507936 / 70  (51.7):  69%|▋| 69/100 [01:16<00:34,  1.11s/\u001b[A\n",
      "Average Metric: 36.21507936507936 / 70  (51.7):  70%|▋| 70/100 [01:16<00:33,  1.12s/\u001b[A\n",
      "Average Metric: 37.21507936507936 / 71  (52.4):  70%|▋| 70/100 [01:17<00:33,  1.12s/\u001b[A\n",
      "Average Metric: 37.21507936507936 / 71  (52.4):  71%|▋| 71/100 [01:17<00:32,  1.11s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.881746031746026 / 72  (52.6):  71%|▋| 71/100 [01:19<00:32,  1.11s\u001b[A\n",
      "Average Metric: 37.881746031746026 / 72  (52.6):  72%|▋| 72/100 [01:19<00:36,  1.29s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.881746031746026 / 73  (53.3):  72%|▋| 72/100 [01:20<00:36,  1.29s\u001b[A\n",
      "Average Metric: 38.881746031746026 / 73  (53.3):  73%|▋| 73/100 [01:20<00:32,  1.21s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.21507936507936 / 74  (53.0):  73%|▋| 73/100 [01:21<00:32,  1.21s/\u001b[A\n",
      "Average Metric: 39.21507936507936 / 74  (53.0):  74%|▋| 74/100 [01:21<00:30,  1.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.21507936507936 / 75  (52.3):  74%|▋| 74/100 [01:24<00:30,  1.17s/\u001b[A\n",
      "Average Metric: 39.21507936507936 / 75  (52.3):  75%|▊| 75/100 [01:24<00:38,  1.55s/\u001b[A\n",
      "Average Metric: 40.21507936507936 / 76  (52.9):  75%|▊| 75/100 [01:24<00:38,  1.55s/\u001b[A\n",
      "Average Metric: 40.46507936507936 / 77  (52.6):  76%|▊| 76/100 [01:25<00:37,  1.55s/\u001b[A\n",
      "Average Metric: 40.46507936507936 / 77  (52.6):  77%|▊| 77/100 [01:25<00:27,  1.20s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 9.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 19.6 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.46507936507936 / 78  (53.2):  77%|▊| 77/100 [01:27<00:27,  1.20s/\u001b[A\n",
      "Average Metric: 41.46507936507936 / 78  (53.2):  78%|▊| 78/100 [01:27<00:32,  1.47s/\u001b[A\n",
      "Average Metric: 42.46507936507936 / 79  (53.8):  78%|▊| 78/100 [01:29<00:32,  1.47s/\u001b[A\n",
      "Average Metric: 42.46507936507936 / 79  (53.8):  79%|▊| 79/100 [01:29<00:30,  1.46s/\u001b[A\n",
      "Average Metric: 42.96507936507936 / 80  (53.7):  79%|▊| 79/100 [01:30<00:30,  1.46s/\u001b[A\n",
      "Average Metric: 42.96507936507936 / 80  (53.7):  80%|▊| 80/100 [01:30<00:26,  1.32s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 38.4 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.165079365079364 / 81  (53.3):  80%|▊| 80/100 [01:31<00:26,  1.32s\u001b[A\n",
      "Average Metric: 43.165079365079364 / 81  (53.3):  81%|▊| 81/100 [01:31<00:22,  1.19s\u001b[A\n",
      "Average Metric: 43.83174603174603 / 82  (53.5):  81%|▊| 81/100 [01:32<00:22,  1.19s/\u001b[A\n",
      "Average Metric: 43.83174603174603 / 82  (53.5):  82%|▊| 82/100 [01:32<00:22,  1.25s/\u001b[A\n",
      "Average Metric: 43.83174603174603 / 83  (52.8):  82%|▊| 82/100 [01:33<00:22,  1.25s/\u001b[A\n",
      "Average Metric: 43.83174603174603 / 83  (52.8):  83%|▊| 83/100 [01:33<00:20,  1.18s/\u001b[A\n",
      "Average Metric: 44.83174603174603 / 84  (53.4):  83%|▊| 83/100 [01:34<00:20,  1.18s/\u001b[A\n",
      "Average Metric: 44.83174603174603 / 84  (53.4):  84%|▊| 84/100 [01:34<00:19,  1.20s/\u001b[A\n",
      "Average Metric: 45.08174603174603 / 85  (53.0):  84%|▊| 84/100 [01:35<00:19,  1.20s/\u001b[A\n",
      "Average Metric: 45.08174603174603 / 85  (53.0):  85%|▊| 85/100 [01:35<00:17,  1.17s/\u001b[A\n",
      "Average Metric: 46.08174603174603 / 86  (53.6):  85%|▊| 85/100 [01:36<00:17,  1.17s/\u001b[A\n",
      "Average Metric: 47.08174603174603 / 87  (54.1):  86%|▊| 86/100 [01:37<00:16,  1.17s/\u001b[A\n",
      "Average Metric: 47.08174603174603 / 87  (54.1):  87%|▊| 87/100 [01:37<00:12,  1.02it\u001b[A\n",
      "Average Metric: 48.08174603174603 / 88  (54.6):  87%|▊| 87/100 [01:37<00:12,  1.02it\u001b[A\n",
      "Average Metric: 48.08174603174603 / 88  (54.6):  88%|▉| 88/100 [01:37<00:09,  1.28it\u001b[A\n",
      "Average Metric: 49.08174603174603 / 89  (55.1):  88%|▉| 88/100 [01:38<00:09,  1.28it\u001b[A\n",
      "Average Metric: 49.08174603174603 / 89  (55.1):  89%|▉| 89/100 [01:38<00:08,  1.30it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.08174603174603 / 90  (55.6):  89%|▉| 89/100 [01:39<00:08,  1.30it\u001b[A\n",
      "Average Metric: 50.08174603174603 / 90  (55.6):  90%|▉| 90/100 [01:39<00:07,  1.33it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.33174603174603 / 91  (55.3):  90%|▉| 90/100 [01:40<00:07,  1.33it\u001b[A\n",
      "Average Metric: 50.33174603174603 / 91  (55.3):  91%|▉| 91/100 [01:40<00:08,  1.07it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.33174603174603 / 92  (55.8):  91%|▉| 91/100 [01:41<00:08,  1.07it\u001b[A\n",
      "Average Metric: 51.33174603174603 / 92  (55.8):  92%|▉| 92/100 [01:41<00:08,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.33174603174603 / 93  (56.3):  92%|▉| 92/100 [01:42<00:08,  1.03s/\u001b[A\n",
      "Average Metric: 52.33174603174603 / 93  (56.3):  93%|▉| 93/100 [01:42<00:07,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 53.33174603174603 / 94  (56.7):  93%|▉| 93/100 [01:43<00:07,  1.03s/\u001b[A\n",
      "Average Metric: 53.33174603174603 / 94  (56.7):  94%|▉| 94/100 [01:43<00:06,  1.04s/\u001b[A\n",
      "Average Metric: 53.33174603174603 / 95  (56.1):  94%|▉| 94/100 [01:44<00:06,  1.04s/\u001b[A\n",
      "Average Metric: 53.33174603174603 / 95  (56.1):  95%|▉| 95/100 [01:44<00:05,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 54.33174603174603 / 96  (56.6):  95%|▉| 95/100 [01:46<00:05,  1.05s/\u001b[A\n",
      "Average Metric: 54.33174603174603 / 96  (56.6):  96%|▉| 96/100 [01:46<00:04,  1.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 54.53174603174603 / 97  (56.2):  96%|▉| 96/100 [01:48<00:04,  1.17s/\u001b[A\n",
      "Average Metric: 54.53174603174603 / 97  (56.2):  97%|▉| 97/100 [01:48<00:04,  1.53s/\u001b[A\n",
      "Average Metric: 55.03174603174603 / 98  (56.2):  97%|▉| 97/100 [01:50<00:04,  1.53s/\u001b[A\n",
      "Average Metric: 55.03174603174603 / 98  (56.2):  98%|▉| 98/100 [01:50<00:03,  1.52s/\u001b[A\n",
      "Average Metric: 56.03174603174603 / 99  (56.6):  98%|▉| 98/100 [01:54<00:03,  1.52s/\u001b[A\n",
      "Average Metric: 56.03174603174603 / 99  (56.6):  99%|▉| 99/100 [01:54<00:02,  2.32s/\u001b[A\n",
      "Average Metric: 57.03174603174603 / 100  (57.0):  99%|▉| 99/100 [02:09<00:02,  2.32s\u001b[A\n",
      "Average Metric: 57.03174603174603 / 100  (57.0): 100%|█| 100/100 [02:09<00:00,  1.30\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 57.03174603174603 / 100  (57.0%)\n",
      "Score: 57.03 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87, 57.03]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8848333333333334\n",
      "Average of max per entry across top 5 scores: 0.9475\n",
      "Average of max per entry across top 8 scores: 0.9783333333333334\n",
      "Average of max per entry across top 9999 scores: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:13,  1.35s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:02<02:14,  1.37s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:03<02:06,  1.30s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:06<02:57,  1.84s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:07<02:36,  1.65s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:09<02:38,  1.69s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:10<02:20,  1.51s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:12<02:19,  1.51s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:13<02:12,  1.46s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 1  (33.3):   0%|       | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 1  (33.3):   1%| | 1/100 [00:01<02:01,  1.23s/i\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   1%| | 1/100 [00:01<02:01,  1.23s/i\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   2%| | 2/100 [00:01<00:58,  1.69it/\u001b[A\n",
      "Average Metric: 1.3333333333333333 / 3  (44.4):   2%| | 2/100 [00:01<00:58,  1.69it/\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):   3%| | 3/100 [00:01<00:57,  1.69it/\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):   4%| | 4/100 [00:01<00:56,  1.69it/\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):   5%| | 5/100 [00:01<00:21,  4.41it/\u001b[A\n",
      "Average Metric: 2.583333333333333 / 6  (43.1):   5%| | 5/100 [00:01<00:21,  4.41it/s\u001b[A\n",
      "Average Metric: 2.583333333333333 / 7  (36.9):   6%| | 6/100 [00:02<00:21,  4.41it/s\u001b[A\n",
      "Average Metric: 2.583333333333333 / 7  (36.9):   7%| | 7/100 [00:02<00:20,  4.49it/s\u001b[A\n",
      "Average Metric: 2.583333333333333 / 8  (32.3):   7%| | 7/100 [00:02<00:20,  4.49it/s\u001b[A\n",
      "Average Metric: 2.583333333333333 / 8  (32.3):   8%| | 8/100 [00:02<00:27,  3.36it/s\u001b[A\n",
      "Average Metric: 3.083333333333333 / 9  (34.3):   8%| | 8/100 [00:02<00:27,  3.36it/s\u001b[A\n",
      "Average Metric: 3.083333333333333 / 9  (34.3):   9%| | 9/100 [00:02<00:26,  3.48it/s\u001b[A\n",
      "Average Metric: 4.083333333333333 / 10  (40.8):   9%| | 9/100 [00:02<00:26,  3.48it/\u001b[A\n",
      "Average Metric: 4.083333333333333 / 10  (40.8):  10%| | 10/100 [00:02<00:21,  4.11it\u001b[A\n",
      "Average Metric: 4.527777777777778 / 11  (41.2):  10%| | 10/100 [00:03<00:21,  4.11it\u001b[A\n",
      "Average Metric: 4.527777777777778 / 11  (41.2):  11%| | 11/100 [00:03<00:20,  4.36it\u001b[A\n",
      "Average Metric: 5.527777777777778 / 12  (46.1):  11%| | 11/100 [00:03<00:20,  4.36it\u001b[A\n",
      "Average Metric: 5.777777777777778 / 13  (44.4):  12%| | 12/100 [00:03<00:20,  4.36it\u001b[A\n",
      "Average Metric: 5.777777777777778 / 13  (44.4):  13%|▏| 13/100 [00:03<00:19,  4.55it\u001b[A\n",
      "Average Metric: 6.777777777777778 / 14  (48.4):  13%|▏| 13/100 [00:04<00:19,  4.55it\u001b[A\n",
      "Average Metric: 6.777777777777778 / 14  (48.4):  14%|▏| 14/100 [00:04<00:28,  3.04it\u001b[A\n",
      "Average Metric: 6.977777777777778 / 15  (46.5):  14%|▏| 14/100 [00:04<00:28,  3.04it\u001b[A\n",
      "Average Metric: 7.177777777777778 / 16  (44.9):  15%|▏| 15/100 [00:04<00:27,  3.04it\u001b[A\n",
      "Average Metric: 7.177777777777778 / 16  (44.9):  16%|▏| 16/100 [00:04<00:20,  4.01it\u001b[A\n",
      "Average Metric: 7.511111111111111 / 17  (44.2):  16%|▏| 16/100 [00:04<00:20,  4.01it\u001b[A\n",
      "Average Metric: 8.511111111111111 / 18  (47.3):  17%|▏| 17/100 [00:04<00:20,  4.01it\u001b[A\n",
      "Average Metric: 8.511111111111111 / 18  (47.3):  18%|▏| 18/100 [00:04<00:15,  5.23it\u001b[A\n",
      "Average Metric: 8.844444444444445 / 19  (46.5):  18%|▏| 18/100 [00:04<00:15,  5.23it\u001b[A\n",
      "Average Metric: 8.844444444444445 / 19  (46.5):  19%|▏| 19/100 [00:04<00:15,  5.32it\u001b[A\n",
      "Average Metric: 8.844444444444445 / 20  (44.2):  19%|▏| 19/100 [00:05<00:15,  5.32it\u001b[A\n",
      "Average Metric: 8.844444444444445 / 20  (44.2):  20%|▏| 20/100 [00:05<00:19,  4.00it\u001b[A\n",
      "Average Metric: 9.344444444444445 / 21  (44.5):  20%|▏| 20/100 [00:05<00:19,  4.00it\u001b[A\n",
      "Average Metric: 9.344444444444445 / 22  (42.5):  21%|▏| 21/100 [00:05<00:19,  4.00it\u001b[A\n",
      "Average Metric: 9.344444444444445 / 22  (42.5):  22%|▏| 22/100 [00:05<00:20,  3.80it\u001b[A\n",
      "Average Metric: 10.011111111111111 / 23  (43.5):  22%|▏| 22/100 [00:06<00:20,  3.80i\u001b[A\n",
      "Average Metric: 10.011111111111111 / 23  (43.5):  23%|▏| 23/100 [00:06<00:21,  3.54i\u001b[A\n",
      "Average Metric: 10.011111111111111 / 24  (41.7):  23%|▏| 23/100 [00:06<00:21,  3.54i\u001b[A\n",
      "Average Metric: 10.011111111111111 / 24  (41.7):  24%|▏| 24/100 [00:06<00:19,  3.97i\u001b[A\n",
      "Average Metric: 10.511111111111111 / 25  (42.0):  24%|▏| 24/100 [00:06<00:19,  3.97i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.511111111111111 / 26  (44.3):  25%|▎| 25/100 [00:08<00:18,  3.97i\u001b[A\n",
      "Average Metric: 11.511111111111111 / 26  (44.3):  26%|▎| 26/100 [00:08<00:41,  1.77i\u001b[A\n",
      "Average Metric: 12.511111111111111 / 27  (46.3):  26%|▎| 26/100 [00:08<00:41,  1.77i\u001b[A\n",
      "Average Metric: 12.511111111111111 / 27  (46.3):  27%|▎| 27/100 [00:08<00:38,  1.89i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.511111111111111 / 28  (48.3):  27%|▎| 27/100 [00:09<00:38,  1.89i\u001b[A\n",
      "Average Metric: 13.511111111111111 / 28  (48.3):  28%|▎| 28/100 [00:09<00:43,  1.66i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.844444444444445 / 29  (47.7):  28%|▎| 28/100 [00:10<00:43,  1.66i\u001b[A\n",
      "Average Metric: 13.844444444444445 / 29  (47.7):  29%|▎| 29/100 [00:10<00:54,  1.29i\u001b[A\n",
      "Average Metric: 14.594444444444445 / 30  (48.6):  29%|▎| 29/100 [00:11<00:54,  1.29i\u001b[A\n",
      "Average Metric: 14.594444444444445 / 30  (48.6):  30%|▎| 30/100 [00:11<00:43,  1.60i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.927777777777779 / 31  (48.2):  30%|▎| 30/100 [00:12<00:43,  1.60i\u001b[A\n",
      "Average Metric: 14.927777777777779 / 31  (48.2):  31%|▎| 31/100 [00:12<00:55,  1.25i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.927777777777779 / 32  (49.8):  31%|▎| 31/100 [00:13<00:55,  1.25i\u001b[A\n",
      "Average Metric: 15.927777777777779 / 32  (49.8):  32%|▎| 32/100 [00:13<01:06,  1.03i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.594444444444445 / 33  (50.3):  32%|▎| 32/100 [00:14<01:06,  1.03i\u001b[A\n",
      "Average Metric: 16.594444444444445 / 33  (50.3):  33%|▎| 33/100 [00:14<01:03,  1.06i\u001b[A\n",
      "Average Metric: 17.594444444444445 / 34  (51.7):  33%|▎| 33/100 [00:14<01:03,  1.06i\u001b[A\n",
      "Average Metric: 17.594444444444445 / 34  (51.7):  34%|▎| 34/100 [00:14<00:48,  1.36i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.594444444444445 / 35  (50.3):  34%|▎| 34/100 [00:16<00:48,  1.36i\u001b[A\n",
      "Average Metric: 17.594444444444445 / 35  (50.3):  35%|▎| 35/100 [00:16<00:57,  1.14i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.594444444444445 / 36  (51.7):  35%|▎| 35/100 [00:17<00:57,  1.14i\u001b[A\n",
      "Average Metric: 18.594444444444445 / 36  (51.7):  36%|▎| 36/100 [00:17<01:09,  1.08s\u001b[A\n",
      "Average Metric: 19.261111111111113 / 37  (52.1):  36%|▎| 36/100 [00:18<01:09,  1.08s\u001b[A\n",
      "Average Metric: 19.261111111111113 / 37  (52.1):  37%|▎| 37/100 [00:18<00:56,  1.12i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.761111111111113 / 38  (52.0):  37%|▎| 37/100 [00:19<00:56,  1.12i\u001b[A\n",
      "Average Metric: 19.761111111111113 / 38  (52.0):  38%|▍| 38/100 [00:19<01:01,  1.00i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.761111111111113 / 39  (53.2):  38%|▍| 38/100 [00:20<01:01,  1.00i\u001b[A\n",
      "Average Metric: 20.761111111111113 / 39  (53.2):  39%|▍| 39/100 [00:20<01:00,  1.00i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.761111111111113 / 40  (54.4):  39%|▍| 39/100 [00:21<01:00,  1.00i\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.761111111111113 / 40  (54.4):  40%|▍| 40/100 [00:21<01:06,  1.11s\u001b[A\n",
      "Average Metric: 22.16111111111111 / 41  (54.1):  40%|▍| 40/100 [00:23<01:06,  1.11s/\u001b[A\n",
      "Average Metric: 22.16111111111111 / 41  (54.1):  41%|▍| 41/100 [00:23<01:08,  1.15s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.16111111111111 / 42  (55.1):  41%|▍| 41/100 [00:24<01:08,  1.15s/\u001b[A\n",
      "Average Metric: 23.16111111111111 / 42  (55.1):  42%|▍| 42/100 [00:24<01:04,  1.11s/\u001b[A\n",
      "Average Metric: 23.16111111111111 / 43  (53.9):  42%|▍| 42/100 [00:25<01:04,  1.11s/\u001b[A\n",
      "Average Metric: 23.16111111111111 / 43  (53.9):  43%|▍| 43/100 [00:25<01:01,  1.08s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 20.5 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.494444444444444 / 44  (53.4):  43%|▍| 43/100 [00:26<01:01,  1.08s\u001b[A\n",
      "Average Metric: 23.494444444444444 / 44  (53.4):  44%|▍| 44/100 [00:26<01:14,  1.33s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.494444444444444 / 45  (54.4):  44%|▍| 44/100 [00:30<01:14,  1.33s\u001b[A\n",
      "Average Metric: 24.494444444444444 / 45  (54.4):  45%|▍| 45/100 [00:30<01:45,  1.91s\u001b[A\n",
      "Average Metric: 24.744444444444444 / 46  (53.8):  45%|▍| 45/100 [00:30<01:45,  1.91s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.41111111111111 / 47  (54.1):  46%|▍| 46/100 [00:30<01:43,  1.91s/\u001b[A\n",
      "Average Metric: 25.41111111111111 / 47  (54.1):  47%|▍| 47/100 [00:30<01:01,  1.16s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.41111111111111 / 48  (55.0):  47%|▍| 47/100 [00:31<01:01,  1.16s/\u001b[A\n",
      "Average Metric: 26.41111111111111 / 48  (55.0):  48%|▍| 48/100 [00:31<00:59,  1.15s/\u001b[A\n",
      "Average Metric: 27.41111111111111 / 49  (55.9):  48%|▍| 48/100 [00:32<00:59,  1.15s/\u001b[A\n",
      "Average Metric: 27.41111111111111 / 49  (55.9):  49%|▍| 49/100 [00:32<00:54,  1.07s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.41111111111111 / 50  (56.8):  49%|▍| 49/100 [00:33<00:54,  1.07s/\u001b[A\n",
      "Average Metric: 28.41111111111111 / 50  (56.8):  50%|▌| 50/100 [00:33<00:51,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.91111111111111 / 51  (56.7):  50%|▌| 50/100 [00:35<00:51,  1.03s/\u001b[A\n",
      "Average Metric: 28.91111111111111 / 51  (56.7):  51%|▌| 51/100 [00:35<00:58,  1.20s/\u001b[A\n",
      "Average Metric: 29.91111111111111 / 52  (57.5):  51%|▌| 51/100 [00:35<00:58,  1.20s/\u001b[A\n",
      "Average Metric: 29.91111111111111 / 52  (57.5):  52%|▌| 52/100 [00:35<00:49,  1.04s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.91111111111111 / 53  (58.3):  52%|▌| 52/100 [00:38<00:49,  1.04s/\u001b[A\n",
      "Average Metric: 30.91111111111111 / 53  (58.3):  53%|▌| 53/100 [00:38<01:02,  1.32s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.41111111111111 / 54  (58.2):  53%|▌| 53/100 [00:40<01:02,  1.32s/\u001b[A\n",
      "Average Metric: 31.41111111111111 / 54  (58.2):  54%|▌| 54/100 [00:40<01:11,  1.54s/\u001b[A\n",
      "Average Metric: 31.744444444444444 / 55  (57.7):  54%|▌| 54/100 [00:40<01:11,  1.54s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.744444444444444 / 56  (56.7):  55%|▌| 55/100 [00:41<01:09,  1.54s\u001b[A\n",
      "Average Metric: 31.744444444444444 / 56  (56.7):  56%|▌| 56/100 [00:41<00:47,  1.08s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.744444444444444 / 57  (55.7):  56%|▌| 56/100 [00:41<00:47,  1.08s\u001b[A\n",
      "Average Metric: 31.744444444444444 / 57  (55.7):  57%|▌| 57/100 [00:41<00:41,  1.03i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.744444444444444 / 58  (54.7):  57%|▌| 57/100 [00:42<00:41,  1.03i\u001b[A\n",
      "Average Metric: 31.744444444444444 / 58  (54.7):  58%|▌| 58/100 [00:42<00:41,  1.01i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.744444444444444 / 59  (53.8):  58%|▌| 58/100 [00:43<00:41,  1.01i\u001b[A\n",
      "Average Metric: 31.744444444444444 / 59  (53.8):  59%|▌| 59/100 [00:43<00:41,  1.02s\u001b[A\n",
      "Average Metric: 32.24444444444444 / 60  (53.7):  59%|▌| 59/100 [00:44<00:41,  1.02s/\u001b[A\n",
      "Average Metric: 32.24444444444444 / 60  (53.7):  60%|▌| 60/100 [00:44<00:41,  1.04s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.577777777777776 / 61  (53.4):  60%|▌| 60/100 [00:48<00:41,  1.04s\u001b[A\n",
      "Average Metric: 32.577777777777776 / 61  (53.4):  61%|▌| 61/100 [00:48<01:02,  1.61s\u001b[A\n",
      "Average Metric: 32.577777777777776 / 62  (52.5):  61%|▌| 61/100 [00:48<01:02,  1.61s\u001b[A\n",
      "Average Metric: 32.577777777777776 / 62  (52.5):  62%|▌| 62/100 [00:48<00:45,  1.19s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.577777777777776 / 63  (51.7):  62%|▌| 62/100 [00:49<00:45,  1.19s\u001b[A\n",
      "Average Metric: 32.577777777777776 / 63  (51.7):  63%|▋| 63/100 [00:49<00:50,  1.37s\u001b[A\n",
      "Average Metric: 33.077777777777776 / 64  (51.7):  63%|▋| 63/100 [00:50<00:50,  1.37s\u001b[A\n",
      "Average Metric: 33.077777777777776 / 64  (51.7):  64%|▋| 64/100 [00:50<00:37,  1.03s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.327777777777776 / 65  (51.3):  64%|▋| 64/100 [00:51<00:37,  1.03s\u001b[A\n",
      "Average Metric: 33.327777777777776 / 65  (51.3):  65%|▋| 65/100 [00:51<00:40,  1.15s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.327777777777776 / 66  (52.0):  65%|▋| 65/100 [00:53<00:40,  1.15s\u001b[A\n",
      "Average Metric: 34.327777777777776 / 66  (52.0):  66%|▋| 66/100 [00:53<00:47,  1.39s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.327777777777776 / 67  (52.7):  66%|▋| 66/100 [00:54<00:47,  1.39s\u001b[A\n",
      "Average Metric: 35.327777777777776 / 67  (52.7):  67%|▋| 67/100 [00:54<00:40,  1.24s\u001b[A\n",
      "Average Metric: 35.827777777777776 / 68  (52.7):  67%|▋| 67/100 [00:54<00:40,  1.24s\u001b[A\n",
      "Average Metric: 35.827777777777776 / 68  (52.7):  68%|▋| 68/100 [00:54<00:29,  1.10i\u001b[A\n",
      "Average Metric: 36.827777777777776 / 69  (53.4):  68%|▋| 68/100 [00:55<00:29,  1.10i\u001b[A\n",
      "Average Metric: 36.827777777777776 / 69  (53.4):  69%|▋| 69/100 [00:55<00:28,  1.08i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.16111111111111 / 70  (53.1):  69%|▋| 69/100 [00:55<00:28,  1.08it\u001b[A\n",
      "Average Metric: 37.16111111111111 / 70  (53.1):  70%|▋| 70/100 [00:55<00:22,  1.35it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.7 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.16111111111111 / 71  (53.7):  70%|▋| 70/100 [00:57<00:22,  1.35it\u001b[A\n",
      "Average Metric: 38.16111111111111 / 71  (53.7):  71%|▋| 71/100 [00:57<00:28,  1.01it\u001b[A\n",
      "Average Metric: 39.16111111111111 / 72  (54.4):  71%|▋| 71/100 [00:57<00:28,  1.01it\u001b[A\n",
      "Average Metric: 39.16111111111111 / 72  (54.4):  72%|▋| 72/100 [00:57<00:23,  1.18it\u001b[A\n",
      "Average Metric: 39.49444444444445 / 73  (54.1):  72%|▋| 72/100 [00:58<00:23,  1.18it\u001b[A\n",
      "Average Metric: 39.49444444444445 / 73  (54.1):  73%|▋| 73/100 [00:58<00:23,  1.13it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.49444444444445 / 74  (53.4):  73%|▋| 73/100 [00:59<00:23,  1.13it\u001b[A\n",
      "Average Metric: 39.49444444444445 / 74  (53.4):  74%|▋| 74/100 [00:59<00:21,  1.23it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.82777777777778 / 75  (53.1):  74%|▋| 74/100 [01:01<00:21,  1.23it\u001b[A\n",
      "Average Metric: 39.82777777777778 / 75  (53.1):  75%|▊| 75/100 [01:01<00:28,  1.13s/\u001b[A\n",
      "Average Metric: 39.82777777777778 / 76  (52.4):  75%|▊| 75/100 [01:01<00:28,  1.13s/\u001b[A\n",
      "Average Metric: 39.82777777777778 / 76  (52.4):  76%|▊| 76/100 [01:01<00:21,  1.10it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 16.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.027777777777786 / 77  (52.0):  76%|▊| 76/100 [01:03<00:21,  1.10i\u001b[A\n",
      "Average Metric: 40.027777777777786 / 77  (52.0):  77%|▊| 77/100 [01:03<00:23,  1.02s\u001b[A\n",
      "Average Metric: 41.027777777777786 / 78  (52.6):  77%|▊| 77/100 [01:05<00:23,  1.02s\u001b[A\n",
      "Average Metric: 41.027777777777786 / 78  (52.6):  78%|▊| 78/100 [01:05<00:28,  1.29s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.22777777777779 / 79  (52.2):  78%|▊| 78/100 [01:05<00:28,  1.29s/\u001b[A\n",
      "Average Metric: 41.22777777777779 / 79  (52.2):  79%|▊| 79/100 [01:05<00:23,  1.13s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 55.0 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.72777777777779 / 80  (52.2):  79%|▊| 79/100 [01:06<00:23,  1.13s/\u001b[A\n",
      "Average Metric: 41.72777777777779 / 80  (52.2):  80%|▊| 80/100 [01:06<00:19,  1.02it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.72777777777779 / 81  (52.8):  80%|▊| 80/100 [01:07<00:19,  1.02it\u001b[A\n",
      "Average Metric: 42.72777777777779 / 81  (52.8):  81%|▊| 81/100 [01:07<00:19,  1.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.72777777777779 / 82  (52.1):  81%|▊| 81/100 [01:08<00:19,  1.02s/\u001b[A\n",
      "Average Metric: 42.72777777777779 / 82  (52.1):  82%|▊| 82/100 [01:08<00:17,  1.04it\u001b[A\n",
      "Average Metric: 42.72777777777779 / 83  (51.5):  82%|▊| 82/100 [01:09<00:17,  1.04it\u001b[A\n",
      "Average Metric: 42.72777777777779 / 83  (51.5):  83%|▊| 83/100 [01:09<00:17,  1.05s/\u001b[A\n",
      "Average Metric: 43.72777777777779 / 84  (52.1):  83%|▊| 83/100 [01:09<00:17,  1.05s/\u001b[A\n",
      "Average Metric: 43.72777777777779 / 84  (52.1):  84%|▊| 84/100 [01:09<00:12,  1.28it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.72777777777779 / 85  (52.6):  84%|▊| 84/100 [01:10<00:12,  1.28it\u001b[A\n",
      "Average Metric: 44.72777777777779 / 85  (52.6):  85%|▊| 85/100 [01:10<00:13,  1.10it\u001b[A\n",
      "Average Metric: 45.72777777777779 / 86  (53.2):  85%|▊| 85/100 [01:11<00:13,  1.10it\u001b[A\n",
      "Average Metric: 46.72777777777779 / 87  (53.7):  86%|▊| 86/100 [01:11<00:12,  1.10it\u001b[A\n",
      "Average Metric: 46.72777777777779 / 87  (53.7):  87%|▊| 87/100 [01:11<00:08,  1.45it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.72777777777779 / 88  (54.2):  87%|▊| 87/100 [01:12<00:08,  1.45it\u001b[A\n",
      "Average Metric: 47.72777777777779 / 88  (54.2):  88%|▉| 88/100 [01:12<00:07,  1.62it\u001b[A\n",
      "Average Metric: 48.72777777777779 / 89  (54.8):  88%|▉| 88/100 [01:13<00:07,  1.62it\u001b[A\n",
      "Average Metric: 48.72777777777779 / 89  (54.8):  89%|▉| 89/100 [01:13<00:07,  1.43it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.72777777777779 / 90  (55.3):  89%|▉| 89/100 [01:14<00:07,  1.43it\u001b[A\n",
      "Average Metric: 49.72777777777779 / 90  (55.3):  90%|▉| 90/100 [01:14<00:07,  1.35it\u001b[A\n",
      "Average Metric: 50.72777777777779 / 91  (55.7):  90%|▉| 90/100 [01:14<00:07,  1.35it\u001b[A\n",
      "Average Metric: 50.72777777777779 / 91  (55.7):  91%|▉| 91/100 [01:14<00:07,  1.26it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.72777777777779 / 92  (56.2):  91%|▉| 91/100 [01:16<00:07,  1.26it\u001b[A\n",
      "Average Metric: 51.72777777777779 / 92  (56.2):  92%|▉| 92/100 [01:16<00:07,  1.03it\u001b[A\n",
      "Average Metric: 52.72777777777779 / 93  (56.7):  92%|▉| 92/100 [01:17<00:07,  1.03it\u001b[A\n",
      "Average Metric: 52.72777777777779 / 93  (56.7):  93%|▉| 93/100 [01:17<00:06,  1.00it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.72777777777779 / 94  (56.1):  93%|▉| 93/100 [01:19<00:06,  1.00it\u001b[A\n",
      "Average Metric: 52.72777777777779 / 94  (56.1):  94%|▉| 94/100 [01:19<00:07,  1.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.72777777777779 / 95  (55.5):  94%|▉| 94/100 [01:20<00:07,  1.17s/\u001b[A\n",
      "Average Metric: 52.72777777777779 / 95  (55.5):  95%|▉| 95/100 [01:20<00:06,  1.29s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.72777777777779 / 96  (54.9):  95%|▉| 95/100 [01:22<00:06,  1.29s/\u001b[A\n",
      "Average Metric: 52.72777777777779 / 96  (54.9):  96%|▉| 96/100 [01:22<00:05,  1.35s/\u001b[A\n",
      "Average Metric: 53.72777777777779 / 97  (55.4):  96%|▉| 96/100 [01:22<00:05,  1.35s/\u001b[A\n",
      "Average Metric: 53.72777777777779 / 97  (55.4):  97%|▉| 97/100 [01:22<00:03,  1.09s/\u001b[A\n",
      "Average Metric: 54.22777777777779 / 98  (55.3):  97%|▉| 97/100 [01:24<00:03,  1.09s/\u001b[A\n",
      "Average Metric: 54.22777777777779 / 98  (55.3):  98%|▉| 98/100 [01:24<00:02,  1.22s/\u001b[A\n",
      "Average Metric: 55.22777777777779 / 99  (55.8):  98%|▉| 98/100 [01:35<00:02,  1.22s/\u001b[A\n",
      "Average Metric: 55.22777777777779 / 99  (55.8):  99%|▉| 99/100 [01:35<00:04,  4.35s/\u001b[A\n",
      "Average Metric: 55.561111111111124 / 100  (55.6):  99%|▉| 99/100 [02:02<00:04,  4.35\u001b[A\n",
      "Average Metric: 55.561111111111124 / 100  (55.6): 100%|█| 100/100 [02:02<00:00,  1.2\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 55.561111111111124 / 100  (55.6%)\n",
      "Score: 55.56 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87, 57.03, 55.56]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8848333333333334\n",
      "Average of max per entry across top 5 scores: 0.9475\n",
      "Average of max per entry across top 8 scores: 0.9766666666666666\n",
      "Average of max per entry across top 9999 scores: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:02<03:55,  2.38s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:03<02:41,  1.65s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:04<02:16,  1.41s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:06<02:22,  1.49s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:07<02:16,  1.44s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:10<03:02,  1.95s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:12<02:47,  1.80s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:13<02:42,  1.77s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:15<02:31,  1.66s/it]\u001b[A\n",
      " 10%|████▌                                         | 10/100 [00:17<02:38,  1.77s/it]\u001b[A\n",
      " 11%|█████                                         | 11/100 [00:18<02:28,  1.66s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                      | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   1%|▏             | 1/100 [00:01<01:48,  1.10s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   1%|▏             | 1/100 [00:01<01:48,  1.10s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   2%|▎             | 2/100 [00:01<01:47,  1.10s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   3%|▍             | 3/100 [00:01<00:43,  2.21it/s]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):   3%|▍             | 3/100 [00:01<00:43,  2.21it/s]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):   4%|▌             | 4/100 [00:01<00:34,  2.76it/s]\u001b[A\n",
      "Average Metric: 2.5 / 5  (50.0):   4%|▌             | 4/100 [00:01<00:34,  2.76it/s]\u001b[A\n",
      "Average Metric: 2.5 / 5  (50.0):   5%|▋             | 5/100 [00:01<00:28,  3.28it/s]\u001b[A\n",
      "Average Metric: 2.5 / 6  (41.7):   5%|▋             | 5/100 [00:02<00:28,  3.28it/s]\u001b[A\n",
      "Average Metric: 2.5 / 6  (41.7):   6%|▊             | 6/100 [00:02<00:50,  1.85it/s]\u001b[A\n",
      "Average Metric: 3.25 / 7  (46.4):   6%|▊            | 6/100 [00:02<00:50,  1.85it/s]\u001b[A\n",
      "Average Metric: 3.6944444444444446 / 8  (46.2):   7%| | 7/100 [00:03<00:50,  1.85it/\u001b[A\n",
      "Average Metric: 3.6944444444444446 / 8  (46.2):   8%| | 8/100 [00:03<00:37,  2.48it/\u001b[A\n",
      "Average Metric: 3.9444444444444446 / 9  (43.8):   8%| | 8/100 [00:03<00:37,  2.48it/\u001b[A\n",
      "Average Metric: 3.9444444444444446 / 10  (39.4):   9%| | 9/100 [00:03<00:36,  2.48it\u001b[A\n",
      "Average Metric: 4.277777777777778 / 11  (38.9):  10%| | 10/100 [00:04<00:36,  2.48it\u001b[A\n",
      "Average Metric: 4.277777777777778 / 11  (38.9):  11%| | 11/100 [00:04<00:26,  3.33it\u001b[A\n",
      "Average Metric: 5.277777777777778 / 12  (44.0):  11%| | 11/100 [00:04<00:26,  3.33it\u001b[A\n",
      "Average Metric: 5.527777777777778 / 13  (42.5):  12%| | 12/100 [00:04<00:26,  3.33it\u001b[A\n",
      "Average Metric: 6.527777777777778 / 14  (46.6):  13%|▏| 13/100 [00:04<00:26,  3.33it\u001b[A\n",
      "Average Metric: 6.527777777777778 / 14  (46.6):  14%|▏| 14/100 [00:04<00:20,  4.13it\u001b[A\n",
      "Average Metric: 7.527777777777778 / 15  (50.2):  14%|▏| 14/100 [00:04<00:20,  4.13it\u001b[A\n",
      "Average Metric: 7.527777777777778 / 15  (50.2):  15%|▏| 15/100 [00:04<00:22,  3.71it\u001b[A\n",
      "Average Metric: 7.861111111111111 / 16  (49.1):  15%|▏| 15/100 [00:05<00:22,  3.71it\u001b[A\n",
      "Average Metric: 7.861111111111111 / 16  (49.1):  16%|▏| 16/100 [00:05<00:24,  3.48it\u001b[A\n",
      "Average Metric: 8.61111111111111 / 17  (50.7):  16%|▏| 16/100 [00:05<00:24,  3.48it/\u001b[A\n",
      "Average Metric: 8.61111111111111 / 17  (50.7):  17%|▏| 17/100 [00:05<00:24,  3.33it/\u001b[A\n",
      "Average Metric: 9.61111111111111 / 18  (53.4):  17%|▏| 17/100 [00:05<00:24,  3.33it/\u001b[A\n",
      "Average Metric: 10.11111111111111 / 19  (53.2):  18%|▏| 18/100 [00:06<00:24,  3.33it\u001b[A\n",
      "Average Metric: 10.11111111111111 / 19  (53.2):  19%|▏| 19/100 [00:06<00:22,  3.61it\u001b[A\n",
      "Average Metric: 10.11111111111111 / 20  (50.6):  19%|▏| 19/100 [00:06<00:22,  3.61it\u001b[A\n",
      "Average Metric: 10.11111111111111 / 21  (48.1):  20%|▏| 20/100 [00:06<00:22,  3.61it\u001b[A\n",
      "Average Metric: 10.86111111111111 / 22  (49.4):  21%|▏| 21/100 [00:06<00:21,  3.61it\u001b[A\n",
      "Average Metric: 10.86111111111111 / 22  (49.4):  22%|▏| 22/100 [00:06<00:17,  4.40it\u001b[A\n",
      "Average Metric: 11.86111111111111 / 23  (51.6):  22%|▏| 22/100 [00:06<00:17,  4.40it\u001b[A\n",
      "Average Metric: 11.86111111111111 / 23  (51.6):  23%|▏| 23/100 [00:06<00:17,  4.40it\u001b[A\n",
      "Average Metric: 12.36111111111111 / 24  (51.5):  23%|▏| 23/100 [00:06<00:17,  4.40it\u001b[A\n",
      "Average Metric: 13.11111111111111 / 25  (52.4):  24%|▏| 24/100 [00:07<00:17,  4.40it\u001b[A\n",
      "Average Metric: 13.11111111111111 / 25  (52.4):  25%|▎| 25/100 [00:07<00:18,  4.01it\u001b[A\n",
      "Average Metric: 14.11111111111111 / 26  (54.3):  25%|▎| 25/100 [00:07<00:18,  4.01it\u001b[A\n",
      "Average Metric: 14.777777777777777 / 27  (54.7):  26%|▎| 26/100 [00:07<00:18,  4.01i\u001b[A\n",
      "Average Metric: 14.777777777777777 / 28  (52.8):  27%|▎| 27/100 [00:07<00:18,  4.01i\u001b[A\n",
      "Average Metric: 15.777777777777777 / 29  (54.4):  28%|▎| 28/100 [00:07<00:17,  4.01i\u001b[A\n",
      "Average Metric: 15.777777777777777 / 29  (54.4):  29%|▎| 29/100 [00:07<00:10,  6.58i\u001b[A\n",
      "Average Metric: 16.77777777777778 / 30  (55.9):  29%|▎| 29/100 [00:08<00:10,  6.58it\u001b[A\n",
      "Average Metric: 16.77777777777778 / 30  (55.9):  30%|▎| 30/100 [00:08<00:14,  4.75it\u001b[A\n",
      "Average Metric: 16.77777777777778 / 31  (54.1):  30%|▎| 30/100 [00:08<00:14,  4.75it\u001b[A\n",
      "Average Metric: 16.77777777777778 / 31  (54.1):  31%|▎| 31/100 [00:08<00:17,  3.94it\u001b[A\n",
      "Average Metric: 16.77777777777778 / 32  (52.4):  31%|▎| 31/100 [00:08<00:17,  3.94it\u001b[A\n",
      "Average Metric: 17.11111111111111 / 33  (51.9):  32%|▎| 32/100 [00:08<00:17,  3.94it\u001b[A\n",
      "Average Metric: 17.36111111111111 / 34  (51.1):  33%|▎| 33/100 [00:09<00:17,  3.94it\u001b[A\n",
      "Average Metric: 17.36111111111111 / 34  (51.1):  34%|▎| 34/100 [00:09<00:12,  5.13it\u001b[A\n",
      "Average Metric: 17.36111111111111 / 35  (49.6):  34%|▎| 34/100 [00:09<00:12,  5.13it\u001b[A\n",
      "Average Metric: 17.36111111111111 / 35  (49.6):  35%|▎| 35/100 [00:09<00:16,  3.86it\u001b[A\n",
      "Average Metric: 17.694444444444443 / 36  (49.2):  35%|▎| 35/100 [00:10<00:16,  3.86i\u001b[A\n",
      "Average Metric: 17.694444444444443 / 36  (49.2):  36%|▎| 36/100 [00:10<00:20,  3.13i\u001b[A\n",
      "Average Metric: 18.36111111111111 / 37  (49.6):  36%|▎| 36/100 [00:10<00:20,  3.13it\u001b[A\n",
      "Average Metric: 19.02777777777778 / 38  (50.1):  37%|▎| 37/100 [00:10<00:20,  3.13it\u001b[A\n",
      "Average Metric: 19.02777777777778 / 38  (50.1):  38%|▍| 38/100 [00:10<00:19,  3.24it\u001b[A\n",
      "Average Metric: 19.52777777777778 / 39  (50.1):  38%|▍| 38/100 [00:10<00:19,  3.24it\u001b[A\n",
      "Average Metric: 20.02777777777778 / 40  (50.1):  39%|▍| 39/100 [00:10<00:18,  3.24it\u001b[A\n",
      "Average Metric: 20.427777777777777 / 41  (49.8):  40%|▍| 40/100 [00:10<00:18,  3.24i\u001b[A\n",
      "Average Metric: 20.427777777777777 / 41  (49.8):  41%|▍| 41/100 [00:10<00:12,  4.85i\u001b[A\n",
      "Average Metric: 20.76111111111111 / 42  (49.4):  41%|▍| 41/100 [00:11<00:12,  4.85it\u001b[A\n",
      "Average Metric: 20.76111111111111 / 42  (49.4):  42%|▍| 42/100 [00:11<00:13,  4.23it\u001b[A\n",
      "Average Metric: 21.09444444444444 / 43  (49.1):  42%|▍| 42/100 [00:11<00:13,  4.23it\u001b[A\n",
      "Average Metric: 21.09444444444444 / 43  (49.1):  43%|▍| 43/100 [00:11<00:15,  3.61it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.09444444444444 / 44  (50.2):  43%|▍| 43/100 [00:12<00:15,  3.61it\u001b[A\n",
      "Average Metric: 22.09444444444444 / 44  (50.2):  44%|▍| 44/100 [00:12<00:26,  2.10it\u001b[A\n",
      "Average Metric: 22.09444444444444 / 45  (49.1):  44%|▍| 44/100 [00:13<00:26,  2.10it\u001b[A\n",
      "Average Metric: 22.09444444444444 / 45  (49.1):  45%|▍| 45/100 [00:13<00:23,  2.36it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.59444444444444 / 46  (49.1):  45%|▍| 45/100 [00:13<00:23,  2.36it\u001b[A\n",
      "Average Metric: 22.59444444444444 / 46  (49.1):  46%|▍| 46/100 [00:13<00:24,  2.20it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.84444444444444 / 47  (48.6):  46%|▍| 46/100 [00:14<00:24,  2.20it\u001b[A\n",
      "Average Metric: 22.84444444444444 / 47  (48.6):  47%|▍| 47/100 [00:14<00:31,  1.69it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.177777777777774 / 48  (48.3):  47%|▍| 47/100 [00:16<00:31,  1.69i\u001b[A\n",
      "Average Metric: 23.177777777777774 / 48  (48.3):  48%|▍| 48/100 [00:16<00:42,  1.22i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.177777777777774 / 49  (49.3):  48%|▍| 48/100 [00:17<00:42,  1.22i\u001b[A\n",
      "Average Metric: 24.177777777777774 / 49  (49.3):  49%|▍| 49/100 [00:17<00:52,  1.03s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.177777777777774 / 50  (50.4):  49%|▍| 49/100 [00:18<00:52,  1.03s\u001b[A\n",
      "Average Metric: 25.177777777777774 / 50  (50.4):  50%|▌| 50/100 [00:18<00:52,  1.05s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.177777777777774 / 51  (51.3):  50%|▌| 50/100 [00:19<00:52,  1.05s\u001b[A\n",
      "Average Metric: 26.177777777777774 / 51  (51.3):  51%|▌| 51/100 [00:19<00:50,  1.04s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.677777777777774 / 52  (51.3):  51%|▌| 51/100 [00:21<00:50,  1.04s\u001b[A\n",
      "Average Metric: 26.677777777777774 / 52  (51.3):  52%|▌| 52/100 [00:21<00:55,  1.15s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.677777777777774 / 53  (50.3):  52%|▌| 52/100 [00:23<00:55,  1.15s\u001b[A\n",
      "Average Metric: 26.677777777777774 / 53  (50.3):  53%|▌| 53/100 [00:23<01:02,  1.34s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.677777777777774 / 54  (51.3):  53%|▌| 53/100 [00:24<01:02,  1.34s\u001b[A\n",
      "Average Metric: 27.677777777777774 / 54  (51.3):  54%|▌| 54/100 [00:24<01:06,  1.44s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.677777777777774 / 55  (50.3):  54%|▌| 54/100 [00:25<01:06,  1.44s\u001b[A\n",
      "Average Metric: 27.677777777777774 / 55  (50.3):  55%|▌| 55/100 [00:25<00:58,  1.31s\u001b[A\n",
      "Average Metric: 27.677777777777774 / 56  (49.4):  55%|▌| 55/100 [00:26<00:58,  1.31s\u001b[A\n",
      "Average Metric: 27.677777777777774 / 56  (49.4):  56%|▌| 56/100 [00:26<00:52,  1.19s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.677777777777774 / 57  (50.3):  56%|▌| 56/100 [00:27<00:52,  1.19s\u001b[A\n",
      "Average Metric: 28.677777777777774 / 57  (50.3):  57%|▌| 57/100 [00:27<00:53,  1.24s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.011111111111106 / 58  (50.0):  57%|▌| 57/100 [00:29<00:53,  1.24s\u001b[A\n",
      "Average Metric: 29.011111111111106 / 58  (50.0):  58%|▌| 58/100 [00:29<00:50,  1.21s\u001b[A\n",
      "Average Metric: 29.011111111111106 / 59  (49.2):  58%|▌| 58/100 [00:29<00:50,  1.21s\u001b[A\n",
      "Average Metric: 29.011111111111106 / 59  (49.2):  59%|▌| 59/100 [00:29<00:42,  1.05s\u001b[A\n",
      "Average Metric: 29.511111111111106 / 60  (49.2):  59%|▌| 59/100 [00:30<00:42,  1.05s\u001b[A\n",
      "Average Metric: 29.511111111111106 / 60  (49.2):  60%|▌| 60/100 [00:30<00:38,  1.04i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.511111111111106 / 61  (48.4):  60%|▌| 60/100 [00:31<00:38,  1.04i\u001b[A\n",
      "Average Metric: 29.511111111111106 / 61  (48.4):  61%|▌| 61/100 [00:31<00:36,  1.06i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.011111111111106 / 62  (48.4):  61%|▌| 61/100 [00:32<00:36,  1.06i\u001b[A\n",
      "Average Metric: 30.011111111111106 / 62  (48.4):  62%|▌| 62/100 [00:32<00:36,  1.04i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.011111111111106 / 63  (47.6):  62%|▌| 62/100 [00:33<00:36,  1.04i\u001b[A\n",
      "Average Metric: 30.011111111111106 / 63  (47.6):  63%|▋| 63/100 [00:33<00:40,  1.10s\u001b[A\n",
      "Average Metric: 30.011111111111106 / 64  (46.9):  63%|▋| 63/100 [00:35<00:40,  1.10s\u001b[A\n",
      "Average Metric: 30.011111111111106 / 64  (46.9):  64%|▋| 64/100 [00:35<00:41,  1.15s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.011111111111106 / 65  (47.7):  64%|▋| 64/100 [00:35<00:41,  1.15s\u001b[A\n",
      "Average Metric: 31.011111111111106 / 65  (47.7):  65%|▋| 65/100 [00:35<00:33,  1.05i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.011111111111106 / 66  (48.5):  65%|▋| 65/100 [00:37<00:33,  1.05i\u001b[A\n",
      "Average Metric: 32.011111111111106 / 66  (48.5):  66%|▋| 66/100 [00:37<00:37,  1.09s\u001b[A\n",
      "Average Metric: 32.511111111111106 / 67  (48.5):  66%|▋| 66/100 [00:38<00:37,  1.09s\u001b[A\n",
      "Average Metric: 32.511111111111106 / 67  (48.5):  67%|▋| 67/100 [00:38<00:37,  1.14s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.511111111111106 / 68  (49.3):  67%|▋| 67/100 [00:39<00:37,  1.14s\u001b[A\n",
      "Average Metric: 33.511111111111106 / 68  (49.3):  68%|▋| 68/100 [00:39<00:38,  1.22s\u001b[A\n",
      "Average Metric: 34.511111111111106 / 69  (50.0):  68%|▋| 68/100 [00:40<00:38,  1.22s\u001b[A\n",
      "Average Metric: 34.511111111111106 / 69  (50.0):  69%|▋| 69/100 [00:40<00:32,  1.04s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.84444444444444 / 70  (49.8):  69%|▋| 69/100 [00:42<00:32,  1.04s/\u001b[A\n",
      "Average Metric: 34.84444444444444 / 70  (49.8):  70%|▋| 70/100 [00:42<00:39,  1.30s/\u001b[A\n",
      "Average Metric: 35.17777777777778 / 71  (49.5):  70%|▋| 70/100 [00:42<00:39,  1.30s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 13.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.17777777777778 / 72  (48.9):  71%|▋| 71/100 [00:43<00:37,  1.30s/\u001b[A\n",
      "Average Metric: 35.17777777777778 / 72  (48.9):  72%|▋| 72/100 [00:43<00:28,  1.01s/\u001b[A\n",
      "Average Metric: 35.51111111111111 / 73  (48.6):  72%|▋| 72/100 [00:44<00:28,  1.01s/\u001b[A\n",
      "Average Metric: 35.51111111111111 / 73  (48.6):  73%|▋| 73/100 [00:44<00:26,  1.03it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.51111111111111 / 74  (48.0):  73%|▋| 73/100 [00:46<00:26,  1.03it\u001b[A\n",
      "Average Metric: 35.51111111111111 / 74  (48.0):  74%|▋| 74/100 [00:46<00:29,  1.14s/\u001b[A\n",
      "Average Metric: 35.51111111111111 / 75  (47.3):  74%|▋| 74/100 [00:46<00:29,  1.14s/\u001b[A\n",
      "Average Metric: 35.51111111111111 / 75  (47.3):  75%|▊| 75/100 [00:46<00:23,  1.08it\u001b[A\n",
      "Average Metric: 35.76111111111111 / 76  (47.1):  75%|▊| 75/100 [00:47<00:23,  1.08it\u001b[A\n",
      "Average Metric: 35.76111111111111 / 76  (47.1):  76%|▊| 76/100 [00:47<00:24,  1.04s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.09444444444445 / 77  (46.9):  76%|▊| 76/100 [00:48<00:24,  1.04s/\u001b[A\n",
      "Average Metric: 36.09444444444445 / 77  (46.9):  77%|▊| 77/100 [00:48<00:23,  1.01s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.09444444444445 / 78  (47.6):  77%|▊| 77/100 [00:49<00:23,  1.01s/\u001b[A\n",
      "Average Metric: 37.09444444444445 / 78  (47.6):  78%|▊| 78/100 [00:49<00:19,  1.15it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.09444444444445 / 79  (47.0):  78%|▊| 78/100 [00:50<00:19,  1.15it\u001b[A\n",
      "Average Metric: 37.09444444444445 / 79  (47.0):  79%|▊| 79/100 [00:50<00:20,  1.03it\u001b[A\n",
      "Average Metric: 38.09444444444445 / 80  (47.6):  79%|▊| 79/100 [00:51<00:20,  1.03it\u001b[A\n",
      "Average Metric: 38.09444444444445 / 80  (47.6):  80%|▊| 80/100 [00:51<00:20,  1.04s/\u001b[A\n",
      "Average Metric: 39.09444444444445 / 81  (48.3):  80%|▊| 80/100 [00:52<00:20,  1.04s/\u001b[A\n",
      "Average Metric: 39.09444444444445 / 81  (48.3):  81%|▊| 81/100 [00:52<00:18,  1.05it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.09444444444445 / 82  (47.7):  81%|▊| 81/100 [00:53<00:18,  1.05it\u001b[A\n",
      "Average Metric: 39.09444444444445 / 82  (47.7):  82%|▊| 82/100 [00:53<00:18,  1.01s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.09444444444445 / 83  (48.3):  82%|▊| 82/100 [00:54<00:18,  1.01s/\u001b[A\n",
      "Average Metric: 40.09444444444445 / 83  (48.3):  83%|▊| 83/100 [00:54<00:16,  1.05it\u001b[A\n",
      "Average Metric: 40.34444444444445 / 84  (48.0):  83%|▊| 83/100 [00:55<00:16,  1.05it\u001b[A\n",
      "Average Metric: 40.34444444444445 / 84  (48.0):  84%|▊| 84/100 [00:55<00:17,  1.08s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.01111111111111 / 85  (48.2):  84%|▊| 84/100 [00:56<00:17,  1.08s/\u001b[A\n",
      "Average Metric: 41.01111111111111 / 85  (48.2):  85%|▊| 85/100 [00:56<00:15,  1.06s/\u001b[A\n",
      "Average Metric: 42.01111111111111 / 86  (48.9):  85%|▊| 85/100 [00:57<00:15,  1.06s/\u001b[A\n",
      "Average Metric: 42.01111111111111 / 86  (48.9):  86%|▊| 86/100 [00:57<00:12,  1.09it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 17.5 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.01111111111111 / 87  (49.4):  86%|▊| 86/100 [00:58<00:12,  1.09it\u001b[A\n",
      "Average Metric: 43.01111111111111 / 87  (49.4):  87%|▊| 87/100 [00:58<00:11,  1.11it\u001b[A\n",
      "Average Metric: 44.01111111111111 / 88  (50.0):  87%|▊| 87/100 [00:58<00:11,  1.11it\u001b[A\n",
      "Average Metric: 44.01111111111111 / 88  (50.0):  88%|▉| 88/100 [00:58<00:10,  1.17it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.01111111111111 / 89  (50.6):  88%|▉| 88/100 [00:59<00:10,  1.17it\u001b[A\n",
      "Average Metric: 45.01111111111111 / 89  (50.6):  89%|▉| 89/100 [00:59<00:09,  1.11it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 25.0 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46.01111111111111 / 90  (51.1):  89%|▉| 89/100 [01:01<00:09,  1.11it\u001b[A\n",
      "Average Metric: 46.01111111111111 / 90  (51.1):  90%|▉| 90/100 [01:01<00:10,  1.00s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 19.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.01111111111111 / 91  (51.7):  90%|▉| 90/100 [01:02<00:10,  1.00s/\u001b[A\n",
      "Average Metric: 47.01111111111111 / 91  (51.7):  91%|▉| 91/100 [01:02<00:09,  1.09s/\u001b[A\n",
      "Average Metric: 48.01111111111111 / 92  (52.2):  91%|▉| 91/100 [01:03<00:09,  1.09s/\u001b[A\n",
      "Average Metric: 48.01111111111111 / 92  (52.2):  92%|▉| 92/100 [01:03<00:09,  1.22s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 48.01111111111111 / 93  (51.6):  92%|▉| 92/100 [01:06<00:09,  1.22s/\u001b[A\n",
      "Average Metric: 48.01111111111111 / 93  (51.6):  93%|▉| 93/100 [01:06<00:11,  1.67s/\u001b[A\n",
      "Average Metric: 49.01111111111111 / 94  (52.1):  93%|▉| 93/100 [01:07<00:11,  1.67s/\u001b[A\n",
      "Average Metric: 49.01111111111111 / 94  (52.1):  94%|▉| 94/100 [01:07<00:08,  1.47s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.233333333333334 / 95  (51.8):  94%|▉| 94/100 [01:08<00:08,  1.47s\u001b[A\n",
      "Average Metric: 49.233333333333334 / 95  (51.8):  95%|▉| 95/100 [01:08<00:06,  1.37s\u001b[A\n",
      "Average Metric: 49.233333333333334 / 96  (51.3):  95%|▉| 95/100 [01:10<00:06,  1.37s\u001b[A\n",
      "Average Metric: 49.233333333333334 / 96  (51.3):  96%|▉| 96/100 [01:10<00:05,  1.40s\u001b[A\n",
      "Average Metric: 50.233333333333334 / 97  (51.8):  96%|▉| 96/100 [01:15<00:05,  1.40s\u001b[A\n",
      "Average Metric: 50.233333333333334 / 97  (51.8):  97%|▉| 97/100 [01:15<00:07,  2.63s\u001b[A\n",
      "Average Metric: 50.56666666666667 / 98  (51.6):  97%|▉| 97/100 [01:16<00:07,  2.63s/\u001b[A\n",
      "Average Metric: 50.56666666666667 / 98  (51.6):  98%|▉| 98/100 [01:16<00:04,  2.16s/\u001b[A\n",
      "Average Metric: 50.81666666666667 / 99  (51.3):  98%|▉| 98/100 [01:22<00:04,  2.16s/\u001b[A\n",
      "Average Metric: 50.81666666666667 / 99  (51.3):  99%|▉| 99/100 [01:22<00:03,  3.28s/\u001b[A\n",
      "Average Metric: 51.81666666666667 / 100  (51.8):  99%|▉| 99/100 [01:26<00:03,  3.28s\u001b[A\n",
      "Average Metric: 51.81666666666667 / 100  (51.8): 100%|█| 100/100 [01:26<00:00,  1.15\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 51.81666666666667 / 100  (51.8%)\n",
      "Score: 51.82 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87, 57.03, 55.56, 51.82]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8848333333333334\n",
      "Average of max per entry across top 5 scores: 0.9475\n",
      "Average of max per entry across top 8 scores: 0.9766666666666666\n",
      "Average of max per entry across top 9999 scores: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:33,  1.55s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:03<02:30,  1.54s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:04<02:19,  1.44s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:05<02:07,  1.33s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:06<01:59,  1.26s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:09<02:23,  1.52s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                     | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   1%|▏            | 1/100 [00:01<01:48,  1.10s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   1%|▏             | 1/100 [00:01<01:48,  1.10s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   2%|▎             | 2/100 [00:01<00:53,  1.82it/s]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   2%|▎             | 2/100 [00:01<00:53,  1.82it/s]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   3%|▍             | 3/100 [00:01<00:38,  2.49it/s]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):   3%|▍             | 3/100 [00:01<00:38,  2.49it/s]\u001b[A\n",
      "Average Metric: 1.2857142857142856 / 5  (25.7):   4%| | 4/100 [00:01<00:38,  2.49it/\u001b[A\n",
      "Average Metric: 1.2857142857142856 / 5  (25.7):   5%| | 5/100 [00:01<00:25,  3.79it/\u001b[A\n",
      "Average Metric: 2.2857142857142856 / 6  (38.1):   5%| | 5/100 [00:02<00:25,  3.79it/\u001b[A\n",
      "Average Metric: 2.2857142857142856 / 6  (38.1):   6%| | 6/100 [00:02<00:25,  3.75it/\u001b[A\n",
      "Average Metric: 2.2857142857142856 / 7  (32.7):   6%| | 6/100 [00:02<00:25,  3.75it/\u001b[A\n",
      "Average Metric: 2.2857142857142856 / 7  (32.7):   7%| | 7/100 [00:02<00:20,  4.48it/\u001b[A\n",
      "Average Metric: 3.2857142857142856 / 8  (41.1):   7%| | 7/100 [00:02<00:20,  4.48it/\u001b[A\n",
      "Average Metric: 3.2857142857142856 / 8  (41.1):   8%| | 8/100 [00:02<00:28,  3.27it/\u001b[A\n",
      "Average Metric: 3.2857142857142856 / 9  (36.5):   8%| | 8/100 [00:02<00:28,  3.27it/\u001b[A\n",
      "Average Metric: 3.2857142857142856 / 9  (36.5):   9%| | 9/100 [00:02<00:25,  3.51it/\u001b[A\n",
      "Average Metric: 3.619047619047619 / 10  (36.2):   9%| | 9/100 [00:03<00:25,  3.51it/\u001b[A\n",
      "Average Metric: 3.619047619047619 / 10  (36.2):  10%| | 10/100 [00:03<00:23,  3.80it\u001b[A\n",
      "Average Metric: 3.869047619047619 / 11  (35.2):  10%| | 10/100 [00:03<00:23,  3.80it\u001b[A\n",
      "Average Metric: 3.869047619047619 / 11  (35.2):  11%| | 11/100 [00:03<00:21,  4.22it\u001b[A\n",
      "Average Metric: 4.869047619047619 / 12  (40.6):  11%| | 11/100 [00:03<00:21,  4.22it\u001b[A\n",
      "Average Metric: 4.869047619047619 / 12  (40.6):  12%| | 12/100 [00:03<00:18,  4.83it\u001b[A\n",
      "Average Metric: 5.269047619047619 / 13  (40.5):  12%| | 12/100 [00:03<00:18,  4.83it\u001b[A\n",
      "Average Metric: 5.269047619047619 / 13  (40.5):  13%|▏| 13/100 [00:03<00:19,  4.36it\u001b[A\n",
      "Average Metric: 6.269047619047619 / 14  (44.8):  13%|▏| 13/100 [00:03<00:19,  4.36it\u001b[A\n",
      "Average Metric: 6.869047619047619 / 15  (45.8):  14%|▏| 14/100 [00:04<00:19,  4.36it\u001b[A\n",
      "Average Metric: 6.869047619047619 / 15  (45.8):  15%|▏| 15/100 [00:04<00:23,  3.59it\u001b[A\n",
      "Average Metric: 7.869047619047619 / 16  (49.2):  15%|▏| 15/100 [00:04<00:23,  3.59it\u001b[A\n",
      "Average Metric: 7.869047619047619 / 16  (49.2):  16%|▏| 16/100 [00:04<00:25,  3.28it\u001b[A\n",
      "Average Metric: 8.202380952380953 / 17  (48.2):  16%|▏| 16/100 [00:04<00:25,  3.28it\u001b[A\n",
      "Average Metric: 8.952380952380953 / 18  (49.7):  17%|▏| 17/100 [00:04<00:25,  3.28it\u001b[A\n",
      "Average Metric: 8.952380952380953 / 18  (49.7):  18%|▏| 18/100 [00:04<00:17,  4.74it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.452380952380953 / 19  (49.7):  18%|▏| 18/100 [00:07<00:17,  4.74it\u001b[A\n",
      "Average Metric: 9.452380952380953 / 19  (49.7):  19%|▏| 19/100 [00:07<01:00,  1.33it\u001b[A\n",
      "Average Metric: 9.652380952380952 / 20  (48.3):  19%|▏| 19/100 [00:07<01:00,  1.33it\u001b[A\n",
      "Average Metric: 9.652380952380952 / 20  (48.3):  20%|▏| 20/100 [00:07<00:50,  1.59it\u001b[A\n",
      "Average Metric: 9.652380952380952 / 21  (46.0):  20%|▏| 20/100 [00:08<00:50,  1.59it\u001b[A\n",
      "Average Metric: 9.652380952380952 / 21  (46.0):  21%|▏| 21/100 [00:08<00:44,  1.76it\u001b[A\n",
      "Average Metric: 9.652380952380952 / 22  (43.9):  21%|▏| 21/100 [00:08<00:44,  1.76it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.652380952380952 / 23  (46.3):  22%|▏| 22/100 [00:09<00:44,  1.76i\u001b[A\n",
      "Average Metric: 10.652380952380952 / 23  (46.3):  23%|▏| 23/100 [00:09<00:41,  1.86i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.652380952380952 / 24  (44.4):  23%|▏| 23/100 [00:10<00:41,  1.86i\u001b[A\n",
      "Average Metric: 10.652380952380952 / 24  (44.4):  24%|▏| 24/100 [00:10<00:51,  1.47i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.402380952380952 / 25  (45.6):  24%|▏| 24/100 [00:12<00:51,  1.47i\u001b[A\n",
      "Average Metric: 11.402380952380952 / 25  (45.6):  25%|▎| 25/100 [00:12<01:10,  1.06i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.652380952380952 / 26  (44.8):  25%|▎| 25/100 [00:13<01:10,  1.06i\u001b[A\n",
      "Average Metric: 11.652380952380952 / 26  (44.8):  26%|▎| 26/100 [00:13<01:21,  1.10s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.652380952380952 / 27  (46.9):  26%|▎| 26/100 [00:14<01:21,  1.10s\u001b[A\n",
      "Average Metric: 12.652380952380952 / 27  (46.9):  27%|▎| 27/100 [00:14<01:14,  1.02s\u001b[A\n",
      "Average Metric: 12.652380952380952 / 28  (45.2):  27%|▎| 27/100 [00:15<01:14,  1.02s\u001b[A\n",
      "Average Metric: 12.652380952380952 / 28  (45.2):  28%|▎| 28/100 [00:15<01:08,  1.05i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.652380952380952 / 29  (47.1):  28%|▎| 28/100 [00:18<01:08,  1.05i\u001b[A\n",
      "Average Metric: 13.652380952380952 / 29  (47.1):  29%|▎| 29/100 [00:18<01:49,  1.54s\u001b[A\n",
      "Average Metric: 13.819047619047618 / 30  (46.1):  29%|▎| 29/100 [00:18<01:49,  1.54s\u001b[A\n",
      "Average Metric: 13.819047619047618 / 30  (46.1):  30%|▎| 30/100 [00:18<01:22,  1.18s\u001b[A\n",
      "Average Metric: 14.219047619047618 / 31  (45.9):  30%|▎| 30/100 [00:19<01:22,  1.18s\u001b[A\n",
      "Average Metric: 14.219047619047618 / 31  (45.9):  31%|▎| 31/100 [00:19<01:18,  1.14s\u001b[A\n",
      "Average Metric: 14.219047619047618 / 32  (44.4):  31%|▎| 31/100 [00:19<01:18,  1.14s\u001b[A\n",
      "Average Metric: 14.219047619047618 / 32  (44.4):  32%|▎| 32/100 [00:19<01:03,  1.07i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.619047619047619 / 33  (44.3):  32%|▎| 32/100 [00:21<01:03,  1.07i\u001b[A\n",
      "Average Metric: 14.619047619047619 / 33  (44.3):  33%|▎| 33/100 [00:21<01:05,  1.02i\u001b[A\n",
      "Average Metric: 14.952380952380953 / 34  (44.0):  33%|▎| 33/100 [00:21<01:05,  1.02i\u001b[A\n",
      "Average Metric: 14.952380952380953 / 34  (44.0):  34%|▎| 34/100 [00:21<00:57,  1.14i\u001b[A\n",
      "Average Metric: 14.952380952380953 / 35  (42.7):  34%|▎| 34/100 [00:22<00:57,  1.14i\u001b[A\n",
      "Average Metric: 14.952380952380953 / 35  (42.7):  35%|▎| 35/100 [00:22<00:55,  1.17i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.452380952380953 / 36  (42.9):  35%|▎| 35/100 [00:23<00:55,  1.17i\u001b[A\n",
      "Average Metric: 15.452380952380953 / 36  (42.9):  36%|▎| 36/100 [00:23<00:49,  1.29i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.452380952380953 / 37  (41.8):  36%|▎| 36/100 [00:24<00:49,  1.29i\u001b[A\n",
      "Average Metric: 15.452380952380953 / 37  (41.8):  37%|▎| 37/100 [00:24<00:55,  1.13i\u001b[A\n",
      "Average Metric: 15.952380952380953 / 38  (42.0):  37%|▎| 37/100 [00:24<00:55,  1.13i\u001b[A\n",
      "Average Metric: 15.952380952380953 / 38  (42.0):  38%|▍| 38/100 [00:24<00:45,  1.36i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.452380952380953 / 39  (42.2):  38%|▍| 38/100 [00:25<00:45,  1.36i\u001b[A\n",
      "Average Metric: 16.452380952380953 / 39  (42.2):  39%|▍| 39/100 [00:25<00:51,  1.18i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.452380952380953 / 40  (43.6):  39%|▍| 39/100 [00:26<00:51,  1.18i\u001b[A\n",
      "Average Metric: 17.452380952380953 / 40  (43.6):  40%|▍| 40/100 [00:26<00:55,  1.08i\u001b[A\n",
      "Average Metric: 18.452380952380953 / 41  (45.0):  40%|▍| 40/100 [00:28<00:55,  1.08i\u001b[A\n",
      "Average Metric: 18.452380952380953 / 41  (45.0):  41%|▍| 41/100 [00:28<01:04,  1.09s\u001b[A\n",
      "Average Metric: 18.702380952380953 / 42  (44.5):  41%|▍| 41/100 [00:29<01:04,  1.09s\u001b[A\n",
      "Average Metric: 18.702380952380953 / 42  (44.5):  42%|▍| 42/100 [00:29<01:11,  1.23s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.202380952380953 / 43  (44.7):  42%|▍| 42/100 [00:31<01:11,  1.23s\u001b[A\n",
      "Average Metric: 19.202380952380953 / 43  (44.7):  43%|▍| 43/100 [00:31<01:14,  1.30s\u001b[A\n",
      "Average Metric: 20.202380952380953 / 44  (45.9):  43%|▍| 43/100 [00:31<01:14,  1.30s\u001b[A\n",
      "Average Metric: 21.202380952380953 / 45  (47.1):  44%|▍| 44/100 [00:32<01:13,  1.30s\u001b[A\n",
      "Average Metric: 21.202380952380953 / 45  (47.1):  45%|▍| 45/100 [00:32<00:53,  1.02i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.86904761904762 / 46  (47.5):  45%|▍| 45/100 [00:33<00:53,  1.02it\u001b[A\n",
      "Average Metric: 21.86904761904762 / 46  (47.5):  46%|▍| 46/100 [00:33<00:58,  1.09s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.86904761904762 / 47  (48.7):  46%|▍| 46/100 [00:34<00:58,  1.09s/\u001b[A\n",
      "Average Metric: 22.86904761904762 / 47  (48.7):  47%|▍| 47/100 [00:34<00:55,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.202380952380953 / 48  (48.3):  47%|▍| 47/100 [00:35<00:55,  1.05s\u001b[A\n",
      "Average Metric: 23.202380952380953 / 48  (48.3):  48%|▍| 48/100 [00:35<00:54,  1.05s\u001b[A\n",
      "Average Metric: 23.202380952380953 / 49  (47.4):  48%|▍| 48/100 [00:37<00:54,  1.05s\u001b[A\n",
      "Average Metric: 23.202380952380953 / 49  (47.4):  49%|▍| 49/100 [00:37<00:57,  1.12s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.202380952380953 / 50  (48.4):  49%|▍| 49/100 [00:38<00:57,  1.12s\u001b[A\n",
      "Average Metric: 24.202380952380953 / 50  (48.4):  50%|▌| 50/100 [00:38<00:51,  1.03s\u001b[A\n",
      "Average Metric: 24.535714285714285 / 51  (48.1):  50%|▌| 50/100 [00:38<00:51,  1.03s\u001b[A\n",
      "Average Metric: 24.535714285714285 / 51  (48.1):  51%|▌| 51/100 [00:38<00:48,  1.00i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.202380952380953 / 52  (48.5):  51%|▌| 51/100 [00:40<00:48,  1.00i\u001b[A\n",
      "Average Metric: 25.202380952380953 / 52  (48.5):  52%|▌| 52/100 [00:40<00:56,  1.18s\u001b[A\n",
      "Average Metric: 26.202380952380953 / 53  (49.4):  52%|▌| 52/100 [00:40<00:56,  1.18s\u001b[A\n",
      "Average Metric: 26.202380952380953 / 53  (49.4):  53%|▌| 53/100 [00:40<00:44,  1.06i\u001b[A\n",
      "Average Metric: 26.202380952380953 / 54  (48.5):  53%|▌| 53/100 [00:42<00:44,  1.06i\u001b[A\n",
      "Average Metric: 26.202380952380953 / 54  (48.5):  54%|▌| 54/100 [00:42<00:47,  1.04s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.202380952380953 / 55  (49.5):  54%|▌| 54/100 [00:43<00:47,  1.04s\u001b[A\n",
      "Average Metric: 27.202380952380953 / 55  (49.5):  55%|▌| 55/100 [00:43<00:55,  1.23s\u001b[A\n",
      "Average Metric: 28.202380952380953 / 56  (50.4):  55%|▌| 55/100 [00:44<00:55,  1.23s\u001b[A\n",
      "Average Metric: 28.202380952380953 / 56  (50.4):  56%|▌| 56/100 [00:44<00:41,  1.07i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.202380952380953 / 57  (49.5):  56%|▌| 56/100 [00:45<00:41,  1.07i\u001b[A\n",
      "Average Metric: 28.202380952380953 / 57  (49.5):  57%|▌| 57/100 [00:45<00:43,  1.02s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 39.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.702380952380953 / 58  (49.5):  57%|▌| 57/100 [00:46<00:43,  1.02s\u001b[A\n",
      "Average Metric: 28.702380952380953 / 58  (49.5):  58%|▌| 58/100 [00:46<00:43,  1.04s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.702380952380953 / 59  (50.3):  58%|▌| 58/100 [00:47<00:43,  1.04s\u001b[A\n",
      "Average Metric: 29.702380952380953 / 59  (50.3):  59%|▌| 59/100 [00:47<00:43,  1.06s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.702380952380953 / 60  (51.2):  59%|▌| 59/100 [00:48<00:43,  1.06s\u001b[A\n",
      "Average Metric: 30.702380952380953 / 60  (51.2):  60%|▌| 60/100 [00:48<00:43,  1.08s\u001b[A\n",
      "Average Metric: 31.035714285714285 / 61  (50.9):  60%|▌| 60/100 [00:49<00:43,  1.08s\u001b[A\n",
      "Average Metric: 31.035714285714285 / 61  (50.9):  61%|▌| 61/100 [00:49<00:44,  1.14s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.035714285714285 / 62  (50.1):  61%|▌| 61/100 [00:50<00:44,  1.14s\u001b[A\n",
      "Average Metric: 31.035714285714285 / 62  (50.1):  62%|▌| 62/100 [00:50<00:41,  1.09s\u001b[A\n",
      "Average Metric: 31.235714285714284 / 63  (49.6):  62%|▌| 62/100 [00:52<00:41,  1.09s\u001b[A\n",
      "Average Metric: 31.235714285714284 / 63  (49.6):  63%|▋| 63/100 [00:52<00:43,  1.17s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.235714285714284 / 64  (48.8):  63%|▋| 63/100 [00:53<00:43,  1.17s\u001b[A\n",
      "Average Metric: 31.235714285714284 / 64  (48.8):  64%|▋| 64/100 [00:53<00:42,  1.18s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.23571428571428 / 65  (49.6):  64%|▋| 64/100 [00:53<00:42,  1.18s/\u001b[A\n",
      "Average Metric: 32.23571428571428 / 65  (49.6):  65%|▋| 65/100 [00:53<00:31,  1.11it\u001b[A\n",
      "Average Metric: 33.23571428571428 / 66  (50.4):  65%|▋| 65/100 [00:54<00:31,  1.11it\u001b[A\n",
      "Average Metric: 33.23571428571428 / 66  (50.4):  66%|▋| 66/100 [00:54<00:28,  1.19it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.73571428571428 / 67  (50.4):  66%|▋| 66/100 [00:56<00:28,  1.19it\u001b[A\n",
      "Average Metric: 33.73571428571428 / 67  (50.4):  67%|▋| 67/100 [00:56<00:36,  1.10s/\u001b[A\n",
      "Average Metric: 34.73571428571428 / 68  (51.1):  67%|▋| 67/100 [00:56<00:36,  1.10s/\u001b[A\n",
      "Average Metric: 34.73571428571428 / 68  (51.1):  68%|▋| 68/100 [00:56<00:26,  1.20it\u001b[A\n",
      "Average Metric: 35.73571428571428 / 69  (51.8):  68%|▋| 68/100 [00:57<00:26,  1.20it\u001b[A\n",
      "Average Metric: 35.73571428571428 / 69  (51.8):  69%|▋| 69/100 [00:57<00:27,  1.14it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.069047619047616 / 70  (51.5):  69%|▋| 69/100 [00:59<00:27,  1.14i\u001b[A\n",
      "Average Metric: 36.069047619047616 / 70  (51.5):  70%|▋| 70/100 [00:59<00:37,  1.24s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.319047619047616 / 71  (51.2):  70%|▋| 70/100 [00:59<00:37,  1.24s\u001b[A\n",
      "Average Metric: 36.319047619047616 / 71  (51.2):  71%|▋| 71/100 [00:59<00:28,  1.03i\u001b[A\n",
      "Average Metric: 37.319047619047616 / 72  (51.8):  71%|▋| 71/100 [01:00<00:28,  1.03i\u001b[A\n",
      "Average Metric: 37.319047619047616 / 72  (51.8):  72%|▋| 72/100 [01:00<00:27,  1.03i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.65238095238095 / 73  (51.6):  72%|▋| 72/100 [01:03<00:27,  1.03it\u001b[A\n",
      "Average Metric: 37.65238095238095 / 73  (51.6):  73%|▋| 73/100 [01:03<00:37,  1.37s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 18.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.65238095238095 / 74  (52.2):  73%|▋| 73/100 [01:03<00:37,  1.37s/\u001b[A\n",
      "Average Metric: 38.65238095238095 / 74  (52.2):  74%|▋| 74/100 [01:03<00:31,  1.21s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.65238095238095 / 75  (51.5):  74%|▋| 74/100 [01:05<00:31,  1.21s/\u001b[A\n",
      "Average Metric: 38.65238095238095 / 75  (51.5):  75%|▊| 75/100 [01:05<00:33,  1.33s/\u001b[A\n",
      "Average Metric: 39.65238095238095 / 76  (52.2):  75%|▊| 75/100 [01:06<00:33,  1.33s/\u001b[A\n",
      "Average Metric: 39.65238095238095 / 76  (52.2):  76%|▊| 76/100 [01:06<00:28,  1.19s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.65238095238095 / 77  (52.8):  76%|▊| 76/100 [01:08<00:28,  1.19s/\u001b[A\n",
      "Average Metric: 40.65238095238095 / 77  (52.8):  77%|▊| 77/100 [01:08<00:30,  1.33s/\u001b[A\n",
      "Average Metric: 40.98571428571429 / 78  (52.5):  77%|▊| 77/100 [01:08<00:30,  1.33s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.98571428571429 / 79  (53.1):  78%|▊| 78/100 [01:11<00:29,  1.33s/\u001b[A\n",
      "Average Metric: 41.98571428571429 / 79  (53.1):  79%|▊| 79/100 [01:11<00:32,  1.56s/\u001b[A\n",
      "Average Metric: 42.18571428571429 / 80  (52.7):  79%|▊| 79/100 [01:12<00:32,  1.56s/\u001b[A\n",
      "Average Metric: 42.18571428571429 / 80  (52.7):  80%|▊| 80/100 [01:12<00:26,  1.34s/\u001b[A\n",
      "Average Metric: 42.38571428571429 / 81  (52.3):  80%|▊| 80/100 [01:12<00:26,  1.34s/\u001b[A\n",
      "Average Metric: 42.38571428571429 / 81  (52.3):  81%|▊| 81/100 [01:12<00:21,  1.14s/\u001b[A\n",
      "Average Metric: 43.38571428571429 / 82  (52.9):  81%|▊| 81/100 [01:13<00:21,  1.14s/\u001b[A\n",
      "Average Metric: 43.38571428571429 / 82  (52.9):  82%|▊| 82/100 [01:13<00:20,  1.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.38571428571429 / 83  (52.3):  82%|▊| 82/100 [01:15<00:20,  1.12s/\u001b[A\n",
      "Average Metric: 43.38571428571429 / 83  (52.3):  83%|▊| 83/100 [01:15<00:20,  1.18s/\u001b[A\n",
      "Average Metric: 43.63571428571429 / 84  (51.9):  83%|▊| 83/100 [01:17<00:20,  1.18s/\u001b[A\n",
      "Average Metric: 43.63571428571429 / 84  (51.9):  84%|▊| 84/100 [01:17<00:21,  1.36s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.63571428571429 / 85  (52.5):  84%|▊| 84/100 [01:18<00:21,  1.36s/\u001b[A\n",
      "Average Metric: 44.63571428571429 / 85  (52.5):  85%|▊| 85/100 [01:18<00:20,  1.35s/\u001b[A\n",
      "Average Metric: 44.63571428571429 / 86  (51.9):  85%|▊| 85/100 [01:19<00:20,  1.35s/\u001b[A\n",
      "Average Metric: 44.63571428571429 / 86  (51.9):  86%|▊| 86/100 [01:19<00:16,  1.17s/\u001b[A\n",
      "Average Metric: 44.63571428571429 / 87  (51.3):  86%|▊| 86/100 [01:19<00:16,  1.17s/\u001b[A\n",
      "Average Metric: 44.63571428571429 / 87  (51.3):  87%|▊| 87/100 [01:19<00:11,  1.15it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.63571428571429 / 88  (51.9):  87%|▊| 87/100 [01:20<00:11,  1.15it\u001b[A\n",
      "Average Metric: 45.63571428571429 / 88  (51.9):  88%|▉| 88/100 [01:20<00:10,  1.18it\u001b[A\n",
      "Average Metric: 46.63571428571429 / 89  (52.4):  88%|▉| 88/100 [01:20<00:10,  1.18it\u001b[A\n",
      "Average Metric: 46.63571428571429 / 89  (52.4):  89%|▉| 89/100 [01:20<00:09,  1.19it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.63571428571429 / 90  (52.9):  89%|▉| 89/100 [01:22<00:09,  1.19it\u001b[A\n",
      "Average Metric: 47.63571428571429 / 90  (52.9):  90%|▉| 90/100 [01:22<00:10,  1.03s/\u001b[A\n",
      "Average Metric: 48.63571428571429 / 91  (53.4):  90%|▉| 90/100 [01:23<00:10,  1.03s/\u001b[A\n",
      "Average Metric: 48.63571428571429 / 91  (53.4):  91%|▉| 91/100 [01:23<00:09,  1.00s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 55.5 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.63571428571429 / 92  (54.0):  91%|▉| 91/100 [01:24<00:09,  1.00s/\u001b[A\n",
      "Average Metric: 49.63571428571429 / 92  (54.0):  92%|▉| 92/100 [01:24<00:08,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.13571428571429 / 93  (53.9):  92%|▉| 92/100 [01:25<00:08,  1.05s/\u001b[A\n",
      "Average Metric: 50.13571428571429 / 93  (53.9):  93%|▉| 93/100 [01:25<00:07,  1.10s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.13571428571429 / 94  (54.4):  93%|▉| 93/100 [01:26<00:07,  1.10s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 41.9 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 51.13571428571429 / 94  (54.4):  94%|▉| 94/100 [01:26<00:06,  1.08s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.13571428571429 / 95  (53.8):  94%|▉| 94/100 [01:28<00:06,  1.08s/\u001b[A\n",
      "Average Metric: 51.13571428571429 / 95  (53.8):  95%|▉| 95/100 [01:28<00:05,  1.16s/\u001b[A\n",
      "Average Metric: 51.63571428571429 / 96  (53.8):  95%|▉| 95/100 [01:29<00:05,  1.16s/\u001b[A\n",
      "Average Metric: 51.63571428571429 / 96  (53.8):  96%|▉| 96/100 [01:29<00:05,  1.26s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.63571428571429 / 97  (54.3):  96%|▉| 96/100 [01:32<00:05,  1.26s/\u001b[A\n",
      "Average Metric: 52.63571428571429 / 97  (54.3):  97%|▉| 97/100 [01:32<00:04,  1.64s/\u001b[A\n",
      "Average Metric: 53.63571428571429 / 98  (54.7):  97%|▉| 97/100 [01:37<00:04,  1.64s/\u001b[A\n",
      "Average Metric: 53.63571428571429 / 98  (54.7):  98%|▉| 98/100 [01:37<00:05,  2.65s/\u001b[A\n",
      "Average Metric: 54.13571428571429 / 99  (54.7):  98%|▉| 98/100 [02:10<00:05,  2.65s/\u001b[A\n",
      "Average Metric: 54.13571428571429 / 99  (54.7):  99%|▉| 99/100 [02:10<00:11, 11.80s/\u001b[A\n",
      "Average Metric: 54.13571428571429 / 100  (54.1):  99%|▉| 99/100 [02:19<00:11, 11.80s\u001b[A\n",
      "Average Metric: 54.13571428571429 / 100  (54.1): 100%|█| 100/100 [02:19<00:00,  1.40\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.13571428571429 / 100  (54.1%)\n",
      "Score: 54.14 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87, 57.03, 55.56, 51.82, 54.14]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8848333333333334\n",
      "Average of max per entry across top 5 scores: 0.9475\n",
      "Average of max per entry across top 8 scores: 0.9766666666666666\n",
      "Average of max per entry across top 9999 scores: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:02<04:53,  2.97s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:04<03:15,  2.00s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:06<03:21,  2.08s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:07<02:53,  1.81s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:08<02:26,  1.55s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:10<02:18,  1.47s/it]\u001b[A\n",
      "  7%|███▎                                           | 7/100 [00:12<02:24,  1.56s/it]\u001b[A\n",
      "  8%|███▊                                           | 8/100 [00:12<02:06,  1.37s/it]\u001b[A\n",
      "  9%|████▏                                          | 9/100 [00:14<02:10,  1.44s/it]\u001b[A\n",
      " 10%|████▌                                         | 10/100 [00:15<02:08,  1.42s/it]\u001b[A\n",
      " 11%|█████                                         | 11/100 [00:17<02:08,  1.44s/it]\u001b[A\n",
      " 12%|█████▌                                        | 12/100 [00:18<02:06,  1.44s/it]\u001b[A\n",
      " 13%|█████▉                                        | 13/100 [00:20<02:05,  1.44s/it]\u001b[A\n",
      " 14%|██████▍                                       | 14/100 [00:23<02:44,  1.91s/it]\u001b[A\n",
      " 15%|██████▉                                       | 15/100 [00:24<02:17,  1.61s/it]\u001b[A\n",
      " 16%|███████▎                                      | 16/100 [00:25<02:12,  1.58s/it]\u001b[A\n",
      " 17%|███████▊                                      | 17/100 [00:30<03:19,  2.40s/it]\u001b[A\n",
      " 18%|████████▎                                     | 18/100 [00:31<02:56,  2.15s/it]\u001b[A\n",
      " 19%|████████▋                                     | 19/100 [00:35<03:32,  2.63s/it]\u001b[A\n",
      " 20%|█████████▏                                    | 20/100 [00:36<02:26,  1.83s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 21 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:01<02:02,  1.24s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|▏              | 1/100 [00:01<02:02,  1.24s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   2%|▎              | 2/100 [00:01<01:00,  1.62it/s]\u001b[A\n",
      "Average Metric: 0.25 / 3  (8.3):   2%|▎             | 2/100 [00:01<01:00,  1.62it/s]\u001b[A\n",
      "Average Metric: 0.25 / 4  (6.2):   3%|▍             | 3/100 [00:01<00:59,  1.62it/s]\u001b[A\n",
      "Average Metric: 0.25 / 4  (6.2):   4%|▌             | 4/100 [00:01<00:27,  3.50it/s]\u001b[A\n",
      "Average Metric: 0.5357142857142857 / 5  (10.7):   4%| | 4/100 [00:01<00:27,  3.50it/\u001b[A\n",
      "Average Metric: 0.5357142857142857 / 5  (10.7):   5%| | 5/100 [00:01<00:26,  3.64it/\u001b[A\n",
      "Average Metric: 1.5357142857142856 / 6  (25.6):   5%| | 5/100 [00:02<00:26,  3.64it/\u001b[A\n",
      "Average Metric: 1.5357142857142856 / 6  (25.6):   6%| | 6/100 [00:02<00:24,  3.81it/\u001b[A\n",
      "Average Metric: 2.5357142857142856 / 7  (36.2):   6%| | 6/100 [00:02<00:24,  3.81it/\u001b[A\n",
      "Average Metric: 2.5357142857142856 / 7  (36.2):   7%| | 7/100 [00:02<00:20,  4.44it/\u001b[A\n",
      "Average Metric: 3.5357142857142856 / 8  (44.2):   7%| | 7/100 [00:03<00:20,  4.44it/\u001b[A\n",
      "Average Metric: 3.5357142857142856 / 8  (44.2):   8%| | 8/100 [00:03<00:36,  2.52it/\u001b[A\n",
      "Average Metric: 3.5357142857142856 / 9  (39.3):   8%| | 8/100 [00:03<00:36,  2.52it/\u001b[A\n",
      "Average Metric: 3.869047619047619 / 10  (38.7):   9%| | 9/100 [00:03<00:36,  2.52it/\u001b[A\n",
      "Average Metric: 3.869047619047619 / 10  (38.7):  10%| | 10/100 [00:03<00:24,  3.67it\u001b[A\n",
      "Average Metric: 4.2023809523809526 / 11  (38.2):  10%| | 10/100 [00:03<00:24,  3.67i\u001b[A\n",
      "Average Metric: 4.2023809523809526 / 11  (38.2):  11%| | 11/100 [00:03<00:24,  3.59i\u001b[A\n",
      "Average Metric: 4.535714285714286 / 12  (37.8):  11%| | 11/100 [00:03<00:24,  3.59it\u001b[A\n",
      "Average Metric: 4.535714285714286 / 12  (37.8):  12%| | 12/100 [00:03<00:24,  3.61it\u001b[A\n",
      "Average Metric: 5.285714285714286 / 13  (40.7):  12%| | 12/100 [00:04<00:24,  3.61it\u001b[A\n",
      "Average Metric: 5.285714285714286 / 13  (40.7):  13%|▏| 13/100 [00:04<00:35,  2.46it\u001b[A\n",
      "Average Metric: 5.507936507936508 / 14  (39.3):  13%|▏| 13/100 [00:04<00:35,  2.46it\u001b[A\n",
      "Average Metric: 5.507936507936508 / 14  (39.3):  14%|▏| 14/100 [00:04<00:28,  3.03it\u001b[A\n",
      "Average Metric: 5.674603174603175 / 15  (37.8):  14%|▏| 14/100 [00:05<00:28,  3.03it\u001b[A\n",
      "Average Metric: 5.674603174603175 / 15  (37.8):  15%|▏| 15/100 [00:05<00:31,  2.66it\u001b[A\n",
      "Average Metric: 5.841269841269842 / 16  (36.5):  15%|▏| 15/100 [00:05<00:31,  2.66it\u001b[A\n",
      "Average Metric: 6.841269841269842 / 17  (40.2):  16%|▏| 16/100 [00:05<00:31,  2.66it\u001b[A\n",
      "Average Metric: 7.174603174603175 / 18  (39.9):  17%|▏| 17/100 [00:05<00:31,  2.66it\u001b[A\n",
      "Average Metric: 7.174603174603175 / 18  (39.9):  18%|▏| 18/100 [00:05<00:18,  4.35it\u001b[A\n",
      "Average Metric: 8.174603174603174 / 19  (43.0):  18%|▏| 18/100 [00:05<00:18,  4.35it\u001b[A\n",
      "Average Metric: 8.174603174603174 / 19  (43.0):  19%|▏| 19/100 [00:05<00:20,  3.86it\u001b[A\n",
      "Average Metric: 9.174603174603174 / 20  (45.9):  19%|▏| 19/100 [00:06<00:20,  3.86it\u001b[A\n",
      "Average Metric: 9.174603174603174 / 20  (45.9):  20%|▏| 20/100 [00:06<00:19,  4.12it\u001b[A\n",
      "Average Metric: 9.174603174603174 / 21  (43.7):  20%|▏| 20/100 [00:06<00:19,  4.12it\u001b[A\n",
      "Average Metric: 9.174603174603174 / 21  (43.7):  21%|▏| 21/100 [00:06<00:17,  4.59it\u001b[A\n",
      "Average Metric: 9.507936507936508 / 22  (43.2):  21%|▏| 21/100 [00:06<00:17,  4.59it\u001b[A\n",
      "Average Metric: 10.007936507936508 / 23  (43.5):  22%|▏| 22/100 [00:06<00:17,  4.59i\u001b[A\n",
      "Average Metric: 10.007936507936508 / 23  (43.5):  23%|▏| 23/100 [00:06<00:20,  3.72i\u001b[A\n",
      "Average Metric: 10.757936507936508 / 24  (44.8):  23%|▏| 23/100 [00:07<00:20,  3.72i\u001b[A\n",
      "Average Metric: 10.757936507936508 / 24  (44.8):  24%|▏| 24/100 [00:07<00:17,  4.30i\u001b[A\n",
      "Average Metric: 11.757936507936508 / 25  (47.0):  24%|▏| 24/100 [00:07<00:17,  4.30i\u001b[A\n",
      "Average Metric: 12.757936507936508 / 26  (49.1):  25%|▎| 25/100 [00:07<00:17,  4.30i\u001b[A\n",
      "Average Metric: 13.757936507936508 / 27  (51.0):  26%|▎| 26/100 [00:07<00:17,  4.30i\u001b[A\n",
      "Average Metric: 14.257936507936508 / 28  (50.9):  27%|▎| 27/100 [00:07<00:16,  4.30i\u001b[A\n",
      "Average Metric: 14.257936507936508 / 28  (50.9):  28%|▎| 28/100 [00:07<00:10,  7.00i\u001b[A\n",
      "Average Metric: 14.257936507936508 / 29  (49.2):  28%|▎| 28/100 [00:07<00:10,  7.00i\u001b[A\n",
      "Average Metric: 14.257936507936508 / 29  (49.2):  29%|▎| 29/100 [00:07<00:16,  4.36i\u001b[A\n",
      "Average Metric: 14.757936507936508 / 30  (49.2):  29%|▎| 29/100 [00:08<00:16,  4.36i\u001b[A\n",
      "Average Metric: 14.757936507936508 / 30  (49.2):  30%|▎| 30/100 [00:08<00:16,  4.18i\u001b[A\n",
      "Average Metric: 15.757936507936508 / 31  (50.8):  30%|▎| 30/100 [00:08<00:16,  4.18i\u001b[A\n",
      "Average Metric: 15.757936507936508 / 32  (49.2):  31%|▎| 31/100 [00:08<00:16,  4.18i\u001b[A\n",
      "Average Metric: 16.757936507936506 / 33  (50.8):  32%|▎| 32/100 [00:08<00:16,  4.18i\u001b[A\n",
      "Average Metric: 16.757936507936506 / 33  (50.8):  33%|▎| 33/100 [00:08<00:10,  6.43i\u001b[A\n",
      "Average Metric: 17.09126984126984 / 34  (50.3):  33%|▎| 33/100 [00:08<00:10,  6.43it\u001b[A\n",
      "Average Metric: 17.09126984126984 / 34  (50.3):  34%|▎| 34/100 [00:08<00:10,  6.04it\u001b[A\n",
      "Average Metric: 17.59126984126984 / 35  (50.3):  34%|▎| 34/100 [00:08<00:10,  6.04it\u001b[A\n",
      "Average Metric: 17.59126984126984 / 35  (50.3):  35%|▎| 35/100 [00:08<00:12,  5.19it\u001b[A\n",
      "Average Metric: 17.92460317460317 / 36  (49.8):  35%|▎| 35/100 [00:09<00:12,  5.19it\u001b[A\n",
      "Average Metric: 17.92460317460317 / 36  (49.8):  36%|▎| 36/100 [00:09<00:15,  4.06it\u001b[A\n",
      "Average Metric: 17.92460317460317 / 37  (48.4):  36%|▎| 36/100 [00:09<00:15,  4.06it\u001b[A\n",
      "Average Metric: 17.92460317460317 / 37  (48.4):  37%|▎| 37/100 [00:09<00:16,  3.85it\u001b[A\n",
      "Average Metric: 18.42460317460317 / 38  (48.5):  37%|▎| 37/100 [00:09<00:16,  3.85it\u001b[A\n",
      "Average Metric: 18.42460317460317 / 38  (48.5):  38%|▍| 38/100 [00:09<00:13,  4.46it\u001b[A\n",
      "Average Metric: 18.757936507936503 / 39  (48.1):  38%|▍| 38/100 [00:09<00:13,  4.46i\u001b[A\n",
      "Average Metric: 18.957936507936502 / 40  (47.4):  39%|▍| 39/100 [00:09<00:13,  4.46i\u001b[A\n",
      "Average Metric: 18.957936507936502 / 40  (47.4):  40%|▍| 40/100 [00:09<00:10,  5.98i\u001b[A\n",
      "Average Metric: 18.957936507936502 / 41  (46.2):  40%|▍| 40/100 [00:10<00:10,  5.98i\u001b[A\n",
      "Average Metric: 18.957936507936502 / 41  (46.2):  41%|▍| 41/100 [00:10<00:10,  5.44i\u001b[A\n",
      "Average Metric: 19.957936507936502 / 42  (47.5):  41%|▍| 41/100 [00:10<00:10,  5.44i\u001b[A\n",
      "Average Metric: 19.957936507936502 / 42  (47.5):  42%|▍| 42/100 [00:10<00:13,  4.20i\u001b[A\n",
      "Average Metric: 20.291269841269834 / 43  (47.2):  42%|▍| 42/100 [00:10<00:13,  4.20i\u001b[A\n",
      "Average Metric: 21.291269841269834 / 44  (48.4):  43%|▍| 43/100 [00:10<00:13,  4.20i\u001b[A\n",
      "Average Metric: 21.291269841269834 / 44  (48.4):  44%|▍| 44/100 [00:10<00:10,  5.48i\u001b[A\n",
      "Average Metric: 22.291269841269834 / 45  (49.5):  44%|▍| 44/100 [00:10<00:10,  5.48i\u001b[A\n",
      "Average Metric: 22.291269841269834 / 46  (48.5):  45%|▍| 45/100 [00:11<00:10,  5.48i\u001b[A\n",
      "Average Metric: 22.291269841269834 / 46  (48.5):  46%|▍| 46/100 [00:11<00:10,  4.97i\u001b[A\n",
      "Average Metric: 22.791269841269834 / 47  (48.5):  46%|▍| 46/100 [00:11<00:10,  4.97i\u001b[A\n",
      "Average Metric: 22.791269841269834 / 47  (48.5):  47%|▍| 47/100 [00:11<00:11,  4.68i\u001b[A\n",
      "Average Metric: 23.791269841269834 / 48  (49.6):  47%|▍| 47/100 [00:11<00:11,  4.68i\u001b[A\n",
      "Average Metric: 23.791269841269834 / 48  (49.6):  48%|▍| 48/100 [00:11<00:13,  3.92i\u001b[A\n",
      "Average Metric: 24.041269841269834 / 49  (49.1):  48%|▍| 48/100 [00:11<00:13,  3.92i\u001b[A\n",
      "Average Metric: 24.374603174603166 / 50  (48.7):  49%|▍| 49/100 [00:11<00:13,  3.92i\u001b[A\n",
      "Average Metric: 25.374603174603166 / 51  (49.8):  50%|▌| 50/100 [00:12<00:12,  3.92i\u001b[A\n",
      "Average Metric: 25.374603174603166 / 51  (49.8):  51%|▌| 51/100 [00:12<00:07,  6.86i\u001b[A\n",
      "Average Metric: 25.7079365079365 / 52  (49.4):  51%|▌| 51/100 [00:12<00:07,  6.86it/\u001b[A\n",
      "Average Metric: 26.2079365079365 / 53  (49.4):  52%|▌| 52/100 [00:12<00:06,  6.86it/\u001b[A\n",
      "Average Metric: 26.2079365079365 / 53  (49.4):  53%|▌| 53/100 [00:12<00:11,  4.09it/\u001b[A\n",
      "Average Metric: 26.54126984126983 / 54  (49.2):  53%|▌| 53/100 [00:13<00:11,  4.09it\u001b[A\n",
      "Average Metric: 27.54126984126983 / 55  (50.1):  54%|▌| 54/100 [00:13<00:11,  4.09it\u001b[A\n",
      "Average Metric: 27.54126984126983 / 55  (50.1):  55%|▌| 55/100 [00:13<00:08,  5.22it\u001b[A\n",
      "Average Metric: 27.874603174603163 / 56  (49.8):  55%|▌| 55/100 [00:13<00:08,  5.22i\u001b[A\n",
      "Average Metric: 28.207936507936495 / 57  (49.5):  56%|▌| 56/100 [00:13<00:08,  5.22i\u001b[A\n",
      "Average Metric: 28.207936507936495 / 57  (49.5):  57%|▌| 57/100 [00:13<00:08,  5.27i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 58  (50.4):  57%|▌| 57/100 [00:13<00:08,  5.27i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 58  (50.4):  58%|▌| 58/100 [00:13<00:09,  4.61i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 59  (49.5):  58%|▌| 58/100 [00:13<00:09,  4.61i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 59  (49.5):  59%|▌| 59/100 [00:13<00:08,  5.11i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 60  (48.7):  59%|▌| 59/100 [00:14<00:08,  5.11i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 60  (48.7):  60%|▌| 60/100 [00:14<00:07,  5.36i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 61  (47.9):  60%|▌| 60/100 [00:14<00:07,  5.36i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 62  (47.1):  61%|▌| 61/100 [00:14<00:07,  5.36i\u001b[A\n",
      "Average Metric: 29.207936507936495 / 62  (47.1):  62%|▌| 62/100 [00:14<00:07,  5.27i\u001b[A\n",
      "Average Metric: 30.207936507936495 / 63  (47.9):  62%|▌| 62/100 [00:14<00:07,  5.27i\u001b[A\n",
      "Average Metric: 30.207936507936495 / 63  (47.9):  63%|▋| 63/100 [00:14<00:07,  4.88i\u001b[A\n",
      "Average Metric: 30.707936507936495 / 64  (48.0):  63%|▋| 63/100 [00:15<00:07,  4.88i\u001b[A\n",
      "Average Metric: 30.707936507936495 / 64  (48.0):  64%|▋| 64/100 [00:15<00:08,  4.28i\u001b[A\n",
      "Average Metric: 31.207936507936495 / 65  (48.0):  64%|▋| 64/100 [00:15<00:08,  4.28i\u001b[A\n",
      "Average Metric: 31.874603174603163 / 66  (48.3):  65%|▋| 65/100 [00:15<00:08,  4.28i\u001b[A\n",
      "Average Metric: 31.874603174603163 / 66  (48.3):  66%|▋| 66/100 [00:15<00:06,  5.09i\u001b[A\n",
      "Average Metric: 32.207936507936495 / 67  (48.1):  66%|▋| 66/100 [00:15<00:06,  5.09i\u001b[A\n",
      "Average Metric: 32.207936507936495 / 68  (47.4):  67%|▋| 67/100 [00:16<00:06,  5.09i\u001b[A\n",
      "Average Metric: 32.207936507936495 / 68  (47.4):  68%|▋| 68/100 [00:16<00:08,  3.65i\u001b[A\n",
      "Average Metric: 32.707936507936495 / 69  (47.4):  68%|▋| 68/100 [00:16<00:08,  3.65i\u001b[A\n",
      "Average Metric: 32.707936507936495 / 69  (47.4):  69%|▋| 69/100 [00:16<00:08,  3.52i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.207936507936495 / 70  (47.4):  69%|▋| 69/100 [00:16<00:08,  3.52i\u001b[A\n",
      "Average Metric: 33.207936507936495 / 70  (47.4):  70%|▋| 70/100 [00:16<00:08,  3.69i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.207936507936495 / 71  (46.8):  70%|▋| 70/100 [00:17<00:08,  3.69i\u001b[A\n",
      "Average Metric: 33.207936507936495 / 71  (46.8):  71%|▋| 71/100 [00:17<00:11,  2.56i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.207936507936495 / 72  (47.5):  71%|▋| 71/100 [00:18<00:11,  2.56i\u001b[A\n",
      "Average Metric: 34.207936507936495 / 72  (47.5):  72%|▋| 72/100 [00:18<00:14,  1.90i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.207936507936495 / 73  (48.2):  72%|▋| 72/100 [00:19<00:14,  1.90i\u001b[A\n",
      "Average Metric: 35.207936507936495 / 73  (48.2):  73%|▋| 73/100 [00:19<00:17,  1.58i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.207936507936495 / 74  (48.9):  73%|▋| 73/100 [00:19<00:17,  1.58i\u001b[A\n",
      "Average Metric: 36.207936507936495 / 74  (48.9):  74%|▋| 74/100 [00:19<00:16,  1.61i\u001b[A\n",
      "Average Metric: 36.207936507936495 / 75  (48.3):  74%|▋| 74/100 [00:21<00:16,  1.61i\u001b[A\n",
      "Average Metric: 36.207936507936495 / 75  (48.3):  75%|▊| 75/100 [00:21<00:19,  1.29i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.207936507936495 / 76  (49.0):  75%|▊| 75/100 [00:22<00:19,  1.29i\u001b[A\n",
      "Average Metric: 37.207936507936495 / 76  (49.0):  76%|▊| 76/100 [00:22<00:19,  1.21i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.207936507936495 / 77  (49.6):  76%|▊| 76/100 [00:22<00:19,  1.21i\u001b[A\n",
      "Average Metric: 38.207936507936495 / 77  (49.6):  77%|▊| 77/100 [00:22<00:17,  1.31i\u001b[A\n",
      "Average Metric: 39.207936507936495 / 78  (50.3):  77%|▊| 77/100 [00:23<00:17,  1.31i\u001b[A\n",
      "Average Metric: 39.207936507936495 / 78  (50.3):  78%|▊| 78/100 [00:23<00:16,  1.35i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.54126984126983 / 79  (50.1):  78%|▊| 78/100 [00:24<00:16,  1.35it\u001b[A\n",
      "Average Metric: 39.54126984126983 / 79  (50.1):  79%|▊| 79/100 [00:24<00:18,  1.13it\u001b[A\n",
      "Average Metric: 40.04126984126983 / 80  (50.1):  79%|▊| 79/100 [00:24<00:18,  1.13it\u001b[A\n",
      "Average Metric: 40.04126984126983 / 80  (50.1):  80%|▊| 80/100 [00:24<00:15,  1.32it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.04126984126983 / 81  (50.7):  80%|▊| 80/100 [00:25<00:15,  1.32it\u001b[A\n",
      "Average Metric: 41.04126984126983 / 81  (50.7):  81%|▊| 81/100 [00:25<00:13,  1.36it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 13.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.707936507936495 / 82  (50.9):  81%|▊| 81/100 [00:27<00:13,  1.36i\u001b[A\n",
      "Average Metric: 41.707936507936495 / 82  (50.9):  82%|▊| 82/100 [00:27<00:19,  1.09s\u001b[A\n",
      "Average Metric: 42.04126984126983 / 83  (50.7):  82%|▊| 82/100 [00:28<00:19,  1.09s/\u001b[A\n",
      "Average Metric: 42.04126984126983 / 83  (50.7):  83%|▊| 83/100 [00:28<00:15,  1.06it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.29126984126983 / 84  (50.3):  83%|▊| 83/100 [00:29<00:15,  1.06it\u001b[A\n",
      "Average Metric: 42.29126984126983 / 84  (50.3):  84%|▊| 84/100 [00:29<00:16,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.29126984126983 / 85  (50.9):  84%|▊| 84/100 [00:30<00:16,  1.03s/\u001b[A\n",
      "Average Metric: 43.29126984126983 / 85  (50.9):  85%|▊| 85/100 [00:30<00:17,  1.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.29126984126983 / 86  (50.3):  85%|▊| 85/100 [00:31<00:17,  1.17s/\u001b[A\n",
      "Average Metric: 43.29126984126983 / 86  (50.3):  86%|▊| 86/100 [00:31<00:13,  1.07it\u001b[A\n",
      "Average Metric: 44.29126984126983 / 87  (50.9):  86%|▊| 86/100 [00:32<00:13,  1.07it\u001b[A\n",
      "Average Metric: 44.29126984126983 / 87  (50.9):  87%|▊| 87/100 [00:32<00:12,  1.04it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.29126984126983 / 88  (51.5):  87%|▊| 87/100 [00:33<00:12,  1.04it\u001b[A\n",
      "Average Metric: 45.29126984126983 / 88  (51.5):  88%|▉| 88/100 [00:33<00:12,  1.07s/\u001b[A\n",
      "Average Metric: 46.29126984126983 / 89  (52.0):  88%|▉| 88/100 [00:34<00:12,  1.07s/\u001b[A\n",
      "Average Metric: 46.29126984126983 / 89  (52.0):  89%|▉| 89/100 [00:34<00:12,  1.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.29126984126983 / 90  (52.5):  89%|▉| 89/100 [00:36<00:12,  1.12s/\u001b[A\n",
      "Average Metric: 47.29126984126983 / 90  (52.5):  90%|▉| 90/100 [00:36<00:11,  1.14s/\u001b[A\n",
      "Average Metric: 47.624603174603166 / 91  (52.3):  90%|▉| 90/100 [00:37<00:11,  1.14s\u001b[A\n",
      "Average Metric: 47.624603174603166 / 91  (52.3):  91%|▉| 91/100 [00:37<00:11,  1.29s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 48.624603174603166 / 92  (52.9):  91%|▉| 91/100 [00:39<00:11,  1.29s\u001b[A\n",
      "Average Metric: 48.624603174603166 / 92  (52.9):  92%|▉| 92/100 [00:39<00:10,  1.32s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.124603174603166 / 93  (52.8):  92%|▉| 92/100 [00:41<00:10,  1.32s\u001b[A\n",
      "Average Metric: 49.124603174603166 / 93  (52.8):  93%|▉| 93/100 [00:41<00:11,  1.59s\u001b[A\n",
      "Average Metric: 49.83888888888888 / 94  (53.0):  93%|▉| 93/100 [00:41<00:11,  1.59s/\u001b[A\n",
      "Average Metric: 49.83888888888888 / 94  (53.0):  94%|▉| 94/100 [00:41<00:06,  1.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 16.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.83888888888888 / 95  (52.5):  94%|▉| 94/100 [00:43<00:06,  1.17s/\u001b[A\n",
      "Average Metric: 49.83888888888888 / 95  (52.5):  95%|▉| 95/100 [00:43<00:07,  1.46s/\u001b[A\n",
      "Average Metric: 49.83888888888888 / 96  (51.9):  95%|▉| 95/100 [00:43<00:07,  1.46s/\u001b[A\n",
      "Average Metric: 49.83888888888888 / 96  (51.9):  96%|▉| 96/100 [00:43<00:04,  1.12s/\u001b[A\n",
      "Average Metric: 50.83888888888888 / 97  (52.4):  96%|▉| 96/100 [00:44<00:04,  1.12s/\u001b[A\n",
      "Average Metric: 50.83888888888888 / 97  (52.4):  97%|▉| 97/100 [00:44<00:03,  1.06s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.33888888888888 / 98  (52.4):  97%|▉| 97/100 [00:45<00:03,  1.06s/\u001b[A\n",
      "Average Metric: 51.33888888888888 / 98  (52.4):  98%|▉| 98/100 [00:45<00:01,  1.12it\u001b[A\n",
      "Average Metric: 52.33888888888888 / 99  (52.9):  98%|▉| 98/100 [00:47<00:01,  1.12it\u001b[A\n",
      "Average Metric: 52.33888888888888 / 99  (52.9):  99%|▉| 99/100 [00:47<00:01,  1.24s/\u001b[A\n",
      "Average Metric: 53.33888888888888 / 100  (53.3):  99%|▉| 99/100 [01:00<00:01,  1.24s\u001b[A\n",
      "Average Metric: 53.33888888888888 / 100  (53.3): 100%|█| 100/100 [01:00<00:00,  1.66\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 53.33888888888888 / 100  (53.3%)\n",
      "Score: 53.34 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87, 57.03, 55.56, 51.82, 54.14, 53.34]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8848333333333334\n",
      "Average of max per entry across top 5 scores: 0.9475\n",
      "Average of max per entry across top 8 scores: 0.9766666666666666\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:19,  1.41s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:01<02:06,  1.28s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   1%|▏             | 1/100 [00:01<02:06,  1.28s/it]\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   2%| | 2/100 [00:01<02:05,  1.28s/i\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   3%| | 3/100 [00:01<00:43,  2.24it/\u001b[A\n",
      "Average Metric: 1.2333333333333334 / 4  (30.8):   3%| | 3/100 [00:01<00:43,  2.24it/\u001b[A\n",
      "Average Metric: 1.2333333333333334 / 4  (30.8):   4%| | 4/100 [00:01<00:33,  2.82it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 5  (44.7):   4%| | 4/100 [00:01<00:33,  2.82it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 5  (44.7):   5%| | 5/100 [00:01<00:26,  3.65it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 6  (37.2):   5%| | 5/100 [00:02<00:26,  3.65it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 6  (37.2):   6%| | 6/100 [00:02<00:25,  3.70it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):   6%| | 6/100 [00:02<00:25,  3.70it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):   7%| | 7/100 [00:02<00:28,  3.28it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 8  (27.9):   7%| | 7/100 [00:03<00:28,  3.28it/\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 8  (27.9):   8%| | 8/100 [00:03<00:40,  2.26it/\u001b[A\n",
      "Average Metric: 2.7333333333333334 / 9  (30.4):   8%| | 8/100 [00:03<00:40,  2.26it/\u001b[A\n",
      "Average Metric: 2.7333333333333334 / 9  (30.4):   9%| | 9/100 [00:03<00:37,  2.44it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.9833333333333334 / 10  (29.8):   9%| | 9/100 [00:04<00:37,  2.44it\u001b[A\n",
      "Average Metric: 2.9833333333333334 / 10  (29.8):  10%| | 10/100 [00:04<00:43,  2.09i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.9833333333333334 / 11  (36.2):  10%| | 10/100 [00:04<00:43,  2.09i\u001b[A\n",
      "Average Metric: 3.9833333333333334 / 11  (36.2):  11%| | 11/100 [00:04<00:43,  2.05i\u001b[A\n",
      "Average Metric: 4.427777777777778 / 12  (36.9):  11%| | 11/100 [00:05<00:43,  2.05it\u001b[A\n",
      "Average Metric: 4.427777777777778 / 12  (36.9):  12%| | 12/100 [00:05<00:41,  2.13it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.427777777777778 / 13  (41.8):  12%| | 12/100 [00:06<00:41,  2.13it\u001b[A\n",
      "Average Metric: 5.427777777777778 / 13  (41.8):  13%|▏| 13/100 [00:06<00:53,  1.62it\u001b[A\n",
      "Average Metric: 6.177777777777778 / 14  (44.1):  13%|▏| 13/100 [00:06<00:53,  1.62it\u001b[A\n",
      "Average Metric: 6.177777777777778 / 14  (44.1):  14%|▏| 14/100 [00:06<00:46,  1.87it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.177777777777778 / 15  (47.9):  14%|▏| 14/100 [00:08<00:46,  1.87it\u001b[A\n",
      "Average Metric: 7.177777777777778 / 15  (47.9):  15%|▏| 15/100 [00:08<01:21,  1.04it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.177777777777777 / 16  (51.1):  15%|▏| 15/100 [00:09<01:21,  1.04it\u001b[A\n",
      "Average Metric: 8.177777777777777 / 16  (51.1):  16%|▏| 16/100 [00:09<01:20,  1.04it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.177777777777777 / 17  (48.1):  16%|▏| 16/100 [00:10<01:20,  1.04it\u001b[A\n",
      "Average Metric: 8.177777777777777 / 17  (48.1):  17%|▏| 17/100 [00:10<01:22,  1.00it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.177777777777777 / 18  (45.4):  17%|▏| 17/100 [00:12<01:22,  1.00it\u001b[A\n",
      "Average Metric: 8.177777777777777 / 18  (45.4):  18%|▏| 18/100 [00:12<01:46,  1.30s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.344444444444443 / 19  (43.9):  18%|▏| 18/100 [00:13<01:46,  1.30s/\u001b[A\n",
      "Average Metric: 8.344444444444443 / 19  (43.9):  19%|▏| 19/100 [00:13<01:27,  1.09s/\u001b[A\n",
      "Average Metric: 8.344444444444443 / 20  (41.7):  19%|▏| 19/100 [00:14<01:27,  1.09s/\u001b[A\n",
      "Average Metric: 8.344444444444443 / 20  (41.7):  20%|▏| 20/100 [00:14<01:28,  1.11s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.844444444444443 / 21  (42.1):  20%|▏| 20/100 [00:15<01:28,  1.11s/\u001b[A\n",
      "Average Metric: 8.844444444444443 / 21  (42.1):  21%|▏| 21/100 [00:15<01:37,  1.23s/\u001b[A\n",
      "Average Metric: 9.844444444444443 / 22  (44.7):  21%|▏| 21/100 [00:16<01:37,  1.23s/\u001b[A\n",
      "Average Metric: 9.844444444444443 / 22  (44.7):  22%|▏| 22/100 [00:16<01:34,  1.21s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.177777777777777 / 23  (44.3):  22%|▏| 22/100 [00:18<01:34,  1.21s\u001b[A\n",
      "Average Metric: 10.177777777777777 / 23  (44.3):  23%|▏| 23/100 [00:18<01:51,  1.45s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.927777777777777 / 24  (45.5):  23%|▏| 23/100 [00:20<01:51,  1.45s\u001b[A\n",
      "Average Metric: 10.927777777777777 / 24  (45.5):  24%|▏| 24/100 [00:20<01:54,  1.51s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.927777777777777 / 25  (43.7):  24%|▏| 24/100 [00:21<01:54,  1.51s\u001b[A\n",
      "Average Metric: 10.927777777777777 / 25  (43.7):  25%|▎| 25/100 [00:21<01:38,  1.31s\u001b[A\n",
      "Average Metric: 11.261111111111111 / 26  (43.3):  25%|▎| 25/100 [00:23<01:38,  1.31s\u001b[A\n",
      "Average Metric: 11.261111111111111 / 26  (43.3):  26%|▎| 26/100 [00:23<01:45,  1.43s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 5.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.594444444444445 / 27  (42.9):  26%|▎| 26/100 [00:24<01:45,  1.43s\u001b[A\n",
      "Average Metric: 11.594444444444445 / 27  (42.9):  27%|▎| 27/100 [00:24<01:43,  1.42s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.994444444444445 / 28  (42.8):  27%|▎| 27/100 [00:26<01:43,  1.42s\u001b[A\n",
      "Average Metric: 11.994444444444445 / 28  (42.8):  28%|▎| 28/100 [00:26<02:04,  1.73s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.194444444444445 / 29  (42.0):  28%|▎| 28/100 [00:28<02:04,  1.73s\u001b[A\n",
      "Average Metric: 12.194444444444445 / 29  (42.0):  29%|▎| 29/100 [00:28<01:56,  1.65s\u001b[A\n",
      "Average Metric: 12.194444444444445 / 30  (40.6):  29%|▎| 29/100 [00:28<01:56,  1.65s\u001b[A\n",
      "Average Metric: 12.194444444444445 / 30  (40.6):  30%|▎| 30/100 [00:28<01:31,  1.30s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 23.5 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.86111111111111 / 31  (41.5):  30%|▎| 30/100 [00:30<01:31,  1.30s/\u001b[A\n",
      "Average Metric: 12.86111111111111 / 31  (41.5):  31%|▎| 31/100 [00:30<01:42,  1.49s/\u001b[A\n",
      "Average Metric: 12.86111111111111 / 32  (40.2):  31%|▎| 31/100 [00:31<01:42,  1.49s/\u001b[A\n",
      "Average Metric: 12.86111111111111 / 32  (40.2):  32%|▎| 32/100 [00:31<01:30,  1.33s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.86111111111111 / 33  (42.0):  32%|▎| 32/100 [00:32<01:30,  1.33s/\u001b[A\n",
      "Average Metric: 13.86111111111111 / 33  (42.0):  33%|▎| 33/100 [00:32<01:26,  1.29s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.527777777777777 / 34  (42.7):  33%|▎| 33/100 [00:34<01:26,  1.29s\u001b[A\n",
      "Average Metric: 14.527777777777777 / 34  (42.7):  34%|▎| 34/100 [00:34<01:30,  1.37s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.527777777777777 / 35  (41.5):  34%|▎| 34/100 [00:35<01:30,  1.37s\u001b[A\n",
      "Average Metric: 14.527777777777777 / 35  (41.5):  35%|▎| 35/100 [00:35<01:26,  1.33s\u001b[A\n",
      "Average Metric: 15.027777777777777 / 36  (41.7):  35%|▎| 35/100 [00:37<01:26,  1.33s\u001b[A\n",
      "Average Metric: 15.027777777777777 / 36  (41.7):  36%|▎| 36/100 [00:37<01:26,  1.36s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.36111111111111 / 37  (41.5):  36%|▎| 36/100 [00:38<01:26,  1.36s/\u001b[A\n",
      "Average Metric: 15.36111111111111 / 37  (41.5):  37%|▎| 37/100 [00:38<01:25,  1.36s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.86111111111111 / 38  (41.7):  37%|▎| 37/100 [00:41<01:25,  1.36s/\u001b[A\n",
      "Average Metric: 15.86111111111111 / 38  (41.7):  38%|▍| 38/100 [00:41<01:52,  1.81s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.36111111111111 / 39  (42.0):  38%|▍| 38/100 [00:44<01:52,  1.81s/\u001b[A\n",
      "Average Metric: 16.36111111111111 / 39  (42.0):  39%|▍| 39/100 [00:44<02:12,  2.17s/\u001b[A\n",
      "Average Metric: 17.02777777777778 / 40  (42.6):  39%|▍| 39/100 [00:45<02:12,  2.17s/\u001b[A\n",
      "Average Metric: 17.02777777777778 / 40  (42.6):  40%|▍| 40/100 [00:45<01:48,  1.81s/\u001b[A\n",
      "Average Metric: 18.02777777777778 / 41  (44.0):  40%|▍| 40/100 [00:47<01:48,  1.81s/\u001b[A\n",
      "Average Metric: 18.02777777777778 / 41  (44.0):  41%|▍| 41/100 [00:47<01:46,  1.80s/\u001b[A\n",
      "Average Metric: 19.02777777777778 / 42  (45.3):  41%|▍| 41/100 [00:47<01:46,  1.80s/\u001b[A\n",
      "Average Metric: 19.02777777777778 / 42  (45.3):  42%|▍| 42/100 [00:47<01:16,  1.32s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.52777777777778 / 43  (45.4):  42%|▍| 42/100 [00:48<01:16,  1.32s/\u001b[A\n",
      "Average Metric: 19.52777777777778 / 43  (45.4):  43%|▍| 43/100 [00:48<01:12,  1.27s/\u001b[A\n",
      "Average Metric: 20.52777777777778 / 44  (46.7):  43%|▍| 43/100 [00:48<01:12,  1.27s/\u001b[A\n",
      "Average Metric: 20.52777777777778 / 44  (46.7):  44%|▍| 44/100 [00:48<00:54,  1.02it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.52777777777778 / 45  (45.6):  44%|▍| 44/100 [00:51<00:54,  1.02it\u001b[A\n",
      "Average Metric: 20.52777777777778 / 45  (45.6):  45%|▍| 45/100 [00:51<01:13,  1.34s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.52777777777778 / 46  (46.8):  45%|▍| 45/100 [00:52<01:13,  1.34s/\u001b[A\n",
      "Average Metric: 21.52777777777778 / 46  (46.8):  46%|▍| 46/100 [00:52<01:12,  1.35s/\u001b[A\n",
      "Average Metric: 22.52777777777778 / 47  (47.9):  46%|▍| 46/100 [00:52<01:12,  1.35s/\u001b[A\n",
      "Average Metric: 22.52777777777778 / 47  (47.9):  47%|▍| 47/100 [00:52<00:54,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.86111111111111 / 48  (47.6):  47%|▍| 47/100 [00:54<00:54,  1.03s/\u001b[A\n",
      "Average Metric: 22.86111111111111 / 48  (47.6):  48%|▍| 48/100 [00:54<01:05,  1.26s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 56.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.86111111111111 / 49  (48.7):  48%|▍| 48/100 [00:56<01:05,  1.26s/\u001b[A\n",
      "Average Metric: 23.86111111111111 / 49  (48.7):  49%|▍| 49/100 [00:56<01:10,  1.38s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.86111111111111 / 50  (47.7):  49%|▍| 49/100 [00:57<01:10,  1.38s/\u001b[A\n",
      "Average Metric: 23.86111111111111 / 50  (47.7):  50%|▌| 50/100 [00:57<01:08,  1.36s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.36111111111111 / 51  (47.8):  50%|▌| 50/100 [00:58<01:08,  1.36s/\u001b[A\n",
      "Average Metric: 24.36111111111111 / 51  (47.8):  51%|▌| 51/100 [00:58<01:02,  1.28s/\u001b[A\n",
      "Average Metric: 25.36111111111111 / 52  (48.8):  51%|▌| 51/100 [00:59<01:02,  1.28s/\u001b[A\n",
      "Average Metric: 25.36111111111111 / 52  (48.8):  52%|▌| 52/100 [00:59<01:00,  1.27s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.36111111111111 / 53  (49.7):  52%|▌| 52/100 [01:01<01:00,  1.27s/\u001b[A\n",
      "Average Metric: 26.36111111111111 / 53  (49.7):  53%|▌| 53/100 [01:01<01:03,  1.36s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.36111111111111 / 54  (50.7):  53%|▌| 53/100 [01:03<01:03,  1.36s/\u001b[A\n",
      "Average Metric: 27.36111111111111 / 54  (50.7):  54%|▌| 54/100 [01:03<01:10,  1.53s/\u001b[A\n",
      "Average Metric: 27.86111111111111 / 55  (50.7):  54%|▌| 54/100 [01:04<01:10,  1.53s/\u001b[A\n",
      "Average Metric: 27.86111111111111 / 55  (50.7):  55%|▌| 55/100 [01:04<01:01,  1.38s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.86111111111111 / 56  (51.5):  55%|▌| 55/100 [01:05<01:01,  1.38s/\u001b[A\n",
      "Average Metric: 28.86111111111111 / 56  (51.5):  56%|▌| 56/100 [01:05<00:54,  1.24s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.11111111111111 / 57  (51.1):  56%|▌| 56/100 [01:08<00:54,  1.24s/\u001b[A\n",
      "Average Metric: 29.11111111111111 / 57  (51.1):  57%|▌| 57/100 [01:08<01:15,  1.75s/\u001b[A\n",
      "Average Metric: 29.11111111111111 / 58  (50.2):  57%|▌| 57/100 [01:08<01:15,  1.75s/\u001b[A\n",
      "Average Metric: 29.11111111111111 / 58  (50.2):  58%|▌| 58/100 [01:08<00:53,  1.28s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.11111111111111 / 59  (51.0):  58%|▌| 58/100 [01:09<00:53,  1.28s/\u001b[A\n",
      "Average Metric: 30.11111111111111 / 59  (51.0):  59%|▌| 59/100 [01:09<00:50,  1.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.36111111111111 / 60  (50.6):  59%|▌| 59/100 [01:11<00:50,  1.23s/\u001b[A\n",
      "Average Metric: 30.36111111111111 / 60  (50.6):  60%|▌| 60/100 [01:11<01:01,  1.54s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.36111111111111 / 61  (49.8):  60%|▌| 60/100 [01:12<01:01,  1.54s/\u001b[A\n",
      "Average Metric: 30.36111111111111 / 61  (49.8):  61%|▌| 61/100 [01:12<00:55,  1.41s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.36111111111111 / 62  (49.0):  61%|▌| 61/100 [01:13<00:55,  1.41s/\u001b[A\n",
      "Average Metric: 30.36111111111111 / 62  (49.0):  62%|▌| 62/100 [01:13<00:50,  1.33s/\u001b[A\n",
      "Average Metric: 30.36111111111111 / 63  (48.2):  62%|▌| 62/100 [01:15<00:50,  1.33s/\u001b[A\n",
      "Average Metric: 30.36111111111111 / 63  (48.2):  63%|▋| 63/100 [01:15<00:53,  1.43s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.36111111111111 / 64  (49.0):  63%|▋| 63/100 [01:17<00:53,  1.43s/\u001b[A\n",
      "Average Metric: 31.36111111111111 / 64  (49.0):  64%|▋| 64/100 [01:17<00:56,  1.56s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.361111111111114 / 65  (49.8):  64%|▋| 64/100 [01:19<00:56,  1.56s\u001b[A\n",
      "Average Metric: 32.361111111111114 / 65  (49.8):  65%|▋| 65/100 [01:19<00:56,  1.63s\u001b[A\n",
      "Average Metric: 32.861111111111114 / 66  (49.8):  65%|▋| 65/100 [01:19<00:56,  1.63s\u001b[A\n",
      "Average Metric: 32.861111111111114 / 66  (49.8):  66%|▋| 66/100 [01:19<00:44,  1.32s\u001b[A\n",
      "Average Metric: 33.361111111111114 / 67  (49.8):  66%|▋| 66/100 [01:21<00:44,  1.32s\u001b[A\n",
      "Average Metric: 33.361111111111114 / 67  (49.8):  67%|▋| 67/100 [01:21<00:43,  1.32s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.861111111111114 / 68  (49.8):  67%|▋| 67/100 [01:22<00:43,  1.32s\u001b[A\n",
      "Average Metric: 33.861111111111114 / 68  (49.8):  68%|▋| 68/100 [01:22<00:42,  1.32s\u001b[A\n",
      "Average Metric: 33.861111111111114 / 69  (49.1):  68%|▋| 68/100 [01:24<00:42,  1.32s\u001b[A\n",
      "Average Metric: 33.861111111111114 / 69  (49.1):  69%|▋| 69/100 [01:24<00:42,  1.37s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.861111111111114 / 70  (49.8):  69%|▋| 69/100 [01:25<00:42,  1.37s\u001b[A\n",
      "Average Metric: 34.861111111111114 / 70  (49.8):  70%|▋| 70/100 [01:25<00:40,  1.34s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.861111111111114 / 71  (50.5):  70%|▋| 70/100 [01:26<00:40,  1.34s\u001b[A\n",
      "Average Metric: 35.861111111111114 / 71  (50.5):  71%|▋| 71/100 [01:26<00:40,  1.41s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.861111111111114 / 72  (51.2):  71%|▋| 71/100 [01:27<00:40,  1.41s\u001b[A\n",
      "Average Metric: 36.861111111111114 / 72  (51.2):  72%|▋| 72/100 [01:27<00:36,  1.32s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.861111111111114 / 73  (51.9):  72%|▋| 72/100 [01:29<00:36,  1.32s\u001b[A\n",
      "Average Metric: 37.861111111111114 / 73  (51.9):  73%|▋| 73/100 [01:29<00:39,  1.45s\u001b[A\n",
      "Average Metric: 38.861111111111114 / 74  (52.5):  73%|▋| 73/100 [01:30<00:39,  1.45s\u001b[A\n",
      "Average Metric: 38.861111111111114 / 74  (52.5):  74%|▋| 74/100 [01:30<00:34,  1.31s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 27.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.861111111111114 / 75  (51.8):  74%|▋| 74/100 [01:32<00:34,  1.31s\u001b[A\n",
      "Average Metric: 38.861111111111114 / 75  (51.8):  75%|▊| 75/100 [01:32<00:34,  1.40s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.861111111111114 / 76  (52.4):  75%|▊| 75/100 [01:33<00:34,  1.40s\u001b[A\n",
      "Average Metric: 39.861111111111114 / 76  (52.4):  76%|▊| 76/100 [01:33<00:32,  1.33s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 40.861111111111114 / 77  (53.1):  76%|▊| 76/100 [01:34<00:32,  1.33s\u001b[A\n",
      "Average Metric: 40.861111111111114 / 77  (53.1):  77%|▊| 77/100 [01:34<00:28,  1.25s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.083333333333336 / 78  (52.7):  77%|▊| 77/100 [01:37<00:28,  1.25s\u001b[A\n",
      "Average Metric: 41.083333333333336 / 78  (52.7):  78%|▊| 78/100 [01:37<00:35,  1.63s\u001b[A\n",
      "Average Metric: 42.083333333333336 / 79  (53.3):  78%|▊| 78/100 [01:37<00:35,  1.63s\u001b[A\n",
      "Average Metric: 42.083333333333336 / 79  (53.3):  79%|▊| 79/100 [01:37<00:29,  1.39s\u001b[A\n",
      "Average Metric: 42.083333333333336 / 80  (52.6):  79%|▊| 79/100 [01:39<00:29,  1.39s\u001b[A\n",
      "Average Metric: 42.083333333333336 / 80  (52.6):  80%|▊| 80/100 [01:39<00:29,  1.45s\u001b[A\n",
      "Average Metric: 43.083333333333336 / 81  (53.2):  80%|▊| 80/100 [01:40<00:29,  1.45s\u001b[A\n",
      "Average Metric: 43.083333333333336 / 81  (53.2):  81%|▊| 81/100 [01:40<00:24,  1.29s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.75 / 82  (53.4):  81%|████████  | 81/100 [01:42<00:24,  1.29s/it]\u001b[A\n",
      "Average Metric: 43.75 / 82  (53.4):  82%|████████▏ | 82/100 [01:42<00:25,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.75 / 83  (53.9):  82%|████████▏ | 82/100 [01:44<00:25,  1.40s/it]\u001b[A\n",
      "Average Metric: 44.75 / 83  (53.9):  83%|████████▎ | 83/100 [01:44<00:26,  1.57s/it]\u001b[A\n",
      "Average Metric: 45.0 / 84  (53.6):  83%|█████████▏ | 83/100 [01:44<00:26,  1.57s/it]\u001b[A\n",
      "Average Metric: 45.0 / 84  (53.6):  84%|█████████▏ | 84/100 [01:44<00:20,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 41.5 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46.0 / 85  (54.1):  84%|█████████▏ | 84/100 [01:46<00:20,  1.30s/it]\u001b[A\n",
      "Average Metric: 46.0 / 85  (54.1):  85%|█████████▎ | 85/100 [01:46<00:19,  1.32s/it]\u001b[A\n",
      "Average Metric: 47.0 / 86  (54.7):  85%|█████████▎ | 85/100 [01:48<00:19,  1.32s/it]\u001b[A\n",
      "Average Metric: 47.0 / 86  (54.7):  86%|█████████▍ | 86/100 [01:48<00:24,  1.72s/it]\u001b[A\n",
      "Average Metric: 47.25 / 87  (54.3):  86%|████████▌ | 86/100 [01:48<00:24,  1.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 48.25 / 88  (54.8):  87%|████████▋ | 87/100 [01:49<00:22,  1.72s/it]\u001b[A\n",
      "Average Metric: 48.25 / 88  (54.8):  88%|████████▊ | 88/100 [01:49<00:14,  1.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 49.25 / 89  (55.3):  88%|████████▊ | 88/100 [01:51<00:14,  1.20s/it]\u001b[A\n",
      "Average Metric: 49.25 / 89  (55.3):  89%|████████▉ | 89/100 [01:51<00:14,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.25 / 90  (55.8):  89%|████████▉ | 89/100 [01:52<00:14,  1.29s/it]\u001b[A\n",
      "Average Metric: 50.25 / 90  (55.8):  90%|█████████ | 90/100 [01:52<00:12,  1.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 67.5 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.25 / 91  (56.3):  90%|█████████ | 90/100 [01:53<00:12,  1.26s/it]\u001b[A\n",
      "Average Metric: 51.25 / 91  (56.3):  91%|█████████ | 91/100 [01:53<00:11,  1.28s/it]\u001b[A\n",
      "Average Metric: 52.25 / 92  (56.8):  91%|█████████ | 91/100 [01:55<00:11,  1.28s/it]\u001b[A\n",
      "Average Metric: 52.25 / 92  (56.8):  92%|█████████▏| 92/100 [01:55<00:11,  1.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.25 / 93  (56.2):  92%|█████████▏| 92/100 [01:57<00:11,  1.45s/it]\u001b[A\n",
      "Average Metric: 52.25 / 93  (56.2):  93%|█████████▎| 93/100 [01:57<00:09,  1.37s/it]\u001b[A\n",
      "Average Metric: 53.25 / 94  (56.6):  93%|█████████▎| 93/100 [01:58<00:09,  1.37s/it]\u001b[A\n",
      "Average Metric: 53.25 / 94  (56.6):  94%|█████████▍| 94/100 [01:58<00:08,  1.36s/it]\u001b[A\n",
      "Average Metric: 54.25 / 95  (57.1):  94%|█████████▍| 94/100 [01:59<00:08,  1.36s/it]\u001b[A\n",
      "Average Metric: 54.25 / 95  (57.1):  95%|█████████▌| 95/100 [01:59<00:07,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 25.1 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 55.25 / 96  (57.6):  95%|█████████▌| 95/100 [02:01<00:07,  1.40s/it]\u001b[A\n",
      "Average Metric: 55.25 / 96  (57.6):  96%|█████████▌| 96/100 [02:01<00:05,  1.41s/it]\u001b[A\n",
      "Average Metric: 55.25 / 97  (57.0):  96%|█████████▌| 96/100 [02:03<00:05,  1.41s/it]\u001b[A\n",
      "Average Metric: 55.25 / 97  (57.0):  97%|█████████▋| 97/100 [02:03<00:04,  1.53s/it]\u001b[A\n",
      "Average Metric: 56.25 / 98  (57.4):  97%|█████████▋| 97/100 [02:27<00:04,  1.53s/it]\u001b[A\n",
      "Average Metric: 56.25 / 98  (57.4):  98%|█████████▊| 98/100 [02:27<00:16,  8.36s/it]\u001b[A\n",
      "Average Metric: 56.916666666666664 / 99  (57.5):  98%|▉| 98/100 [02:27<00:16,  8.36s\u001b[A\n",
      "Average Metric: 56.916666666666664 / 99  (57.5):  99%|▉| 99/100 [02:27<00:05,  5.98s\u001b[A\n",
      "Average Metric: 56.916666666666664 / 100  (56.9):  99%|▉| 99/100 [03:02<00:05,  5.98\u001b[A\n",
      "Average Metric: 56.916666666666664 / 100  (56.9): 100%|█| 100/100 [03:02<00:00,  1.8\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.916666666666664 / 100  (56.9%)\n",
      "Score: 56.92 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87, 57.03, 55.56, 51.82, 54.14, 53.34, 56.92]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8848333333333334\n",
      "Average of max per entry across top 5 scores: 0.9408333333333335\n",
      "Average of max per entry across top 8 scores: 0.98\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▍                                              | 1/100 [00:01<02:20,  1.42s/it]\u001b[A\n",
      "  2%|▉                                              | 2/100 [00:02<01:50,  1.13s/it]\u001b[A\n",
      "  3%|█▍                                             | 3/100 [00:04<02:17,  1.42s/it]\u001b[A\n",
      "  4%|█▉                                             | 4/100 [00:05<02:04,  1.29s/it]\u001b[A\n",
      "  5%|██▎                                            | 5/100 [00:06<02:10,  1.38s/it]\u001b[A\n",
      "  6%|██▊                                            | 6/100 [00:07<02:03,  1.32s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:01<01:49,  1.11s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|▏              | 1/100 [00:01<01:49,  1.11s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   2%|▎              | 2/100 [00:01<01:02,  1.57it/s]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 3  (11.1):   2%| | 2/100 [00:01<01:02,  1.57it/\u001b[A\n",
      "Average Metric: 1.3333333333333333 / 4  (33.3):   3%| | 3/100 [00:01<01:01,  1.57it/\u001b[A\n",
      "Average Metric: 2.333333333333333 / 5  (46.7):   4%| | 4/100 [00:01<01:01,  1.57it/s\u001b[A\n",
      "Average Metric: 2.333333333333333 / 5  (46.7):   5%| | 5/100 [00:01<00:22,  4.21it/s\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 6  (44.4):   5%| | 5/100 [00:01<00:22,  4.21it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 6  (44.4):   6%| | 6/100 [00:01<00:21,  4.34it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 7  (38.1):   6%| | 6/100 [00:02<00:21,  4.34it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 7  (38.1):   7%| | 7/100 [00:02<00:22,  4.09it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 8  (33.3):   7%| | 7/100 [00:02<00:22,  4.09it/\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 8  (33.3):   8%| | 8/100 [00:02<00:27,  3.40it/\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 9  (40.7):   8%| | 8/100 [00:02<00:27,  3.40it/\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 9  (40.7):   9%| | 9/100 [00:02<00:26,  3.39it/\u001b[A\n",
      "Average Metric: 4.666666666666666 / 10  (46.7):   9%| | 9/100 [00:02<00:26,  3.39it/\u001b[A\n",
      "Average Metric: 4.916666666666666 / 11  (44.7):  10%| | 10/100 [00:03<00:26,  3.39it\u001b[A\n",
      "Average Metric: 4.916666666666666 / 11  (44.7):  11%| | 11/100 [00:03<00:25,  3.49it\u001b[A\n",
      "Average Metric: 5.166666666666666 / 12  (43.1):  11%| | 11/100 [00:03<00:25,  3.49it\u001b[A\n",
      "Average Metric: 6.166666666666666 / 13  (47.4):  12%| | 12/100 [00:03<00:25,  3.49it\u001b[A\n",
      "Average Metric: 7.166666666666666 / 14  (51.2):  13%|▏| 13/100 [00:03<00:24,  3.49it\u001b[A\n",
      "Average Metric: 7.166666666666666 / 14  (51.2):  14%|▏| 14/100 [00:03<00:18,  4.66it\u001b[A\n",
      "Average Metric: 8.166666666666666 / 15  (54.4):  14%|▏| 14/100 [00:04<00:18,  4.66it\u001b[A\n",
      "Average Metric: 8.166666666666666 / 15  (54.4):  15%|▏| 15/100 [00:04<00:24,  3.48it\u001b[A\n",
      "Average Metric: 8.916666666666666 / 16  (55.7):  15%|▏| 15/100 [00:04<00:24,  3.48it\u001b[A\n",
      "Average Metric: 9.25 / 17  (54.4):  16%|█▊         | 16/100 [00:04<00:24,  3.48it/s]\u001b[A\n",
      "Average Metric: 9.25 / 17  (54.4):  17%|█▊         | 17/100 [00:04<00:17,  4.88it/s]\u001b[A\n",
      "Average Metric: 9.75 / 18  (54.2):  17%|█▊         | 17/100 [00:05<00:17,  4.88it/s]\u001b[A\n",
      "Average Metric: 9.75 / 18  (54.2):  18%|█▉         | 18/100 [00:05<00:24,  3.36it/s]\u001b[A\n",
      "Average Metric: 9.75 / 19  (51.3):  18%|█▉         | 18/100 [00:05<00:24,  3.36it/s]\u001b[A\n",
      "Average Metric: 9.75 / 20  (48.8):  19%|██         | 19/100 [00:05<00:24,  3.36it/s]\u001b[A\n",
      "Average Metric: 9.75 / 20  (48.8):  20%|██▏        | 20/100 [00:05<00:17,  4.49it/s]\u001b[A\n",
      "Average Metric: 10.25 / 21  (48.8):  20%|██        | 20/100 [00:05<00:17,  4.49it/s]\u001b[A\n",
      "Average Metric: 10.25 / 21  (48.8):  21%|██        | 21/100 [00:05<00:16,  4.70it/s]\u001b[A\n",
      "Average Metric: 10.45 / 22  (47.5):  21%|██        | 21/100 [00:06<00:16,  4.70it/s]\u001b[A\n",
      "Average Metric: 10.45 / 22  (47.5):  22%|██▏       | 22/100 [00:06<00:20,  3.80it/s]\u001b[A\n",
      "Average Metric: 10.95 / 23  (47.6):  22%|██▏       | 22/100 [00:06<00:20,  3.80it/s]\u001b[A\n",
      "Average Metric: 10.95 / 23  (47.6):  23%|██▎       | 23/100 [00:06<00:22,  3.43it/s]\u001b[A\n",
      "Average Metric: 10.95 / 24  (45.6):  23%|██▎       | 23/100 [00:06<00:22,  3.43it/s]\u001b[A\n",
      "Average Metric: 11.95 / 25  (47.8):  24%|██▍       | 24/100 [00:06<00:22,  3.43it/s]\u001b[A\n",
      "Average Metric: 11.95 / 25  (47.8):  25%|██▌       | 25/100 [00:06<00:18,  4.17it/s]\u001b[A\n",
      "Average Metric: 12.7 / 26  (48.8):  25%|██▊        | 25/100 [00:07<00:18,  4.17it/s]\u001b[A\n",
      "Average Metric: 12.7 / 26  (48.8):  26%|██▊        | 26/100 [00:07<00:19,  3.71it/s]\u001b[A\n",
      "Average Metric: 13.7 / 27  (50.7):  26%|██▊        | 26/100 [00:07<00:19,  3.71it/s]\u001b[A\n",
      "Average Metric: 13.7 / 28  (48.9):  27%|██▉        | 27/100 [00:07<00:19,  3.71it/s]\u001b[A\n",
      "Average Metric: 14.7 / 29  (50.7):  28%|███        | 28/100 [00:07<00:19,  3.71it/s]\u001b[A\n",
      "Average Metric: 14.7 / 29  (50.7):  29%|███▏       | 29/100 [00:07<00:16,  4.34it/s]\u001b[A\n",
      "Average Metric: 15.2 / 30  (50.7):  29%|███▏       | 29/100 [00:08<00:16,  4.34it/s]\u001b[A\n",
      "Average Metric: 15.2 / 30  (50.7):  30%|███▎       | 30/100 [00:08<00:19,  3.63it/s]\u001b[A\n",
      "Average Metric: 15.533333333333333 / 31  (50.1):  30%|▎| 30/100 [00:08<00:19,  3.63i\u001b[A\n",
      "Average Metric: 16.03333333333333 / 32  (50.1):  31%|▎| 31/100 [00:08<00:19,  3.63it\u001b[A\n",
      "Average Metric: 16.03333333333333 / 32  (50.1):  32%|▎| 32/100 [00:08<00:17,  3.85it\u001b[A\n",
      "Average Metric: 17.03333333333333 / 33  (51.6):  32%|▎| 32/100 [00:08<00:17,  3.85it\u001b[A\n",
      "Average Metric: 18.03333333333333 / 34  (53.0):  33%|▎| 33/100 [00:08<00:17,  3.85it\u001b[A\n",
      "Average Metric: 18.03333333333333 / 35  (51.5):  34%|▎| 34/100 [00:08<00:17,  3.85it\u001b[A\n",
      "Average Metric: 18.28333333333333 / 36  (50.8):  35%|▎| 35/100 [00:09<00:16,  3.85it\u001b[A\n",
      "Average Metric: 18.28333333333333 / 36  (50.8):  36%|▎| 36/100 [00:09<00:15,  4.24it\u001b[A\n",
      "Average Metric: 18.28333333333333 / 37  (49.4):  36%|▎| 36/100 [00:09<00:15,  4.24it\u001b[A\n",
      "Average Metric: 18.616666666666664 / 38  (49.0):  37%|▎| 37/100 [00:09<00:14,  4.24i\u001b[A\n",
      "Average Metric: 18.616666666666664 / 38  (49.0):  38%|▍| 38/100 [00:09<00:13,  4.71i\u001b[A\n",
      "Average Metric: 19.116666666666664 / 39  (49.0):  38%|▍| 38/100 [00:09<00:13,  4.71i\u001b[A\n",
      "Average Metric: 20.116666666666664 / 40  (50.3):  39%|▍| 39/100 [00:09<00:12,  4.71i\u001b[A\n",
      "Average Metric: 20.116666666666664 / 40  (50.3):  40%|▍| 40/100 [00:09<00:10,  5.54i\u001b[A\n",
      "Average Metric: 20.616666666666664 / 41  (50.3):  40%|▍| 40/100 [00:09<00:10,  5.54i\u001b[A\n",
      "Average Metric: 21.616666666666664 / 42  (51.5):  41%|▍| 41/100 [00:10<00:10,  5.54i\u001b[A\n",
      "Average Metric: 21.616666666666664 / 42  (51.5):  42%|▍| 42/100 [00:10<00:12,  4.67i\u001b[A\n",
      "Average Metric: 22.116666666666664 / 43  (51.4):  42%|▍| 42/100 [00:10<00:12,  4.67i\u001b[A\n",
      "Average Metric: 22.116666666666664 / 43  (51.4):  43%|▍| 43/100 [00:10<00:12,  4.61i\u001b[A\n",
      "Average Metric: 22.78333333333333 / 44  (51.8):  43%|▍| 43/100 [00:10<00:12,  4.61it\u001b[A\n",
      "Average Metric: 23.78333333333333 / 45  (52.9):  44%|▍| 44/100 [00:10<00:12,  4.61it\u001b[A\n",
      "Average Metric: 23.78333333333333 / 45  (52.9):  45%|▍| 45/100 [00:10<00:09,  6.01it\u001b[A\n",
      "Average Metric: 23.78333333333333 / 46  (51.7):  45%|▍| 45/100 [00:10<00:09,  6.01it\u001b[A\n",
      "Average Metric: 24.78333333333333 / 47  (52.7):  46%|▍| 46/100 [00:11<00:08,  6.01it\u001b[A\n",
      "Average Metric: 24.78333333333333 / 47  (52.7):  47%|▍| 47/100 [00:11<00:12,  4.35it\u001b[A\n",
      "Average Metric: 25.78333333333333 / 48  (53.7):  47%|▍| 47/100 [00:11<00:12,  4.35it\u001b[A\n",
      "Average Metric: 25.78333333333333 / 48  (53.7):  48%|▍| 48/100 [00:11<00:11,  4.39it\u001b[A\n",
      "Average Metric: 26.18333333333333 / 49  (53.4):  48%|▍| 48/100 [00:11<00:11,  4.39it\u001b[A\n",
      "Average Metric: 26.43333333333333 / 50  (52.9):  49%|▍| 49/100 [00:11<00:11,  4.39it\u001b[A\n",
      "Average Metric: 26.766666666666662 / 51  (52.5):  50%|▌| 50/100 [00:12<00:11,  4.39i\u001b[A\n",
      "Average Metric: 26.766666666666662 / 51  (52.5):  51%|▌| 51/100 [00:12<00:07,  6.30i\u001b[A\n",
      "Average Metric: 27.099999999999994 / 52  (52.1):  51%|▌| 51/100 [00:12<00:07,  6.30i\u001b[A\n",
      "Average Metric: 27.099999999999994 / 52  (52.1):  52%|▌| 52/100 [00:12<00:08,  5.64i\u001b[A\n",
      "Average Metric: 27.599999999999994 / 53  (52.1):  52%|▌| 52/100 [00:13<00:08,  5.64i\u001b[A\n",
      "Average Metric: 27.599999999999994 / 53  (52.1):  53%|▌| 53/100 [00:13<00:16,  2.81i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.599999999999994 / 54  (53.0):  53%|▌| 53/100 [00:13<00:16,  2.81i\u001b[A\n",
      "Average Metric: 28.599999999999994 / 54  (53.0):  54%|▌| 54/100 [00:13<00:16,  2.81i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.599999999999994 / 55  (53.8):  54%|▌| 54/100 [00:15<00:16,  2.81i\u001b[A\n",
      "Average Metric: 29.599999999999994 / 55  (53.8):  55%|▌| 55/100 [00:15<00:30,  1.50i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.599999999999994 / 56  (54.6):  55%|▌| 55/100 [00:16<00:30,  1.50i\u001b[A\n",
      "Average Metric: 30.599999999999994 / 56  (54.6):  56%|▌| 56/100 [00:16<00:33,  1.32i\u001b[A\n",
      "Average Metric: 30.599999999999994 / 57  (53.7):  56%|▌| 56/100 [00:17<00:33,  1.32i\u001b[A\n",
      "Average Metric: 30.599999999999994 / 57  (53.7):  57%|▌| 57/100 [00:17<00:33,  1.27i\u001b[A\n",
      "Average Metric: 30.599999999999994 / 58  (52.8):  57%|▌| 57/100 [00:18<00:33,  1.27i\u001b[A\n",
      "Average Metric: 30.599999999999994 / 58  (52.8):  58%|▌| 58/100 [00:18<00:34,  1.23i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.599999999999994 / 59  (51.9):  58%|▌| 58/100 [00:21<00:34,  1.23i\u001b[A\n",
      "Average Metric: 30.599999999999994 / 59  (51.9):  59%|▌| 59/100 [00:21<00:59,  1.46s\u001b[A\n",
      "Average Metric: 31.099999999999994 / 60  (51.8):  59%|▌| 59/100 [00:21<00:59,  1.46s\u001b[A\n",
      "Average Metric: 31.099999999999994 / 60  (51.8):  60%|▌| 60/100 [00:21<00:43,  1.10s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.433333333333326 / 61  (51.5):  60%|▌| 60/100 [00:22<00:43,  1.10s\u001b[A\n",
      "Average Metric: 31.433333333333326 / 61  (51.5):  61%|▌| 61/100 [00:22<00:40,  1.05s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.933333333333326 / 62  (51.5):  61%|▌| 61/100 [00:23<00:40,  1.05s\u001b[A\n",
      "Average Metric: 31.933333333333326 / 62  (51.5):  62%|▌| 62/100 [00:23<00:41,  1.10s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.26666666666666 / 63  (51.2):  62%|▌| 62/100 [00:25<00:41,  1.10s/\u001b[A\n",
      "Average Metric: 32.26666666666666 / 63  (51.2):  63%|▋| 63/100 [00:25<00:44,  1.22s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.26666666666666 / 64  (50.4):  63%|▋| 63/100 [00:26<00:44,  1.22s/\u001b[A\n",
      "Average Metric: 32.26666666666666 / 64  (50.4):  64%|▋| 64/100 [00:26<00:41,  1.14s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.26666666666666 / 65  (51.2):  64%|▋| 64/100 [00:28<00:41,  1.14s/\u001b[A\n",
      "Average Metric: 33.26666666666666 / 65  (51.2):  65%|▋| 65/100 [00:28<00:57,  1.65s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.26666666666666 / 66  (51.9):  65%|▋| 65/100 [00:30<00:57,  1.65s/\u001b[A\n",
      "Average Metric: 34.26666666666666 / 66  (51.9):  66%|▋| 66/100 [00:30<00:51,  1.51s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.93333333333332 / 67  (52.1):  66%|▋| 66/100 [00:31<00:51,  1.51s/\u001b[A\n",
      "Average Metric: 34.93333333333332 / 67  (52.1):  67%|▋| 67/100 [00:31<00:50,  1.54s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.59999999999999 / 68  (52.4):  67%|▋| 67/100 [00:32<00:50,  1.54s/\u001b[A\n",
      "Average Metric: 35.59999999999999 / 68  (52.4):  68%|▋| 68/100 [00:32<00:44,  1.40s/\u001b[A\n",
      "Average Metric: 36.09999999999999 / 69  (52.3):  68%|▋| 68/100 [00:33<00:44,  1.40s/\u001b[A\n",
      "Average Metric: 36.09999999999999 / 69  (52.3):  69%|▋| 69/100 [00:33<00:34,  1.10s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.09999999999999 / 70  (53.0):  69%|▋| 69/100 [00:34<00:34,  1.10s/\u001b[A\n",
      "Average Metric: 37.09999999999999 / 70  (53.0):  70%|▋| 70/100 [00:34<00:34,  1.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.43333333333332 / 71  (52.7):  70%|▋| 70/100 [00:35<00:34,  1.17s/\u001b[A\n",
      "Average Metric: 37.43333333333332 / 71  (52.7):  71%|▋| 71/100 [00:35<00:35,  1.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.43333333333332 / 72  (53.4):  71%|▋| 71/100 [00:37<00:35,  1.23s/\u001b[A\n",
      "Average Metric: 38.43333333333332 / 72  (53.4):  72%|▋| 72/100 [00:37<00:33,  1.20s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.43333333333332 / 73  (52.6):  72%|▋| 72/100 [00:38<00:33,  1.20s/\u001b[A\n",
      "Average Metric: 38.43333333333332 / 73  (52.6):  73%|▋| 73/100 [00:38<00:30,  1.14s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 23.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.43333333333332 / 74  (53.3):  73%|▋| 73/100 [00:39<00:30,  1.14s/\u001b[A\n",
      "Average Metric: 39.43333333333332 / 74  (53.3):  74%|▋| 74/100 [00:39<00:33,  1.27s/\u001b[A\n",
      "Average Metric: 40.43333333333332 / 75  (53.9):  74%|▋| 74/100 [00:40<00:33,  1.27s/\u001b[A\n",
      "Average Metric: 40.43333333333332 / 75  (53.9):  75%|▊| 75/100 [00:40<00:25,  1.03s/\u001b[A\n",
      "Average Metric: 40.93333333333332 / 76  (53.9):  75%|▊| 75/100 [00:41<00:25,  1.03s/\u001b[A\n",
      "Average Metric: 40.93333333333332 / 76  (53.9):  76%|▊| 76/100 [00:41<00:29,  1.24s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.93333333333332 / 77  (54.5):  76%|▊| 76/100 [00:43<00:29,  1.24s/\u001b[A\n",
      "Average Metric: 41.93333333333332 / 77  (54.5):  77%|▊| 77/100 [00:43<00:30,  1.32s/\u001b[A\n",
      "Average Metric: 42.18333333333332 / 78  (54.1):  77%|▊| 77/100 [00:45<00:30,  1.32s/\u001b[A\n",
      "Average Metric: 42.18333333333332 / 78  (54.1):  78%|▊| 78/100 [00:45<00:33,  1.51s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.68333333333332 / 79  (54.0):  78%|▊| 78/100 [00:46<00:33,  1.51s/\u001b[A\n",
      "Average Metric: 42.68333333333332 / 79  (54.0):  79%|▊| 79/100 [00:46<00:30,  1.43s/\u001b[A\n",
      "Average Metric: 43.68333333333332 / 80  (54.6):  79%|▊| 79/100 [00:47<00:30,  1.43s/\u001b[A\n",
      "Average Metric: 43.68333333333332 / 80  (54.6):  80%|▊| 80/100 [00:47<00:26,  1.35s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 13.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.34999999999999 / 81  (54.8):  80%|▊| 80/100 [00:50<00:26,  1.35s/\u001b[A\n",
      "Average Metric: 44.34999999999999 / 81  (54.8):  81%|▊| 81/100 [00:50<00:35,  1.86s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.34999999999999 / 82  (55.3):  81%|▊| 81/100 [00:53<00:35,  1.86s/\u001b[A\n",
      "Average Metric: 45.34999999999999 / 82  (55.3):  82%|▊| 82/100 [00:53<00:37,  2.07s/\u001b[A\n",
      "Average Metric: 45.57222222222221 / 83  (54.9):  82%|▊| 82/100 [00:54<00:37,  2.07s/\u001b[A\n",
      "Average Metric: 45.57222222222221 / 83  (54.9):  83%|▊| 83/100 [00:54<00:28,  1.69s/\u001b[A\n",
      "Average Metric: 45.57222222222221 / 84  (54.3):  83%|▊| 83/100 [00:54<00:28,  1.69s/\u001b[A\n",
      "Average Metric: 45.57222222222221 / 84  (54.3):  84%|▊| 84/100 [00:54<00:20,  1.25s/\u001b[A\n",
      "Average Metric: 45.57222222222221 / 85  (53.6):  84%|▊| 84/100 [00:54<00:20,  1.25s/\u001b[A\n",
      "Average Metric: 45.57222222222221 / 85  (53.6):  85%|▊| 85/100 [00:54<00:15,  1.03s/\u001b[A\n",
      "Average Metric: 46.57222222222221 / 86  (54.2):  85%|▊| 85/100 [00:55<00:15,  1.03s/\u001b[A\n",
      "Average Metric: 46.57222222222221 / 86  (54.2):  86%|▊| 86/100 [00:55<00:14,  1.07s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.57222222222221 / 87  (54.7):  86%|▊| 86/100 [00:57<00:14,  1.07s/\u001b[A\n",
      "Average Metric: 47.57222222222221 / 87  (54.7):  87%|▊| 87/100 [00:57<00:17,  1.35s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 48.57222222222221 / 88  (55.2):  87%|▊| 87/100 [00:58<00:17,  1.35s/\u001b[A\n",
      "Average Metric: 48.57222222222221 / 88  (55.2):  88%|▉| 88/100 [00:58<00:14,  1.24s/\u001b[A\n",
      "Average Metric: 49.57222222222221 / 89  (55.7):  88%|▉| 88/100 [01:00<00:14,  1.24s/\u001b[A\n",
      "Average Metric: 49.57222222222221 / 89  (55.7):  89%|▉| 89/100 [01:00<00:13,  1.22s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 9.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.57222222222221 / 90  (56.2):  89%|▉| 89/100 [01:01<00:13,  1.22s/\u001b[A\n",
      "Average Metric: 50.57222222222221 / 90  (56.2):  90%|▉| 90/100 [01:01<00:13,  1.33s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 50.905555555555544 / 91  (55.9):  90%|▉| 90/100 [01:02<00:13,  1.33s\u001b[A\n",
      "Average Metric: 50.905555555555544 / 91  (55.9):  91%|▉| 91/100 [01:02<00:11,  1.29s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 51.905555555555544 / 92  (56.4):  91%|▉| 91/100 [01:03<00:11,  1.29s\u001b[A\n",
      "Average Metric: 51.905555555555544 / 92  (56.4):  92%|▉| 92/100 [01:03<00:09,  1.15s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 101.7 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 52.405555555555544 / 93  (56.4):  92%|▉| 92/100 [01:05<00:09,  1.15s\u001b[A\n",
      "Average Metric: 52.405555555555544 / 93  (56.4):  93%|▉| 93/100 [01:05<00:09,  1.32s\u001b[A\n",
      "Average Metric: 53.405555555555544 / 94  (56.8):  93%|▉| 93/100 [01:05<00:09,  1.32s\u001b[A\n",
      "Average Metric: 53.405555555555544 / 94  (56.8):  94%|▉| 94/100 [01:05<00:06,  1.06s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 53.405555555555544 / 95  (56.2):  94%|▉| 94/100 [01:06<00:06,  1.06s\u001b[A\n",
      "Average Metric: 53.405555555555544 / 95  (56.2):  95%|▉| 95/100 [01:06<00:05,  1.07s\u001b[A\n",
      "Average Metric: 54.405555555555544 / 96  (56.7):  95%|▉| 95/100 [01:08<00:05,  1.07s\u001b[A\n",
      "Average Metric: 54.405555555555544 / 96  (56.7):  96%|▉| 96/100 [01:08<00:04,  1.15s\u001b[A\n",
      "Average Metric: 54.405555555555544 / 97  (56.1):  96%|▉| 96/100 [01:10<00:04,  1.15s\u001b[A\n",
      "Average Metric: 54.405555555555544 / 97  (56.1):  97%|▉| 97/100 [01:10<00:04,  1.40s\u001b[A\n",
      "Average Metric: 55.405555555555544 / 98  (56.5):  97%|▉| 97/100 [01:11<00:04,  1.40s\u001b[A\n",
      "Average Metric: 55.405555555555544 / 98  (56.5):  98%|▉| 98/100 [01:11<00:02,  1.31s\u001b[A\n",
      "Average Metric: 55.405555555555544 / 99  (56.0):  98%|▉| 98/100 [01:12<00:02,  1.31s\u001b[A\n",
      "Average Metric: 55.405555555555544 / 99  (56.0):  99%|▉| 99/100 [01:12<00:01,  1.38s\u001b[A\n",
      "Average Metric: 56.405555555555544 / 100  (56.4):  99%|▉| 99/100 [02:48<00:01,  1.38\u001b[A\n",
      "Average Metric: 56.405555555555544 / 100  (56.4): 100%|█| 100/100 [02:48<00:00,  1.6\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 56.405555555555544 / 100  (56.4%)\n",
      "Score: 56.41 for set: [16]\n",
      "Scores so far: [30.61, 57.96, 53.19, 51.3, 54.02, 56.31, 59.32, 54.7, 56.91, 52.12, 53.05, 56.87, 57.03, 55.56, 51.82, 54.14, 53.34, 56.92, 56.41]\n",
      "Best score: 59.32\n",
      "Average of max per entry across top 1 scores: 0.5931717171717172\n",
      "Average of max per entry across top 2 scores: 0.7806666666666666\n",
      "Average of max per entry across top 3 scores: 0.8848333333333334\n",
      "Average of max per entry across top 5 scores: 0.9408333333333335\n",
      "Average of max per entry across top 8 scores: 0.98\n",
      "Average of max per entry across top 9999 scores: 1.0\n",
      "19 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "optimizer = BootstrapFewShotWithRandomSearch(metric=validate_venn)\n",
    "compiled_pipeline = optimizer.compile(ABSAPipeline(), teacher=ABSAPipeline(), trainset=dspy_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "2d3467b6-ddac-4b6f-98e4-7090f1dffd5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.25 / 1  (25.0):   0%|                     | 0/100 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.25 / 1  (25.0):   1%|▏            | 1/100 [00:01<02:39,  1.61s/it]\u001b[A\n",
      "Average Metric: 1.25 / 2  (62.5):   1%|▏            | 1/100 [00:01<02:39,  1.61s/it]\u001b[A\n",
      "Average Metric: 2.25 / 3  (75.0):   2%|▎            | 2/100 [00:01<02:37,  1.61s/it]\u001b[A\n",
      "Average Metric: 2.25 / 4  (56.2):   3%|▍            | 3/100 [00:01<02:36,  1.61s/it]\u001b[A\n",
      "Average Metric: 2.5833333333333335 / 5  (51.7):   4%| | 4/100 [00:02<02:34,  1.61s/i\u001b[A\n",
      "Average Metric: 2.5833333333333335 / 5  (51.7):   5%| | 5/100 [00:02<00:37,  2.55it/\u001b[A\n",
      "Average Metric: 2.916666666666667 / 6  (48.6):   5%| | 5/100 [00:02<00:37,  2.55it/s\u001b[A\n",
      "Average Metric: 2.916666666666667 / 6  (48.6):   6%| | 6/100 [00:02<00:32,  2.89it/s\u001b[A\n",
      "Average Metric: 3.2500000000000004 / 7  (46.4):   6%| | 6/100 [00:02<00:32,  2.89it/\u001b[A\n",
      "Average Metric: 3.2500000000000004 / 7  (46.4):   7%| | 7/100 [00:02<00:31,  2.99it/\u001b[A\n",
      "Average Metric: 3.5000000000000004 / 8  (43.8):   7%| | 7/100 [00:03<00:31,  2.99it/\u001b[A\n",
      "Average Metric: 3.5000000000000004 / 8  (43.8):   8%| | 8/100 [00:03<00:28,  3.20it/\u001b[A\n",
      "Average Metric: 3.9000000000000004 / 9  (43.3):   8%| | 8/100 [00:03<00:28,  3.20it/\u001b[A\n",
      "Average Metric: 4.9 / 10  (49.0):   9%|█▏           | 9/100 [00:03<00:28,  3.20it/s]\u001b[A\n",
      "Average Metric: 4.9 / 10  (49.0):  10%|█▏          | 10/100 [00:03<00:31,  2.82it/s]\u001b[A\n",
      "Average Metric: 5.9 / 11  (53.6):  10%|█▏          | 10/100 [00:04<00:31,  2.82it/s]\u001b[A\n",
      "Average Metric: 5.9 / 11  (53.6):  11%|█▎          | 11/100 [00:04<00:28,  3.17it/s]\u001b[A\n",
      "Average Metric: 6.614285714285715 / 12  (55.1):  11%| | 11/100 [00:04<00:28,  3.17it\u001b[A\n",
      "Average Metric: 7.614285714285715 / 13  (58.6):  12%| | 12/100 [00:04<00:27,  3.17it\u001b[A\n",
      "Average Metric: 7.614285714285715 / 13  (58.6):  13%|▏| 13/100 [00:04<00:23,  3.73it\u001b[A\n",
      "Average Metric: 8.614285714285714 / 14  (61.5):  13%|▏| 13/100 [00:04<00:23,  3.73it\u001b[A\n",
      "Average Metric: 9.364285714285714 / 15  (62.4):  14%|▏| 14/100 [00:05<00:23,  3.73it\u001b[A\n",
      "Average Metric: 9.364285714285714 / 15  (62.4):  15%|▏| 15/100 [00:05<00:32,  2.62it\u001b[A\n",
      "Average Metric: 9.364285714285714 / 16  (58.5):  15%|▏| 15/100 [00:05<00:32,  2.62it\u001b[A\n",
      "Average Metric: 9.364285714285714 / 16  (58.5):  16%|▏| 16/100 [00:05<00:29,  2.83it\u001b[A\n",
      "Average Metric: 9.864285714285714 / 17  (58.0):  16%|▏| 16/100 [00:05<00:29,  2.83it\u001b[A\n",
      "Average Metric: 9.864285714285714 / 17  (58.0):  17%|▏| 17/100 [00:05<00:24,  3.34it\u001b[A\n",
      "Average Metric: 10.864285714285714 / 18  (60.4):  17%|▏| 17/100 [00:06<00:24,  3.34i\u001b[A\n",
      "Average Metric: 10.864285714285714 / 18  (60.4):  18%|▏| 18/100 [00:06<00:25,  3.27i\u001b[A\n",
      "Average Metric: 11.53095238095238 / 19  (60.7):  18%|▏| 18/100 [00:06<00:25,  3.27it\u001b[A\n",
      "Average Metric: 11.53095238095238 / 19  (60.7):  19%|▏| 19/100 [00:06<00:21,  3.68it\u001b[A\n",
      "Average Metric: 11.53095238095238 / 20  (57.7):  19%|▏| 19/100 [00:06<00:21,  3.68it\u001b[A\n",
      "Average Metric: 11.53095238095238 / 20  (57.7):  20%|▏| 20/100 [00:06<00:25,  3.14it\u001b[A\n",
      "Average Metric: 11.53095238095238 / 21  (54.9):  20%|▏| 20/100 [00:06<00:25,  3.14it\u001b[A\n",
      "Average Metric: 12.53095238095238 / 22  (57.0):  21%|▏| 21/100 [00:06<00:25,  3.14it\u001b[A\n",
      "Average Metric: 13.28095238095238 / 23  (57.7):  22%|▏| 22/100 [00:07<00:24,  3.14it\u001b[A\n",
      "Average Metric: 13.28095238095238 / 23  (57.7):  23%|▏| 23/100 [00:07<00:13,  5.91it\u001b[A\n",
      "Average Metric: 13.947619047619046 / 24  (58.1):  23%|▏| 23/100 [00:07<00:13,  5.91i\u001b[A\n",
      "Average Metric: 14.947619047619046 / 25  (59.8):  24%|▏| 24/100 [00:07<00:12,  5.91i\u001b[A\n",
      "Average Metric: 14.947619047619046 / 25  (59.8):  25%|▎| 25/100 [00:07<00:14,  5.20i\u001b[A\n",
      "Average Metric: 14.947619047619046 / 26  (57.5):  25%|▎| 25/100 [00:08<00:14,  5.20i\u001b[A\n",
      "Average Metric: 14.947619047619046 / 26  (57.5):  26%|▎| 26/100 [00:08<00:19,  3.71i\u001b[A\n",
      "Average Metric: 15.947619047619046 / 27  (59.1):  26%|▎| 26/100 [00:08<00:19,  3.71i\u001b[A\n",
      "Average Metric: 16.947619047619046 / 28  (60.5):  27%|▎| 27/100 [00:08<00:19,  3.71i\u001b[A\n",
      "Average Metric: 16.947619047619046 / 28  (60.5):  28%|▎| 28/100 [00:08<00:16,  4.43i\u001b[A\n",
      "Average Metric: 16.947619047619046 / 29  (58.4):  28%|▎| 28/100 [00:08<00:16,  4.43i\u001b[A\n",
      "Average Metric: 16.947619047619046 / 29  (58.4):  29%|▎| 29/100 [00:08<00:19,  3.70i\u001b[A\n",
      "Average Metric: 17.947619047619046 / 30  (59.8):  29%|▎| 29/100 [00:09<00:19,  3.70i\u001b[A\n",
      "Average Metric: 17.947619047619046 / 30  (59.8):  30%|▎| 30/100 [00:09<00:18,  3.86i\u001b[A\n",
      "Average Metric: 18.280952380952378 / 31  (59.0):  30%|▎| 30/100 [00:09<00:18,  3.86i\u001b[A\n",
      "Average Metric: 18.280952380952378 / 32  (57.1):  31%|▎| 31/100 [00:09<00:17,  3.86i\u001b[A\n",
      "Average Metric: 18.280952380952378 / 33  (55.4):  32%|▎| 32/100 [00:09<00:17,  3.86i\u001b[A\n",
      "Average Metric: 18.280952380952378 / 33  (55.4):  33%|▎| 33/100 [00:09<00:14,  4.74i\u001b[A\n",
      "Average Metric: 18.280952380952378 / 34  (53.8):  33%|▎| 33/100 [00:09<00:14,  4.74i\u001b[A\n",
      "Average Metric: 18.280952380952378 / 35  (52.2):  34%|▎| 34/100 [00:09<00:13,  4.74i\u001b[A\n",
      "Average Metric: 18.280952380952378 / 35  (52.2):  35%|▎| 35/100 [00:09<00:11,  5.75i\u001b[A\n",
      "Average Metric: 18.780952380952378 / 36  (52.2):  35%|▎| 35/100 [00:09<00:11,  5.75i\u001b[A\n",
      "Average Metric: 18.780952380952378 / 37  (50.8):  36%|▎| 36/100 [00:10<00:11,  5.75i\u001b[A\n",
      "Average Metric: 18.780952380952378 / 37  (50.8):  37%|▎| 37/100 [00:10<00:11,  5.60i\u001b[A\n",
      "Average Metric: 19.780952380952378 / 38  (52.1):  37%|▎| 37/100 [00:10<00:11,  5.60i\u001b[A\n",
      "Average Metric: 20.780952380952378 / 39  (53.3):  38%|▍| 38/100 [00:10<00:11,  5.60i\u001b[A\n",
      "Average Metric: 20.780952380952378 / 39  (53.3):  39%|▍| 39/100 [00:10<00:13,  4.38i\u001b[A\n",
      "Average Metric: 21.280952380952378 / 40  (53.2):  39%|▍| 39/100 [00:11<00:13,  4.38i\u001b[A\n",
      "Average Metric: 21.280952380952378 / 40  (53.2):  40%|▍| 40/100 [00:11<00:16,  3.68i\u001b[A\n",
      "Average Metric: 21.780952380952378 / 41  (53.1):  40%|▍| 40/100 [00:11<00:16,  3.68i\u001b[A\n",
      "Average Metric: 22.280952380952378 / 42  (53.0):  41%|▍| 41/100 [00:11<00:16,  3.68i\u001b[A\n",
      "Average Metric: 22.280952380952378 / 42  (53.0):  42%|▍| 42/100 [00:11<00:13,  4.38i\u001b[A\n",
      "Average Metric: 23.280952380952378 / 43  (54.1):  42%|▍| 42/100 [00:12<00:13,  4.38i\u001b[A\n",
      "Average Metric: 23.280952380952378 / 43  (54.1):  43%|▍| 43/100 [00:12<00:16,  3.48i\u001b[A\n",
      "Average Metric: 24.280952380952378 / 44  (55.2):  43%|▍| 43/100 [00:12<00:16,  3.48i\u001b[A\n",
      "Average Metric: 24.947619047619046 / 45  (55.4):  44%|▍| 44/100 [00:12<00:16,  3.48i\u001b[A\n",
      "Average Metric: 24.947619047619046 / 45  (55.4):  45%|▍| 45/100 [00:12<00:11,  4.89i\u001b[A\n",
      "Average Metric: 25.614285714285714 / 46  (55.7):  45%|▍| 45/100 [00:12<00:11,  4.89i\u001b[A\n",
      "Average Metric: 25.614285714285714 / 46  (55.7):  46%|▍| 46/100 [00:12<00:11,  4.70i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.614285714285714 / 47  (56.6):  46%|▍| 46/100 [00:12<00:11,  4.70i\u001b[A\n",
      "Average Metric: 26.614285714285714 / 47  (56.6):  47%|▍| 47/100 [00:12<00:13,  3.81i\u001b[A\n",
      "Average Metric: 26.947619047619046 / 48  (56.1):  47%|▍| 47/100 [00:12<00:13,  3.81i\u001b[A\n",
      "Average Metric: 26.947619047619046 / 48  (56.1):  48%|▍| 48/100 [00:12<00:11,  4.48i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.947619047619046 / 49  (57.0):  48%|▍| 48/100 [00:13<00:11,  4.48i\u001b[A\n",
      "Average Metric: 27.947619047619046 / 49  (57.0):  49%|▍| 49/100 [00:13<00:15,  3.38i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 27.947619047619046 / 50  (55.9):  49%|▍| 49/100 [00:13<00:15,  3.38i\u001b[A\n",
      "Average Metric: 27.947619047619046 / 50  (55.9):  50%|▌| 50/100 [00:13<00:14,  3.56i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.447619047619046 / 51  (55.8):  50%|▌| 50/100 [00:14<00:14,  3.56i\u001b[A\n",
      "Average Metric: 28.447619047619046 / 51  (55.8):  51%|▌| 51/100 [00:14<00:18,  2.59i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.447619047619046 / 52  (56.6):  51%|▌| 51/100 [00:15<00:18,  2.59i\u001b[A\n",
      "Average Metric: 29.447619047619046 / 52  (56.6):  52%|▌| 52/100 [00:15<00:23,  2.01i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.447619047619046 / 53  (55.6):  52%|▌| 52/100 [00:16<00:23,  2.01i\u001b[A\n",
      "Average Metric: 29.447619047619046 / 53  (55.6):  53%|▌| 53/100 [00:16<00:28,  1.66i\u001b[A\n",
      "Average Metric: 29.447619047619046 / 54  (54.5):  53%|▌| 53/100 [00:16<00:28,  1.66i\u001b[A\n",
      "Average Metric: 29.447619047619046 / 54  (54.5):  54%|▌| 54/100 [00:16<00:24,  1.91i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.247619047619047 / 55  (55.0):  54%|▌| 54/100 [00:17<00:24,  1.91i\u001b[A\n",
      "Average Metric: 30.247619047619047 / 55  (55.0):  55%|▌| 55/100 [00:17<00:27,  1.65i\u001b[A\n",
      "Average Metric: 30.747619047619047 / 56  (54.9):  55%|▌| 55/100 [00:17<00:27,  1.65i\u001b[A\n",
      "Average Metric: 31.747619047619047 / 57  (55.7):  56%|▌| 56/100 [00:17<00:26,  1.65i\u001b[A\n",
      "Average Metric: 31.747619047619047 / 57  (55.7):  57%|▌| 57/100 [00:17<00:15,  2.74i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.74761904761905 / 58  (56.5):  57%|▌| 57/100 [00:18<00:15,  2.74it\u001b[A\n",
      "Average Metric: 32.74761904761905 / 58  (56.5):  58%|▌| 58/100 [00:18<00:18,  2.22it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.08095238095238 / 59  (56.1):  58%|▌| 58/100 [00:19<00:18,  2.22it\u001b[A\n",
      "Average Metric: 33.08095238095238 / 59  (56.1):  59%|▌| 59/100 [00:19<00:34,  1.19it\u001b[A\n",
      "Average Metric: 33.08095238095238 / 60  (55.1):  59%|▌| 59/100 [00:20<00:34,  1.19it\u001b[A\n",
      "Average Metric: 33.08095238095238 / 60  (55.1):  60%|▌| 60/100 [00:20<00:29,  1.35it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.08095238095238 / 61  (55.9):  60%|▌| 60/100 [00:21<00:29,  1.35it\u001b[A\n",
      "Average Metric: 34.08095238095238 / 61  (55.9):  61%|▌| 61/100 [00:21<00:33,  1.17it\u001b[A\n",
      "Average Metric: 34.48095238095238 / 62  (55.6):  61%|▌| 61/100 [00:22<00:33,  1.17it\u001b[A\n",
      "Average Metric: 34.48095238095238 / 62  (55.6):  62%|▌| 62/100 [00:22<00:29,  1.29it\u001b[A\n",
      "Average Metric: 35.48095238095238 / 63  (56.3):  62%|▌| 62/100 [00:22<00:29,  1.29it\u001b[A\n",
      "Average Metric: 35.48095238095238 / 63  (56.3):  63%|▋| 63/100 [00:22<00:23,  1.60it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.48095238095238 / 64  (55.4):  63%|▋| 63/100 [00:23<00:23,  1.60it\u001b[A\n",
      "Average Metric: 35.48095238095238 / 64  (55.4):  64%|▋| 64/100 [00:23<00:26,  1.34it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.98095238095238 / 65  (55.4):  64%|▋| 64/100 [00:25<00:26,  1.34it\u001b[A\n",
      "Average Metric: 35.98095238095238 / 65  (55.4):  65%|▋| 65/100 [00:25<00:34,  1.00it\u001b[A\n",
      "Average Metric: 35.98095238095238 / 66  (54.5):  65%|▋| 65/100 [00:25<00:34,  1.00it\u001b[A\n",
      "Average Metric: 35.98095238095238 / 66  (54.5):  66%|▋| 66/100 [00:25<00:29,  1.17it\u001b[A\n",
      "Average Metric: 36.98095238095238 / 67  (55.2):  66%|▋| 66/100 [00:25<00:29,  1.17it\u001b[A\n",
      "Average Metric: 36.98095238095238 / 67  (55.2):  67%|▋| 67/100 [00:25<00:21,  1.54it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 36.98095238095238 / 68  (54.4):  67%|▋| 67/100 [00:27<00:21,  1.54it\u001b[A\n",
      "Average Metric: 36.98095238095238 / 68  (54.4):  68%|▋| 68/100 [00:27<00:29,  1.09it\u001b[A\n",
      "Average Metric: 37.31428571428572 / 69  (54.1):  68%|▋| 68/100 [00:27<00:29,  1.09it\u001b[A\n",
      "Average Metric: 37.31428571428572 / 69  (54.1):  69%|▋| 69/100 [00:27<00:25,  1.22it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.81428571428572 / 70  (54.0):  69%|▋| 69/100 [00:28<00:25,  1.22it\u001b[A\n",
      "Average Metric: 37.81428571428572 / 70  (54.0):  70%|▋| 70/100 [00:28<00:25,  1.20it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.81428571428572 / 71  (54.7):  70%|▋| 70/100 [00:30<00:25,  1.20it\u001b[A\n",
      "Average Metric: 38.81428571428572 / 71  (54.7):  71%|▋| 71/100 [00:30<00:33,  1.17s/\u001b[A\n",
      "Average Metric: 38.93928571428572 / 72  (54.1):  71%|▋| 71/100 [00:31<00:33,  1.17s/\u001b[A\n",
      "Average Metric: 38.93928571428572 / 72  (54.1):  72%|▋| 72/100 [00:31<00:27,  1.03it\u001b[A\n",
      "Average Metric: 39.18928571428572 / 73  (53.7):  72%|▋| 72/100 [00:31<00:27,  1.03it\u001b[A\n",
      "Average Metric: 39.18928571428572 / 73  (53.7):  73%|▋| 73/100 [00:31<00:22,  1.20it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.93928571428572 / 74  (54.0):  73%|▋| 73/100 [00:32<00:22,  1.20it\u001b[A\n",
      "Average Metric: 39.93928571428572 / 74  (54.0):  74%|▋| 74/100 [00:32<00:20,  1.25it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.93928571428572 / 75  (53.3):  74%|▋| 74/100 [00:32<00:20,  1.25it\u001b[A\n",
      "Average Metric: 39.93928571428572 / 75  (53.3):  75%|▊| 75/100 [00:32<00:17,  1.46it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.93928571428572 / 76  (52.6):  75%|▊| 75/100 [00:34<00:17,  1.46it\u001b[A\n",
      "Average Metric: 39.93928571428572 / 76  (52.6):  76%|▊| 76/100 [00:34<00:21,  1.12it\u001b[A\n",
      "Average Metric: 40.93928571428572 / 77  (53.2):  76%|▊| 76/100 [00:35<00:21,  1.12it\u001b[A\n",
      "Average Metric: 40.93928571428572 / 77  (53.2):  77%|▊| 77/100 [00:35<00:21,  1.06it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.43928571428572 / 78  (53.1):  77%|▊| 77/100 [00:35<00:21,  1.06it\u001b[A\n",
      "Average Metric: 41.43928571428572 / 78  (53.1):  78%|▊| 78/100 [00:35<00:16,  1.36it\u001b[A\n",
      "Average Metric: 41.77261904761905 / 79  (52.9):  78%|▊| 78/100 [00:36<00:16,  1.36it\u001b[A\n",
      "Average Metric: 41.77261904761905 / 79  (52.9):  79%|▊| 79/100 [00:36<00:14,  1.41it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.77261904761905 / 80  (53.5):  79%|▊| 79/100 [00:38<00:14,  1.41it\u001b[A\n",
      "Average Metric: 42.77261904761905 / 80  (53.5):  80%|▊| 80/100 [00:38<00:21,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.77261904761905 / 81  (54.0):  80%|▊| 80/100 [00:39<00:21,  1.05s/\u001b[A\n",
      "Average Metric: 43.77261904761905 / 81  (54.0):  81%|▊| 81/100 [00:39<00:20,  1.08s/\u001b[A\n",
      "Average Metric: 44.77261904761905 / 82  (54.6):  81%|▊| 81/100 [00:39<00:20,  1.08s/\u001b[A\n",
      "Average Metric: 44.77261904761905 / 82  (54.6):  82%|▊| 82/100 [00:39<00:17,  1.03it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.27261904761905 / 83  (54.5):  82%|▊| 82/100 [00:41<00:17,  1.03it\u001b[A\n",
      "Average Metric: 45.27261904761905 / 83  (54.5):  83%|▊| 83/100 [00:41<00:19,  1.16s/\u001b[A\n",
      "Average Metric: 46.27261904761905 / 84  (55.1):  83%|▊| 83/100 [00:41<00:19,  1.16s/\u001b[A\n",
      "Average Metric: 46.27261904761905 / 84  (55.1):  84%|▊| 84/100 [00:41<00:15,  1.06it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.0 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 46.27261904761905 / 85  (54.4):  84%|▊| 84/100 [00:43<00:15,  1.06it\u001b[A\n",
      "Average Metric: 46.27261904761905 / 85  (54.4):  85%|▊| 85/100 [00:43<00:15,  1.01s/\u001b[A\n",
      "Average Metric: 46.77261904761905 / 86  (54.4):  85%|▊| 85/100 [00:43<00:15,  1.01s/\u001b[A\n",
      "Average Metric: 46.77261904761905 / 86  (54.4):  86%|▊| 86/100 [00:43<00:11,  1.26it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.02261904761905 / 87  (54.0):  86%|▊| 86/100 [00:44<00:11,  1.26it\u001b[A\n",
      "Average Metric: 47.02261904761905 / 87  (54.0):  87%|▊| 87/100 [00:44<00:10,  1.19it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.02261904761905 / 88  (53.4):  87%|▊| 87/100 [00:45<00:10,  1.19it\u001b[A\n",
      "Average Metric: 47.02261904761905 / 88  (53.4):  88%|▉| 88/100 [00:45<00:11,  1.07it\u001b[A\n",
      "Average Metric: 47.02261904761905 / 89  (52.8):  88%|▉| 88/100 [00:45<00:11,  1.07it\u001b[A\n",
      "Average Metric: 47.02261904761905 / 89  (52.8):  89%|▉| 89/100 [00:45<00:08,  1.32it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.02261904761905 / 90  (52.2):  89%|▉| 89/100 [00:46<00:08,  1.32it\u001b[A\n",
      "Average Metric: 47.02261904761905 / 90  (52.2):  90%|▉| 90/100 [00:46<00:06,  1.56it\u001b[A\n",
      "Average Metric: 47.02261904761905 / 91  (51.7):  90%|▉| 90/100 [00:46<00:06,  1.56it\u001b[A\n",
      "Average Metric: 47.02261904761905 / 91  (51.7):  91%|▉| 91/100 [00:46<00:06,  1.49it\u001b[A\n",
      "Average Metric: 47.27261904761905 / 92  (51.4):  91%|▉| 91/100 [00:48<00:06,  1.49it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.27261904761905 / 92  (51.4):  92%|▉| 92/100 [00:48<00:07,  1.06it\u001b[A\n",
      "Average Metric: 47.27261904761905 / 93  (50.8):  92%|▉| 92/100 [00:49<00:07,  1.06it\u001b[A\n",
      "Average Metric: 47.27261904761905 / 93  (50.8):  93%|▉| 93/100 [00:49<00:06,  1.15it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 32.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 47.472619047619055 / 94  (50.5):  93%|▉| 93/100 [00:49<00:06,  1.15i\u001b[A\n",
      "Average Metric: 47.472619047619055 / 94  (50.5):  94%|▉| 94/100 [00:49<00:03,  1.53i\u001b[A\n",
      "Average Metric: 47.472619047619055 / 95  (50.0):  94%|▉| 94/100 [00:49<00:03,  1.53i\u001b[A\n",
      "Average Metric: 47.472619047619055 / 95  (50.0):  95%|▉| 95/100 [00:49<00:03,  1.62i\u001b[A\n",
      "Average Metric: 48.472619047619055 / 96  (50.5):  95%|▉| 95/100 [00:51<00:03,  1.62i\u001b[A\n",
      "Average Metric: 48.472619047619055 / 96  (50.5):  96%|▉| 96/100 [00:51<00:03,  1.04i\u001b[A\n",
      "Average Metric: 48.472619047619055 / 97  (50.0):  96%|▉| 96/100 [00:51<00:03,  1.04i\u001b[A\n",
      "Average Metric: 48.472619047619055 / 97  (50.0):  97%|▉| 97/100 [00:51<00:02,  1.31i\u001b[A\n",
      "Average Metric: 48.80595238095239 / 98  (49.8):  97%|▉| 97/100 [00:57<00:02,  1.31it\u001b[A\n",
      "Average Metric: 48.80595238095239 / 98  (49.8):  98%|▉| 98/100 [00:57<00:04,  2.24s/\u001b[A\n",
      "Average Metric: 48.80595238095239 / 99  (49.3):  98%|▉| 98/100 [01:00<00:04,  2.24s/\u001b[A\n",
      "Average Metric: 48.80595238095239 / 99  (49.3):  99%|▉| 99/100 [01:00<00:02,  2.36s/\u001b[A\n",
      "Average Metric: 49.80595238095239 / 100  (49.8):  99%|▉| 99/100 [01:23<00:02,  2.36s\u001b[A\n",
      "Average Metric: 49.80595238095239 / 100  (49.8): 100%|█| 100/100 [01:23<00:00,  1.20\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 49.80595238095239 / 100  (49.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.7142857142857143' '1.0' '0.3333333333333333' '0.0'\n",
      " '0.3333333333333333']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_de484 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_de484 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_de484_row0_col0, #T_de484_row0_col1, #T_de484_row0_col2, #T_de484_row0_col3, #T_de484_row0_col4, #T_de484_row1_col0, #T_de484_row1_col1, #T_de484_row1_col2, #T_de484_row1_col3, #T_de484_row1_col4, #T_de484_row2_col0, #T_de484_row2_col1, #T_de484_row2_col2, #T_de484_row2_col3, #T_de484_row2_col4, #T_de484_row3_col0, #T_de484_row3_col1, #T_de484_row3_col2, #T_de484_row3_col3, #T_de484_row3_col4, #T_de484_row4_col0, #T_de484_row4_col1, #T_de484_row4_col2, #T_de484_row4_col3, #T_de484_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_de484\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_de484_level0_col0\" class=\"col_heading level0 col0\" >review</th>\n",
       "      <th id=\"T_de484_level0_col1\" class=\"col_heading level0 col1\" >example_aspects_with_label</th>\n",
       "      <th id=\"T_de484_level0_col2\" class=\"col_heading level0 col2\" >aspects_list</th>\n",
       "      <th id=\"T_de484_level0_col3\" class=\"col_heading level0 col3\" >pred_aspects_with_label</th>\n",
       "      <th id=\"T_de484_level0_col4\" class=\"col_heading level0 col4\" >validate_venn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_de484_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_de484_row0_col0\" class=\"data row0 col0\" >\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.</td>\n",
       "      <td id=\"T_de484_row0_col1\" class=\"data row0 col1\" >{'menu': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'pub fare': 0}</td>\n",
       "      <td id=\"T_de484_row0_col2\" class=\"data row0 col2\" >dict_keys(['menu', 'burgers', 'steaks', 'shepherds pie', 'portabella lasagna', 'pub fare'])</td>\n",
       "      <td id=\"T_de484_row0_col3\" class=\"data row0 col3\" >{'pub fare': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'vegetarians': 0}</td>\n",
       "      <td id=\"T_de484_row0_col4\" class=\"data row0 col4\" >0.7142857142857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de484_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_de484_row1_col0\" class=\"data row1 col0\" >(The sashimi is cut a little thinly.</td>\n",
       "      <td id=\"T_de484_row1_col1\" class=\"data row1 col1\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_de484_row1_col2\" class=\"data row1 col2\" >dict_keys(['sashimi'])</td>\n",
       "      <td id=\"T_de484_row1_col3\" class=\"data row1 col3\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_de484_row1_col4\" class=\"data row1 col4\" >1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de484_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_de484_row2_col0\" class=\"data row2 col0\" >) It's not the best Japanese restaurant in the East Village, but it's a pretty solid one for its modest prices, and worth repeat visits.</td>\n",
       "      <td id=\"T_de484_row2_col1\" class=\"data row2 col1\" >{'prices': 1}</td>\n",
       "      <td id=\"T_de484_row2_col2\" class=\"data row2 col2\" >dict_keys(['prices'])</td>\n",
       "      <td id=\"T_de484_row2_col3\" class=\"data row2 col3\" >{'Japanese restaurant': 0, 'East Village': 0, 'prices': 1}</td>\n",
       "      <td id=\"T_de484_row2_col4\" class=\"data row2 col4\" >0.3333333333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de484_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_de484_row3_col0\" class=\"data row3 col0\" >15% gratuity automatically added to the bill.</td>\n",
       "      <td id=\"T_de484_row3_col1\" class=\"data row3 col1\" >{'bill': -1, 'gratuity': -1}</td>\n",
       "      <td id=\"T_de484_row3_col2\" class=\"data row3 col2\" >dict_keys(['bill', 'gratuity'])</td>\n",
       "      <td id=\"T_de484_row3_col3\" class=\"data row3 col3\" >{'gratuity': 0}</td>\n",
       "      <td id=\"T_de484_row3_col4\" class=\"data row3 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_de484_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_de484_row4_col0\" class=\"data row4 col0\" >A beautiful atmosphere, perfect for drinks and/or appetizers.</td>\n",
       "      <td id=\"T_de484_row4_col1\" class=\"data row4 col1\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_de484_row4_col2\" class=\"data row4 col2\" >dict_keys(['atmosphere', 'drinks', 'appetizers'])</td>\n",
       "      <td id=\"T_de484_row4_col3\" class=\"data row4 col3\" >{'atmosphere': 1, 'drinks': 1, 'appetizers': 1}</td>\n",
       "      <td id=\"T_de484_row4_col4\" class=\"data row4 col4\" >0.3333333333333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x37d55e410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uncompiled_pipeline_score = evaluate_test(uncompiled_pipeline, metric=validate_f1, display=False)\n",
    "\n",
    "compiled_pipeline_score = evaluate_test(compiled_pipeline, metric=validate_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "57ae9505-cc36-4b15-b209-70d9bf4a313f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41.21, 49.81)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompiled_pipeline_score, compiled_pipeline_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06367c7c-eb9b-41e5-9180-86884698719c",
   "metadata": {},
   "source": [
    "## V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5f5dab3e-a6b7-4e15-aa1d-43d4786a073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review2Aspects(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Identify aspects from a customer review. The aspects must be words or phrases in the review. The aspect\n",
    "    is typically a noun, and it must be the narrowest word or phrase possible. The response must be a valid Python list,\n",
    "    where each item is an aspect.\n",
    "    \"\"\"\n",
    "\n",
    "    review: str = dspy.InputField(desc=\"a customer review\")\n",
    "    aspects_list: str = dspy.OutputField(desc=dedent(\"\"\"\n",
    "        A list of all the aspects in the customer review. Must be a valid Python list.\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "120aad95-5f4d-49f2-b26a-97769bd2b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aspects2Reasons(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Using the customer review and list of aspects, reason about whether each aspect is positive, neutral, or negative.\n",
    "    Think deeply about each aspect in the context of the entire review.\n",
    "    \"\"\"\n",
    "\n",
    "    review: str = dspy.InputField(desc=\"a customer review\")\n",
    "    aspects_list: str = dspy.InputField(desc=dedent(\"\"\"\n",
    "        A list of all the aspects in the customer review\n",
    "        \"\"\"))\n",
    "    reasons: str = dspy.OutputField(desc=dedent(\"\"\"\n",
    "        A list of all the aspects in the customer review. Under each aspect, there are some thoughts or reasons\n",
    "        about whether the aspect is positive, neutral, or negative.\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "01aec1b1-c391-4c96-90bb-ee302650e234",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reasons2Labels(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Labels each aspect as 1 meaning positive, 0 meaning neutral, and -1 meaning negative. The response must be a \n",
    "    valid Python dictionary, where each key is an aspect and the value is the integer label.\n",
    "    \"\"\"\n",
    "\n",
    "    aspects_list: str = dspy.InputField(desc=dedent(\"\"\"\n",
    "        A list of all the aspects in the customer review\n",
    "        \"\"\"))\n",
    "    reasons: str = dspy.InputField(desc=dedent(\"\"\"\n",
    "        A list of all the aspects in the customer review. Under each aspect, there are some thoughts or reasons\n",
    "        about whether the aspect is positive, neutral, or negative.\n",
    "        \"\"\"))\n",
    "    aspects_with_label: dict = dspy.OutputField(format=dict, desc=dedent(\"\"\"\n",
    "        a single Python dictionary, where each key is an aspect and the value is the label,\n",
    "        with label 1 indicating positive sentiment, 0 indicating neutral sentiment, and -1\n",
    "        indicating negative sentiment.\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ba610ec6-43f2-4265-b1c6-b6e6a8662874",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABSAPipelineV2(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_aspects = dspy.TypedChainOfThought(Review2Aspects)\n",
    "        self.generate_reasons = dspy.ChainOfThought(Aspects2Reasons)\n",
    "        self.generate_labels = dspy.TypedChainOfThought(Reasons2Labels)\n",
    "\n",
    "    def forward(self, review):\n",
    "        aspects_list = self.generate_aspects(review=review)\n",
    "        reasons = self.generate_reasons(review=review, aspects_list=aspects_list.aspects_list)\n",
    "        pred = self.generate_labels(aspects_list=aspects_list.aspects_list, reasons=reasons.reasons)\n",
    "        return dspy.Prediction(aspects_with_label=pred.aspects_with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3b215d95-d594-4fd8-b28b-03625c632dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncompiled_pipeline = ABSAPipelineV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "dd22226d-7851-4244-98fb-2ffc3b6b8a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = uncompiled_pipeline(dspy_test[0].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "13ca8252-5b3d-4822-be3e-fdb42af33f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    aspects_with_label={'burgers': 1, 'steaks': 1, 'shepherds pie': 1, 'portabella lasagna': 1, 'vegetarians': 1}\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0c2b685c-6706-4925-be64-eb58e2ea55ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to train 16 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:00<00:03,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:00<00:03,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 3  (11.1):   7%| | 2/30 [00:00<00:03,  8.86it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 4  (8.3):  10%| | 3/30 [00:00<00:03,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 5  (6.7):  13%|▏| 4/30 [00:00<00:02,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 6  (5.6):  17%|▏| 5/30 [00:00<00:02,  8.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 6  (5.6):  20%|▏| 6/30 [00:00<00:00, 31.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.8333333333333333 / 7  (11.9):  20%|▏| 6/30 [00:00<00:00, 31.76it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.3333333333333333 / 8  (16.7):  23%|▏| 7/30 [00:00<00:00, 31.76it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.3333333333333333 / 9  (14.8):  27%|▎| 8/30 [00:00<00:00, 31.76it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.5555555555555554 / 10  (15.6):  30%|▎| 9/30 [00:00<00:00, 31.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.5555555555555554 / 10  (15.6):  33%|▎| 10/30 [00:00<00:00, 28.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.5555555555555554 / 11  (14.1):  33%|▎| 10/30 [00:00<00:00, 28.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.5555555555555554 / 12  (13.0):  37%|▎| 11/30 [00:00<00:00, 28.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.8055555555555554 / 13  (13.9):  40%|▍| 12/30 [00:00<00:00, 28.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.8055555555555554 / 14  (20.0):  43%|▍| 13/30 [00:00<00:00, 28.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.472222222222222 / 15  (23.1):  47%|▍| 14/30 [00:00<00:00, 28.28it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.472222222222222 / 15  (23.1):  50%|▌| 15/30 [00:00<00:00, 30.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.672222222222222 / 16  (23.0):  50%|▌| 15/30 [00:00<00:00, 30.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.672222222222222 / 17  (21.6):  53%|▌| 16/30 [00:00<00:00, 30.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.8722222222222222 / 18  (21.5):  57%|▌| 17/30 [00:00<00:00, 30.09it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.038888888888889 / 19  (21.3):  60%|▌| 18/30 [00:00<00:00, 30.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.038888888888889 / 20  (20.2):  63%|▋| 19/30 [00:00<00:00, 30.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.038888888888889 / 20  (20.2):  67%|▋| 20/30 [00:00<00:00, 34.49it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.038888888888889 / 21  (19.2):  67%|▋| 20/30 [00:00<00:00, 34.49it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.038888888888889 / 22  (18.4):  70%|▋| 21/30 [00:00<00:00, 34.49it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.138888888888888 / 23  (18.0):  73%|▋| 22/30 [00:00<00:00, 34.49it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.138888888888888 / 24  (17.2):  77%|▊| 23/30 [00:00<00:00, 34.49it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.138888888888888 / 24  (17.2):  80%|▊| 24/30 [00:00<00:00, 33.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.138888888888888 / 25  (16.6):  80%|▊| 24/30 [00:00<00:00, 33.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.638888888888888 / 26  (17.8):  83%|▊| 25/30 [00:00<00:00, 33.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.638888888888888 / 27  (20.9):  87%|▊| 26/30 [00:00<00:00, 33.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.638888888888888 / 28  (23.7):  90%|▉| 27/30 [00:00<00:00, 33.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.638888888888888 / 29  (26.3):  93%|▉| 28/30 [00:00<00:00, 33.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.38888888888889 / 30  (28.0): 100%|█| 30/30 [00:00<00:00, 35.23it/s\u001b[A\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.38888888888889 / 30  (28.0%)\n",
      "Score: 27.96 for set: [0, 0, 0]\n",
      "New best score: 27.96 for seed -3\n",
      "Scores so far: [27.96]\n",
      "Best score: 27.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 1  (33.3):   0%|        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   3%| | 1/30 [00:00<00:02, 11.76it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.3333333333333333 / 3  (44.4):   7%| | 2/30 [00:00<00:01, 19.29it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.3333333333333333 / 3  (44.4):  10%| | 3/30 [00:00<00:01, 26.35it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.333333333333333 / 4  (58.3):  10%| | 3/30 [00:00<00:01, 26.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.833333333333333 / 5  (56.7):  13%|▏| 4/30 [00:00<00:00, 26.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.233333333333333 / 6  (53.9):  17%|▏| 5/30 [00:00<00:00, 26.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.2333333333333325 / 7  (60.5):  20%|▏| 6/30 [00:00<00:00, 26.35it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.2333333333333325 / 7  (60.5):  23%|▏| 7/30 [00:00<00:00, 33.02it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.333333333333332 / 8  (54.2):  23%|▏| 7/30 [00:00<00:00, 33.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.933333333333332 / 9  (54.8):  27%|▎| 8/30 [00:00<00:00, 33.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.933333333333332 / 10  (49.3):  30%|▎| 9/30 [00:00<00:00, 33.02it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.599999999999999 / 11  (50.9):  33%|▎| 10/30 [00:00<00:00, 33.02it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.599999999999999 / 12  (46.7):  37%|▎| 11/30 [00:00<00:00, 33.02it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.933333333333332 / 13  (45.6):  40%|▍| 12/30 [00:00<00:00, 33.02it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.933333333333332 / 13  (45.6):  43%|▍| 13/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.933333333333332 / 14  (49.5):  43%|▍| 13/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.433333333333332 / 15  (49.6):  47%|▍| 14/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.766666666666665 / 16  (48.5):  50%|▌| 15/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.766666666666665 / 17  (45.7):  53%|▌| 16/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.766666666666666 / 18  (48.7):  57%|▌| 17/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.1 / 19  (47.9):  60%|███████▊     | 18/30 [00:00<00:00, 39.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.1 / 19  (47.9):  63%|████████▏    | 19/30 [00:00<00:00, 43.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.1 / 20  (50.5):  63%|███████▌    | 19/30 [00:00<00:00, 43.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.1 / 21  (48.1):  67%|████████    | 20/30 [00:00<00:00, 43.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.1 / 22  (50.5):  70%|████████▍   | 21/30 [00:00<00:00, 43.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.9 / 23  (51.7):  73%|████████▊   | 22/30 [00:00<00:00, 43.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.9 / 24  (49.6):  77%|█████████▏  | 23/30 [00:00<00:00, 43.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.9 / 25  (47.6):  80%|█████████▌  | 24/30 [00:00<00:00, 43.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.9 / 25  (47.6):  83%|██████████  | 25/30 [00:00<00:00, 46.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.9 / 26  (49.6):  83%|██████████  | 25/30 [00:00<00:00, 46.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.4 / 27  (49.6):  87%|██████████▍ | 26/30 [00:00<00:00, 46.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.4 / 28  (51.4):  90%|██████████▊ | 27/30 [00:00<00:00, 46.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.4 / 29  (53.1):  93%|███████████▏| 28/30 [00:00<00:00, 46.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.4 / 30  (51.3): 100%|████████████| 30/30 [00:00<00:00, 50.01it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.4 / 30  (51.3%)\n",
      "Score: 51.33 for set: [16, 16, 16]\n",
      "New best score: 51.33 for seed -2\n",
      "Scores so far: [27.96, 51.33]\n",
      "Best score: 51.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 47.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████████▏                             | 11/30 [00:00<00:00, 40.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|████████████████████████████▏                  | 18/30 [00:00<00:00, 38.01it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 19 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.4 / 1  (40.0):   0%|                       | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.4 / 1  (40.0):   3%|▌              | 1/30 [00:00<00:03,  7.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.4 / 2  (70.0):   3%|▌              | 1/30 [00:00<00:03,  7.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.4 / 3  (46.7):   7%|█              | 2/30 [00:00<00:03,  7.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.4 / 4  (60.0):  10%|█▌             | 3/30 [00:00<00:03,  7.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4 / 5  (68.0):  13%|██             | 4/30 [00:00<00:03,  7.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4 / 6  (56.7):  17%|██▌            | 5/30 [00:00<00:03,  7.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4 / 6  (56.7):  20%|███            | 6/30 [00:00<00:00, 27.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4 / 7  (48.6):  20%|███            | 6/30 [00:00<00:00, 27.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 8  (46.7):  23%|▏| 7/30 [00:00<00:00, 27.38it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 9  (41.5):  27%|▎| 8/30 [00:00<00:00, 27.38it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 9  (41.5):  30%|▎| 9/30 [00:00<00:01, 19.63it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.233333333333333 / 10  (42.3):  30%|▎| 9/30 [00:00<00:01, 19.63it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.233333333333333 / 11  (38.5):  33%|▎| 10/30 [00:00<00:01, 19.63it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.733333333333333 / 12  (39.4):  37%|▎| 11/30 [00:00<00:00, 19.63it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.733333333333333 / 12  (39.4):  40%|▍| 12/30 [00:00<00:00, 21.52it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.066666666666666 / 13  (39.0):  40%|▍| 12/30 [00:00<00:00, 21.52it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.816666666666666 / 14  (41.5):  43%|▍| 13/30 [00:00<00:00, 21.52it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.816666666666666 / 15  (45.4):  47%|▍| 14/30 [00:00<00:00, 21.52it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.066666666666666 / 16  (44.2):  50%|▌| 15/30 [00:00<00:00, 21.52it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.066666666666666 / 17  (47.5):  53%|▌| 16/30 [00:00<00:00, 21.52it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.066666666666666 / 17  (47.5):  57%|▌| 17/30 [00:00<00:00, 28.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.066666666666666 / 18  (50.4):  57%|▌| 17/30 [00:00<00:00, 28.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.066666666666666 / 19  (47.7):  60%|▌| 18/30 [00:00<00:00, 28.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.566666666666666 / 20  (47.8):  63%|▋| 19/30 [00:00<00:00, 28.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.566666666666666 / 21  (45.6):  67%|▋| 20/30 [00:00<00:00, 28.09it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.566666666666666 / 21  (45.6):  70%|▋| 21/30 [00:00<00:00, 29.82it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.733333333333333 / 22  (44.2):  70%|▋| 21/30 [00:00<00:00, 29.82it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.733333333333333 / 23  (42.3):  73%|▋| 22/30 [00:00<00:00, 29.82it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.483333333333333 / 24  (43.7):  77%|▊| 23/30 [00:00<00:00, 29.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.483333333333333 / 25  (41.9):  80%|▊| 24/30 [00:00<00:00, 29.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.983333333333333 / 26  (42.2):  83%|▊| 25/30 [00:00<00:00, 29.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.983333333333333 / 27  (40.7):  87%|▊| 26/30 [00:00<00:00, 29.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.983333333333333 / 28  (42.8):  90%|▉| 27/30 [00:00<00:00, 29.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.983333333333333 / 29  (44.8):  93%|▉| 28/30 [00:00<00:00, 29.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.733333333333333 / 30  (45.8):  97%|▉| 29/30 [00:00<00:00, 29.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.733333333333333 / 30  (45.8): 100%|█| 30/30 [00:00<00:00, 32.86it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.733333333333333 / 30  (45.8%)\n",
      "Score: 45.78 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78]\n",
      "Best score: 51.33\n",
      "Average of max per entry across top 1 scores: 0.5133333333333333\n",
      "Average of max per entry across top 2 scores: 0.7066666666666668\n",
      "Average of max per entry across top 3 scores: 0.7288888888888889\n",
      "Average of max per entry across top 5 scores: 0.7288888888888889\n",
      "Average of max per entry across top 8 scores: 0.7288888888888889\n",
      "Average of max per entry across top 9999 scores: 0.7288888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 47.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|██████████████████▊                            | 12/30 [00:00<00:00, 50.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|████████████████████████████▏                  | 18/30 [00:00<00:00, 47.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████████████▎    | 27/30 [00:00<00:00, 49.39it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 28 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:00<00:03,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.8333333333333333 / 2  (41.7):   3%| | 1/30 [00:00<00:03,  9.34it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 3  (61.1):   7%| | 2/30 [00:00<00:02,  9.34it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):  10%| | 3/30 [00:00<00:02,  9.34it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.833333333333333 / 5  (56.7):  13%|▏| 4/30 [00:00<00:02,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 6  (63.9):  17%|▏| 5/30 [00:00<00:02,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 7  (54.8):  20%|▏| 6/30 [00:00<00:02,  9.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 7  (54.8):  23%|▏| 7/30 [00:00<00:00, 33.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.133333333333333 / 8  (51.7):  23%|▏| 7/30 [00:00<00:00, 33.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.133333333333333 / 9  (45.9):  27%|▎| 8/30 [00:00<00:00, 33.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.133333333333333 / 10  (41.3):  30%|▎| 9/30 [00:00<00:00, 33.63it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.133333333333333 / 11  (46.7):  33%|▎| 10/30 [00:00<00:00, 33.63it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.633333333333333 / 12  (46.9):  37%|▎| 11/30 [00:00<00:00, 33.63it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.633333333333333 / 13  (43.3):  40%|▍| 12/30 [00:00<00:00, 33.63it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.633333333333333 / 13  (43.3):  43%|▍| 13/30 [00:00<00:00, 34.70it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.633333333333333 / 14  (47.4):  43%|▍| 13/30 [00:00<00:00, 34.70it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.633333333333333 / 15  (44.2):  47%|▍| 14/30 [00:00<00:00, 34.70it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.633333333333333 / 16  (41.5):  50%|▌| 15/30 [00:00<00:00, 34.70it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.133333333333333 / 17  (42.0):  53%|▌| 16/30 [00:00<00:00, 34.70it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.133333333333333 / 18  (45.2):  57%|▌| 17/30 [00:00<00:00, 34.70it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.133333333333333 / 19  (42.8):  60%|▌| 18/30 [00:00<00:00, 34.70it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.133333333333333 / 19  (42.8):  63%|▋| 19/30 [00:00<00:00, 40.36it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.383333333333333 / 20  (41.9):  63%|▋| 19/30 [00:00<00:00, 40.36it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.716666666666667 / 21  (41.5):  67%|▋| 20/30 [00:00<00:00, 40.36it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.466666666666667 / 22  (43.0):  70%|▋| 21/30 [00:00<00:00, 40.36it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.466666666666667 / 23  (41.2):  73%|▋| 22/30 [00:00<00:00, 40.36it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.966666666666667 / 24  (41.5):  77%|▊| 23/30 [00:00<00:00, 40.36it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.966666666666667 / 25  (39.9):  80%|▊| 24/30 [00:00<00:00, 40.36it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.966666666666667 / 25  (39.9):  83%|▊| 25/30 [00:00<00:00, 45.14it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.466666666666667 / 26  (40.3):  83%|▊| 25/30 [00:00<00:00, 45.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.466666666666667 / 27  (42.5):  87%|▊| 26/30 [00:00<00:00, 45.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.466666666666667 / 28  (44.5):  90%|▉| 27/30 [00:00<00:00, 45.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.466666666666667 / 29  (46.4):  93%|▉| 28/30 [00:00<00:00, 45.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.466666666666667 / 30  (48.2): 100%|█| 30/30 [00:00<00:00, 45.89it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.466666666666667 / 30  (48.2%)\n",
      "Score: 48.22 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22]\n",
      "Best score: 51.33\n",
      "Average of max per entry across top 1 scores: 0.5133333333333333\n",
      "Average of max per entry across top 2 scores: 0.6955555555555556\n",
      "Average of max per entry across top 3 scores: 0.7772222222222224\n",
      "Average of max per entry across top 5 scores: 0.7827777777777779\n",
      "Average of max per entry across top 8 scores: 0.7827777777777779\n",
      "Average of max per entry across top 9999 scores: 0.7827777777777779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 50.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|██████████████████▊                            | 12/30 [00:00<00:00, 50.33it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:00<00:03,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:00<00:03,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.3333333333333335 / 4  (58.3):  10%| | 3/30 [00:00<00:02,  9.12it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.666666666666667 / 5  (53.3):  13%|▏| 4/30 [00:00<00:02,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.166666666666667 / 6  (52.8):  17%|▏| 5/30 [00:00<00:02,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.466666666666667 / 7  (49.5):  20%|▏| 6/30 [00:00<00:02,  9.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.466666666666667 / 7  (49.5):  23%|▏| 7/30 [00:00<00:00, 31.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.466666666666667 / 8  (43.3):  23%|▏| 7/30 [00:00<00:00, 31.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.466666666666667 / 9  (38.5):  27%|▎| 8/30 [00:00<00:00, 31.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.966666666666667 / 10  (39.7):  30%|▎| 9/30 [00:00<00:00, 31.40it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.966666666666667 / 11  (45.2):  33%|▎| 10/30 [00:00<00:00, 31.40it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.966666666666667 / 12  (41.4):  37%|▎| 11/30 [00:00<00:00, 31.40it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.216666666666667 / 13  (40.1):  40%|▍| 12/30 [00:00<00:00, 31.40it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.216666666666667 / 13  (40.1):  43%|▍| 13/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.55 / 14  (39.6):  43%|█████▏      | 13/30 [00:00<00:00, 39.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.3 / 15  (42.0):  47%|██████       | 14/30 [00:00<00:00, 39.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.3 / 16  (45.6):  50%|██████▌      | 15/30 [00:00<00:00, 39.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.8 / 17  (45.9):  53%|██████▉      | 16/30 [00:00<00:00, 39.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.133333333333333 / 18  (45.2):  57%|▌| 17/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.133333333333333 / 19  (42.8):  60%|▌| 18/30 [00:00<00:00, 39.79it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.133333333333333 / 19  (42.8):  63%|▋| 19/30 [00:00<00:00, 43.24it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.633333333333333 / 20  (43.2):  63%|▋| 19/30 [00:00<00:00, 43.24it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.133333333333333 / 21  (43.5):  67%|▋| 20/30 [00:00<00:00, 43.24it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.133333333333333 / 22  (41.5):  70%|▋| 21/30 [00:00<00:00, 43.24it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.883333333333333 / 23  (43.0):  73%|▋| 22/30 [00:00<00:00, 43.24it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.883333333333333 / 24  (45.3):  77%|▊| 23/30 [00:00<00:00, 43.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.883333333333333 / 25  (43.5):  80%|▊| 24/30 [00:00<00:00, 43.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.883333333333333 / 25  (43.5):  83%|▊| 25/30 [00:00<00:00, 46.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.383333333333333 / 26  (43.8):  83%|▊| 25/30 [00:00<00:00, 46.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.383333333333333 / 27  (45.9):  87%|▊| 26/30 [00:00<00:00, 46.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.383333333333333 / 28  (44.2):  90%|▉| 27/30 [00:00<00:00, 46.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.383333333333333 / 29  (46.1):  93%|▉| 28/30 [00:00<00:00, 46.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.133333333333333 / 30  (47.1): 100%|█| 30/30 [00:00<00:00, 48.10it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.133333333333333 / 30  (47.1%)\n",
      "Score: 47.11 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11]\n",
      "Best score: 51.33\n",
      "Average of max per entry across top 1 scores: 0.5133333333333333\n",
      "Average of max per entry across top 2 scores: 0.6955555555555556\n",
      "Average of max per entry across top 3 scores: 0.8038888888888889\n",
      "Average of max per entry across top 5 scores: 0.8355555555555555\n",
      "Average of max per entry across top 8 scores: 0.8355555555555555\n",
      "Average of max per entry across top 9999 scores: 0.8355555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  3%|█▌                                              | 1/30 [00:00<00:00, 41.39it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:02,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:00<00:02,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:00<00:02,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.0 / 4  (75.0):  10%|█▌             | 3/30 [00:00<00:02,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.3333333333333335 / 5  (66.7):  13%|▏| 4/30 [00:00<00:02,  9.90it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 6  (62.2):  17%|▏| 5/30 [00:00<00:02,  9.90it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 7  (53.3):  20%|▏| 6/30 [00:00<00:02,  9.90it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.483333333333333 / 8  (56.0):  23%|▏| 7/30 [00:00<00:02,  9.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.483333333333333 / 8  (56.0):  27%|▎| 8/30 [00:00<00:00, 42.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.816666666666666 / 9  (53.5):  27%|▎| 8/30 [00:00<00:00, 42.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.483333333333333 / 10  (54.8):  30%|▎| 9/30 [00:00<00:00, 42.80it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.783333333333333 / 11  (52.6):  33%|▎| 10/30 [00:00<00:00, 42.80it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.783333333333333 / 12  (48.2):  37%|▎| 11/30 [00:00<00:00, 42.80it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.116666666666666 / 13  (47.1):  40%|▍| 12/30 [00:00<00:00, 42.80it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.116666666666666 / 14  (50.8):  43%|▍| 13/30 [00:00<00:00, 42.80it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.116666666666666 / 14  (50.8):  47%|▍| 14/30 [00:00<00:00, 44.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.116666666666667 / 15  (54.1):  47%|▍| 14/30 [00:00<00:00, 44.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.783333333333333 / 16  (54.9):  50%|▌| 15/30 [00:00<00:00, 44.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.033333333333333 / 17  (53.1):  53%|▌| 16/30 [00:00<00:00, 44.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.366666666666667 / 18  (52.0):  57%|▌| 17/30 [00:00<00:00, 44.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.366666666666667 / 19  (49.3):  60%|▌| 18/30 [00:00<00:00, 44.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.866666666666667 / 20  (49.3):  63%|▋| 19/30 [00:00<00:00, 44.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.866666666666667 / 20  (49.3):  67%|▋| 20/30 [00:00<00:00, 45.94it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.116666666666667 / 21  (48.2):  67%|▋| 20/30 [00:00<00:00, 45.94it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.116666666666667 / 22  (50.5):  70%|▋| 21/30 [00:00<00:00, 45.94it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.450000000000001 / 23  (49.8):  73%|▋| 22/30 [00:00<00:00, 45.94it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.450000000000001 / 24  (51.9):  77%|▊| 23/30 [00:00<00:00, 45.94it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.450000000000001 / 25  (49.8):  80%|▊| 24/30 [00:00<00:00, 45.94it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.950000000000001 / 26  (49.8):  83%|▊| 25/30 [00:00<00:00, 45.94it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.950000000000001 / 27  (48.0):  87%|▊| 26/30 [00:00<00:00, 45.94it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.950000000000001 / 27  (48.0):  90%|▉| 27/30 [00:00<00:00, 53.26it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.950000000000001 / 28  (46.2):  90%|▉| 27/30 [00:00<00:00, 53.26it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.950000000000001 / 29  (48.1):  93%|▉| 28/30 [00:00<00:00, 53.26it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.950000000000001 / 30  (49.8): 100%|█| 30/30 [00:00<00:00, 51.77it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.950000000000001 / 30  (49.8%)\n",
      "Score: 49.83 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83]\n",
      "Best score: 51.33\n",
      "Average of max per entry across top 1 scores: 0.5133333333333333\n",
      "Average of max per entry across top 2 scores: 0.7238888888888889\n",
      "Average of max per entry across top 3 scores: 0.8161111111111111\n",
      "Average of max per entry across top 5 scores: 0.8494444444444444\n",
      "Average of max per entry across top 8 scores: 0.8494444444444444\n",
      "Average of max per entry across top 9999 scores: 0.8494444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████████▏                             | 11/30 [00:00<00:00, 55.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.6 / 1  (60.0):   0%|                       | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.6 / 2  (30.0):   3%|▌              | 1/30 [00:00<00:02, 10.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.6 / 2  (30.0):   7%|█              | 2/30 [00:00<00:01, 19.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.6 / 3  (53.3):   7%|█              | 2/30 [00:00<00:01, 19.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.6 / 4  (40.0):  10%|█▌             | 3/30 [00:00<00:01, 19.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.1 / 5  (42.0):  13%|██             | 4/30 [00:00<00:01, 19.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.1 / 6  (51.7):  17%|██▌            | 5/30 [00:00<00:01, 19.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.1 / 7  (44.3):  20%|███            | 6/30 [00:00<00:01, 19.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.1 / 7  (44.3):  23%|███▌           | 7/30 [00:00<00:00, 34.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.475 / 8  (43.4):  23%|███          | 7/30 [00:00<00:00, 34.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.975 / 9  (44.2):  27%|███▍         | 8/30 [00:00<00:00, 34.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.975 / 10  (39.8):  30%|███▌        | 9/30 [00:00<00:00, 34.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.475 / 11  (40.7):  33%|███▋       | 10/30 [00:00<00:00, 34.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.808333333333333 / 12  (40.1):  37%|▎| 11/30 [00:00<00:00, 34.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.141666666666666 / 13  (39.6):  40%|▍| 12/30 [00:00<00:00, 34.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.141666666666666 / 13  (39.6):  43%|▍| 13/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.141666666666666 / 14  (43.9):  43%|▍| 13/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.641666666666666 / 15  (44.3):  47%|▍| 14/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.391666666666666 / 16  (46.2):  50%|▌| 15/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.724999999999999 / 17  (45.4):  53%|▌| 16/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.474999999999998 / 18  (47.1):  57%|▌| 17/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.474999999999998 / 19  (44.6):  60%|▌| 18/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.474999999999998 / 19  (44.6):  63%|▋| 19/30 [00:00<00:00, 42.44it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.724999999999998 / 20  (43.6):  63%|▋| 19/30 [00:00<00:00, 42.44it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.724999999999998 / 21  (41.5):  67%|▋| 20/30 [00:00<00:00, 42.44it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.724999999999998 / 22  (39.7):  70%|▋| 21/30 [00:00<00:00, 42.44it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.058333333333332 / 23  (39.4):  73%|▋| 22/30 [00:00<00:00, 42.44it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.808333333333332 / 24  (40.9):  77%|▊| 23/30 [00:00<00:00, 42.44it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.808333333333332 / 25  (39.2):  80%|▊| 24/30 [00:00<00:00, 42.44it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.808333333333332 / 25  (39.2):  83%|▊| 25/30 [00:00<00:00, 45.89it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.808333333333332 / 26  (41.6):  83%|▊| 25/30 [00:00<00:00, 45.89it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.808333333333332 / 27  (40.0):  87%|▊| 26/30 [00:00<00:00, 45.89it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.808333333333332 / 28  (42.2):  90%|▉| 27/30 [00:00<00:00, 45.89it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.808333333333332 / 29  (44.2):  93%|▉| 28/30 [00:00<00:00, 45.89it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.308333333333332 / 30  (44.4): 100%|█| 30/30 [00:00<00:00, 49.87it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.308333333333332 / 30  (44.4%)\n",
      "Score: 44.36 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36]\n",
      "Best score: 51.33\n",
      "Average of max per entry across top 1 scores: 0.5133333333333333\n",
      "Average of max per entry across top 2 scores: 0.7238888888888889\n",
      "Average of max per entry across top 3 scores: 0.8161111111111111\n",
      "Average of max per entry across top 5 scores: 0.8494444444444444\n",
      "Average of max per entry across top 8 scores: 0.8494444444444444\n",
      "Average of max per entry across top 9999 scores: 0.8494444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|████████████▊                                   | 8/30 [00:00<00:00, 51.40it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.3333333333333333 / 2  (66.7):   3%| | 1/30 [00:00<00:02, 12.41it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.7333333333333334 / 3  (57.8):   7%| | 2/30 [00:00<00:01, 21.26it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.7333333333333334 / 4  (68.3):  10%| | 3/30 [00:00<00:00, 29.48it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.7333333333333334 / 4  (68.3):  13%|▏| 4/30 [00:00<00:00, 37.34it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 5  (74.7):  13%|▏| 4/30 [00:00<00:00, 37.34it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 6  (62.2):  17%|▏| 5/30 [00:00<00:00, 37.34it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 7  (53.3):  20%|▏| 6/30 [00:00<00:00, 37.34it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.533333333333333 / 8  (56.7):  23%|▏| 7/30 [00:00<00:00, 37.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.533333333333333 / 8  (56.7):  27%|▎| 8/30 [00:00<00:00, 38.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.866666666666666 / 9  (54.1):  27%|▎| 8/30 [00:00<00:00, 38.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.866666666666666 / 10  (58.7):  30%|▎| 9/30 [00:00<00:00, 38.30it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.866666666666666 / 11  (53.3):  33%|▎| 10/30 [00:00<00:00, 38.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.366666666666666 / 12  (53.1):  37%|▎| 11/30 [00:00<00:00, 38.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.699999999999999 / 13  (51.5):  40%|▍| 12/30 [00:00<00:00, 38.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.699999999999999 / 14  (55.0):  43%|▍| 13/30 [00:00<00:00, 38.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.699999999999999 / 14  (55.0):  47%|▍| 14/30 [00:00<00:00, 46.61it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.45 / 15  (56.3):  47%|█████▌      | 14/30 [00:00<00:00, 46.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.783333333333333 / 16  (54.9):  50%|▌| 15/30 [00:00<00:00, 46.61it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.95 / 17  (52.6):  53%|██████▍     | 16/30 [00:00<00:00, 46.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.2 / 18  (51.1):  57%|███████▎     | 17/30 [00:00<00:00, 46.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.2 / 19  (48.4):  60%|███████▊     | 18/30 [00:00<00:00, 46.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.2 / 19  (48.4):  63%|████████▏    | 19/30 [00:00<00:00, 47.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.7 / 20  (48.5):  63%|████████▏    | 19/30 [00:00<00:00, 47.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.7 / 21  (51.0):  67%|████████    | 20/30 [00:00<00:00, 47.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.7 / 22  (53.2):  70%|████████▍   | 21/30 [00:00<00:00, 47.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.45 / 23  (54.1):  73%|████████   | 22/30 [00:00<00:00, 47.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.783333333333333 / 24  (53.3):  77%|▊| 23/30 [00:00<00:00, 47.72it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.783333333333333 / 25  (51.1):  80%|▊| 24/30 [00:00<00:00, 47.72it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.283333333333333 / 26  (51.1):  83%|▊| 25/30 [00:00<00:00, 47.72it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.283333333333333 / 26  (51.1):  87%|▊| 26/30 [00:00<00:00, 51.54it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.283333333333333 / 27  (52.9):  87%|▊| 26/30 [00:00<00:00, 51.54it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.283333333333333 / 28  (51.0):  90%|▉| 27/30 [00:00<00:00, 51.54it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.283333333333333 / 29  (52.7):  93%|▉| 28/30 [00:00<00:00, 51.54it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.28333333333333 / 30  (54.3): 100%|█| 30/30 [00:00<00:00, 54.25it/\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.28333333333333 / 30  (54.3%)\n",
      "Score: 54.28 for set: [16, 16, 16]\n",
      "New best score: 54.28 for seed 4\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28]\n",
      "Best score: 54.28\n",
      "Average of max per entry across top 1 scores: 0.5427777777777777\n",
      "Average of max per entry across top 2 scores: 0.745\n",
      "Average of max per entry across top 3 scores: 0.8116666666666668\n",
      "Average of max per entry across top 5 scores: 0.8622222222222222\n",
      "Average of max per entry across top 8 scores: 0.8788888888888889\n",
      "Average of max per entry across top 9999 scores: 0.8788888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|████████                                        | 5/30 [00:00<00:00, 47.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████████▏                             | 11/30 [00:00<00:00, 51.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|████████████████████████████████▉              | 21/30 [00:00<00:00, 50.13it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 22 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.2857142857142857 / 1  (28.6):   0%|        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.2857142857142857 / 1  (28.6):   3%| | 1/30 [00:00<00:03,  9.53it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.2857142857142856 / 2  (64.3):   3%| | 1/30 [00:00<00:03,  9.53it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2857142857142856 / 3  (76.2):   7%| | 2/30 [00:00<00:02,  9.53it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2857142857142856 / 4  (57.1):  10%| | 3/30 [00:00<00:02,  9.53it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2857142857142856 / 5  (45.7):  13%|▏| 4/30 [00:00<00:02,  9.53it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.7857142857142856 / 6  (46.4):  17%|▏| 5/30 [00:00<00:02,  9.53it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.452380952380952 / 7  (49.3):  20%|▏| 6/30 [00:00<00:02,  9.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.452380952380952 / 7  (49.3):  23%|▏| 7/30 [00:00<00:00, 33.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.452380952380952 / 8  (43.2):  23%|▏| 7/30 [00:00<00:00, 33.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.752380952380952 / 9  (41.7):  27%|▎| 8/30 [00:00<00:00, 33.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.552380952380952 / 10  (45.5):  30%|▎| 9/30 [00:00<00:00, 33.83it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.885714285714285 / 11  (44.4):  33%|▎| 10/30 [00:00<00:00, 33.83it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.219047619047618 / 12  (43.5):  37%|▎| 11/30 [00:00<00:00, 33.83it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.719047619047618 / 13  (44.0):  40%|▍| 12/30 [00:00<00:00, 33.83it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.719047619047618 / 13  (44.0):  43%|▍| 13/30 [00:00<00:00, 44.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.719047619047618 / 14  (48.0):  43%|▍| 13/30 [00:00<00:00, 44.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.969047619047618 / 15  (46.5):  47%|▍| 14/30 [00:00<00:00, 44.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.719047619047618 / 16  (48.2):  50%|▌| 15/30 [00:00<00:00, 44.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.719047619047618 / 17  (51.3):  53%|▌| 16/30 [00:00<00:00, 44.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.719047619047618 / 18  (54.0):  57%|▌| 17/30 [00:00<00:00, 44.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.719047619047618 / 19  (51.2):  60%|▌| 18/30 [00:00<00:00, 44.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.719047619047618 / 19  (51.2):  63%|▋| 19/30 [00:00<00:00, 45.84it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.219047619047618 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 45.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.219047619047618 / 21  (48.7):  67%|▋| 20/30 [00:00<00:00, 45.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.219047619047618 / 22  (51.0):  70%|▋| 21/30 [00:00<00:00, 45.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.719047619047618 / 23  (51.0):  73%|▋| 22/30 [00:00<00:00, 45.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.469047619047618 / 24  (52.0):  77%|▊| 23/30 [00:00<00:00, 45.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.969047619047618 / 25  (51.9):  80%|▊| 24/30 [00:00<00:00, 45.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.969047619047618 / 26  (53.7):  83%|▊| 25/30 [00:00<00:00, 45.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.969047619047618 / 26  (53.7):  87%|▊| 26/30 [00:00<00:00, 53.70it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.969047619047618 / 27  (51.7):  87%|▊| 26/30 [00:00<00:00, 53.70it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.969047619047618 / 28  (53.5):  90%|▉| 27/30 [00:00<00:00, 53.70it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.969047619047618 / 29  (55.1):  93%|▉| 28/30 [00:00<00:00, 53.70it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.71904761904762 / 30  (55.7): 100%|█| 30/30 [00:00<00:00, 52.80it/\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.71904761904762 / 30  (55.7%)\n",
      "Score: 55.73 for set: [16, 16, 16]\n",
      "New best score: 55.73 for seed 5\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73]\n",
      "Best score: 55.73\n",
      "Average of max per entry across top 1 scores: 0.5573015873015873\n",
      "Average of max per entry across top 2 scores: 0.7877777777777778\n",
      "Average of max per entry across top 3 scores: 0.8483333333333333\n",
      "Average of max per entry across top 5 scores: 0.8927777777777777\n",
      "Average of max per entry across top 8 scores: 0.9011111111111111\n",
      "Average of max per entry across top 9999 scores: 0.9011111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|██████▍                                         | 4/30 [00:00<00:00, 48.37it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.8333333333333333 / 2  (41.7):   3%| | 1/30 [00:00<00:02, 10.37it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.8333333333333333 / 2  (41.7):   7%| | 2/30 [00:00<00:01, 18.02it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 3  (61.1):   7%| | 2/30 [00:00<00:01, 18.02it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.833333333333333 / 4  (70.8):  10%| | 3/30 [00:00<00:01, 18.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 5  (76.7):  13%|▏| 4/30 [00:00<00:01, 18.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 6  (63.9):  17%|▏| 5/30 [00:00<00:01, 18.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 7  (54.8):  20%|▏| 6/30 [00:00<00:01, 18.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 8  (47.9):  23%|▏| 7/30 [00:00<00:01, 18.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.833333333333333 / 8  (47.9):  27%|▎| 8/30 [00:00<00:00, 39.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.166666666666666 / 9  (46.3):  27%|▎| 8/30 [00:00<00:00, 39.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.466666666666666 / 10  (44.7):  30%|▎| 9/30 [00:00<00:00, 39.42it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.133333333333333 / 11  (46.7):  33%|▎| 10/30 [00:00<00:00, 39.42it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.758333333333333 / 12  (48.0):  37%|▎| 11/30 [00:00<00:00, 39.42it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.091666666666666 / 13  (46.9):  40%|▍| 12/30 [00:00<00:00, 39.42it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.424999999999999 / 14  (45.9):  43%|▍| 13/30 [00:00<00:00, 39.42it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.424999999999999 / 14  (45.9):  47%|▍| 14/30 [00:00<00:00, 43.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.424999999999999 / 15  (49.5):  47%|▍| 14/30 [00:00<00:00, 43.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.674999999999999 / 16  (48.0):  50%|▌| 15/30 [00:00<00:00, 43.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.424999999999999 / 17  (49.6):  53%|▌| 16/30 [00:00<00:00, 43.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.758333333333333 / 18  (48.7):  57%|▌| 17/30 [00:00<00:00, 43.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.758333333333333 / 19  (46.1):  60%|▌| 18/30 [00:00<00:00, 43.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.758333333333333 / 19  (46.1):  63%|▋| 19/30 [00:00<00:00, 45.77it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.258333333333333 / 20  (46.3):  63%|▋| 19/30 [00:00<00:00, 45.77it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.258333333333333 / 21  (48.8):  67%|▋| 20/30 [00:00<00:00, 45.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.258333333333333 / 22  (51.2):  70%|▋| 21/30 [00:00<00:00, 45.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.591666666666667 / 23  (50.4):  73%|▋| 22/30 [00:00<00:00, 45.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.341666666666667 / 24  (51.4):  77%|▊| 23/30 [00:00<00:00, 45.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.341666666666667 / 25  (49.4):  80%|▊| 24/30 [00:00<00:00, 45.77it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.341666666666667 / 25  (49.4):  83%|▊| 25/30 [00:00<00:00, 47.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.841666666666667 / 26  (49.4):  83%|▊| 25/30 [00:00<00:00, 47.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.841666666666667 / 27  (51.3):  87%|▊| 26/30 [00:00<00:00, 47.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.841666666666667 / 28  (49.4):  90%|▉| 27/30 [00:00<00:00, 47.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.841666666666667 / 29  (51.2):  93%|▉| 28/30 [00:00<00:00, 47.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.591666666666667 / 30  (52.0): 100%|█| 30/30 [00:00<00:00, 51.18it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.591666666666667 / 30  (52.0%)\n",
      "Score: 51.97 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97]\n",
      "Best score: 55.73\n",
      "Average of max per entry across top 1 scores: 0.5573015873015873\n",
      "Average of max per entry across top 2 scores: 0.7877777777777778\n",
      "Average of max per entry across top 3 scores: 0.8113888888888889\n",
      "Average of max per entry across top 5 scores: 0.8691666666666666\n",
      "Average of max per entry across top 8 scores: 0.9052777777777777\n",
      "Average of max per entry across top 9999 scores: 0.9052777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████████▏                             | 11/30 [00:00<00:00, 54.21it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.4 / 2  (70.0):   3%|▌              | 1/30 [00:00<00:03,  9.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.4 / 2  (70.0):   7%|█              | 2/30 [00:00<00:01, 17.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.4 / 3  (46.7):   7%|█              | 2/30 [00:00<00:01, 17.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.4 / 4  (60.0):  10%|█▌             | 3/30 [00:00<00:01, 17.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.7333333333333334 / 5  (54.7):  13%|▏| 4/30 [00:00<00:01, 17.31it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 6  (62.2):  17%|▏| 5/30 [00:00<00:01, 17.31it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.4 / 7  (62.9):  20%|███            | 6/30 [00:00<00:01, 17.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.4 / 7  (62.9):  23%|███▌           | 7/30 [00:00<00:00, 33.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.733333333333333 / 8  (59.2):  23%|▏| 7/30 [00:00<00:00, 33.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.533333333333333 / 9  (61.5):  27%|▎| 8/30 [00:00<00:00, 33.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.033333333333333 / 10  (60.3):  30%|▎| 9/30 [00:00<00:00, 33.73it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.533333333333333 / 11  (59.4):  33%|▎| 10/30 [00:00<00:00, 33.73it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.533333333333333 / 12  (54.4):  37%|▎| 11/30 [00:00<00:00, 33.73it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.533333333333333 / 13  (50.3):  40%|▍| 12/30 [00:00<00:00, 33.73it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.783333333333333 / 14  (48.5):  43%|▍| 13/30 [00:00<00:00, 33.73it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.783333333333333 / 14  (48.5):  47%|▍| 14/30 [00:00<00:00, 46.04it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.95 / 15  (46.3):  47%|█████▌      | 14/30 [00:00<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.95 / 16  (43.4):  50%|██████      | 15/30 [00:00<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.95 / 17  (46.8):  53%|██████▍     | 16/30 [00:00<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.95 / 18  (49.7):  57%|██████▊     | 17/30 [00:00<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.95 / 19  (47.1):  60%|███████▏    | 18/30 [00:00<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.45 / 20  (47.2):  63%|███████▌    | 19/30 [00:00<00:00, 46.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.45 / 20  (47.2):  67%|████████    | 20/30 [00:00<00:00, 49.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.45 / 21  (45.0):  67%|████████    | 20/30 [00:00<00:00, 49.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.45 / 22  (47.5):  70%|███████▋   | 21/30 [00:00<00:00, 49.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.25 / 23  (48.9):  73%|████████   | 22/30 [00:00<00:00, 49.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.0 / 24  (50.0):  77%|█████████▏  | 23/30 [00:00<00:00, 49.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.5 / 25  (50.0):  80%|█████████▌  | 24/30 [00:00<00:00, 49.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.5 / 25  (50.0):  83%|██████████  | 25/30 [00:00<00:00, 48.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.5 / 26  (48.1):  83%|██████████  | 25/30 [00:00<00:00, 48.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.5 / 27  (50.0):  87%|██████████▍ | 26/30 [00:00<00:00, 48.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.5 / 28  (51.8):  90%|██████████▊ | 27/30 [00:00<00:00, 48.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.5 / 29  (50.0):  93%|███████████▏| 28/30 [00:00<00:00, 48.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.25 / 30  (50.8): 100%|███████████| 30/30 [00:00<00:00, 51.79it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.25 / 30  (50.8%)\n",
      "Score: 50.83 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83]\n",
      "Best score: 55.73\n",
      "Average of max per entry across top 1 scores: 0.5573015873015873\n",
      "Average of max per entry across top 2 scores: 0.7877777777777778\n",
      "Average of max per entry across top 3 scores: 0.8113888888888889\n",
      "Average of max per entry across top 5 scores: 0.8841666666666667\n",
      "Average of max per entry across top 8 scores: 0.9119444444444444\n",
      "Average of max per entry across top 9999 scores: 0.9119444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 51.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|██████████████████▊                            | 12/30 [00:00<00:00, 53.64it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:00<00:02,  9.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   3%| | 1/30 [00:00<00:02,  9.86it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.3333333333333333 / 3  (44.4):   7%| | 2/30 [00:00<00:02,  9.86it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.7333333333333334 / 4  (43.3):  10%| | 3/30 [00:00<00:02,  9.86it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.7333333333333334 / 5  (54.7):  13%|▏| 4/30 [00:00<00:02,  9.86it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.066666666666667 / 6  (51.1):  17%|▏| 5/30 [00:00<00:02,  9.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.066666666666667 / 7  (43.8):  20%|▏| 6/30 [00:00<00:02,  9.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.066666666666667 / 7  (43.8):  23%|▏| 7/30 [00:00<00:00, 35.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.816666666666667 / 8  (47.7):  23%|▏| 7/30 [00:00<00:00, 35.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.191666666666666 / 9  (46.6):  27%|▎| 8/30 [00:00<00:00, 35.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.691666666666666 / 10  (46.9):  30%|▎| 9/30 [00:00<00:00, 35.87it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.691666666666666 / 11  (42.7):  33%|▎| 10/30 [00:00<00:00, 35.87it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.0249999999999995 / 12  (41.9):  37%|▎| 11/30 [00:00<00:00, 35.87it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.3583333333333325 / 13  (41.2):  40%|▍| 12/30 [00:00<00:00, 35.87it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.3583333333333325 / 13  (41.2):  43%|▍| 13/30 [00:00<00:00, 42.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.0249999999999995 / 14  (43.0):  43%|▍| 13/30 [00:00<00:00, 42.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.0249999999999995 / 15  (46.8):  47%|▍| 14/30 [00:00<00:00, 42.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.3583333333333325 / 16  (46.0):  50%|▌| 15/30 [00:00<00:00, 42.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.5249999999999995 / 17  (44.3):  53%|▌| 16/30 [00:00<00:00, 42.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.8583333333333325 / 18  (43.7):  57%|▌| 17/30 [00:00<00:00, 42.28it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.191666666666666 / 19  (43.1):  60%|▌| 18/30 [00:00<00:00, 42.28it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.191666666666666 / 19  (43.1):  63%|▋| 19/30 [00:00<00:00, 48.55it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.691666666666666 / 20  (43.5):  63%|▋| 19/30 [00:00<00:00, 48.55it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.691666666666666 / 21  (46.2):  67%|▋| 20/30 [00:00<00:00, 48.55it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.691666666666666 / 22  (44.1):  70%|▋| 21/30 [00:00<00:00, 48.55it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.441666666666666 / 23  (45.4):  73%|▋| 22/30 [00:00<00:00, 48.55it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.775 / 24  (44.9):  77%|███████▋  | 23/30 [00:00<00:00, 48.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.775 / 25  (43.1):  80%|████████  | 24/30 [00:00<00:00, 48.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.775 / 25  (43.1):  83%|████████▎ | 25/30 [00:00<00:00, 48.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.275 / 26  (43.4):  83%|████████▎ | 25/30 [00:00<00:00, 48.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.275 / 27  (45.5):  87%|████████▋ | 26/30 [00:00<00:00, 48.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.275 / 28  (47.4):  90%|█████████ | 27/30 [00:00<00:00, 48.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.275 / 29  (49.2):  93%|█████████▎| 28/30 [00:00<00:00, 48.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.275 / 30  (50.9): 100%|██████████| 30/30 [00:00<00:00, 51.60it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.275 / 30  (50.9%)\n",
      "Score: 50.92 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92]\n",
      "Best score: 55.73\n",
      "Average of max per entry across top 1 scores: 0.5573015873015873\n",
      "Average of max per entry across top 2 scores: 0.7877777777777778\n",
      "Average of max per entry across top 3 scores: 0.8113888888888889\n",
      "Average of max per entry across top 5 scores: 0.8608333333333333\n",
      "Average of max per entry across top 8 scores: 0.9036111111111111\n",
      "Average of max per entry across top 9999 scores: 0.9119444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|████████                                        | 5/30 [00:00<00:00, 49.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|██████████████████▊                            | 12/30 [00:00<00:00, 51.58it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:00<00:03,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:00<00:03,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.0 / 4  (75.0):  10%|█▌             | 3/30 [00:00<00:03,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4 / 5  (68.0):  13%|██             | 4/30 [00:00<00:02,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.7333333333333334 / 6  (62.2):  17%|▏| 5/30 [00:00<00:02,  8.78it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.233333333333333 / 7  (60.5):  20%|▏| 6/30 [00:00<00:02,  8.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.233333333333333 / 7  (60.5):  23%|▏| 7/30 [00:00<00:00, 36.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.233333333333333 / 8  (52.9):  23%|▏| 7/30 [00:00<00:00, 36.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.233333333333333 / 9  (47.0):  27%|▎| 8/30 [00:00<00:00, 36.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.533333333333333 / 10  (45.3):  30%|▎| 9/30 [00:00<00:00, 36.30it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.533333333333333 / 11  (50.3):  33%|▎| 10/30 [00:00<00:00, 36.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.533333333333333 / 12  (46.1):  37%|▎| 11/30 [00:00<00:00, 36.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.033333333333333 / 13  (46.4):  40%|▍| 12/30 [00:00<00:00, 36.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.033333333333333 / 13  (46.4):  43%|▍| 13/30 [00:00<00:00, 41.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.783333333333333 / 14  (48.5):  43%|▍| 13/30 [00:00<00:00, 41.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.783333333333333 / 15  (51.9):  47%|▍| 14/30 [00:00<00:00, 41.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.533333333333333 / 16  (53.3):  50%|▌| 15/30 [00:00<00:00, 41.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.533333333333333 / 17  (56.1):  53%|▌| 16/30 [00:00<00:00, 41.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.533333333333333 / 18  (58.5):  57%|▌| 17/30 [00:00<00:00, 41.35it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.866666666666667 / 19  (57.2):  60%|▌| 18/30 [00:00<00:00, 41.35it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.866666666666667 / 19  (57.2):  63%|▋| 19/30 [00:00<00:00, 44.96it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.866666666666667 / 20  (59.3):  63%|▋| 19/30 [00:00<00:00, 44.96it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.366666666666667 / 21  (58.9):  67%|▋| 20/30 [00:00<00:00, 44.96it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.116666666666667 / 22  (59.6):  70%|▋| 21/30 [00:00<00:00, 44.96it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.283333333333333 / 23  (57.8):  73%|▋| 22/30 [00:00<00:00, 44.96it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.283333333333333 / 24  (59.5):  77%|▊| 23/30 [00:00<00:00, 44.96it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.783333333333333 / 25  (59.1):  80%|▊| 24/30 [00:00<00:00, 44.96it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.783333333333333 / 25  (59.1):  83%|▊| 25/30 [00:00<00:00, 46.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.783333333333333 / 26  (60.7):  83%|▊| 25/30 [00:00<00:00, 46.84it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.78333333333333 / 27  (62.2):  87%|▊| 26/30 [00:00<00:00, 46.84it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.78333333333333 / 28  (59.9):  90%|▉| 27/30 [00:00<00:00, 46.84it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 17.78333333333333 / 29  (61.3):  93%|▉| 28/30 [00:00<00:00, 46.84it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.78333333333333 / 30  (62.6): 100%|█| 30/30 [00:00<00:00, 50.12it/\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 18.78333333333333 / 30  (62.6%)\n",
      "Score: 62.61 for set: [16, 16, 16]\n",
      "New best score: 62.61 for seed 9\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92, 62.61]\n",
      "Best score: 62.61\n",
      "Average of max per entry across top 1 scores: 0.6261111111111111\n",
      "Average of max per entry across top 2 scores: 0.7694444444444445\n",
      "Average of max per entry across top 3 scores: 0.8544444444444445\n",
      "Average of max per entry across top 5 scores: 0.8802777777777777\n",
      "Average of max per entry across top 8 scores: 0.9036111111111111\n",
      "Average of max per entry across top 9999 scores: 0.9119444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|███████████▏                                    | 7/30 [00:00<00:00, 54.19it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:00<00:02,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:00<00:02,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:00<00:02,  9.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.3333333333333335 / 4  (58.3):  10%| | 3/30 [00:00<00:02,  9.82it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.8333333333333335 / 5  (56.7):  13%|▏| 4/30 [00:00<00:02,  9.82it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.8333333333333335 / 6  (63.9):  17%|▏| 5/30 [00:00<00:02,  9.82it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.8333333333333335 / 7  (54.8):  20%|▏| 6/30 [00:00<00:02,  9.82it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.8333333333333335 / 7  (54.8):  23%|▏| 7/30 [00:00<00:00, 38.25it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.133333333333334 / 8  (51.7):  23%|▏| 7/30 [00:00<00:00, 38.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.466666666666667 / 9  (49.6):  27%|▎| 8/30 [00:00<00:00, 38.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.133333333333334 / 10  (51.3):  30%|▎| 9/30 [00:00<00:00, 38.25it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.633333333333334 / 11  (51.2):  33%|▎| 10/30 [00:00<00:00, 38.25it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.633333333333334 / 12  (46.9):  37%|▎| 11/30 [00:00<00:00, 38.25it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.133333333333334 / 13  (47.2):  40%|▍| 12/30 [00:00<00:00, 38.25it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.133333333333334 / 13  (47.2):  43%|▍| 13/30 [00:00<00:00, 40.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.466666666666667 / 14  (46.2):  43%|▍| 13/30 [00:00<00:00, 40.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.216666666666667 / 15  (48.1):  47%|▍| 14/30 [00:00<00:00, 40.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.216666666666667 / 16  (51.4):  50%|▌| 15/30 [00:00<00:00, 40.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.466666666666667 / 17  (49.8):  53%|▌| 16/30 [00:00<00:00, 40.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.8 / 18  (48.9):  57%|███████▎     | 17/30 [00:00<00:00, 40.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.8 / 19  (51.6):  60%|███████▊     | 18/30 [00:00<00:00, 40.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.8 / 19  (51.6):  63%|████████▏    | 19/30 [00:00<00:00, 37.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.8 / 20  (49.0):  63%|████████▏    | 19/30 [00:00<00:00, 37.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.8 / 21  (51.4):  67%|████████    | 20/30 [00:00<00:00, 37.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.3 / 22  (51.4):  70%|████████▍   | 21/30 [00:00<00:00, 37.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.633333333333335 / 23  (50.6):  73%|▋| 22/30 [00:00<00:00, 37.27it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.383333333333335 / 24  (51.6):  77%|▊| 23/30 [00:00<00:00, 37.27it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.383333333333335 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 37.27it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.383333333333335 / 25  (53.5):  83%|▊| 25/30 [00:00<00:00, 38.59it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.383333333333335 / 26  (51.5):  83%|▊| 25/30 [00:00<00:00, 38.59it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.883333333333335 / 27  (51.4):  87%|▊| 26/30 [00:00<00:00, 38.59it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.883333333333335 / 28  (53.2):  90%|▉| 27/30 [00:00<00:00, 38.59it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.883333333333335 / 29  (51.3):  93%|▉| 28/30 [00:00<00:00, 38.59it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.633333333333335 / 30  (52.1): 100%|█| 30/30 [00:00<00:00, 43.04it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.633333333333335 / 30  (52.1%)\n",
      "Score: 52.11 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92, 62.61, 52.11]\n",
      "Best score: 62.61\n",
      "Average of max per entry across top 1 scores: 0.6261111111111111\n",
      "Average of max per entry across top 2 scores: 0.7694444444444445\n",
      "Average of max per entry across top 3 scores: 0.8544444444444445\n",
      "Average of max per entry across top 5 scores: 0.9225\n",
      "Average of max per entry across top 8 scores: 0.9508333333333334\n",
      "Average of max per entry across top 9999 scores: 0.9508333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|██████▍                                         | 4/30 [00:00<00:00, 35.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|████████████▊                                   | 8/30 [00:00<00:00, 34.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████████████████████████                      | 16/30 [00:00<00:00, 35.49it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:00<00:02, 10.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:00<00:01, 19.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:00<00:01, 19.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):  10%| | 3/30 [00:00<00:01, 19.50it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):  13%|▏| 4/30 [00:00<00:01, 19.50it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.833333333333333 / 6  (47.2):  17%|▏| 5/30 [00:00<00:01, 19.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.833333333333333 / 7  (40.5):  20%|▏| 6/30 [00:00<00:01, 19.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.833333333333333 / 7  (40.5):  23%|▏| 7/30 [00:00<00:00, 33.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.133333333333333 / 8  (39.2):  23%|▏| 7/30 [00:00<00:00, 33.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4333333333333327 / 9  (38.1):  27%|▎| 8/30 [00:00<00:00, 33.73it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4333333333333327 / 10  (34.3):  30%|▎| 9/30 [00:00<00:00, 33.73it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.1 / 11  (37.3):  33%|████▎        | 10/30 [00:00<00:00, 33.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.433333333333333 / 12  (36.9):  37%|▎| 11/30 [00:00<00:00, 33.73it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.933333333333333 / 13  (37.9):  40%|▍| 12/30 [00:00<00:00, 33.73it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.933333333333333 / 13  (37.9):  43%|▍| 13/30 [00:00<00:00, 44.22it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.933333333333333 / 14  (42.4):  43%|▍| 13/30 [00:00<00:00, 44.22it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.933333333333333 / 15  (46.2):  47%|▍| 14/30 [00:00<00:00, 44.22it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.683333333333333 / 16  (48.0):  50%|▌| 15/30 [00:00<00:00, 44.22it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.883333333333333 / 17  (46.4):  53%|▌| 16/30 [00:00<00:00, 44.22it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.383333333333333 / 18  (46.6):  57%|▌| 17/30 [00:00<00:00, 44.22it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.383333333333333 / 19  (44.1):  60%|▌| 18/30 [00:00<00:00, 44.22it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.383333333333333 / 19  (44.1):  63%|▋| 19/30 [00:00<00:00, 44.16it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.883333333333333 / 20  (44.4):  63%|▋| 19/30 [00:00<00:00, 44.16it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.883333333333333 / 21  (42.3):  67%|▋| 20/30 [00:00<00:00, 44.16it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.883333333333333 / 22  (44.9):  70%|▋| 21/30 [00:00<00:00, 44.16it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.483333333333333 / 23  (45.6):  73%|▋| 22/30 [00:00<00:00, 44.16it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.233333333333333 / 24  (46.8):  77%|▊| 23/30 [00:00<00:00, 44.16it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.233333333333333 / 25  (44.9):  80%|▊| 24/30 [00:00<00:00, 44.16it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.233333333333333 / 25  (44.9):  83%|▊| 25/30 [00:00<00:00, 48.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.733333333333333 / 26  (45.1):  83%|▊| 25/30 [00:00<00:00, 48.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.733333333333333 / 27  (47.2):  87%|▊| 26/30 [00:00<00:00, 48.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.733333333333333 / 28  (49.0):  90%|▉| 27/30 [00:00<00:00, 48.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.733333333333333 / 29  (50.8):  93%|▉| 28/30 [00:00<00:00, 48.82it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.733333333333333 / 30  (52.4): 100%|█| 30/30 [00:00<00:00, 51.59it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.733333333333333 / 30  (52.4%)\n",
      "Score: 52.44 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92, 62.61, 52.11, 52.44]\n",
      "Best score: 62.61\n",
      "Average of max per entry across top 1 scores: 0.6261111111111111\n",
      "Average of max per entry across top 2 scores: 0.7694444444444445\n",
      "Average of max per entry across top 3 scores: 0.8544444444444445\n",
      "Average of max per entry across top 5 scores: 0.9183333333333333\n",
      "Average of max per entry across top 8 scores: 0.9441666666666666\n",
      "Average of max per entry across top 9999 scores: 0.9508333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 56.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|██████████████████▊                            | 12/30 [00:00<00:00, 56.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|██████████████████████████████████▍            | 22/30 [00:00<00:00, 48.63it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 23 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.4 / 1  (40.0):   0%|                       | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.4 / 1  (40.0):   3%|▌              | 1/30 [00:00<00:03,  8.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.7333333333333334 / 2  (36.7):   3%| | 1/30 [00:00<00:03,  8.24it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.7333333333333334 / 3  (24.4):   7%| | 2/30 [00:00<00:03,  8.24it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.7333333333333334 / 4  (18.3):  10%| | 3/30 [00:00<00:03,  8.24it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.2333333333333334 / 5  (24.7):  13%|▏| 4/30 [00:00<00:03,  8.24it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2333333333333334 / 6  (37.2):  17%|▏| 5/30 [00:00<00:03,  8.24it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):  20%|▏| 6/30 [00:00<00:02,  8.24it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):  23%|▏| 7/30 [00:00<00:00, 33.61it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.8333333333333335 / 8  (35.4):  23%|▏| 7/30 [00:00<00:00, 33.61it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.5 / 9  (38.9):  27%|████           | 8/30 [00:00<00:00, 33.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.5 / 10  (35.0):  30%|████▏         | 9/30 [00:00<00:00, 33.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.8333333333333335 / 11  (34.8):  33%|▎| 10/30 [00:00<00:00, 33.61it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.133333333333334 / 12  (34.4):  37%|▎| 11/30 [00:00<00:00, 33.61it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.133333333333334 / 13  (31.8):  40%|▍| 12/30 [00:00<00:00, 33.61it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.133333333333334 / 13  (31.8):  43%|▍| 13/30 [00:00<00:00, 42.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.133333333333334 / 14  (36.7):  43%|▍| 13/30 [00:00<00:00, 42.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.883333333333334 / 15  (39.2):  47%|▍| 14/30 [00:00<00:00, 42.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.883333333333334 / 16  (43.0):  50%|▌| 15/30 [00:00<00:00, 42.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.383333333333334 / 17  (43.4):  53%|▌| 16/30 [00:00<00:00, 42.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.383333333333333 / 18  (46.6):  57%|▌| 17/30 [00:00<00:00, 42.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.383333333333333 / 19  (44.1):  60%|▌| 18/30 [00:00<00:00, 42.08it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.383333333333333 / 19  (44.1):  63%|▋| 19/30 [00:00<00:00, 44.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.633333333333333 / 20  (43.2):  63%|▋| 19/30 [00:00<00:00, 44.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.633333333333333 / 21  (41.1):  67%|▋| 20/30 [00:00<00:00, 44.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.133333333333333 / 22  (41.5):  70%|▋| 21/30 [00:00<00:00, 44.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.633333333333333 / 23  (41.9):  73%|▋| 22/30 [00:00<00:00, 44.93it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.383333333333333 / 24  (43.3):  77%|▊| 23/30 [00:00<00:00, 44.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.383333333333333 / 25  (41.5):  80%|▊| 24/30 [00:00<00:00, 44.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.383333333333333 / 25  (41.5):  83%|▊| 25/30 [00:00<00:00, 48.46it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.383333333333333 / 26  (43.8):  83%|▊| 25/30 [00:00<00:00, 48.46it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.883333333333333 / 27  (44.0):  87%|▊| 26/30 [00:00<00:00, 48.46it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.883333333333333 / 28  (46.0):  90%|▉| 27/30 [00:00<00:00, 48.46it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.633333333333333 / 29  (47.0):  93%|▉| 28/30 [00:00<00:00, 48.46it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.633333333333333 / 30  (48.8): 100%|█| 30/30 [00:00<00:00, 49.04it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.633333333333333 / 30  (48.8%)\n",
      "Score: 48.78 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92, 62.61, 52.11, 52.44, 48.78]\n",
      "Best score: 62.61\n",
      "Average of max per entry across top 1 scores: 0.6261111111111111\n",
      "Average of max per entry across top 2 scores: 0.7694444444444445\n",
      "Average of max per entry across top 3 scores: 0.8544444444444445\n",
      "Average of max per entry across top 5 scores: 0.9183333333333333\n",
      "Average of max per entry across top 8 scores: 0.9441666666666666\n",
      "Average of max per entry across top 9999 scores: 0.9508333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███████████████▋                               | 10/30 [00:00<00:00, 52.76it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.6666666666666666 / 1  (66.7):   0%|        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.9166666666666666 / 2  (45.8):   3%| | 1/30 [00:00<00:02, 10.88it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.9166666666666666 / 2  (45.8):   7%| | 2/30 [00:00<00:01, 19.81it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.1166666666666667 / 3  (37.2):   7%| | 2/30 [00:00<00:01, 19.81it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.1166666666666667 / 4  (52.9):  10%| | 3/30 [00:00<00:01, 19.81it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.1166666666666667 / 5  (42.3):  13%|▏| 4/30 [00:00<00:01, 19.81it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.1166666666666667 / 6  (35.3):  17%|▏| 5/30 [00:00<00:01, 19.81it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.1166666666666667 / 7  (30.2):  20%|▏| 6/30 [00:00<00:01, 19.81it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.6166666666666667 / 8  (32.7):  23%|▏| 7/30 [00:00<00:01, 19.81it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.6166666666666667 / 8  (32.7):  27%|▎| 8/30 [00:00<00:00, 40.39it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.9166666666666665 / 9  (32.4):  27%|▎| 8/30 [00:00<00:00, 40.39it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4166666666666665 / 10  (34.2):  30%|▎| 9/30 [00:00<00:00, 40.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4166666666666665 / 11  (31.1):  33%|▎| 10/30 [00:00<00:00, 40.39it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4166666666666665 / 12  (28.5):  37%|▎| 11/30 [00:00<00:00, 40.39it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.75 / 13  (28.8):  40%|████▊       | 12/30 [00:00<00:00, 40.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.75 / 13  (28.8):  43%|█████▏      | 13/30 [00:00<00:00, 44.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.083333333333333 / 14  (29.2):  43%|▍| 13/30 [00:00<00:00, 44.10it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.583333333333333 / 15  (30.6):  47%|▍| 14/30 [00:00<00:00, 44.10it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.583333333333333 / 16  (34.9):  50%|▌| 15/30 [00:00<00:00, 44.10it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.583333333333333 / 17  (38.7):  53%|▌| 16/30 [00:00<00:00, 44.10it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.783333333333333 / 18  (37.7):  57%|▌| 17/30 [00:00<00:00, 44.10it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.783333333333333 / 19  (35.7):  60%|▌| 18/30 [00:00<00:00, 44.10it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.783333333333333 / 19  (35.7):  63%|▋| 19/30 [00:00<00:00, 46.54it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.783333333333333 / 20  (33.9):  63%|▋| 19/30 [00:00<00:00, 46.54it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.283333333333333 / 21  (34.7):  67%|▋| 20/30 [00:00<00:00, 46.54it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.616666666666666 / 22  (34.6):  70%|▋| 21/30 [00:00<00:00, 46.54it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.616666666666666 / 23  (33.1):  73%|▋| 22/30 [00:00<00:00, 46.54it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.616666666666667 / 24  (35.9):  77%|▊| 23/30 [00:00<00:00, 46.54it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.616666666666667 / 25  (34.5):  80%|▊| 24/30 [00:00<00:00, 46.54it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.616666666666667 / 25  (34.5):  83%|▊| 25/30 [00:00<00:00, 49.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.116666666666667 / 26  (35.1):  83%|▊| 25/30 [00:00<00:00, 49.47it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.116666666666667 / 27  (37.5):  87%|▊| 26/30 [00:00<00:00, 49.47it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.116666666666667 / 28  (36.1):  90%|▉| 27/30 [00:00<00:00, 49.47it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.116666666666667 / 29  (38.3):  93%|▉| 28/30 [00:00<00:00, 49.47it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.116666666666667 / 30  (40.4): 100%|█| 30/30 [00:00<00:00, 54.06it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.116666666666667 / 30  (40.4%)\n",
      "Score: 40.39 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92, 62.61, 52.11, 52.44, 48.78, 40.39]\n",
      "Best score: 62.61\n",
      "Average of max per entry across top 1 scores: 0.6261111111111111\n",
      "Average of max per entry across top 2 scores: 0.7694444444444445\n",
      "Average of max per entry across top 3 scores: 0.8544444444444445\n",
      "Average of max per entry across top 5 scores: 0.9183333333333333\n",
      "Average of max per entry across top 8 scores: 0.9441666666666666\n",
      "Average of max per entry across top 9999 scores: 0.9508333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 13%|██████▍                                         | 4/30 [00:00<00:00, 49.31it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.25 / 2  (62.5):   3%|▍             | 1/30 [00:00<00:02, 11.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.65 / 3  (55.0):   7%|▉             | 2/30 [00:00<00:01, 21.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.65 / 3  (55.0):  10%|█▍            | 3/30 [00:00<00:00, 29.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.65 / 4  (66.2):  10%|█▍            | 3/30 [00:00<00:00, 29.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.9833333333333334 / 5  (59.7):  13%|▏| 4/30 [00:00<00:00, 29.26it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.9833333333333334 / 6  (49.7):  17%|▏| 5/30 [00:00<00:00, 29.26it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4833333333333334 / 7  (49.8):  20%|▏| 6/30 [00:00<00:00, 29.26it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.4833333333333334 / 7  (49.8):  23%|▏| 7/30 [00:00<00:00, 32.68it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.783333333333333 / 8  (47.3):  23%|▏| 7/30 [00:00<00:00, 32.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.383333333333333 / 9  (48.7):  27%|▎| 8/30 [00:00<00:00, 32.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.383333333333333 / 10  (43.8):  30%|▎| 9/30 [00:00<00:00, 32.68it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.716666666666666 / 11  (42.9):  33%|▎| 10/30 [00:00<00:00, 32.68it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.716666666666666 / 12  (39.3):  37%|▎| 11/30 [00:00<00:00, 32.68it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.216666666666666 / 13  (40.1):  40%|▍| 12/30 [00:00<00:00, 32.68it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.216666666666666 / 13  (40.1):  43%|▍| 13/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.466666666666666 / 14  (39.0):  43%|▍| 13/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.799999999999999 / 15  (38.7):  47%|▍| 14/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.799999999999999 / 16  (42.5):  50%|▌| 15/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.966666666666666 / 17  (41.0):  53%|▌| 16/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.299999999999999 / 18  (40.6):  57%|▌| 17/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.799999999999999 / 19  (41.1):  60%|▌| 18/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.799999999999999 / 19  (41.1):  63%|▋| 19/30 [00:00<00:00, 45.51it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.799999999999999 / 20  (39.0):  63%|▋| 19/30 [00:00<00:00, 45.51it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.799999999999999 / 21  (37.1):  67%|▋| 20/30 [00:00<00:00, 45.51it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.133333333333333 / 22  (37.0):  70%|▋| 21/30 [00:00<00:00, 45.51it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.533333333333333 / 23  (37.1):  73%|▋| 22/30 [00:00<00:00, 45.51it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.283333333333333 / 24  (38.7):  77%|▊| 23/30 [00:00<00:00, 45.51it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.283333333333333 / 25  (37.1):  80%|▊| 24/30 [00:00<00:00, 45.51it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.283333333333333 / 25  (37.1):  83%|▊| 25/30 [00:00<00:00, 48.87it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.283333333333333 / 26  (39.6):  83%|▊| 25/30 [00:00<00:00, 48.87it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.783333333333333 / 27  (39.9):  87%|▊| 26/30 [00:00<00:00, 48.87it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.783333333333333 / 28  (42.1):  90%|▉| 27/30 [00:00<00:00, 48.87it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.783333333333333 / 29  (40.6):  93%|▉| 28/30 [00:00<00:00, 48.87it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.783333333333333 / 30  (42.6): 100%|█| 30/30 [00:00<00:00, 53.08it\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.783333333333333 / 30  (42.6%)\n",
      "Score: 42.61 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92, 62.61, 52.11, 52.44, 48.78, 40.39, 42.61]\n",
      "Best score: 62.61\n",
      "Average of max per entry across top 1 scores: 0.6261111111111111\n",
      "Average of max per entry across top 2 scores: 0.7694444444444445\n",
      "Average of max per entry across top 3 scores: 0.8544444444444445\n",
      "Average of max per entry across top 5 scores: 0.9183333333333333\n",
      "Average of max per entry across top 8 scores: 0.9441666666666666\n",
      "Average of max per entry across top 9999 scores: 0.9508333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███████████████▋                               | 10/30 [00:00<00:00, 50.02it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.2857142857142856 / 2  (64.3):   3%| | 1/30 [00:00<00:02, 10.73it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.2857142857142856 / 2  (64.3):   7%| | 2/30 [00:00<00:01, 19.10it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2857142857142856 / 3  (76.2):   7%| | 2/30 [00:00<00:01, 19.10it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.2857142857142856 / 4  (57.1):  10%| | 3/30 [00:00<00:01, 19.10it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.2857142857142856 / 5  (65.7):  13%|▏| 4/30 [00:00<00:01, 19.10it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.619047619047619 / 6  (60.3):  17%|▏| 5/30 [00:00<00:01, 19.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.619047619047619 / 7  (51.7):  20%|▏| 6/30 [00:00<00:01, 19.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.619047619047619 / 7  (51.7):  23%|▏| 7/30 [00:00<00:00, 33.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.9523809523809526 / 8  (49.4):  23%|▏| 7/30 [00:00<00:00, 33.29it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.152380952380953 / 9  (46.1):  27%|▎| 8/30 [00:00<00:00, 33.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.152380952380953 / 10  (41.5):  30%|▎| 9/30 [00:00<00:00, 33.29it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.652380952380953 / 11  (42.3):  33%|▎| 10/30 [00:00<00:00, 33.29it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.31904761904762 / 12  (44.3):  37%|▎| 11/30 [00:00<00:00, 33.29it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.81904761904762 / 13  (44.8):  40%|▍| 12/30 [00:00<00:00, 33.29it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.81904761904762 / 13  (44.8):  43%|▍| 13/30 [00:00<00:00, 43.35it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.152380952380953 / 14  (43.9):  43%|▍| 13/30 [00:00<00:00, 43.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.485714285714286 / 15  (43.2):  47%|▍| 14/30 [00:00<00:00, 43.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.819047619047619 / 16  (42.6):  50%|▌| 15/30 [00:00<00:00, 43.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.819047619047619 / 17  (46.0):  53%|▌| 16/30 [00:00<00:00, 43.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.152380952380952 / 18  (45.3):  57%|▌| 17/30 [00:00<00:00, 43.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.652380952380952 / 19  (45.5):  60%|▌| 18/30 [00:00<00:00, 43.35it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.652380952380952 / 19  (45.5):  63%|▋| 19/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.652380952380952 / 20  (43.3):  63%|▋| 19/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.985714285714286 / 21  (42.8):  67%|▋| 20/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.235714285714286 / 22  (42.0):  70%|▋| 21/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.735714285714286 / 23  (42.3):  73%|▋| 22/30 [00:00<00:00, 42.53it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.485714285714286 / 24  (43.7):  77%|▊| 23/30 [00:00<00:00, 42.53it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.485714285714286 / 25  (41.9):  80%|▊| 24/30 [00:00<00:00, 42.53it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.485714285714286 / 25  (41.9):  83%|▊| 25/30 [00:00<00:00, 45.95it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.985714285714286 / 26  (42.3):  83%|▊| 25/30 [00:00<00:00, 45.95it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.985714285714286 / 27  (40.7):  87%|▊| 26/30 [00:00<00:00, 45.95it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.985714285714286 / 28  (42.8):  90%|▉| 27/30 [00:00<00:00, 45.95it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.985714285714286 / 29  (44.8):  93%|▉| 28/30 [00:00<00:00, 45.95it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.735714285714286 / 30  (45.8): 100%|█| 30/30 [00:00<00:00, 49.95it\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.735714285714286 / 30  (45.8%)\n",
      "Score: 45.79 for set: [16, 16, 16]\n",
      "Scores so far: [27.96, 51.33, 45.78, 48.22, 47.11, 49.83, 44.36, 54.28, 55.73, 51.97, 50.83, 50.92, 62.61, 52.11, 52.44, 48.78, 40.39, 42.61, 45.79]\n",
      "Best score: 62.61\n",
      "Average of max per entry across top 1 scores: 0.6261111111111111\n",
      "Average of max per entry across top 2 scores: 0.7694444444444445\n",
      "Average of max per entry across top 3 scores: 0.8544444444444445\n",
      "Average of max per entry across top 5 scores: 0.9183333333333333\n",
      "Average of max per entry across top 8 scores: 0.9441666666666666\n",
      "Average of max per entry across top 9999 scores: 0.9522222222222222\n",
      "19 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "optimizer = BootstrapFewShotWithRandomSearch(metric=validate_venn, metric_threshold=0.8)\n",
    "compiled_pipeline = optimizer.compile(ABSAPipelineV2(), teacher=ABSAPipelineV2(), trainset=dspy_train[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f3e91937-0dcf-4c84-898e-0495ee9ffd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.4 / 1  (40.0):   0%|                      | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.4 / 1  (40.0):   1%|▏             | 1/100 [00:00<00:15,  6.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.4 / 2  (20.0):   1%|▏             | 1/100 [00:00<00:15,  6.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.9714285714285714 / 3  (32.4):   2%| | 2/100 [00:00<00:15,  6.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.3047619047619048 / 4  (32.6):   3%| | 3/100 [00:00<00:15,  6.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.8047619047619048 / 5  (36.1):   4%| | 4/100 [00:00<00:15,  6.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.3047619047619046 / 6  (38.4):   5%| | 5/100 [00:00<00:14,  6.39it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.3047619047619046 / 6  (38.4):   6%| | 6/100 [00:00<00:03, 26.68it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.138095238095238 / 7  (44.8):   6%| | 6/100 [00:00<00:03, 26.68it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.138095238095238 / 8  (51.7):   7%| | 7/100 [00:00<00:03, 26.68it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.138095238095238 / 9  (46.0):   8%| | 8/100 [00:00<00:03, 26.68it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.388095238095238 / 10  (43.9):   9%| | 9/100 [00:00<00:03, 26.68it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.388095238095238 / 11  (49.0):  10%| | 10/100 [00:00<00:03, 26.68it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.388095238095238 / 11  (49.0):  11%| | 11/100 [00:00<00:02, 34.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.188095238095237 / 12  (51.6):  11%| | 11/100 [00:00<00:02, 34.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.188095238095237 / 13  (55.3):  12%| | 12/100 [00:00<00:02, 34.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.854761904761904 / 14  (56.1):  13%|▏| 13/100 [00:00<00:02, 34.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.52142857142857 / 15  (56.8):  14%|▏| 14/100 [00:00<00:02, 34.07it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.52142857142857 / 15  (56.8):  15%|▏| 15/100 [00:00<00:02, 35.11it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.52142857142857 / 16  (53.3):  15%|▏| 15/100 [00:00<00:02, 35.11it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.52142857142857 / 17  (56.0):  16%|▏| 16/100 [00:00<00:02, 35.11it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.52142857142857 / 18  (52.9):  17%|▏| 17/100 [00:00<00:02, 35.11it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.02142857142857 / 19  (52.7):  18%|▏| 18/100 [00:00<00:02, 35.11it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.02142857142857 / 19  (52.7):  19%|▏| 19/100 [00:00<00:02, 36.23it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.02142857142857 / 20  (50.1):  19%|▏| 19/100 [00:00<00:02, 36.23it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.878571428571428 / 21  (51.8):  20%|▏| 20/100 [00:00<00:02, 36.23i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.545238095238094 / 22  (52.5):  21%|▏| 21/100 [00:00<00:02, 36.23i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.545238095238094 / 23  (54.5):  22%|▏| 22/100 [00:00<00:02, 36.23i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.545238095238094 / 24  (52.3):  23%|▏| 23/100 [00:00<00:02, 36.23i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.545238095238094 / 25  (54.2):  24%|▏| 24/100 [00:00<00:02, 36.23i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.545238095238094 / 25  (54.2):  25%|▎| 25/100 [00:00<00:01, 42.21i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.295238095238094 / 26  (55.0):  25%|▎| 25/100 [00:00<00:01, 42.21i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.295238095238094 / 27  (56.6):  26%|▎| 26/100 [00:00<00:01, 42.21i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.295238095238094 / 28  (58.2):  27%|▎| 27/100 [00:00<00:01, 42.21i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.295238095238094 / 29  (56.2):  28%|▎| 28/100 [00:00<00:01, 42.21i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 17.295238095238094 / 30  (57.7):  29%|▎| 29/100 [00:00<00:01, 42.21i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 17.295238095238094 / 30  (57.7):  30%|▎| 30/100 [00:00<00:01, 43.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.295238095238094 / 31  (59.0):  30%|▎| 30/100 [00:00<00:01, 43.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.295238095238094 / 32  (57.2):  31%|▎| 31/100 [00:00<00:01, 43.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.795238095238094 / 33  (57.0):  32%|▎| 32/100 [00:00<00:01, 43.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.795238095238094 / 34  (55.3):  33%|▎| 33/100 [00:00<00:01, 43.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 19.295238095238094 / 35  (55.1):  34%|▎| 34/100 [00:00<00:01, 43.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 19.295238095238094 / 35  (55.1):  35%|▎| 35/100 [00:00<00:01, 43.08i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 19.295238095238094 / 36  (53.6):  35%|▎| 35/100 [00:00<00:01, 43.08i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 19.295238095238094 / 37  (52.1):  36%|▎| 36/100 [00:00<00:01, 43.08i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 20.295238095238094 / 38  (53.4):  37%|▎| 37/100 [00:00<00:01, 43.08i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 21.295238095238094 / 39  (54.6):  38%|▍| 38/100 [00:01<00:01, 43.08i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.295238095238094 / 40  (55.7):  39%|▍| 39/100 [00:01<00:01, 43.08i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.295238095238094 / 40  (55.7):  40%|▍| 40/100 [00:01<00:01, 43.42i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 23.295238095238094 / 41  (56.8):  40%|▍| 40/100 [00:01<00:01, 43.42i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 23.695238095238093 / 42  (56.4):  41%|▍| 41/100 [00:01<00:01, 43.42i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 24.695238095238093 / 43  (57.4):  42%|▍| 42/100 [00:01<00:01, 43.42i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.695238095238093 / 44  (58.4):  43%|▍| 43/100 [00:01<00:01, 43.42i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.695238095238093 / 45  (59.3):  44%|▍| 44/100 [00:01<00:01, 43.42i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.195238095238093 / 46  (59.1):  45%|▍| 45/100 [00:01<00:01, 43.42i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.195238095238093 / 46  (59.1):  46%|▍| 46/100 [00:01<00:01, 44.74i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.995238095238093 / 47  (59.6):  46%|▍| 46/100 [00:01<00:01, 44.74i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 28.66190476190476 / 48  (59.7):  47%|▍| 47/100 [00:01<00:01, 44.74it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 29.66190476190476 / 49  (60.5):  48%|▍| 48/100 [00:01<00:01, 44.74it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 30.06190476190476 / 50  (60.1):  49%|▍| 49/100 [00:01<00:01, 44.74it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 30.06190476190476 / 51  (58.9):  50%|▌| 50/100 [00:01<00:01, 44.74it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 30.06190476190476 / 51  (58.9):  51%|▌| 51/100 [00:01<00:01, 44.20it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 30.728571428571428 / 52  (59.1):  51%|▌| 51/100 [00:01<00:01, 44.20i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.06190476190476 / 53  (58.6):  52%|▌| 52/100 [00:01<00:01, 44.20it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.56190476190476 / 54  (58.4):  53%|▌| 53/100 [00:01<00:01, 44.20it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 32.561904761904756 / 55  (59.2):  54%|▌| 54/100 [00:01<00:01, 44.20i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 32.561904761904756 / 56  (58.1):  55%|▌| 55/100 [00:01<00:01, 44.20i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 32.561904761904756 / 56  (58.1):  56%|▌| 56/100 [00:01<00:01, 42.86i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.561904761904756 / 57  (58.9):  56%|▌| 56/100 [00:01<00:01, 42.86i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.36190476190475 / 58  (59.2):  57%|▌| 57/100 [00:01<00:01, 42.86it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.36190476190475 / 59  (58.2):  58%|▌| 58/100 [00:01<00:00, 42.86it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.36190476190475 / 60  (57.3):  59%|▌| 59/100 [00:01<00:00, 42.86it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.36190476190475 / 61  (56.3):  60%|▌| 60/100 [00:01<00:00, 42.86it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.36190476190475 / 61  (56.3):  61%|▌| 61/100 [00:01<00:00, 41.88it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 35.16190476190475 / 62  (56.7):  61%|▌| 61/100 [00:01<00:00, 41.88it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.16190476190475 / 63  (57.4):  62%|▌| 62/100 [00:01<00:00, 41.88it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.16190476190475 / 64  (56.5):  63%|▋| 63/100 [00:01<00:00, 41.88it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.495238095238086 / 65  (56.1):  64%|▋| 64/100 [00:01<00:00, 41.88i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.495238095238086 / 66  (55.3):  65%|▋| 65/100 [00:01<00:00, 41.88i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.895238095238085 / 67  (55.1):  66%|▋| 66/100 [00:01<00:00, 41.88i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.895238095238085 / 67  (55.1):  67%|▋| 67/100 [00:01<00:00, 45.71i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 37.25887445887445 / 68  (54.8):  67%|▋| 67/100 [00:01<00:00, 45.71it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 38.25887445887445 / 69  (55.4):  68%|▋| 68/100 [00:01<00:00, 45.71it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 38.25887445887445 / 70  (54.7):  69%|▋| 69/100 [00:01<00:00, 45.71it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 39.25887445887445 / 71  (55.3):  70%|▋| 70/100 [00:01<00:00, 45.71it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.25887445887445 / 72  (55.9):  71%|▋| 71/100 [00:01<00:00, 45.71it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.25887445887445 / 72  (55.9):  72%|▋| 72/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 41.25887445887445 / 73  (56.5):  72%|▋| 72/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 41.25887445887445 / 74  (55.8):  73%|▋| 73/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.25887445887445 / 75  (56.3):  74%|▋| 74/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.25887445887445 / 76  (55.6):  75%|▊| 75/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.83030303030302 / 77  (55.6):  76%|▊| 76/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.83030303030302 / 78  (54.9):  77%|▊| 77/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 43.05252525252524 / 79  (54.5):  78%|▊| 78/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 44.05252525252524 / 80  (55.1):  79%|▊| 79/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 44.45252525252524 / 81  (54.9):  80%|▊| 80/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 44.45252525252524 / 82  (54.2):  81%|▊| 81/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 45.309668109668095 / 83  (54.6):  82%|▊| 82/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 46.309668109668095 / 84  (55.1):  83%|▊| 83/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 47.309668109668095 / 85  (55.7):  84%|▊| 84/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 48.309668109668095 / 86  (56.2):  85%|▊| 85/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 48.97633477633476 / 87  (56.3):  86%|▊| 86/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 48.97633477633476 / 88  (55.7):  87%|▊| 87/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 49.97633477633476 / 89  (56.2):  88%|▉| 88/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 50.643001443001424 / 90  (56.3):  89%|▉| 89/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 51.143001443001424 / 91  (56.2):  90%|▉| 90/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 51.643001443001424 / 92  (56.1):  91%|▉| 91/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 52.643001443001424 / 93  (56.6):  92%|▉| 92/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 52.643001443001424 / 94  (56.0):  93%|▉| 93/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 53.393001443001424 / 95  (56.2):  94%|▉| 94/100 [00:01<00:00, 43.03i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 53.72633477633476 / 96  (56.0):  95%|▉| 95/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 53.72633477633476 / 97  (55.4):  96%|▉| 96/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 53.72633477633476 / 98  (54.8):  97%|▉| 97/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 54.12633477633476 / 99  (54.7):  98%|▉| 98/100 [00:01<00:00, 43.03it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 54.79300144300142 / 100  (54.8): 100%|█| 100/100 [00:01<00:00, 54.49\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 54.79300144300142 / 100  (54.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.8333333333333334' '0.0' '0.4' '0.0' '0.5']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_84a28 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_84a28 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_84a28_row0_col0, #T_84a28_row0_col1, #T_84a28_row0_col2, #T_84a28_row0_col3, #T_84a28_row0_col4, #T_84a28_row1_col0, #T_84a28_row1_col1, #T_84a28_row1_col2, #T_84a28_row1_col3, #T_84a28_row1_col4, #T_84a28_row2_col0, #T_84a28_row2_col1, #T_84a28_row2_col2, #T_84a28_row2_col3, #T_84a28_row2_col4, #T_84a28_row3_col0, #T_84a28_row3_col1, #T_84a28_row3_col2, #T_84a28_row3_col3, #T_84a28_row3_col4, #T_84a28_row4_col0, #T_84a28_row4_col1, #T_84a28_row4_col2, #T_84a28_row4_col3, #T_84a28_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_84a28\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_84a28_level0_col0\" class=\"col_heading level0 col0\" >review</th>\n",
       "      <th id=\"T_84a28_level0_col1\" class=\"col_heading level0 col1\" >example_aspects_with_label</th>\n",
       "      <th id=\"T_84a28_level0_col2\" class=\"col_heading level0 col2\" >aspects_list</th>\n",
       "      <th id=\"T_84a28_level0_col3\" class=\"col_heading level0 col3\" >pred_aspects_with_label</th>\n",
       "      <th id=\"T_84a28_level0_col4\" class=\"col_heading level0 col4\" >validate_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_84a28_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_84a28_row0_col0\" class=\"data row0 col0\" >\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.</td>\n",
       "      <td id=\"T_84a28_row0_col1\" class=\"data row0 col1\" >{'menu': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'pub fare': 0}</td>\n",
       "      <td id=\"T_84a28_row0_col2\" class=\"data row0 col2\" >dict_keys(['menu', 'burgers', 'steaks', 'shepherds pie', 'portabella lasagna', 'pub fare'])</td>\n",
       "      <td id=\"T_84a28_row0_col3\" class=\"data row0 col3\" >{'menu': 0, 'pub fare': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 1, 'vegetarians': 1}</td>\n",
       "      <td id=\"T_84a28_row0_col4\" class=\"data row0 col4\" >0.8333333333333334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84a28_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_84a28_row1_col0\" class=\"data row1 col0\" >(The sashimi is cut a little thinly.</td>\n",
       "      <td id=\"T_84a28_row1_col1\" class=\"data row1 col1\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_84a28_row1_col2\" class=\"data row1 col2\" >dict_keys(['sashimi'])</td>\n",
       "      <td id=\"T_84a28_row1_col3\" class=\"data row1 col3\" >{'sashimi': 0}</td>\n",
       "      <td id=\"T_84a28_row1_col4\" class=\"data row1 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84a28_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_84a28_row2_col0\" class=\"data row2 col0\" >) It's not the best Japanese restaurant in the East Village, but it's a pretty solid one for its modest prices, and worth repeat visits.</td>\n",
       "      <td id=\"T_84a28_row2_col1\" class=\"data row2 col1\" >{'prices': 1}</td>\n",
       "      <td id=\"T_84a28_row2_col2\" class=\"data row2 col2\" >dict_keys(['prices'])</td>\n",
       "      <td id=\"T_84a28_row2_col3\" class=\"data row2 col3\" >{'Japanese restaurant': 0, 'East Village': 0, 'prices': 1, 'repeat visits': 1}</td>\n",
       "      <td id=\"T_84a28_row2_col4\" class=\"data row2 col4\" >0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84a28_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_84a28_row3_col0\" class=\"data row3 col0\" >15% gratuity automatically added to the bill.</td>\n",
       "      <td id=\"T_84a28_row3_col1\" class=\"data row3 col1\" >{'bill': -1, 'gratuity': -1}</td>\n",
       "      <td id=\"T_84a28_row3_col2\" class=\"data row3 col2\" >dict_keys(['bill', 'gratuity'])</td>\n",
       "      <td id=\"T_84a28_row3_col3\" class=\"data row3 col3\" >{'gratuity': 0, 'bill': 0}</td>\n",
       "      <td id=\"T_84a28_row3_col4\" class=\"data row3 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_84a28_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_84a28_row4_col0\" class=\"data row4 col0\" >A beautiful atmosphere, perfect for drinks and/or appetizers.</td>\n",
       "      <td id=\"T_84a28_row4_col1\" class=\"data row4 col1\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_84a28_row4_col2\" class=\"data row4 col2\" >dict_keys(['atmosphere', 'drinks', 'appetizers'])</td>\n",
       "      <td id=\"T_84a28_row4_col3\" class=\"data row4 col3\" >{'atmosphere': 1, 'drinks': 1, 'appetizers': 1}</td>\n",
       "      <td id=\"T_84a28_row4_col4\" class=\"data row4 col4\" >0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x36184d1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "54.79"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compiled_pipeline = ABSAPipelineV2()\n",
    "# ABSAPipelineV2.load(compiled_pipeline, \"./ABSAPipelineV2.json\")\n",
    "evaluate_test(compiled_pipeline, metric=validate_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b64f64a1-fcc8-4102-944a-a555a9b95968",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_pipeline.save(\"./ABSAPipelineV2thresh.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ad64fc41-0e04-4018-ac59-60ed1f00e0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiled_pipeline.save(\"./ABSAPipelineV2.json\")\n",
    "compiled_v2 = ABSAPipelineV2()\n",
    "ABSAPipelineV2.load(compiled_v2, \"./ABSAPipelineV2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "a8a2e548-3e8a-454c-8069-f829fef532b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to train 16 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.623809523809523 / 30  (28.7): 100%|█| 30/30 [00:00<00:00, 52.17it/\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.623809523809523 / 30  (28.7%)\n",
      "Score: 28.75 for set: [0, 0, 0]\n",
      "New best score: 28.75 for seed -3\n",
      "Scores so far: [28.75]\n",
      "Best score: 28.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.357142857142858 / 30  (37.9): 100%|█| 30/30 [00:00<00:00, 54.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.357142857142858 / 30  (37.9%)\n",
      "Score: 37.86 for set: [16, 16, 16]\n",
      "New best score: 37.86 for seed -2\n",
      "Scores so far: [28.75, 37.86]\n",
      "Best score: 37.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|█████████████████████▉                         | 14/30 [00:00<00:00, 53.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 15 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.8999999999999995 / 18  (32.8):  60%|▌| 18/30 [00:17<00:10,  1.09it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 4.7 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.8999999999999995 / 19  (31.1):  63%|▋| 19/30 [00:24<00:32,  2.94s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.8999999999999995 / 20  (29.5):  67%|▋| 20/30 [00:27<00:28,  2.85s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.8999999999999995 / 21  (32.9):  70%|▋| 21/30 [00:30<00:25,  2.79s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 31.9 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 5.7 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 7.6 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.566666666666666 / 22  (34.4):  73%|▋| 22/30 [00:35<00:28,  3.56s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.566666666666666 / 23  (37.2):  77%|▊| 23/30 [00:38<00:23,  3.43s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 6.5 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 12.5 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.4 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.566666666666666 / 24  (39.9):  80%|▊| 24/30 [00:43<00:23,  3.89s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 19.9 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.566666666666666 / 25  (38.3):  83%|▊| 25/30 [00:47<00:19,  3.92s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.6 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.09047619047619 / 30  (37.0): 100%|█| 30/30 [01:07<00:00,  2.26s/i\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.09047619047619 / 30  (37.0%)\n",
      "Score: 36.97 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97]\n",
      "Best score: 37.86\n",
      "Average of max per entry across top 1 scores: 0.3785714285714286\n",
      "Average of max per entry across top 2 scores: 0.6149206349206349\n",
      "Average of max per entry across top 3 scores: 0.6696825396825397\n",
      "Average of max per entry across top 5 scores: 0.6696825396825397\n",
      "Average of max per entry across top 8 scores: 0.6696825396825397\n",
      "Average of max per entry across top 9999 scores: 0.6696825396825397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████▋                    | 17/30 [00:00<00:00, 49.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:03<00:46,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 3  (0.0):  10%|█▌              | 3/30 [00:05<00:42,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 4  (0.0):  13%|██▏             | 4/30 [00:09<01:05,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 5  (0.0):  17%|██▋             | 5/30 [00:14<01:22,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 15.2 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 6  (0.0):  20%|███▏            | 6/30 [00:18<01:27,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 4.0 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.8 / 7  (11.4):  23%|███▌           | 7/30 [00:24<01:40,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.8 / 8  (10.0):  27%|████           | 8/30 [00:24<01:10,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 9.6 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.8 / 9  (8.9):  30%|████▊           | 9/30 [00:29<01:15,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.8 / 10  (8.0):  33%|████▋         | 10/30 [00:31<01:00,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 22.0 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.8 / 12  (15.0):  40%|█████▏       | 12/30 [00:38<00:55,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 6.6 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.8 / 13  (21.5):  43%|█████▋       | 13/30 [00:44<01:07,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.8 / 14  (20.0):  47%|██████       | 14/30 [00:47<00:56,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 61.0 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 8.5 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.8 / 15  (25.3):  50%|██████▌      | 15/30 [00:50<00:54,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.8 / 16  (23.8):  53%|██████▉      | 16/30 [00:54<00:52,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 4.7 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.8 / 17  (22.4):  57%|███████▎     | 17/30 [00:57<00:43,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.8 / 18  (21.1):  60%|███████▊     | 18/30 [00:58<00:32,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 25.2 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.1 seconds after 8 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.8 / 19  (20.0):  63%|████████▏    | 19/30 [01:04<00:39,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 52.6 seconds after 9 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.8 / 20  (19.0):  67%|████████▋    | 20/30 [01:07<00:35,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.8 / 21  (18.1):  70%|█████████    | 21/30 [01:10<00:30,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.466666666666667 / 22  (20.3):  73%|▋| 22/30 [01:12<00:23,  2.98s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.466666666666667 / 23  (23.8):  77%|▊| 23/30 [01:16<00:23,  3.33s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.466666666666667 / 24  (26.9):  80%|▊| 24/30 [01:20<00:21,  3.50s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 4.7 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.580952380952382 / 30  (35.3): 100%|█| 30/30 [02:00<00:00,  4.01s/\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.580952380952382 / 30  (35.3%)\n",
      "Score: 35.27 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27]\n",
      "Best score: 37.86\n",
      "Average of max per entry across top 1 scores: 0.3785714285714286\n",
      "Average of max per entry across top 2 scores: 0.6149206349206349\n",
      "Average of max per entry across top 3 scores: 0.681111111111111\n",
      "Average of max per entry across top 5 scores: 0.731111111111111\n",
      "Average of max per entry across top 8 scores: 0.731111111111111\n",
      "Average of max per entry across top 9999 scores: 0.731111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████▊                                   | 8/30 [00:00<00:00, 51.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.966666666666667 / 24  (24.9):  77%|▊| 23/30 [00:00<00:00, 49.24it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects_with_labels': \"ValueError('json output should start and end with { and }')\"})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.49047619047619 / 30  (31.6): 100%|█| 30/30 [00:00<00:00, 58.59it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.49047619047619 / 30  (31.6%)\n",
      "Score: 31.63 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63]\n",
      "Best score: 37.86\n",
      "Average of max per entry across top 1 scores: 0.3785714285714286\n",
      "Average of max per entry across top 2 scores: 0.6149206349206349\n",
      "Average of max per entry across top 3 scores: 0.681111111111111\n",
      "Average of max per entry across top 5 scores: 0.7866666666666666\n",
      "Average of max per entry across top 8 scores: 0.7866666666666666\n",
      "Average of max per entry across top 9999 scores: 0.7866666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████▍                                 | 9/30 [00:14<00:34,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.99047619047619 / 30  (40.0): 100%|█| 30/30 [00:29<00:00,  1.01it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.99047619047619 / 30  (40.0%)\n",
      "Score: 39.97 for set: [16, 16, 16]\n",
      "New best score: 39.97 for seed 2\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97]\n",
      "Best score: 39.97\n",
      "Average of max per entry across top 1 scores: 0.3996825396825397\n",
      "Average of max per entry across top 2 scores: 0.5726984126984127\n",
      "Average of max per entry across top 3 scores: 0.7338095238095239\n",
      "Average of max per entry across top 5 scores: 0.8455555555555556\n",
      "Average of max per entry across top 8 scores: 0.868888888888889\n",
      "Average of max per entry across top 9999 scores: 0.868888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▊                                           | 3/30 [00:00<00:00, 41.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 4 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.266666666666667 / 23  (18.6):  73%|▋| 22/30 [00:00<00:00, 55.12it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects_with_labels': \"ValueError('json output should start and end with { and }')\"})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.733333333333334 / 30  (29.1): 100%|█| 30/30 [00:00<00:00, 58.05it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.733333333333334 / 30  (29.1%)\n",
      "Score: 29.11 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11]\n",
      "Best score: 39.97\n",
      "Average of max per entry across top 1 scores: 0.3996825396825397\n",
      "Average of max per entry across top 2 scores: 0.5726984126984127\n",
      "Average of max per entry across top 3 scores: 0.7338095238095239\n",
      "Average of max per entry across top 5 scores: 0.8455555555555556\n",
      "Average of max per entry across top 8 scores: 0.8811111111111113\n",
      "Average of max per entry across top 9999 scores: 0.8811111111111113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████▊                                   | 8/30 [00:00<00:00, 53.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.833333333333332 / 30  (39.4): 100%|█| 30/30 [00:00<00:00, 62.23it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.833333333333332 / 30  (39.4%)\n",
      "Score: 39.44 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44]\n",
      "Best score: 39.97\n",
      "Average of max per entry across top 1 scores: 0.3996825396825397\n",
      "Average of max per entry across top 2 scores: 0.5852380952380952\n",
      "Average of max per entry across top 3 scores: 0.6915873015873015\n",
      "Average of max per entry across top 5 scores: 0.8366666666666667\n",
      "Average of max per entry across top 8 scores: 0.898888888888889\n",
      "Average of max per entry across top 9999 scores: 0.898888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 59.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.333333333333332 / 30  (37.8): 100%|█| 30/30 [00:00<00:00, 62.08it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.333333333333332 / 30  (37.8%)\n",
      "Score: 37.78 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78]\n",
      "Best score: 39.97\n",
      "Average of max per entry across top 1 scores: 0.3996825396825397\n",
      "Average of max per entry across top 2 scores: 0.5852380952380952\n",
      "Average of max per entry across top 3 scores: 0.6915873015873015\n",
      "Average of max per entry across top 5 scores: 0.8271428571428573\n",
      "Average of max per entry across top 8 scores: 0.9033333333333334\n",
      "Average of max per entry across top 9999 scores: 0.9100000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████▍                                         | 4/30 [00:00<00:00, 54.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.666666666666666 / 30  (42.2): 100%|█| 30/30 [00:00<00:00, 43.32it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.666666666666666 / 30  (42.2%)\n",
      "Score: 42.22 for set: [16, 16, 16]\n",
      "New best score: 42.22 for seed 6\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.5152380952380953\n",
      "Average of max per entry across top 3 scores: 0.6563492063492063\n",
      "Average of max per entry across top 5 scores: 0.7738095238095238\n",
      "Average of max per entry across top 8 scores: 0.9100000000000001\n",
      "Average of max per entry across top 9999 scores: 0.9100000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|███████████▏                                    | 7/30 [00:00<00:00, 56.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.333333333333333 / 11  (21.2):  33%|▎| 10/30 [00:10<00:26,  1.30s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.333333333333333 / 12  (19.4):  40%|▍| 12/30 [00:13<00:16,  1.09it/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.333333333333333 / 14  (23.8):  47%|▍| 14/30 [00:15<00:16,  1.01s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.19047619047619 / 15  (27.9):  50%|▌| 15/30 [00:20<00:25,  1.71s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.19047619047619 / 17  (24.6):  57%|▌| 17/30 [00:21<00:16,  1.29s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 16.0 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.19047619047619 / 19  (22.1):  63%|▋| 19/30 [00:26<00:17,  1.64s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 5.3 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.19047619047619 / 21  (20.0):  70%|▋| 21/30 [00:30<00:15,  1.69s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 6.5 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.19047619047619 / 22  (23.6):  73%|▋| 22/30 [00:32<00:14,  1.84s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.69047619047619 / 23  (24.7):  77%|▊| 23/30 [00:34<00:12,  1.81s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 28.6 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.69047619047619 / 25  (30.8):  83%|▊| 25/30 [00:38<00:08,  1.76s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.7 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.69047619047619 / 26  (33.4):  87%|▊| 26/30 [00:42<00:09,  2.43s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.214285714285714 / 30  (34.0): 100%|█| 30/30 [01:08<00:00,  2.29s/\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects_with_labels': \"ValueError('json output should start and end with { and }')\"})\n",
      "Average Metric: 10.214285714285714 / 30  (34.0%)\n",
      "Score: 34.05 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.5152380952380953\n",
      "Average of max per entry across top 3 scores: 0.6563492063492063\n",
      "Average of max per entry across top 5 scores: 0.7738095238095238\n",
      "Average of max per entry across top 8 scores: 0.898888888888889\n",
      "Average of max per entry across top 9999 scores: 0.9322222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████▊                                   | 8/30 [00:00<00:00, 52.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.19047619047619 / 30  (40.6): 100%|█| 30/30 [00:00<00:00, 62.34it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.19047619047619 / 30  (40.6%)\n",
      "Score: 40.63 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.7952380952380953\n",
      "Average of max per entry across top 8 scores: 0.9211111111111112\n",
      "Average of max per entry across top 9999 scores: 0.9433333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████▋                               | 10/30 [00:00<00:00, 54.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.5 / 8  (18.8):  23%|███▌           | 7/30 [00:11<00:33,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.5 / 9  (16.7):  30%|████▌          | 9/30 [00:12<00:23,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.5 / 10  (15.0):  33%|████▎        | 10/30 [00:16<00:35,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.2 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.5 / 11  (22.7):  37%|████▊        | 11/30 [00:21<00:45,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 7.0 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.5 / 12  (20.8):  40%|█████▏       | 12/30 [00:23<00:44,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 29.5 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.5 / 13  (26.9):  43%|█████▋       | 13/30 [00:27<00:48,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 15.1 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.5 / 15  (30.0):  50%|██████▌      | 15/30 [00:32<00:38,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.5 / 16  (28.1):  53%|██████▉      | 16/30 [00:38<00:49,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.3 / 17  (31.2):  57%|███████▎     | 17/30 [00:40<00:38,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.3 / 18  (29.4):  60%|███████▊     | 18/30 [00:43<00:37,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.3 / 19  (27.9):  63%|████████▏    | 19/30 [00:45<00:30,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.0 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 20.2 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.3 / 20  (26.5):  67%|████████▋    | 20/30 [00:51<00:35,  3.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 12.1 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.3 / 21  (30.0):  70%|█████████    | 21/30 [00:53<00:30,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 47.7 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.966666666666667 / 22  (31.7):  73%|▋| 22/30 [00:56<00:26,  3.25s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.966666666666667 / 23  (34.6):  77%|▊| 23/30 [00:58<00:19,  2.76s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.966666666666667 / 25  (39.9):  83%|▊| 25/30 [01:05<00:15,  3.17s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.6 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.966666666666667 / 29  (37.8):  97%|▉| 29/30 [01:19<00:03,  4.00s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects_with_labels': \"JSONDecodeError('Unexpected character in found when decoding object value')\"})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.766666666666667 / 30  (39.2): 100%|█| 30/30 [01:44<00:00,  3.49s/\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.766666666666667 / 30  (39.2%)\n",
      "Score: 39.22 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63, 39.22]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.883015873015873\n",
      "Average of max per entry across top 8 scores: 0.9341269841269841\n",
      "Average of max per entry across top 9999 scores: 0.9766666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 49.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.19047619047619 / 30  (34.0): 100%|█| 30/30 [00:26<00:00,  1.15it/\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.19047619047619 / 30  (34.0%)\n",
      "Score: 33.97 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63, 39.22, 33.97]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.883015873015873\n",
      "Average of max per entry across top 8 scores: 0.9341269841269841\n",
      "Average of max per entry across top 9999 scores: 0.9933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████████▍                                 | 9/30 [00:00<00:00, 48.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:51,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:09<02:16,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.6666666666666666 / 3  (22.2):  10%| | 3/30 [00:11<01:32,  3.42s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 5.5 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.6666666666666666 / 4  (16.7):  13%|▏| 4/30 [00:13<01:23,  3.20s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 15.5 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.6666666666666666 / 6  (11.1):  20%|▏| 6/30 [00:18<01:01,  2.56s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 14.3 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.6666666666666666 / 7  (9.5):  23%|▏| 7/30 [00:22<01:10,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.6666666666666666 / 8  (8.3):  27%|▎| 8/30 [00:25<01:06,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.4666666666666668 / 10  (14.7):  33%|▎| 10/30 [00:30<00:54,  2.70s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 3.5 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.323809523809524 / 11  (21.1):  37%|▎| 11/30 [00:34<00:56,  2.95s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 6.0 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.323809523809524 / 13  (25.6):  43%|▍| 13/30 [00:37<00:39,  2.35s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.3 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 39.0 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.9904761904761905 / 15  (26.6):  50%|▌| 15/30 [00:42<00:33,  2.20s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 41.9 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.9904761904761905 / 16  (24.9):  53%|▌| 16/30 [00:45<00:35,  2.55s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 35.7 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.9904761904761905 / 17  (23.5):  57%|▌| 17/30 [00:46<00:28,  2.18s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.9904761904761905 / 20  (25.0):  67%|▋| 20/30 [00:55<00:23,  2.37s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.9904761904761905 / 21  (28.5):  70%|▋| 21/30 [00:58<00:24,  2.69s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.6571428571428575 / 22  (30.3):  73%|▋| 22/30 [00:59<00:16,  2.05s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.6571428571428575 / 23  (33.3):  77%|▊| 23/30 [01:02<00:18,  2.59s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.657142857142858 / 24  (36.1):  80%|▊| 24/30 [01:05<00:16,  2.68s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.957142857142859 / 30  (36.5): 100%|█| 30/30 [01:26<00:00,  2.88s/\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.957142857142859 / 30  (36.5%)\n",
      "Score: 36.52 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63, 39.22, 33.97, 36.52]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.883015873015873\n",
      "Average of max per entry across top 8 scores: 0.9341269841269841\n",
      "Average of max per entry across top 9999 scores: 0.9933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████████▊                 | 19/30 [00:01<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 20 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.9714285714285713 / 5  (39.4):  17%|▏| 5/30 [00:05<00:21,  1.18it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.9714285714285713 / 6  (32.9):  20%|▏| 6/30 [00:09<00:44,  1.87s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.9714285714285713 / 7  (28.2):  23%|▏| 7/30 [00:13<00:58,  2.54s/it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.638095238095238 / 8  (33.0):  27%|▎| 8/30 [00:15<00:46,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {'max_tokens': 75, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.638095238095238 / 10  (26.4):  33%|▎| 10/30 [00:19<00:40,  2.02s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.6 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.638095238095238 / 12  (30.3):  40%|▍| 12/30 [00:25<00:41,  2.33s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 13.1 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 16.1 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 4.638095238095238 / 13  (35.7):  43%|▍| 13/30 [00:26<00:32,  1.92s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.304761904761905 / 14  (37.9):  47%|▍| 14/30 [00:31<00:42,  2.63s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.104761904761904 / 15  (40.7):  50%|▌| 15/30 [00:34<00:42,  2.85s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 6.104761904761904 / 16  (38.2):  53%|▌| 16/30 [00:36<00:38,  2.77s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.104761904761904 / 19  (37.4):  63%|▋| 19/30 [00:40<00:17,  1.60s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.3 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 13.4 seconds after 5 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 28.4 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.104761904761904 / 20  (35.5):  67%|▋| 20/30 [00:46<00:28,  2.84s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.4 seconds after 7 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.104761904761904 / 22  (32.3):  73%|▋| 22/30 [00:51<00:18,  2.35s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.771428571428571 / 23  (33.8):  77%|▊| 23/30 [00:55<00:20,  2.91s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 122.7 seconds after 8 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.771428571428572 / 25  (39.1):  83%|▊| 25/30 [00:58<00:11,  2.21s/i"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n",
      "Backing off 22.3 seconds after 6 tries calling function <function GPT3.request at 0x174b6c900> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.571428571428573 / 30  (38.6): 100%|█| 30/30 [03:02<00:00,  6.07s/\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.571428571428573 / 30  (38.6%)\n",
      "Score: 38.57 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63, 39.22, 33.97, 36.52, 38.57]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.883015873015873\n",
      "Average of max per entry across top 8 scores: 0.9396825396825397\n",
      "Average of max per entry across top 9999 scores: 0.9933333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████▋                               | 10/30 [00:00<00:00, 54.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.333333333333332 / 30  (34.4): 100%|█| 30/30 [00:00<00:00, 62.98it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.333333333333332 / 30  (34.4%)\n",
      "Score: 34.44 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63, 39.22, 33.97, 36.52, 38.57, 34.44]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.883015873015873\n",
      "Average of max per entry across top 8 scores: 0.9396825396825397\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▌                                              | 1/30 [00:00<00:00, 49.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.933333333333334 / 30  (36.4): 100%|█| 30/30 [00:00<00:00, 56.90it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.933333333333334 / 30  (36.4%)\n",
      "Score: 36.44 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63, 39.22, 33.97, 36.52, 38.57, 34.44, 36.44]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.883015873015873\n",
      "Average of max per entry across top 8 scores: 0.9396825396825397\n",
      "Average of max per entry across top 9999 scores: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|████████                                        | 5/30 [00:00<00:00, 49.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 6 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.757142857142856 / 30  (35.9): 100%|█| 30/30 [00:00<00:00, 48.88it"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.757142857142856 / 30  (35.9%)\n",
      "Score: 35.86 for set: [16, 16, 16]\n",
      "Scores so far: [28.75, 37.86, 36.97, 35.27, 31.63, 39.97, 29.11, 39.44, 37.78, 42.22, 34.05, 40.63, 39.22, 33.97, 36.52, 38.57, 34.44, 36.44, 35.86]\n",
      "Best score: 42.22\n",
      "Average of max per entry across top 1 scores: 0.4222222222222222\n",
      "Average of max per entry across top 2 scores: 0.631111111111111\n",
      "Average of max per entry across top 3 scores: 0.6974603174603174\n",
      "Average of max per entry across top 5 scores: 0.883015873015873\n",
      "Average of max per entry across top 8 scores: 0.9396825396825397\n",
      "Average of max per entry across top 9999 scores: 1.0\n",
      "19 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "optimizer = BootstrapFewShotWithRandomSearch(metric=validate_f1)\n",
    "compiled_f1 = optimizer.compile(ABSAPipelineV2(), teacher=ABSAPipelineV2(), trainset=dspy_train[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "382c193f-d3e7-452c-982d-9e495f475e98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0 / 1  (0.0):   0%|                         | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0 / 1  (0.0):   1%|▏                | 1/100 [00:00<00:21,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0 / 2  (0.0):   1%|▏                | 1/100 [00:00<00:21,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 3  (0.0):   2%|▎              | 2/100 [00:00<00:21,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.5 / 4  (12.5):   3%|▍             | 3/100 [00:00<00:21,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 5  (20.0):   4%|▌             | 4/100 [00:00<00:20,  4.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 5  (20.0):   5%|▋             | 5/100 [00:00<00:05, 18.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.0 / 6  (16.7):   5%|▋             | 5/100 [00:00<00:05, 18.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.0 / 7  (28.6):   6%|▊             | 6/100 [00:00<00:05, 18.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.0 / 8  (37.5):   7%|▉             | 7/100 [00:00<00:05, 18.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.0 / 8  (37.5):   8%|█             | 8/100 [00:00<00:04, 21.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.0 / 9  (33.3):   8%|█             | 8/100 [00:00<00:04, 21.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.0 / 10  (30.0):   9%|█▏           | 9/100 [00:00<00:04, 21.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.0 / 11  (36.4):  10%|█▏          | 10/100 [00:00<00:04, 21.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.0 / 12  (33.3):  11%|█▎          | 11/100 [00:00<00:04, 21.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.0 / 12  (33.3):  12%|█▍          | 12/100 [00:00<00:03, 26.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.0 / 13  (30.8):  12%|█▍          | 12/100 [00:00<00:03, 26.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.666666666666667 / 14  (33.3):  13%|▏| 13/100 [00:00<00:03, 26.78it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.466666666666667 / 15  (36.4):  14%|▏| 14/100 [00:00<00:03, 26.78it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.466666666666667 / 16  (40.4):  15%|▏| 15/100 [00:00<00:03, 26.78it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.466666666666667 / 16  (40.4):  16%|▏| 16/100 [00:00<00:02, 29.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.466666666666667 / 17  (38.0):  16%|▏| 16/100 [00:00<00:02, 29.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.466666666666667 / 18  (35.9):  17%|▏| 17/100 [00:00<00:02, 29.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.966666666666667 / 19  (36.7):  18%|▏| 18/100 [00:00<00:02, 29.14it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.8238095238095235 / 20  (39.1):  19%|▏| 19/100 [00:00<00:02, 29.14i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.8238095238095235 / 21  (37.3):  20%|▏| 20/100 [00:00<00:02, 29.14i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.8238095238095235 / 21  (37.3):  21%|▏| 21/100 [00:00<00:02, 31.70i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.823809523809523 / 22  (40.1):  21%|▏| 21/100 [00:00<00:02, 31.70it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.823809523809523 / 23  (38.4):  22%|▏| 22/100 [00:00<00:02, 31.70it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.823809523809523 / 24  (40.9):  23%|▏| 23/100 [00:00<00:02, 31.70it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.823809523809523 / 25  (43.3):  24%|▏| 24/100 [00:00<00:02, 31.70i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.823809523809523 / 25  (43.3):  25%|▎| 25/100 [00:00<00:02, 32.72i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.823809523809523 / 26  (41.6):  25%|▎| 25/100 [00:00<00:02, 32.72i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.823809523809523 / 27  (43.8):  26%|▎| 26/100 [00:00<00:02, 32.72i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 12.823809523809523 / 28  (45.8):  27%|▎| 27/100 [00:00<00:02, 32.72i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.68095238095238 / 29  (47.2):  28%|▎| 28/100 [00:00<00:02, 32.72it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.68095238095238 / 29  (47.2):  29%|▎| 29/100 [00:01<00:02, 34.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.68095238095238 / 30  (45.6):  29%|▎| 29/100 [00:01<00:02, 34.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.68095238095238 / 31  (47.4):  30%|▎| 30/100 [00:01<00:02, 34.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.68095238095238 / 32  (45.9):  31%|▎| 31/100 [00:01<00:01, 34.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.68095238095238 / 33  (44.5):  32%|▎| 32/100 [00:01<00:01, 34.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.68095238095238 / 33  (44.5):  33%|▎| 33/100 [00:01<00:02, 33.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.68095238095238 / 34  (43.2):  33%|▎| 33/100 [00:01<00:02, 33.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.68095238095238 / 35  (41.9):  34%|▎| 34/100 [00:01<00:01, 33.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.68095238095238 / 36  (43.6):  35%|▎| 35/100 [00:01<00:01, 33.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.68095238095238 / 37  (42.4):  36%|▎| 36/100 [00:01<00:01, 33.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.68095238095238 / 37  (42.4):  37%|▎| 37/100 [00:01<00:02, 29.80it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.68095238095238 / 38  (43.9):  37%|▎| 37/100 [00:01<00:02, 29.80it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.68095238095238 / 39  (42.8):  38%|▍| 38/100 [00:01<00:02, 29.80it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 17.68095238095238 / 40  (44.2):  39%|▍| 39/100 [00:01<00:02, 29.80it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.68095238095238 / 41  (45.6):  40%|▍| 40/100 [00:01<00:02, 29.80it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.68095238095238 / 41  (45.6):  41%|▍| 41/100 [00:01<00:02, 29.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 19.48095238095238 / 42  (46.4):  41%|▍| 41/100 [00:01<00:02, 29.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 20.48095238095238 / 43  (47.6):  42%|▍| 42/100 [00:01<00:01, 29.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 21.48095238095238 / 44  (48.8):  43%|▍| 43/100 [00:01<00:01, 29.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.48095238095238 / 45  (50.0):  44%|▍| 44/100 [00:01<00:01, 29.41it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.48095238095238 / 45  (50.0):  45%|▍| 45/100 [00:01<00:01, 30.33it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 23.48095238095238 / 46  (51.0):  45%|▍| 45/100 [00:01<00:01, 30.33it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 24.48095238095238 / 47  (52.1):  46%|▍| 46/100 [00:01<00:01, 30.33it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.14761904761905 / 48  (52.4):  47%|▍| 47/100 [00:01<00:01, 30.33it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.14761904761905 / 49  (53.4):  48%|▍| 48/100 [00:01<00:01, 30.33it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.14761904761905 / 49  (53.4):  49%|▍| 49/100 [00:01<00:01, 27.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.14761904761905 / 50  (52.3):  49%|▍| 49/100 [00:01<00:01, 27.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.14761904761905 / 51  (51.3):  50%|▌| 50/100 [00:01<00:01, 27.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.14761904761905 / 52  (50.3):  51%|▌| 51/100 [00:01<00:01, 27.58it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.14761904761905 / 52  (50.3):  52%|▌| 52/100 [00:01<00:01, 27.61it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.14761904761905 / 53  (51.2):  52%|▌| 52/100 [00:01<00:01, 27.61it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.14761904761905 / 54  (50.3):  53%|▌| 53/100 [00:01<00:01, 27.61it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 28.14761904761905 / 55  (51.2):  54%|▌| 54/100 [00:01<00:01, 27.61it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 28.14761904761905 / 55  (51.2):  55%|▌| 55/100 [00:02<00:01, 28.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 68  (46.4):  68%|▋| 68/100 [33:20<15:41, 29.42s\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 28.14761904761905 / 57  (49.4):  56%|▌| 56/100 [00:02<00:01, 28.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 9  (0.0):  30%|████▌          | 9/30 [20:35<48:02, 137.24s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 29.14761904761905 / 58  (50.3):  58%|▌| 58/100 [00:03<00:05,  8.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 29.14761904761905 / 59  (49.4):  58%|▌| 58/100 [00:03<00:05,  8.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 29.14761904761905 / 60  (48.6):  59%|▌| 59/100 [00:03<00:05,  8.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 29.94761904761905 / 61  (49.1):  60%|▌| 60/100 [00:03<00:04,  8.07it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 29.94761904761905 / 61  (49.1):  61%|▌| 61/100 [00:03<00:05,  7.47it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 29.94761904761905 / 62  (48.3):  61%|▌| 61/100 [00:03<00:05,  7.47it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 29.94761904761905 / 63  (47.5):  62%|▌| 62/100 [00:03<00:05,  7.47it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 30.519047619047623 / 64  (47.7):  63%|▋| 63/100 [00:03<00:04,  7.47i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 30.519047619047623 / 65  (47.0):  64%|▋| 64/100 [00:03<00:04,  7.47i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 30.519047619047623 / 65  (47.0):  65%|▋| 65/100 [00:03<00:03, 10.32i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 66  (47.8):  65%|▋| 65/100 [00:03<00:03, 10.32i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 67  (47.0):  66%|▋| 66/100 [00:03<00:03, 10.32i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 68  (46.4):  67%|▋| 67/100 [00:03<00:03, 10.32i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 68  (46.4):  68%|▋| 68/100 [00:03<00:02, 12.45i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 69  (45.7):  68%|▋| 68/100 [00:03<00:02, 12.45i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 70  (45.0):  69%|▋| 69/100 [00:03<00:02, 12.45i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 71  (44.4):  70%|▋| 70/100 [00:03<00:02, 12.45i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.519047619047623 / 71  (44.4):  71%|▋| 71/100 [00:03<00:01, 14.60i\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects_with_labels': \"ValueError('json output should start and end with { and }')\"})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.519047619047623 / 72  (43.8):  71%|▋| 71/100 [00:03<00:01, 14.60i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 32.18571428571429 / 73  (44.1):  72%|▋| 72/100 [00:03<00:01, 14.60it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.18571428571429 / 74  (44.8):  73%|▋| 73/100 [00:03<00:01, 14.60it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.18571428571429 / 75  (44.2):  74%|▋| 74/100 [00:03<00:01, 14.60it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.18571428571429 / 76  (43.7):  75%|▊| 75/100 [00:03<00:01, 14.60it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.18571428571429 / 76  (43.7):  76%|▊| 76/100 [00:04<00:01, 19.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.58571428571429 / 77  (43.6):  76%|▊| 76/100 [00:04<00:01, 19.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.58571428571429 / 78  (43.1):  77%|▊| 77/100 [00:04<00:01, 19.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.58571428571429 / 79  (42.5):  78%|▊| 78/100 [00:04<00:01, 19.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.58571428571429 / 80  (42.0):  79%|▊| 79/100 [00:04<00:01, 19.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.58571428571429 / 81  (41.5):  80%|▊| 80/100 [00:04<00:01, 19.24it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.58571428571429 / 81  (41.5):  81%|▊| 81/100 [00:04<00:00, 22.32it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.25238095238095 / 82  (41.8):  81%|▊| 81/100 [00:04<00:00, 22.32it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.25238095238095 / 83  (41.3):  82%|▊| 82/100 [00:04<00:00, 22.32it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 35.25238095238095 / 84  (42.0):  83%|▊| 83/100 [00:04<00:00, 22.32it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.25238095238095 / 85  (42.6):  84%|▊| 84/100 [00:04<00:00, 22.32it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.91904761904762 / 86  (42.9):  85%|▊| 85/100 [00:04<00:00, 22.32it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.91904761904762 / 86  (42.9):  86%|▊| 86/100 [00:04<00:00, 26.66it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 37.91904761904762 / 87  (43.6):  86%|▊| 86/100 [00:04<00:00, 26.66it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 38.91904761904762 / 88  (44.2):  87%|▊| 87/100 [00:04<00:00, 26.66it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 39.91904761904762 / 89  (44.9):  88%|▉| 88/100 [00:04<00:00, 26.66it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 39.91904761904762 / 90  (44.4):  89%|▉| 89/100 [00:04<00:00, 26.66it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 91  (45.0):  90%|▉| 90/100 [00:04<00:00, 26.66it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 91  (45.0):  91%|▉| 91/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 92  (44.5):  91%|▉| 91/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 93  (44.0):  92%|▉| 92/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 94  (43.5):  93%|▉| 93/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 95  (43.1):  94%|▉| 94/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 96  (42.6):  95%|▉| 95/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 97  (42.2):  96%|▉| 96/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.91904761904762 / 98  (41.8):  97%|▉| 97/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 41.41904761904762 / 99  (41.8):  98%|▉| 98/100 [00:04<00:00, 26.93it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 41.41904761904762 / 100  (41.4): 100%|█| 100/100 [00:04<00:00, 22.19\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects_with_labels': 'Field required: value (error type: missing)'})\n",
      "Average Metric: 41.41904761904762 / 100  (41.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.0' '0.0' '0.0' '0.0' '1.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bd4e5 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bd4e5 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_bd4e5_row0_col0, #T_bd4e5_row0_col1, #T_bd4e5_row0_col2, #T_bd4e5_row0_col3, #T_bd4e5_row0_col4, #T_bd4e5_row1_col0, #T_bd4e5_row1_col1, #T_bd4e5_row1_col2, #T_bd4e5_row1_col3, #T_bd4e5_row1_col4, #T_bd4e5_row2_col0, #T_bd4e5_row2_col1, #T_bd4e5_row2_col2, #T_bd4e5_row2_col3, #T_bd4e5_row2_col4, #T_bd4e5_row3_col0, #T_bd4e5_row3_col1, #T_bd4e5_row3_col2, #T_bd4e5_row3_col3, #T_bd4e5_row3_col4, #T_bd4e5_row4_col0, #T_bd4e5_row4_col1, #T_bd4e5_row4_col2, #T_bd4e5_row4_col3, #T_bd4e5_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bd4e5\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bd4e5_level0_col0\" class=\"col_heading level0 col0\" >review</th>\n",
       "      <th id=\"T_bd4e5_level0_col1\" class=\"col_heading level0 col1\" >example_aspects</th>\n",
       "      <th id=\"T_bd4e5_level0_col2\" class=\"col_heading level0 col2\" >pred_aspects</th>\n",
       "      <th id=\"T_bd4e5_level0_col3\" class=\"col_heading level0 col3\" >validate_f1</th>\n",
       "      <th id=\"T_bd4e5_level0_col4\" class=\"col_heading level0 col4\" >aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bd4e5_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bd4e5_row0_col0\" class=\"data row0 col0\" >\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.</td>\n",
       "      <td id=\"T_bd4e5_row0_col1\" class=\"data row0 col1\" >{'menu': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'pub fare': 0}</td>\n",
       "      <td id=\"T_bd4e5_row0_col2\" class=\"data row0 col2\" >{'menu': 0, 'pub fare': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 1, 'vegetarians': 1}</td>\n",
       "      <td id=\"T_bd4e5_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_bd4e5_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd4e5_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bd4e5_row1_col0\" class=\"data row1 col0\" >(The sashimi is cut a little thinly.</td>\n",
       "      <td id=\"T_bd4e5_row1_col1\" class=\"data row1 col1\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_bd4e5_row1_col2\" class=\"data row1 col2\" >{'sashimi': 0}</td>\n",
       "      <td id=\"T_bd4e5_row1_col3\" class=\"data row1 col3\" >0.0</td>\n",
       "      <td id=\"T_bd4e5_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd4e5_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bd4e5_row2_col0\" class=\"data row2 col0\" >) It's not the best Japanese restaurant in the East Village, but it's a pretty solid one for its modest prices, and worth repeat visits.</td>\n",
       "      <td id=\"T_bd4e5_row2_col1\" class=\"data row2 col1\" >{'prices': 1}</td>\n",
       "      <td id=\"T_bd4e5_row2_col2\" class=\"data row2 col2\" >{'Japanese restaurant': 0, 'East Village': 0, 'modest prices': 1, 'repeat visits': 1}</td>\n",
       "      <td id=\"T_bd4e5_row2_col3\" class=\"data row2 col3\" >0.0</td>\n",
       "      <td id=\"T_bd4e5_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd4e5_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bd4e5_row3_col0\" class=\"data row3 col0\" >15% gratuity automatically added to the bill.</td>\n",
       "      <td id=\"T_bd4e5_row3_col1\" class=\"data row3 col1\" >{'bill': -1, 'gratuity': -1}</td>\n",
       "      <td id=\"T_bd4e5_row3_col2\" class=\"data row3 col2\" >{'gratuity': 0}</td>\n",
       "      <td id=\"T_bd4e5_row3_col3\" class=\"data row3 col3\" >0.0</td>\n",
       "      <td id=\"T_bd4e5_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bd4e5_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bd4e5_row4_col0\" class=\"data row4 col0\" >A beautiful atmosphere, perfect for drinks and/or appetizers.</td>\n",
       "      <td id=\"T_bd4e5_row4_col1\" class=\"data row4 col1\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_bd4e5_row4_col2\" class=\"data row4 col2\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_bd4e5_row4_col3\" class=\"data row4 col3\" >1.0</td>\n",
       "      <td id=\"T_bd4e5_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x33f181ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "41.42"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_f1_score = evaluate_test(compiled_f1, metric=validate_f1)\n",
    "compiled_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eaced9-4164-447d-b294-a0175546670f",
   "metadata": {},
   "source": [
    "## With Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e1843149-590e-4455-8e4a-a4da76ab4f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to train 16 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▍                                        | 1/30 [00:05<02:47,  5.78s/it]\u001b[A\n",
      "  7%|██▊                                       | 2/30 [00:11<02:41,  5.75s/it]\u001b[A\n",
      " 10%|████▏                                     | 3/30 [00:17<02:41,  6.00s/it]\u001b[A\n",
      " 13%|█████▌                                    | 4/30 [00:23<02:34,  5.96s/it]\u001b[A\n",
      " 17%|███████                                   | 5/30 [00:27<02:05,  5.02s/it]\u001b[A\n",
      " 20%|████████▍                                 | 6/30 [00:32<02:02,  5.10s/it]\u001b[A\n",
      " 23%|█████████▊                                | 7/30 [00:37<02:01,  5.27s/it]\u001b[A\n",
      " 27%|███████████▏                              | 8/30 [00:45<02:13,  6.08s/it]\u001b[A\n",
      " 30%|████████████▌                             | 9/30 [00:49<01:54,  5.46s/it]\u001b[A\n",
      " 33%|█████████████▋                           | 10/30 [00:54<01:42,  5.12s/it]\u001b[A\n",
      " 37%|███████████████                          | 11/30 [01:00<01:43,  5.47s/it]\u001b[A\n",
      " 40%|████████████████▍                        | 12/30 [01:06<01:43,  5.76s/it]\u001b[A\n",
      " 43%|█████████████████▊                       | 13/30 [01:11<01:34,  5.54s/it]\u001b[A\n",
      " 47%|███████████████████▏                     | 14/30 [01:18<01:31,  5.71s/it]\u001b[A\n",
      " 50%|████████████████████▌                    | 15/30 [01:25<01:32,  6.19s/it]\u001b[A\n",
      " 53%|█████████████████████▊                   | 16/30 [01:32<01:31,  6.52s/it]\u001b[A\n",
      " 57%|███████████████████████▏                 | 17/30 [01:38<01:21,  6.26s/it]\u001b[A\n",
      " 60%|████████████████████████▌                | 18/30 [01:43<01:09,  5.81s/it]\u001b[A\n",
      " 63%|█████████████████████████▉               | 19/30 [01:48<01:03,  5.73s/it]\u001b[A\n",
      " 67%|███████████████████████████▎             | 20/30 [01:55<01:00,  6.09s/it]\u001b[A\n",
      " 70%|████████████████████████████▋            | 21/30 [02:03<01:00,  6.77s/it]\u001b[A\n",
      " 73%|██████████████████████████████           | 22/30 [02:07<00:47,  5.97s/it]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 23/30 [02:13<00:40,  5.77s/it]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 24/30 [02:20<00:36,  6.10s/it]\u001b[A\n",
      " 83%|██████████████████████████████████▏      | 25/30 [02:25<00:29,  5.89s/it]\u001b[A\n",
      " 87%|███████████████████████████████████▌     | 26/30 [02:32<00:24,  6.11s/it]\u001b[A\n",
      " 90%|████████████████████████████████████▉    | 27/30 [02:36<00:16,  5.65s/it]\u001b[A\n",
      " 93%|██████████████████████████████████████▎  | 28/30 [02:42<00:11,  5.59s/it]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 29/30 [02:47<00:05,  5.53s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████| 30/30 [02:52<00:00,  5.74s/it]\u001b[A\n",
      "[I 2024-04-30 08:59:58,267] A new study created in memory with name: no-name-39f1490d-625f-4ff4-98bf-48dc7be0698c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 6 full traces after 30 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                 | 0/30 [00:05<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▎        | 1/30 [00:05<02:44,  5.68s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▎        | 1/30 [00:05<02:44,  5.68s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|▌        | 2/30 [00:05<01:10,  2.53s/it]\u001b[A\n",
      "Average Metric: 0.9 / 3  (30.0):   7%|▌        | 2/30 [00:06<01:10,  2.53s/it]\u001b[A\n",
      "Average Metric: 0.9 / 3  (30.0):  10%|▉        | 3/30 [00:06<00:39,  1.47s/it]\u001b[A\n",
      "Average Metric: 1.1 / 4  (27.5):  10%|▉        | 3/30 [00:07<00:39,  1.47s/it]\u001b[A\n",
      "Average Metric: 1.1 / 4  (27.5):  13%|█▏       | 4/30 [00:07<00:32,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.1 / 5  (22.0):  13%|█▏       | 4/30 [00:08<00:32,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.1 / 5  (22.0):  17%|█▌       | 5/30 [00:08<00:31,  1.24s/it]\u001b[A\n",
      "Average Metric: 1.2428571428571429 / 6  (20.7):  17%|▏| 5/30 [00:10<00:31,  1.\u001b[A\n",
      "Average Metric: 1.2428571428571429 / 6  (20.7):  20%|▏| 6/30 [00:10<00:39,  1.\u001b[A\n",
      "Average Metric: 1.7428571428571429 / 7  (24.9):  20%|▏| 6/30 [00:11<00:39,  1.\u001b[A\n",
      "Average Metric: 1.7428571428571429 / 7  (24.9):  23%|▏| 7/30 [00:11<00:27,  1.\u001b[A\n",
      "Average Metric: 2.0761904761904764 / 8  (26.0):  23%|▏| 7/30 [00:11<00:27,  1.\u001b[A\n",
      "Average Metric: 2.0761904761904764 / 8  (26.0):  27%|▎| 8/30 [00:11<00:18,  1.\u001b[A\n",
      "Average Metric: 2.4761904761904763 / 9  (27.5):  27%|▎| 8/30 [00:11<00:18,  1.\u001b[A\n",
      "Average Metric: 2.4761904761904763 / 9  (27.5):  30%|▎| 9/30 [00:11<00:15,  1.\u001b[A\n",
      "Average Metric: 2.9761904761904763 / 10  (29.8):  30%|▎| 9/30 [00:12<00:15,  1\u001b[A\n",
      "Average Metric: 2.9761904761904763 / 10  (29.8):  33%|▎| 10/30 [00:12<00:17,  \u001b[A\n",
      "Average Metric: 2.9761904761904763 / 11  (27.1):  33%|▎| 10/30 [00:13<00:17,  \u001b[A\n",
      "Average Metric: 2.9761904761904763 / 11  (27.1):  37%|▎| 11/30 [00:13<00:13,  \u001b[A\n",
      "Average Metric: 3.9761904761904763 / 12  (33.1):  37%|▎| 11/30 [00:13<00:13,  \u001b[A\n",
      "Average Metric: 3.9761904761904763 / 12  (33.1):  40%|▍| 12/30 [00:13<00:12,  \u001b[A\n",
      "Average Metric: 3.9761904761904763 / 13  (30.6):  40%|▍| 12/30 [00:14<00:12,  \u001b[A\n",
      "Average Metric: 3.9761904761904763 / 13  (30.6):  43%|▍| 13/30 [00:14<00:14,  \u001b[A\n",
      "Average Metric: 4.642857142857143 / 14  (33.2):  43%|▍| 13/30 [00:14<00:14,  1\u001b[A\n",
      "Average Metric: 5.142857142857143 / 15  (34.3):  47%|▍| 14/30 [00:15<00:13,  1\u001b[A\n",
      "Average Metric: 5.142857142857143 / 15  (34.3):  50%|▌| 15/30 [00:15<00:07,  1\u001b[A\n",
      "Average Metric: 5.476190476190476 / 16  (34.2):  50%|▌| 15/30 [00:15<00:07,  1\u001b[A\n",
      "Average Metric: 5.476190476190476 / 16  (34.2):  53%|▌| 16/30 [00:15<00:06,  2\u001b[A\n",
      "Average Metric: 5.476190476190476 / 17  (32.2):  53%|▌| 16/30 [00:17<00:06,  2\u001b[A\n",
      "Average Metric: 5.476190476190476 / 17  (32.2):  57%|▌| 17/30 [00:17<00:10,  1\u001b[A\n",
      "Average Metric: 6.476190476190476 / 18  (36.0):  57%|▌| 17/30 [00:17<00:10,  1\u001b[A\n",
      "Average Metric: 6.476190476190476 / 18  (36.0):  60%|▌| 18/30 [00:17<00:09,  1\u001b[A\n",
      "Average Metric: 7.476190476190476 / 19  (39.3):  60%|▌| 18/30 [00:18<00:09,  1\u001b[A\n",
      "Average Metric: 7.476190476190476 / 20  (37.4):  63%|▋| 19/30 [00:19<00:08,  1\u001b[A\n",
      "Average Metric: 7.476190476190476 / 20  (37.4):  67%|▋| 20/30 [00:19<00:07,  1\u001b[A\n",
      "Average Metric: 7.976190476190476 / 21  (38.0):  67%|▋| 20/30 [00:19<00:07,  1\u001b[A\n",
      "Average Metric: 7.976190476190476 / 21  (38.0):  70%|▋| 21/30 [00:19<00:05,  1\u001b[A\n",
      "Average Metric: 7.976190476190476 / 22  (36.3):  70%|▋| 21/30 [00:19<00:05,  1\u001b[A\n",
      "Average Metric: 7.976190476190476 / 22  (36.3):  73%|▋| 22/30 [00:19<00:03,  2\u001b[A\n",
      "Average Metric: 8.976190476190476 / 23  (39.0):  73%|▋| 22/30 [00:21<00:03,  2\u001b[A\n",
      "Average Metric: 8.976190476190476 / 23  (39.0):  77%|▊| 23/30 [00:21<00:05,  1\u001b[A\n",
      "Average Metric: 9.476190476190476 / 24  (39.5):  77%|▊| 23/30 [00:22<00:05,  1\u001b[A\n",
      "Average Metric: 9.476190476190476 / 24  (39.5):  80%|▊| 24/30 [00:22<00:05,  1\u001b[A\n",
      "Average Metric: 9.976190476190476 / 25  (39.9):  80%|▊| 24/30 [00:22<00:05,  1\u001b[A\n",
      "Average Metric: 9.976190476190476 / 25  (39.9):  83%|▊| 25/30 [00:22<00:03,  1\u001b[A\n",
      "Average Metric: 10.30952380952381 / 26  (39.7):  83%|▊| 25/30 [00:23<00:03,  1\u001b[A\n",
      "Average Metric: 10.30952380952381 / 26  (39.7):  87%|▊| 26/30 [00:23<00:02,  1\u001b[A\n",
      "Average Metric: 10.642857142857144 / 27  (39.4):  87%|▊| 26/30 [00:24<00:02,  \u001b[A\n",
      "Average Metric: 10.642857142857144 / 27  (39.4):  90%|▉| 27/30 [00:24<00:02,  \u001b[A\n",
      "Average Metric: 11.642857142857144 / 28  (41.6):  90%|▉| 27/30 [00:25<00:02,  \u001b[A\n",
      "Average Metric: 11.642857142857144 / 28  (41.6):  93%|▉| 28/30 [00:25<00:01,  \u001b[A\n",
      "Average Metric: 11.642857142857144 / 29  (40.1):  93%|▉| 28/30 [00:26<00:01,  \u001b[A\n",
      "Average Metric: 11.642857142857144 / 29  (40.1):  97%|▉| 29/30 [00:26<00:00,  \u001b[A\n",
      "Average Metric: 11.642857142857144 / 30  (38.8):  97%|▉| 29/30 [00:27<00:00,  \u001b[A\n",
      "Average Metric: 11.642857142857144 / 30  (38.8): 100%|█| 30/30 [00:27<00:00,  \u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-30 09:00:25,396] Trial 0 finished with value: 38.81 and parameters: {'demo_index_for_generate_aspects.predictor': 15, 'demo_index_for_generate_reasons': 15, 'demo_index_for_generate_labels.predictor': 0}. Best is trial 0 with value: 38.81.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.642857142857144 / 30  (38.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4 / 1  (40.0):   0%|                 | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4 / 1  (40.0):   3%|▎        | 1/30 [00:02<01:16,  2.63s/it]\u001b[A\n",
      "Average Metric: 0.9 / 2  (45.0):   3%|▎        | 1/30 [00:02<01:16,  2.63s/it]\u001b[A\n",
      "Average Metric: 0.9 / 3  (30.0):   7%|▌        | 2/30 [00:02<01:13,  2.63s/it]\u001b[A\n",
      "Average Metric: 0.9 / 3  (30.0):  10%|▉        | 3/30 [00:02<00:21,  1.27it/s]\u001b[A\n",
      "Average Metric: 0.9 / 4  (22.5):  10%|▉        | 3/30 [00:03<00:21,  1.27it/s]\u001b[A\n",
      "Average Metric: 0.9 / 4  (22.5):  13%|█▏       | 4/30 [00:03<00:19,  1.35it/s]\u001b[A\n",
      "Average Metric: 1.5666666666666667 / 5  (31.3):  13%|▏| 4/30 [00:04<00:19,  1.\u001b[A\n",
      "Average Metric: 1.5666666666666667 / 5  (31.3):  17%|▏| 5/30 [00:04<00:19,  1.\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 6  (34.4):  17%|▏| 5/30 [00:05<00:19,  1.\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 6  (34.4):  20%|▏| 6/30 [00:05<00:18,  1.\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 7  (29.5):  20%|▏| 6/30 [00:06<00:18,  1.\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 7  (29.5):  23%|▏| 7/30 [00:06<00:19,  1.\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  23%|▏| 7/30 [00:06<00:19,  1.\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  27%|▎| 8/30 [00:06<00:14,  1.\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  27%|▎| 8/30 [00:06<00:14,  1.\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  30%|▎| 9/30 [00:06<00:11,  1.\u001b[A\n",
      "Average Metric: 3.5666666666666664 / 10  (35.7):  30%|▎| 9/30 [00:08<00:11,  1\u001b[A\n",
      "Average Metric: 3.5666666666666664 / 10  (35.7):  33%|▎| 10/30 [00:08<00:19,  \u001b[A\n",
      "Average Metric: 3.9 / 11  (35.5):  33%|██▎    | 10/30 [00:08<00:19,  1.01it/s]\u001b[A\n",
      "Average Metric: 3.9 / 11  (35.5):  37%|██▌    | 11/30 [00:08<00:14,  1.31it/s]\u001b[A\n",
      "Average Metric: 3.9 / 12  (32.5):  37%|██▌    | 11/30 [00:09<00:14,  1.31it/s]\u001b[A\n",
      "Average Metric: 3.9 / 12  (32.5):  40%|██▊    | 12/30 [00:09<00:12,  1.49it/s]\u001b[A\n",
      "Average Metric: 4.4 / 13  (33.8):  40%|██▊    | 12/30 [00:09<00:12,  1.49it/s]\u001b[A\n",
      "Average Metric: 4.4 / 13  (33.8):  43%|███    | 13/30 [00:09<00:10,  1.67it/s]\u001b[A\n",
      "Average Metric: 4.4 / 14  (31.4):  43%|███    | 13/30 [00:10<00:10,  1.67it/s]\u001b[A\n",
      "Average Metric: 4.4 / 14  (31.4):  47%|███▎   | 14/30 [00:10<00:08,  1.90it/s]\u001b[A\n",
      "Average Metric: 4.4 / 15  (29.3):  47%|███▎   | 14/30 [00:10<00:08,  1.90it/s]\u001b[A\n",
      "Average Metric: 4.4 / 15  (29.3):  50%|███▌   | 15/30 [00:10<00:06,  2.50it/s]\u001b[A\n",
      "Average Metric: 4.4 / 16  (27.5):  50%|███▌   | 15/30 [00:12<00:06,  2.50it/s]\u001b[A\n",
      "Average Metric: 4.4 / 16  (27.5):  53%|███▋   | 16/30 [00:12<00:11,  1.21it/s]\u001b[A\n",
      "Average Metric: 5.4 / 17  (31.8):  53%|███▋   | 16/30 [00:13<00:11,  1.21it/s]\u001b[A\n",
      "Average Metric: 5.4 / 17  (31.8):  57%|███▉   | 17/30 [00:13<00:12,  1.02it/s]\u001b[A\n",
      "Average Metric: 5.733333333333333 / 18  (31.9):  57%|▌| 17/30 [00:14<00:12,  1\u001b[A\n",
      "Average Metric: 5.733333333333333 / 18  (31.9):  60%|▌| 18/30 [00:14<00:11,  1\u001b[A\n",
      "Average Metric: 5.733333333333333 / 19  (30.2):  60%|▌| 18/30 [00:15<00:11,  1\u001b[A\n",
      "Average Metric: 5.733333333333333 / 19  (30.2):  63%|▋| 19/30 [00:15<00:09,  1\u001b[A\n",
      "Average Metric: 6.733333333333333 / 20  (33.7):  63%|▋| 19/30 [00:15<00:09,  1\u001b[A\n",
      "Average Metric: 7.733333333333333 / 21  (36.8):  67%|▋| 20/30 [00:15<00:08,  1\u001b[A\n",
      "Average Metric: 7.733333333333333 / 21  (36.8):  70%|▋| 21/30 [00:15<00:05,  1\u001b[A\n",
      "Average Metric: 8.133333333333333 / 22  (37.0):  70%|▋| 21/30 [00:15<00:05,  1\u001b[A\n",
      "Average Metric: 8.466666666666667 / 23  (36.8):  73%|▋| 22/30 [00:16<00:04,  1\u001b[A\n",
      "Average Metric: 8.466666666666667 / 23  (36.8):  77%|▊| 23/30 [00:16<00:03,  1\u001b[A\n",
      "Average Metric: 9.466666666666667 / 24  (39.4):  77%|▊| 23/30 [00:16<00:03,  1\u001b[A\n",
      "Average Metric: 9.466666666666667 / 24  (39.4):  80%|▊| 24/30 [00:16<00:03,  1\u001b[A\n",
      "Average Metric: 10.466666666666667 / 25  (41.9):  80%|▊| 24/30 [00:17<00:03,  \u001b[A\n",
      "Average Metric: 10.466666666666667 / 25  (41.9):  83%|▊| 25/30 [00:17<00:02,  \u001b[A\n",
      "Average Metric: 11.466666666666667 / 26  (44.1):  83%|▊| 25/30 [00:18<00:02,  \u001b[A\n",
      "Average Metric: 11.466666666666667 / 26  (44.1):  87%|▊| 26/30 [00:18<00:02,  \u001b[A\n",
      "Average Metric: 11.466666666666667 / 27  (42.5):  87%|▊| 26/30 [00:19<00:02,  \u001b[A\n",
      "Average Metric: 11.466666666666667 / 27  (42.5):  90%|▉| 27/30 [00:19<00:02,  \u001b[A\n",
      "Average Metric: 12.466666666666667 / 28  (44.5):  90%|▉| 27/30 [00:19<00:02,  \u001b[A\n",
      "Average Metric: 12.466666666666667 / 28  (44.5):  93%|▉| 28/30 [00:19<00:01,  \u001b[A\n",
      "Average Metric: 12.466666666666667 / 29  (43.0):  93%|▉| 28/30 [00:19<00:01,  \u001b[A\n",
      "Average Metric: 12.466666666666667 / 29  (43.0):  97%|▉| 29/30 [00:20<00:00,  \u001b[A\n",
      "Average Metric: 13.133333333333333 / 30  (43.8):  97%|▉| 29/30 [00:20<00:00,  \u001b[A\n",
      "Average Metric: 13.133333333333333 / 30  (43.8): 100%|█| 30/30 [00:20<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:00:45,857] Trial 1 finished with value: 43.78 and parameters: {'demo_index_for_generate_aspects.predictor': 11, 'demo_index_for_generate_reasons': 9, 'demo_index_for_generate_labels.predictor': 1}. Best is trial 1 with value: 43.78.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.133333333333333 / 30  (43.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4 / 1  (40.0):   0%|                 | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4 / 1  (40.0):   3%|▎        | 1/30 [00:02<01:16,  2.62s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   3%|▎        | 1/30 [00:03<01:16,  2.62s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   7%|▌        | 2/30 [00:03<00:49,  1.75s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):   7%|▌        | 2/30 [00:05<00:49,  1.75s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):  10%|▉        | 3/30 [00:05<00:42,  1.56s/it]\u001b[A\n",
      "Average Metric: 0.65 / 4  (16.2):  10%|▊       | 3/30 [00:05<00:42,  1.56s/it]\u001b[A\n",
      "Average Metric: 0.65 / 4  (16.2):  13%|█       | 4/30 [00:05<00:32,  1.26s/it]\u001b[A\n",
      "Average Metric: 0.65 / 5  (13.0):  13%|█       | 4/30 [00:06<00:32,  1.26s/it]\u001b[A\n",
      "Average Metric: 0.65 / 5  (13.0):  17%|█▎      | 5/30 [00:06<00:24,  1.04it/s]\u001b[A\n",
      "Average Metric: 0.8166666666666667 / 6  (13.6):  17%|▏| 5/30 [00:06<00:24,  1.\u001b[A\n",
      "Average Metric: 0.8166666666666667 / 6  (13.6):  20%|▏| 6/30 [00:06<00:20,  1.\u001b[A\n",
      "Average Metric: 1.3166666666666667 / 7  (18.8):  20%|▏| 6/30 [00:07<00:20,  1.\u001b[A\n",
      "Average Metric: 1.3166666666666667 / 7  (18.8):  23%|▏| 7/30 [00:07<00:20,  1.\u001b[A\n",
      "Average Metric: 1.3166666666666667 / 8  (16.5):  23%|▏| 7/30 [00:08<00:20,  1.\u001b[A\n",
      "Average Metric: 1.3166666666666667 / 8  (16.5):  27%|▎| 8/30 [00:08<00:17,  1.\u001b[A\n",
      "Average Metric: 1.3166666666666667 / 9  (14.6):  27%|▎| 8/30 [00:08<00:17,  1.\u001b[A\n",
      "Average Metric: 1.7166666666666668 / 10  (17.2):  30%|▎| 9/30 [00:08<00:16,  1\u001b[A\n",
      "Average Metric: 1.7166666666666668 / 10  (17.2):  33%|▎| 10/30 [00:08<00:10,  \u001b[A\n",
      "Average Metric: 2.716666666666667 / 11  (24.7):  33%|▎| 10/30 [00:10<00:10,  1\u001b[A\n",
      "Average Metric: 2.716666666666667 / 11  (24.7):  37%|▎| 11/30 [00:10<00:13,  1\u001b[A\n",
      "Average Metric: 3.716666666666667 / 12  (31.0):  37%|▎| 11/30 [00:10<00:13,  1\u001b[A\n",
      "Average Metric: 3.716666666666667 / 12  (31.0):  40%|▍| 12/30 [00:10<00:10,  1\u001b[A\n",
      "Average Metric: 3.716666666666667 / 13  (28.6):  40%|▍| 12/30 [00:11<00:10,  1\u001b[A\n",
      "Average Metric: 3.716666666666667 / 13  (28.6):  43%|▍| 13/30 [00:11<00:14,  1\u001b[A\n",
      "Average Metric: 4.116666666666667 / 14  (29.4):  43%|▍| 13/30 [00:12<00:14,  1\u001b[A\n",
      "Average Metric: 4.116666666666667 / 14  (29.4):  47%|▍| 14/30 [00:12<00:11,  1\u001b[A\n",
      "Average Metric: 4.783333333333334 / 15  (31.9):  47%|▍| 14/30 [00:12<00:11,  1\u001b[A\n",
      "Average Metric: 5.116666666666667 / 16  (32.0):  50%|▌| 15/30 [00:13<00:11,  1\u001b[A\n",
      "Average Metric: 5.116666666666667 / 16  (32.0):  53%|▌| 16/30 [00:13<00:08,  1\u001b[A\n",
      "Average Metric: 6.116666666666667 / 17  (36.0):  53%|▌| 16/30 [00:15<00:08,  1\u001b[A\n",
      "Average Metric: 6.116666666666667 / 17  (36.0):  57%|▌| 17/30 [00:15<00:12,  1\u001b[A\n",
      "Average Metric: 6.316666666666667 / 18  (35.1):  57%|▌| 17/30 [00:15<00:12,  1\u001b[A\n",
      "Average Metric: 6.316666666666667 / 18  (35.1):  60%|▌| 18/30 [00:15<00:09,  1\u001b[A\n",
      "Average Metric: 6.316666666666667 / 19  (33.2):  60%|▌| 18/30 [00:16<00:09,  1\u001b[A\n",
      "Average Metric: 6.316666666666667 / 19  (33.2):  63%|▋| 19/30 [00:16<00:09,  1\u001b[A\n",
      "Average Metric: 6.65 / 20  (33.2):  63%|███▊  | 19/30 [00:17<00:09,  1.21it/s]\u001b[A\n",
      "Average Metric: 6.65 / 20  (33.2):  67%|████  | 20/30 [00:17<00:07,  1.29it/s]\u001b[A\n",
      "Average Metric: 7.15 / 21  (34.0):  67%|████  | 20/30 [00:17<00:07,  1.29it/s]\u001b[A\n",
      "Average Metric: 7.15 / 21  (34.0):  70%|████▏ | 21/30 [00:17<00:06,  1.42it/s]\u001b[A\n",
      "Average Metric: 7.316666666666667 / 22  (33.3):  70%|▋| 21/30 [00:18<00:06,  1\u001b[A\n",
      "Average Metric: 7.316666666666667 / 22  (33.3):  73%|▋| 22/30 [00:18<00:04,  1\u001b[A\n",
      "Average Metric: 8.316666666666666 / 23  (36.2):  73%|▋| 22/30 [00:18<00:04,  1\u001b[A\n",
      "Average Metric: 8.316666666666666 / 23  (36.2):  77%|▊| 23/30 [00:18<00:03,  1\u001b[A\n",
      "Average Metric: 8.65 / 24  (36.0):  77%|████▌ | 23/30 [00:19<00:03,  1.89it/s]\u001b[A\n",
      "Average Metric: 8.65 / 24  (36.0):  80%|████▊ | 24/30 [00:19<00:03,  1.53it/s]\u001b[A\n",
      "Average Metric: 8.983333333333334 / 25  (35.9):  80%|▊| 24/30 [00:19<00:03,  1\u001b[A\n",
      "Average Metric: 8.983333333333334 / 25  (35.9):  83%|▊| 25/30 [00:19<00:02,  1\u001b[A\n",
      "Average Metric: 9.65 / 26  (37.1):  83%|█████ | 25/30 [00:20<00:02,  1.71it/s]\u001b[A\n",
      "Average Metric: 9.65 / 26  (37.1):  87%|█████▏| 26/30 [00:20<00:02,  1.95it/s]\u001b[A\n",
      "Average Metric: 9.65 / 27  (35.7):  87%|█████▏| 26/30 [00:21<00:02,  1.95it/s]\u001b[A\n",
      "Average Metric: 9.65 / 27  (35.7):  90%|█████▍| 27/30 [00:21<00:01,  1.60it/s]\u001b[A\n",
      "Average Metric: 9.983333333333334 / 28  (35.7):  90%|▉| 27/30 [00:21<00:01,  1\u001b[A\n",
      "Average Metric: 9.983333333333334 / 28  (35.7):  93%|▉| 28/30 [00:21<00:01,  1\u001b[A\n",
      "Average Metric: 10.65 / 29  (36.7):  93%|████▋| 28/30 [00:22<00:01,  1.75it/s]\u001b[A\n",
      "Average Metric: 10.65 / 29  (36.7):  97%|████▊| 29/30 [00:22<00:00,  1.22it/s]\u001b[A\n",
      "Average Metric: 10.65 / 30  (35.5):  97%|████▊| 29/30 [00:24<00:00,  1.22it/s]\u001b[A\n",
      "Average Metric: 10.65 / 30  (35.5): 100%|█████| 30/30 [00:24<00:00,  1.23it/s]\u001b[A\n",
      "[I 2024-04-30 09:01:10,376] Trial 2 finished with value: 35.5 and parameters: {'demo_index_for_generate_aspects.predictor': 2, 'demo_index_for_generate_reasons': 12, 'demo_index_for_generate_labels.predictor': 4}. Best is trial 1 with value: 43.78.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.65 / 30  (35.5%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:01<00:35,  1.22s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   3%|▎        | 1/30 [00:01<00:35,  1.22s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   7%|▌        | 2/30 [00:01<00:18,  1.55it/s]\u001b[A\n",
      "Average Metric: 0.7333333333333334 / 3  (24.4):   7%| | 2/30 [00:04<00:18,  1.\u001b[A\n",
      "Average Metric: 0.7333333333333334 / 3  (24.4):  10%| | 3/30 [00:04<00:51,  1.\u001b[A\n",
      "Average Metric: 0.7333333333333334 / 4  (18.3):  10%| | 3/30 [00:06<00:51,  1.\u001b[A\n",
      "Average Metric: 0.7333333333333334 / 4  (18.3):  13%|▏| 4/30 [00:06<00:47,  1.\u001b[A\n",
      "Average Metric: 0.9 / 5  (18.0):  13%|█▏       | 4/30 [00:06<00:47,  1.85s/it]\u001b[A\n",
      "Average Metric: 0.9 / 6  (15.0):  17%|█▌       | 5/30 [00:06<00:46,  1.85s/it]\u001b[A\n",
      "Average Metric: 1.4 / 7  (20.0):  20%|█▊       | 6/30 [00:06<00:44,  1.85s/it]\u001b[A\n",
      "Average Metric: 1.4 / 7  (20.0):  23%|██       | 7/30 [00:06<00:16,  1.36it/s]\u001b[A\n",
      "Average Metric: 1.9 / 8  (23.8):  23%|██       | 7/30 [00:06<00:16,  1.36it/s]\u001b[A\n",
      "Average Metric: 1.9 / 9  (21.1):  27%|██▍      | 8/30 [00:07<00:16,  1.36it/s]\u001b[A\n",
      "Average Metric: 1.9 / 9  (21.1):  30%|██▋      | 9/30 [00:07<00:12,  1.62it/s]\u001b[A\n",
      "Average Metric: 2.9 / 10  (29.0):  30%|██▍     | 9/30 [00:08<00:12,  1.62it/s]\u001b[A\n",
      "Average Metric: 2.9 / 10  (29.0):  33%|██▎    | 10/30 [00:08<00:11,  1.73it/s]\u001b[A\n",
      "Average Metric: 3.9 / 11  (35.5):  33%|██▎    | 10/30 [00:08<00:11,  1.73it/s]\u001b[A\n",
      "Average Metric: 3.9 / 11  (35.5):  37%|██▌    | 11/30 [00:08<00:11,  1.71it/s]\u001b[A\n",
      "Average Metric: 4.9 / 12  (40.8):  37%|██▌    | 11/30 [00:09<00:11,  1.71it/s]\u001b[A\n",
      "Average Metric: 4.9 / 12  (40.8):  40%|██▊    | 12/30 [00:09<00:12,  1.39it/s]\u001b[A\n",
      "Average Metric: 5.4 / 13  (41.5):  40%|██▊    | 12/30 [00:10<00:12,  1.39it/s]\u001b[A\n",
      "Average Metric: 5.4 / 13  (41.5):  43%|███    | 13/30 [00:10<00:12,  1.35it/s]\u001b[A\n",
      "Average Metric: 6.066666666666667 / 14  (43.3):  43%|▍| 13/30 [00:11<00:12,  1\u001b[A\n",
      "Average Metric: 6.066666666666667 / 14  (43.3):  47%|▍| 14/30 [00:11<00:10,  1\u001b[A\n",
      "Average Metric: 6.066666666666667 / 15  (40.4):  47%|▍| 14/30 [00:11<00:10,  1\u001b[A\n",
      "Average Metric: 6.066666666666667 / 15  (40.4):  50%|▌| 15/30 [00:11<00:07,  1\u001b[A\n",
      "Average Metric: 7.066666666666667 / 16  (44.2):  50%|▌| 15/30 [00:11<00:07,  1\u001b[A\n",
      "Average Metric: 7.066666666666667 / 16  (44.2):  53%|▌| 16/30 [00:11<00:07,  1\u001b[A\n",
      "Average Metric: 7.066666666666667 / 17  (41.6):  53%|▌| 16/30 [00:11<00:07,  1\u001b[A\n",
      "Average Metric: 7.066666666666667 / 17  (41.6):  57%|▌| 17/30 [00:11<00:05,  2\u001b[A\n",
      "Average Metric: 8.066666666666666 / 18  (44.8):  57%|▌| 17/30 [00:12<00:05,  2\u001b[A\n",
      "Average Metric: 8.066666666666666 / 18  (44.8):  60%|▌| 18/30 [00:12<00:06,  1\u001b[A\n",
      "Average Metric: 8.316666666666666 / 19  (43.8):  60%|▌| 18/30 [00:13<00:06,  1\u001b[A\n",
      "Average Metric: 8.316666666666666 / 19  (43.8):  63%|▋| 19/30 [00:13<00:06,  1\u001b[A\n",
      "Average Metric: 8.65 / 20  (43.2):  63%|███▊  | 19/30 [00:14<00:06,  1.72it/s]\u001b[A\n",
      "Average Metric: 8.65 / 20  (43.2):  67%|████  | 20/30 [00:14<00:06,  1.57it/s]\u001b[A\n",
      "Average Metric: 9.65 / 21  (46.0):  67%|████  | 20/30 [00:14<00:06,  1.57it/s]\u001b[A\n",
      "Average Metric: 9.65 / 21  (46.0):  70%|████▏ | 21/30 [00:14<00:04,  2.08it/s]\u001b[A\n",
      "Average Metric: 10.15 / 22  (46.1):  70%|███▌ | 21/30 [00:15<00:04,  2.08it/s]\u001b[A\n",
      "Average Metric: 10.15 / 22  (46.1):  73%|███▋ | 22/30 [00:15<00:05,  1.43it/s]\u001b[A\n",
      "Average Metric: 10.15 / 23  (44.1):  73%|███▋ | 22/30 [00:15<00:05,  1.43it/s]\u001b[A\n",
      "Average Metric: 10.15 / 23  (44.1):  77%|███▊ | 23/30 [00:15<00:04,  1.65it/s]\u001b[A\n",
      "Average Metric: 10.816666666666666 / 24  (45.1):  77%|▊| 23/30 [00:16<00:04,  \u001b[A\n",
      "Average Metric: 10.816666666666666 / 24  (45.1):  80%|▊| 24/30 [00:16<00:04,  \u001b[A\n",
      "Average Metric: 11.483333333333333 / 25  (45.9):  80%|▊| 24/30 [00:17<00:04,  \u001b[A\n",
      "Average Metric: 11.983333333333333 / 26  (46.1):  83%|▊| 25/30 [00:17<00:03,  \u001b[A\n",
      "Average Metric: 11.983333333333333 / 26  (46.1):  87%|▊| 26/30 [00:17<00:02,  \u001b[A\n",
      "Average Metric: 11.983333333333333 / 27  (44.4):  87%|▊| 26/30 [00:18<00:02,  \u001b[A\n",
      "Average Metric: 11.983333333333333 / 27  (44.4):  90%|▉| 27/30 [00:18<00:01,  \u001b[A\n",
      "Average Metric: 11.983333333333333 / 28  (42.8):  90%|▉| 27/30 [00:18<00:01,  \u001b[A\n",
      "Average Metric: 12.483333333333333 / 29  (43.0):  93%|▉| 28/30 [00:18<00:01,  \u001b[A\n",
      "Average Metric: 12.483333333333333 / 29  (43.0):  97%|▉| 29/30 [00:18<00:00,  \u001b[A\n",
      "Average Metric: 12.483333333333333 / 30  (41.6):  97%|▉| 29/30 [00:20<00:00,  \u001b[A\n",
      "Average Metric: 12.483333333333333 / 30  (41.6): 100%|█| 30/30 [00:20<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:01:30,818] Trial 3 finished with value: 41.61 and parameters: {'demo_index_for_generate_aspects.predictor': 1, 'demo_index_for_generate_reasons': 7, 'demo_index_for_generate_labels.predictor': 4}. Best is trial 1 with value: 43.78.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.483333333333333 / 30  (41.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:02<01:05,  2.27s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   3%|▎        | 1/30 [00:03<01:05,  2.27s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   7%|▌        | 2/30 [00:03<00:45,  1.62s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):   7%|▌        | 2/30 [00:04<00:45,  1.62s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):  10%|▉        | 3/30 [00:04<00:33,  1.24s/it]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):  10%|▉        | 3/30 [00:04<00:33,  1.24s/it]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):  13%|█▏       | 4/30 [00:04<00:24,  1.06it/s]\u001b[A\n",
      "Average Metric: 1.4 / 5  (28.0):  13%|█▏       | 4/30 [00:06<00:24,  1.06it/s]\u001b[A\n",
      "Average Metric: 1.4 / 5  (28.0):  17%|█▌       | 5/30 [00:06<00:32,  1.31s/it]\u001b[A\n",
      "Average Metric: 1.4 / 6  (23.3):  17%|█▌       | 5/30 [00:07<00:32,  1.31s/it]\u001b[A\n",
      "Average Metric: 1.4 / 6  (23.3):  20%|█▊       | 6/30 [00:07<00:30,  1.26s/it]\u001b[A\n",
      "Average Metric: 1.7999999999999998 / 7  (25.7):  20%|▏| 6/30 [00:08<00:30,  1.\u001b[A\n",
      "Average Metric: 1.7999999999999998 / 7  (25.7):  23%|▏| 7/30 [00:08<00:23,  1.\u001b[A\n",
      "Average Metric: 1.7999999999999998 / 8  (22.5):  23%|▏| 7/30 [00:09<00:23,  1.\u001b[A\n",
      "Average Metric: 1.7999999999999998 / 8  (22.5):  27%|▎| 8/30 [00:09<00:21,  1.\u001b[A\n",
      "Average Metric: 2.1333333333333333 / 9  (23.7):  27%|▎| 8/30 [00:09<00:21,  1.\u001b[A\n",
      "Average Metric: 2.8 / 10  (28.0):  30%|██▍     | 9/30 [00:10<00:20,  1.04it/s]\u001b[A\n",
      "Average Metric: 2.8 / 10  (28.0):  33%|██▎    | 10/30 [00:10<00:17,  1.15it/s]\u001b[A\n",
      "Average Metric: 3.05 / 11  (27.7):  33%|██    | 10/30 [00:11<00:17,  1.15it/s]\u001b[A\n",
      "Average Metric: 3.05 / 11  (27.7):  37%|██▏   | 11/30 [00:11<00:15,  1.24it/s]\u001b[A\n",
      "Average Metric: 4.05 / 12  (33.8):  37%|██▏   | 11/30 [00:11<00:15,  1.24it/s]\u001b[A\n",
      "Average Metric: 4.383333333333333 / 13  (33.7):  40%|▍| 12/30 [00:13<00:14,  1\u001b[A\n",
      "Average Metric: 4.383333333333333 / 13  (33.7):  43%|▍| 13/30 [00:13<00:15,  1\u001b[A\n",
      "Average Metric: 4.383333333333333 / 14  (31.3):  43%|▍| 13/30 [00:14<00:15,  1\u001b[A\n",
      "Average Metric: 4.383333333333333 / 14  (31.3):  47%|▍| 14/30 [00:14<00:13,  1\u001b[A\n",
      "Average Metric: 4.383333333333333 / 15  (29.2):  47%|▍| 14/30 [00:14<00:13,  1\u001b[A\n",
      "Average Metric: 4.383333333333333 / 16  (27.4):  50%|▌| 15/30 [00:14<00:12,  1\u001b[A\n",
      "Average Metric: 4.383333333333333 / 16  (27.4):  53%|▌| 16/30 [00:14<00:09,  1\u001b[A\n",
      "Average Metric: 4.716666666666666 / 17  (27.7):  53%|▌| 16/30 [00:17<00:09,  1\u001b[A\n",
      "Average Metric: 4.716666666666666 / 17  (27.7):  57%|▌| 17/30 [00:17<00:13,  1\u001b[A\n",
      "Average Metric: 5.716666666666666 / 18  (31.8):  57%|▌| 17/30 [00:17<00:13,  1\u001b[A\n",
      "Average Metric: 5.716666666666666 / 18  (31.8):  60%|▌| 18/30 [00:17<00:10,  1\u001b[A\n",
      "Average Metric: 5.916666666666666 / 19  (31.1):  60%|▌| 18/30 [00:17<00:10,  1\u001b[A\n",
      "Average Metric: 5.916666666666666 / 20  (29.6):  63%|▋| 19/30 [00:18<00:09,  1\u001b[A\n",
      "Average Metric: 5.916666666666666 / 20  (29.6):  67%|▋| 20/30 [00:18<00:06,  1\u001b[A\n",
      "Average Metric: 5.916666666666666 / 21  (28.2):  67%|▋| 20/30 [00:18<00:06,  1\u001b[A\n",
      "Average Metric: 5.916666666666666 / 22  (26.9):  70%|▋| 21/30 [00:18<00:05,  1\u001b[A\n",
      "Average Metric: 5.916666666666666 / 22  (26.9):  73%|▋| 22/30 [00:18<00:04,  1\u001b[A\n",
      "Average Metric: 6.249999999999999 / 23  (27.2):  73%|▋| 22/30 [00:20<00:04,  1\u001b[A\n",
      "Average Metric: 6.249999999999999 / 23  (27.2):  77%|▊| 23/30 [00:20<00:05,  1\u001b[A\n",
      "Average Metric: 6.749999999999999 / 24  (28.1):  77%|▊| 23/30 [00:20<00:05,  1\u001b[A\n",
      "Average Metric: 7.749999999999999 / 25  (31.0):  80%|▊| 24/30 [00:21<00:04,  1\u001b[A\n",
      "Average Metric: 7.749999999999999 / 25  (31.0):  83%|▊| 25/30 [00:21<00:02,  1\u001b[A\n",
      "Average Metric: 8.083333333333332 / 26  (31.1):  83%|▊| 25/30 [00:21<00:02,  1\u001b[A\n",
      "Average Metric: 8.083333333333332 / 27  (29.9):  87%|▊| 26/30 [00:21<00:02,  1\u001b[A\n",
      "Average Metric: 8.083333333333332 / 27  (29.9):  90%|▉| 27/30 [00:21<00:01,  2\u001b[A\n",
      "Average Metric: 8.749999999999998 / 28  (31.2):  90%|▉| 27/30 [00:24<00:01,  2\u001b[A\n",
      "Average Metric: 8.749999999999998 / 28  (31.2):  93%|▉| 28/30 [00:24<00:01,  1\u001b[A\n",
      "Average Metric: 8.749999999999998 / 29  (30.2):  93%|▉| 28/30 [00:24<00:01,  1\u001b[A\n",
      "Average Metric: 8.749999999999998 / 29  (30.2):  97%|▉| 29/30 [00:24<00:00,  1\u001b[A\n",
      "Average Metric: 8.749999999999998 / 30  (29.2):  97%|▉| 29/30 [00:28<00:00,  1\u001b[A\n",
      "Average Metric: 8.749999999999998 / 30  (29.2): 100%|█| 30/30 [00:28<00:00,  1\u001b[A\n",
      "[I 2024-04-30 09:01:58,973] Trial 4 finished with value: 29.17 and parameters: {'demo_index_for_generate_aspects.predictor': 8, 'demo_index_for_generate_reasons': 7, 'demo_index_for_generate_labels.predictor': 10}. Best is trial 1 with value: 43.78.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.749999999999998 / 30  (29.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▎       | 1/30 [00:03<01:51,  3.85s/it]\u001b[A\n",
      "Average Metric: 1.5 / 2  (75.0):   3%|▎        | 1/30 [00:04<01:51,  3.85s/it]\u001b[A\n",
      "Average Metric: 1.5 / 2  (75.0):   7%|▌        | 2/30 [00:04<01:02,  2.25s/it]\u001b[A\n",
      "Average Metric: 1.75 / 3  (58.3):   7%|▌       | 2/30 [00:06<01:02,  2.25s/it]\u001b[A\n",
      "Average Metric: 1.75 / 3  (58.3):  10%|▊       | 3/30 [00:06<00:47,  1.78s/it]\u001b[A\n",
      "Average Metric: 1.75 / 4  (43.8):  10%|▊       | 3/30 [00:06<00:47,  1.78s/it]\u001b[A\n",
      "Average Metric: 1.75 / 4  (43.8):  13%|█       | 4/30 [00:06<00:33,  1.28s/it]\u001b[A\n",
      "Average Metric: 2.15 / 5  (43.0):  13%|█       | 4/30 [00:06<00:33,  1.28s/it]\u001b[A\n",
      "Average Metric: 2.15 / 6  (35.8):  17%|█▎      | 5/30 [00:07<00:31,  1.28s/it]\u001b[A\n",
      "Average Metric: 2.15 / 6  (35.8):  20%|█▌      | 6/30 [00:07<00:20,  1.15it/s]\u001b[A\n",
      "Average Metric: 2.65 / 7  (37.9):  20%|█▌      | 6/30 [00:10<00:20,  1.15it/s]\u001b[A\n",
      "Average Metric: 2.65 / 7  (37.9):  23%|█▊      | 7/30 [00:10<00:32,  1.41s/it]\u001b[A\n",
      "Average Metric: 3.3166666666666664 / 8  (41.5):  23%|▏| 7/30 [00:10<00:32,  1.\u001b[A\n",
      "Average Metric: 3.3166666666666664 / 8  (41.5):  27%|▎| 8/30 [00:10<00:23,  1.\u001b[A\n",
      "Average Metric: 3.3166666666666664 / 9  (36.9):  27%|▎| 8/30 [00:11<00:23,  1.\u001b[A\n",
      "Average Metric: 3.3166666666666664 / 9  (36.9):  30%|▎| 9/30 [00:11<00:20,  1.\u001b[A\n",
      "Average Metric: 3.3166666666666664 / 10  (33.2):  30%|▎| 9/30 [00:11<00:20,  1\u001b[A\n",
      "Average Metric: 3.3166666666666664 / 10  (33.2):  33%|▎| 10/30 [00:11<00:14,  \u001b[A\n",
      "Average Metric: 3.8166666666666664 / 11  (34.7):  33%|▎| 10/30 [00:11<00:14,  \u001b[A\n",
      "Average Metric: 4.566666666666666 / 12  (38.1):  37%|▎| 11/30 [00:14<00:13,  1\u001b[A\n",
      "Average Metric: 4.566666666666666 / 12  (38.1):  40%|▍| 12/30 [00:14<00:18,  1\u001b[A\n",
      "Average Metric: 4.566666666666666 / 13  (35.1):  40%|▍| 12/30 [00:14<00:18,  1\u001b[A\n",
      "Average Metric: 4.566666666666666 / 13  (35.1):  43%|▍| 13/30 [00:14<00:15,  1\u001b[A\n",
      "Average Metric: 5.566666666666666 / 14  (39.8):  43%|▍| 13/30 [00:15<00:15,  1\u001b[A\n",
      "Average Metric: 5.566666666666666 / 14  (39.8):  47%|▍| 14/30 [00:15<00:13,  1\u001b[A\n",
      "Average Metric: 5.8999999999999995 / 15  (39.3):  47%|▍| 14/30 [00:16<00:13,  \u001b[A\n",
      "Average Metric: 5.8999999999999995 / 15  (39.3):  50%|▌| 15/30 [00:16<00:14,  \u001b[A\n",
      "Average Metric: 6.8999999999999995 / 16  (43.1):  50%|▌| 15/30 [00:16<00:14,  \u001b[A\n",
      "Average Metric: 6.8999999999999995 / 16  (43.1):  53%|▌| 16/30 [00:16<00:10,  \u001b[A\n",
      "Average Metric: 6.8999999999999995 / 17  (40.6):  53%|▌| 16/30 [00:18<00:10,  \u001b[A\n",
      "Average Metric: 6.8999999999999995 / 17  (40.6):  57%|▌| 17/30 [00:18<00:13,  \u001b[A\n",
      "Average Metric: 7.3 / 18  (40.6):  57%|███▉   | 17/30 [00:19<00:13,  1.04s/it]\u001b[A\n",
      "Average Metric: 7.3 / 18  (40.6):  60%|████▏  | 18/30 [00:19<00:09,  1.24it/s]\u001b[A\n",
      "Average Metric: 8.3 / 19  (43.7):  60%|████▏  | 18/30 [00:19<00:09,  1.24it/s]\u001b[A\n",
      "Average Metric: 8.3 / 19  (43.7):  63%|████▍  | 19/30 [00:19<00:07,  1.41it/s]\u001b[A\n",
      "Average Metric: 9.3 / 20  (46.5):  63%|████▍  | 19/30 [00:21<00:07,  1.41it/s]\u001b[A\n",
      "Average Metric: 9.3 / 20  (46.5):  67%|████▋  | 20/30 [00:21<00:11,  1.17s/it]\u001b[A\n",
      "Average Metric: 9.8 / 21  (46.7):  67%|████▋  | 20/30 [00:22<00:11,  1.17s/it]\u001b[A\n",
      "Average Metric: 9.8 / 21  (46.7):  70%|████▉  | 21/30 [00:22<00:08,  1.06it/s]\u001b[A\n",
      "Average Metric: 10.0 / 22  (45.5):  70%|████▏ | 21/30 [00:22<00:08,  1.06it/s]\u001b[A\n",
      "Average Metric: 10.0 / 22  (45.5):  73%|████▍ | 22/30 [00:22<00:06,  1.29it/s]\u001b[A\n",
      "Average Metric: 11.0 / 23  (47.8):  73%|████▍ | 22/30 [00:24<00:06,  1.29it/s]\u001b[A\n",
      "Average Metric: 11.0 / 23  (47.8):  77%|████▌ | 23/30 [00:24<00:08,  1.17s/it]\u001b[A\n",
      "Average Metric: 11.5 / 24  (47.9):  77%|████▌ | 23/30 [00:25<00:08,  1.17s/it]\u001b[A\n",
      "Average Metric: 11.5 / 24  (47.9):  80%|████▊ | 24/30 [00:25<00:05,  1.04it/s]\u001b[A\n",
      "Average Metric: 12.5 / 25  (50.0):  80%|████▊ | 24/30 [00:26<00:05,  1.04it/s]\u001b[A\n",
      "Average Metric: 12.5 / 25  (50.0):  83%|█████ | 25/30 [00:26<00:05,  1.08s/it]\u001b[A\n",
      "Average Metric: 13.5 / 26  (51.9):  83%|█████ | 25/30 [00:27<00:05,  1.08s/it]\u001b[A\n",
      "Average Metric: 13.5 / 26  (51.9):  87%|█████▏| 26/30 [00:27<00:04,  1.04s/it]\u001b[A\n",
      "Average Metric: 14.5 / 27  (53.7):  87%|█████▏| 26/30 [00:27<00:04,  1.04s/it]\u001b[A\n",
      "Average Metric: 14.5 / 27  (53.7):  90%|█████▍| 27/30 [00:27<00:02,  1.17it/s]\u001b[A\n",
      "Average Metric: 14.833333333333334 / 28  (53.0):  90%|▉| 27/30 [00:28<00:02,  \u001b[A\n",
      "Average Metric: 14.833333333333334 / 28  (53.0):  93%|▉| 28/30 [00:28<00:01,  \u001b[A\n",
      "Average Metric: 14.833333333333334 / 29  (51.1):  93%|▉| 28/30 [00:28<00:01,  \u001b[A\n",
      "Average Metric: 14.833333333333334 / 29  (51.1):  97%|▉| 29/30 [00:28<00:00,  \u001b[A\n",
      "Average Metric: 14.833333333333334 / 30  (49.4):  97%|▉| 29/30 [00:30<00:00,  \u001b[A\n",
      "Average Metric: 14.833333333333334 / 30  (49.4): 100%|█| 30/30 [00:30<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:02:29,243] Trial 5 finished with value: 49.44 and parameters: {'demo_index_for_generate_aspects.predictor': 3, 'demo_index_for_generate_reasons': 3, 'demo_index_for_generate_labels.predictor': 13}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.833333333333334 / 30  (49.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:01<00:35,  1.22s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▎        | 1/30 [00:01<00:35,  1.22s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|▌        | 2/30 [00:02<00:34,  1.22s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|▉        | 3/30 [00:02<00:19,  1.42it/s]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):  10%|▉        | 3/30 [00:02<00:19,  1.42it/s]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):  13%|█▏       | 4/30 [00:02<00:13,  1.90it/s]\u001b[A\n",
      "Average Metric: 1.4 / 5  (28.0):  13%|█▏       | 4/30 [00:03<00:13,  1.90it/s]\u001b[A\n",
      "Average Metric: 1.4 / 5  (28.0):  17%|█▌       | 5/30 [00:03<00:14,  1.74it/s]\u001b[A\n",
      "Average Metric: 1.4 / 6  (23.3):  17%|█▌       | 5/30 [00:03<00:14,  1.74it/s]\u001b[A\n",
      "Average Metric: 1.7999999999999998 / 7  (25.7):  20%|▏| 6/30 [00:03<00:13,  1.\u001b[A\n",
      "Average Metric: 1.7999999999999998 / 7  (25.7):  23%|▏| 7/30 [00:03<00:07,  3.\u001b[A\n",
      "Average Metric: 2.1333333333333333 / 8  (26.7):  23%|▏| 7/30 [00:03<00:07,  3.\u001b[A\n",
      "Average Metric: 2.1333333333333333 / 8  (26.7):  27%|▎| 8/30 [00:03<00:07,  2.\u001b[A\n",
      "Average Metric: 2.1333333333333333 / 9  (23.7):  27%|▎| 8/30 [00:04<00:07,  2.\u001b[A\n",
      "Average Metric: 2.1333333333333333 / 9  (23.7):  30%|▎| 9/30 [00:04<00:07,  2.\u001b[A\n",
      "Average Metric: 2.3833333333333333 / 10  (23.8):  30%|▎| 9/30 [00:04<00:07,  2\u001b[A\n",
      "Average Metric: 2.3833333333333333 / 10  (23.8):  33%|▎| 10/30 [00:04<00:07,  \u001b[A\n",
      "Average Metric: 2.3833333333333333 / 11  (21.7):  33%|▎| 10/30 [00:04<00:07,  \u001b[A\n",
      "Average Metric: 3.05 / 12  (25.4):  37%|██▏   | 11/30 [00:04<00:07,  2.57it/s]\u001b[A\n",
      "Average Metric: 3.05 / 12  (25.4):  40%|██▍   | 12/30 [00:04<00:05,  3.58it/s]\u001b[A\n",
      "Average Metric: 3.3833333333333333 / 13  (26.0):  40%|▍| 12/30 [00:04<00:05,  \u001b[A\n",
      "Average Metric: 3.3833333333333333 / 14  (24.2):  43%|▍| 13/30 [00:05<00:04,  \u001b[A\n",
      "Average Metric: 3.3833333333333333 / 14  (24.2):  47%|▍| 14/30 [00:05<00:03,  \u001b[A\n",
      "Average Metric: 4.383333333333333 / 15  (29.2):  47%|▍| 14/30 [00:05<00:03,  4\u001b[A\n",
      "Average Metric: 4.383333333333333 / 16  (27.4):  50%|▌| 15/30 [00:05<00:03,  4\u001b[A\n",
      "Average Metric: 4.383333333333333 / 16  (27.4):  53%|▌| 16/30 [00:05<00:03,  4\u001b[A\n",
      "Average Metric: 4.383333333333333 / 17  (25.8):  53%|▌| 16/30 [00:06<00:03,  4\u001b[A\n",
      "Average Metric: 4.383333333333333 / 17  (25.8):  57%|▌| 17/30 [00:06<00:03,  3\u001b[A\n",
      "Average Metric: 4.383333333333333 / 18  (24.4):  57%|▌| 17/30 [00:06<00:03,  3\u001b[A\n",
      "Average Metric: 4.383333333333333 / 18  (24.4):  60%|▌| 18/30 [00:06<00:03,  3\u001b[A\n",
      "Average Metric: 4.583333333333333 / 19  (24.1):  60%|▌| 18/30 [00:06<00:03,  3\u001b[A\n",
      "Average Metric: 4.583333333333333 / 19  (24.1):  63%|▋| 19/30 [00:06<00:02,  3\u001b[A\n",
      "Average Metric: 4.583333333333333 / 20  (22.9):  63%|▋| 19/30 [00:06<00:02,  3\u001b[A\n",
      "Average Metric: 4.916666666666666 / 21  (23.4):  67%|▋| 20/30 [00:06<00:02,  3\u001b[A\n",
      "Average Metric: 5.916666666666666 / 22  (26.9):  70%|▋| 21/30 [00:06<00:02,  3\u001b[A\n",
      "Average Metric: 5.916666666666666 / 22  (26.9):  73%|▋| 22/30 [00:06<00:01,  5\u001b[A\n",
      "Average Metric: 5.916666666666666 / 23  (25.7):  73%|▋| 22/30 [00:07<00:01,  5\u001b[A\n",
      "Average Metric: 5.916666666666666 / 23  (25.7):  77%|▊| 23/30 [00:07<00:01,  3\u001b[A\n",
      "Average Metric: 6.416666666666666 / 24  (26.7):  77%|▊| 23/30 [00:08<00:01,  3\u001b[A\n",
      "Average Metric: 6.416666666666666 / 24  (26.7):  80%|▊| 24/30 [00:08<00:02,  2\u001b[A\n",
      "Average Metric: 6.749999999999999 / 25  (27.0):  80%|▊| 24/30 [00:08<00:02,  2\u001b[A\n",
      "Average Metric: 7.083333333333332 / 26  (27.2):  83%|▊| 25/30 [00:08<00:01,  2\u001b[A\n",
      "Average Metric: 8.083333333333332 / 27  (29.9):  87%|▊| 26/30 [00:08<00:01,  2\u001b[A\n",
      "Average Metric: 8.083333333333332 / 27  (29.9):  90%|▉| 27/30 [00:08<00:00,  4\u001b[A\n",
      "Average Metric: 8.749999999999998 / 28  (31.2):  90%|▉| 27/30 [00:08<00:00,  4\u001b[A\n",
      "Average Metric: 8.749999999999998 / 28  (31.2):  93%|▉| 28/30 [00:08<00:00,  4\u001b[A\n",
      "Average Metric: 8.749999999999998 / 29  (30.2):  93%|▉| 28/30 [00:08<00:00,  4\u001b[A\n",
      "Average Metric: 8.749999999999998 / 29  (30.2):  97%|▉| 29/30 [00:08<00:00,  4\u001b[A\n",
      "Average Metric: 8.749999999999998 / 30  (29.2):  97%|▉| 29/30 [00:09<00:00,  4\u001b[A\n",
      "Average Metric: 8.749999999999998 / 30  (29.2): 100%|█| 30/30 [00:09<00:00,  3\u001b[A\n",
      "[I 2024-04-30 09:02:38,935] Trial 6 finished with value: 29.17 and parameters: {'demo_index_for_generate_aspects.predictor': 8, 'demo_index_for_generate_reasons': 7, 'demo_index_for_generate_labels.predictor': 6}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8.749999999999998 / 30  (29.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4 / 1  (40.0):   0%|                 | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4 / 1  (40.0):   3%|▎        | 1/30 [00:01<00:34,  1.18s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   3%|▎        | 1/30 [00:03<00:34,  1.18s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   7%|▌        | 2/30 [00:03<00:58,  2.08s/it]\u001b[A\n",
      "Average Metric: 0.65 / 3  (21.7):   7%|▌       | 2/30 [00:04<00:58,  2.08s/it]\u001b[A\n",
      "Average Metric: 0.65 / 3  (21.7):  10%|▊       | 3/30 [00:04<00:33,  1.23s/it]\u001b[A\n",
      "Average Metric: 0.65 / 4  (16.2):  10%|▊       | 3/30 [00:06<00:33,  1.23s/it]\u001b[A\n",
      "Average Metric: 0.65 / 4  (16.2):  13%|█       | 4/30 [00:06<00:44,  1.72s/it]\u001b[A\n",
      "Average Metric: 1.05 / 5  (21.0):  13%|█       | 4/30 [00:06<00:44,  1.72s/it]\u001b[A\n",
      "Average Metric: 1.05 / 5  (21.0):  17%|█▎      | 5/30 [00:06<00:30,  1.21s/it]\u001b[A\n",
      "Average Metric: 1.1928571428571428 / 6  (19.9):  17%|▏| 5/30 [00:07<00:30,  1.\u001b[A\n",
      "Average Metric: 1.1928571428571428 / 6  (19.9):  20%|▏| 6/30 [00:07<00:25,  1.\u001b[A\n",
      "Average Metric: 1.3357142857142856 / 7  (19.1):  20%|▏| 6/30 [00:07<00:25,  1.\u001b[A\n",
      "Average Metric: 1.3357142857142856 / 7  (19.1):  23%|▏| 7/30 [00:07<00:19,  1.\u001b[A\n",
      "Average Metric: 1.3357142857142856 / 8  (16.7):  23%|▏| 7/30 [00:08<00:19,  1.\u001b[A\n",
      "Average Metric: 1.3357142857142856 / 8  (16.7):  27%|▎| 8/30 [00:08<00:15,  1.\u001b[A\n",
      "Average Metric: 1.3357142857142856 / 9  (14.8):  27%|▎| 8/30 [00:08<00:15,  1.\u001b[A\n",
      "Average Metric: 1.669047619047619 / 10  (16.7):  30%|▎| 9/30 [00:09<00:14,  1.\u001b[A\n",
      "Average Metric: 1.669047619047619 / 10  (16.7):  33%|▎| 10/30 [00:09<00:11,  1\u001b[A\n",
      "Average Metric: 2.669047619047619 / 11  (24.3):  33%|▎| 10/30 [00:09<00:11,  1\u001b[A\n",
      "Average Metric: 3.669047619047619 / 12  (30.6):  37%|▎| 11/30 [00:10<00:11,  1\u001b[A\n",
      "Average Metric: 3.669047619047619 / 12  (30.6):  40%|▍| 12/30 [00:11<00:12,  1\u001b[A\n",
      "Average Metric: 4.002380952380952 / 13  (30.8):  40%|▍| 12/30 [00:11<00:12,  1\u001b[A\n",
      "Average Metric: 4.002380952380952 / 13  (30.8):  43%|▍| 13/30 [00:11<00:09,  1\u001b[A\n",
      "Average Metric: 4.669047619047619 / 14  (33.4):  43%|▍| 13/30 [00:19<00:09,  1\u001b[A\n",
      "Average Metric: 4.669047619047619 / 14  (33.4):  47%|▍| 14/30 [00:19<00:40,  2\u001b[A\n",
      "Average Metric: 4.669047619047619 / 15  (31.1):  47%|▍| 14/30 [00:20<00:40,  2\u001b[A\n",
      "Average Metric: 4.669047619047619 / 15  (31.1):  50%|▌| 15/30 [00:20<00:29,  2\u001b[A\n",
      "Average Metric: 4.669047619047619 / 16  (29.2):  50%|▌| 15/30 [00:21<00:29,  2\u001b[A\n",
      "Average Metric: 4.669047619047619 / 16  (29.2):  53%|▌| 16/30 [00:21<00:23,  1\u001b[A\n",
      "Average Metric: 5.335714285714286 / 17  (31.4):  53%|▌| 16/30 [00:21<00:23,  1\u001b[A\n",
      "Average Metric: 5.835714285714286 / 18  (32.4):  57%|▌| 17/30 [00:21<00:21,  1\u001b[A\n",
      "Average Metric: 5.835714285714286 / 18  (32.4):  60%|▌| 18/30 [00:21<00:11,  1\u001b[A\n",
      "Average Metric: 6.0357142857142865 / 19  (31.8):  60%|▌| 18/30 [00:21<00:11,  \u001b[A\n",
      "Average Metric: 6.0357142857142865 / 19  (31.8):  63%|▋| 19/30 [00:21<00:09,  \u001b[A\n",
      "Average Metric: 6.5357142857142865 / 20  (32.7):  63%|▋| 19/30 [00:21<00:09,  \u001b[A\n",
      "Average Metric: 6.5357142857142865 / 20  (32.7):  67%|▋| 20/30 [00:21<00:07,  \u001b[A\n",
      "Average Metric: 6.8690476190476195 / 21  (32.7):  67%|▋| 20/30 [00:22<00:07,  \u001b[A\n",
      "Average Metric: 6.8690476190476195 / 21  (32.7):  70%|▋| 21/30 [00:22<00:06,  \u001b[A\n",
      "Average Metric: 7.8690476190476195 / 22  (35.8):  70%|▋| 21/30 [00:22<00:06,  \u001b[A\n",
      "Average Metric: 8.86904761904762 / 23  (38.6):  73%|▋| 22/30 [00:22<00:05,  1.\u001b[A\n",
      "Average Metric: 8.86904761904762 / 23  (38.6):  77%|▊| 23/30 [00:22<00:02,  2.\u001b[A\n",
      "Average Metric: 9.202380952380954 / 24  (38.3):  77%|▊| 23/30 [00:22<00:02,  2\u001b[A\n",
      "Average Metric: 10.202380952380954 / 25  (40.8):  80%|▊| 24/30 [00:23<00:02,  \u001b[A\n",
      "Average Metric: 10.202380952380954 / 25  (40.8):  83%|▊| 25/30 [00:23<00:02,  \u001b[A\n",
      "Average Metric: 10.535714285714288 / 26  (40.5):  83%|▊| 25/30 [00:24<00:02,  \u001b[A\n",
      "Average Metric: 10.535714285714288 / 26  (40.5):  87%|▊| 26/30 [00:24<00:01,  \u001b[A\n",
      "Average Metric: 10.869047619047622 / 27  (40.3):  87%|▊| 26/30 [00:24<00:01,  \u001b[A\n",
      "Average Metric: 10.869047619047622 / 27  (40.3):  90%|▉| 27/30 [00:24<00:01,  \u001b[A\n",
      "Average Metric: 11.369047619047622 / 28  (40.6):  90%|▉| 27/30 [00:24<00:01,  \u001b[A\n",
      "Average Metric: 11.369047619047622 / 28  (40.6):  93%|▉| 28/30 [00:24<00:00,  \u001b[A\n",
      "Average Metric: 11.369047619047622 / 29  (39.2):  93%|▉| 28/30 [00:25<00:00,  \u001b[A\n",
      "Average Metric: 11.369047619047622 / 29  (39.2):  97%|▉| 29/30 [00:25<00:00,  \u001b[A\n",
      "Average Metric: 11.369047619047622 / 30  (37.9):  97%|▉| 29/30 [00:28<00:00,  \u001b[A\n",
      "Average Metric: 11.369047619047622 / 30  (37.9): 100%|█| 30/30 [00:28<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:03:07,266] Trial 7 finished with value: 37.9 and parameters: {'demo_index_for_generate_aspects.predictor': 10, 'demo_index_for_generate_reasons': 11, 'demo_index_for_generate_labels.predictor': 1}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.369047619047622 / 30  (37.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:04<02:18,  4.76s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▎         | 1/30 [00:05<02:18,  4.76s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|▋         | 2/30 [00:05<01:04,  2.31s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):   7%|▌        | 2/30 [00:06<01:04,  2.31s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):  10%|▉        | 3/30 [00:06<00:43,  1.62s/it]\u001b[A\n",
      "Average Metric: 0.65 / 4  (16.2):  10%|▊       | 3/30 [00:06<00:43,  1.62s/it]\u001b[A\n",
      "Average Metric: 0.65 / 5  (13.0):  13%|█       | 4/30 [00:07<00:42,  1.62s/it]\u001b[A\n",
      "Average Metric: 0.65 / 5  (13.0):  17%|█▎      | 5/30 [00:07<00:26,  1.08s/it]\u001b[A\n",
      "Average Metric: 1.05 / 6  (17.5):  17%|█▎      | 5/30 [00:07<00:26,  1.08s/it]\u001b[A\n",
      "Average Metric: 1.05 / 6  (17.5):  20%|█▌      | 6/30 [00:07<00:21,  1.10it/s]\u001b[A\n",
      "Average Metric: 1.55 / 7  (22.1):  20%|█▌      | 6/30 [00:10<00:21,  1.10it/s]\u001b[A\n",
      "Average Metric: 1.55 / 7  (22.1):  23%|█▊      | 7/30 [00:10<00:32,  1.42s/it]\u001b[A\n",
      "Average Metric: 1.9500000000000002 / 8  (24.4):  23%|▏| 7/30 [00:11<00:32,  1.\u001b[A\n",
      "Average Metric: 1.9500000000000002 / 8  (24.4):  27%|▎| 8/30 [00:11<00:26,  1.\u001b[A\n",
      "Average Metric: 2.2833333333333337 / 9  (25.4):  27%|▎| 8/30 [00:11<00:26,  1.\u001b[A\n",
      "Average Metric: 2.2833333333333337 / 9  (25.4):  30%|▎| 9/30 [00:11<00:19,  1.\u001b[A\n",
      "Average Metric: 2.2833333333333337 / 10  (22.8):  30%|▎| 9/30 [00:11<00:19,  1\u001b[A\n",
      "Average Metric: 2.2833333333333337 / 10  (22.8):  33%|▎| 10/30 [00:12<00:15,  \u001b[A\n",
      "Average Metric: 3.2833333333333337 / 11  (29.8):  33%|▎| 10/30 [00:13<00:15,  \u001b[A\n",
      "Average Metric: 3.2833333333333337 / 11  (29.8):  37%|▎| 11/30 [00:13<00:15,  \u001b[A\n",
      "Average Metric: 3.6833333333333336 / 12  (30.7):  37%|▎| 11/30 [00:13<00:15,  \u001b[A\n",
      "Average Metric: 3.6833333333333336 / 12  (30.7):  40%|▍| 12/30 [00:13<00:14,  \u001b[A\n",
      "Average Metric: 4.683333333333334 / 13  (36.0):  40%|▍| 12/30 [00:14<00:14,  1\u001b[A\n",
      "Average Metric: 4.683333333333334 / 13  (36.0):  43%|▍| 13/30 [00:14<00:15,  1\u001b[A\n",
      "Average Metric: 5.683333333333334 / 14  (40.6):  43%|▍| 13/30 [00:16<00:15,  1\u001b[A\n",
      "Average Metric: 5.683333333333334 / 14  (40.6):  47%|▍| 14/30 [00:16<00:16,  1\u001b[A\n",
      "Average Metric: 5.683333333333334 / 15  (37.9):  47%|▍| 14/30 [00:16<00:16,  1\u001b[A\n",
      "Average Metric: 5.683333333333334 / 15  (37.9):  50%|▌| 15/30 [00:16<00:12,  1\u001b[A\n",
      "Average Metric: 6.3500000000000005 / 16  (39.7):  50%|▌| 15/30 [00:16<00:12,  \u001b[A\n",
      "Average Metric: 6.3500000000000005 / 16  (39.7):  53%|▌| 16/30 [00:16<00:08,  \u001b[A\n",
      "Average Metric: 6.750000000000001 / 17  (39.7):  53%|▌| 16/30 [00:19<00:08,  1\u001b[A\n",
      "Average Metric: 6.750000000000001 / 17  (39.7):  57%|▌| 17/30 [00:19<00:16,  1\u001b[A\n",
      "Average Metric: 6.750000000000001 / 18  (37.5):  57%|▌| 17/30 [00:20<00:16,  1\u001b[A\n",
      "Average Metric: 6.750000000000001 / 18  (37.5):  60%|▌| 18/30 [00:20<00:12,  1\u001b[A\n",
      "Average Metric: 7.750000000000001 / 19  (40.8):  60%|▌| 18/30 [00:20<00:12,  1\u001b[A\n",
      "Average Metric: 7.750000000000001 / 19  (40.8):  63%|▋| 19/30 [00:20<00:10,  1\u001b[A\n",
      "Average Metric: 8.25 / 20  (41.2):  63%|███▊  | 19/30 [00:21<00:10,  1.03it/s]\u001b[A\n",
      "Average Metric: 8.25 / 20  (41.2):  67%|████  | 20/30 [00:21<00:07,  1.29it/s]\u001b[A\n",
      "Average Metric: 8.65 / 21  (41.2):  67%|████  | 20/30 [00:21<00:07,  1.29it/s]\u001b[A\n",
      "Average Metric: 8.65 / 21  (41.2):  70%|████▏ | 21/30 [00:21<00:05,  1.69it/s]\u001b[A\n",
      "Average Metric: 8.983333333333334 / 22  (40.8):  70%|▋| 21/30 [00:22<00:05,  1\u001b[A\n",
      "Average Metric: 8.983333333333334 / 22  (40.8):  73%|▋| 22/30 [00:22<00:06,  1\u001b[A\n",
      "Average Metric: 9.316666666666668 / 23  (40.5):  73%|▋| 22/30 [00:25<00:06,  1\u001b[A\n",
      "Average Metric: 9.316666666666668 / 23  (40.5):  77%|▊| 23/30 [00:25<00:09,  1\u001b[A\n",
      "Average Metric: 10.316666666666668 / 24  (43.0):  77%|▊| 23/30 [00:26<00:09,  \u001b[A\n",
      "Average Metric: 10.316666666666668 / 24  (43.0):  80%|▊| 24/30 [00:26<00:07,  \u001b[A\n",
      "Average Metric: 10.650000000000002 / 25  (42.6):  80%|▊| 24/30 [00:26<00:07,  \u001b[A\n",
      "Average Metric: 10.650000000000002 / 25  (42.6):  83%|▊| 25/30 [00:26<00:04,  \u001b[A\n",
      "Average Metric: 10.983333333333336 / 26  (42.2):  83%|▊| 25/30 [00:26<00:04,  \u001b[A\n",
      "Average Metric: 10.983333333333336 / 26  (42.2):  87%|▊| 26/30 [00:26<00:03,  \u001b[A\n",
      "Average Metric: 11.650000000000002 / 27  (43.1):  87%|▊| 26/30 [00:29<00:03,  \u001b[A\n",
      "Average Metric: 11.650000000000002 / 27  (43.1):  90%|▉| 27/30 [00:29<00:04,  \u001b[A\n",
      "Average Metric: 11.650000000000002 / 28  (41.6):  90%|▉| 27/30 [00:30<00:04,  \u001b[A\n",
      "Average Metric: 11.650000000000002 / 28  (41.6):  93%|▉| 28/30 [00:30<00:02,  \u001b[A\n",
      "Average Metric: 12.316666666666668 / 29  (42.5):  93%|▉| 28/30 [00:31<00:02,  \u001b[A\n",
      "Average Metric: 12.316666666666668 / 29  (42.5):  97%|▉| 29/30 [00:31<00:01,  \u001b[A\n",
      "Average Metric: 12.316666666666668 / 30  (41.1):  97%|▉| 29/30 [00:32<00:01,  \u001b[A\n",
      "Average Metric: 12.316666666666668 / 30  (41.1): 100%|█| 30/30 [00:32<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:03:40,048] Trial 8 finished with value: 41.06 and parameters: {'demo_index_for_generate_aspects.predictor': 4, 'demo_index_for_generate_reasons': 2, 'demo_index_for_generate_labels.predictor': 13}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.316666666666668 / 30  (41.1%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:02<01:19,  2.75s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▎        | 1/30 [00:06<01:19,  2.75s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|▌        | 2/30 [00:06<01:40,  3.59s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):   7%|▌        | 2/30 [00:07<01:40,  3.59s/it]\u001b[A\n",
      "Average Metric: 0.9 / 4  (22.5):  10%|▉        | 3/30 [00:07<01:37,  3.59s/it]\u001b[A\n",
      "Average Metric: 0.9 / 4  (22.5):  13%|█▏       | 4/30 [00:07<00:36,  1.42s/it]\u001b[A\n",
      "Average Metric: 0.9 / 5  (18.0):  13%|█▏       | 4/30 [00:07<00:36,  1.42s/it]\u001b[A\n",
      "Average Metric: 1.15 / 6  (19.2):  17%|█▎      | 5/30 [00:07<00:35,  1.42s/it]\u001b[A\n",
      "Average Metric: 1.15 / 6  (19.2):  20%|█▌      | 6/30 [00:07<00:22,  1.07it/s]\u001b[A\n",
      "Average Metric: 1.65 / 7  (23.6):  20%|█▌      | 6/30 [00:09<00:22,  1.07it/s]\u001b[A\n",
      "Average Metric: 1.65 / 7  (23.6):  23%|█▊      | 7/30 [00:09<00:23,  1.01s/it]\u001b[A\n",
      "Average Metric: 1.9833333333333332 / 8  (24.8):  23%|▏| 7/30 [00:09<00:23,  1.\u001b[A\n",
      "Average Metric: 1.9833333333333332 / 8  (24.8):  27%|▎| 8/30 [00:09<00:18,  1.\u001b[A\n",
      "Average Metric: 2.4833333333333334 / 9  (27.6):  27%|▎| 8/30 [00:09<00:18,  1.\u001b[A\n",
      "Average Metric: 2.4833333333333334 / 9  (27.6):  30%|▎| 9/30 [00:09<00:13,  1.\u001b[A\n",
      "Average Metric: 2.9833333333333334 / 10  (29.8):  30%|▎| 9/30 [00:10<00:13,  1\u001b[A\n",
      "Average Metric: 2.9833333333333334 / 10  (29.8):  33%|▎| 10/30 [00:10<00:12,  \u001b[A\n",
      "Average Metric: 3.65 / 11  (33.2):  33%|██    | 10/30 [00:10<00:12,  1.62it/s]\u001b[A\n",
      "Average Metric: 3.65 / 11  (33.2):  37%|██▏   | 11/30 [00:10<00:11,  1.67it/s]\u001b[A\n",
      "Average Metric: 4.65 / 12  (38.8):  37%|██▏   | 11/30 [00:12<00:11,  1.67it/s]\u001b[A\n",
      "Average Metric: 4.65 / 12  (38.8):  40%|██▍   | 12/30 [00:12<00:15,  1.13it/s]\u001b[A\n",
      "Average Metric: 5.65 / 13  (43.5):  40%|██▍   | 12/30 [00:12<00:15,  1.13it/s]\u001b[A\n",
      "Average Metric: 5.65 / 13  (43.5):  43%|██▌   | 13/30 [00:12<00:12,  1.39it/s]\u001b[A\n",
      "Average Metric: 6.65 / 14  (47.5):  43%|██▌   | 13/30 [00:12<00:12,  1.39it/s]\u001b[A\n",
      "Average Metric: 6.65 / 15  (44.3):  47%|██▊   | 14/30 [00:13<00:11,  1.39it/s]\u001b[A\n",
      "Average Metric: 6.65 / 15  (44.3):  50%|███   | 15/30 [00:13<00:08,  1.87it/s]\u001b[A\n",
      "Average Metric: 6.65 / 16  (41.6):  50%|███   | 15/30 [00:13<00:08,  1.87it/s]\u001b[A\n",
      "Average Metric: 6.65 / 16  (41.6):  53%|███▏  | 16/30 [00:13<00:06,  2.30it/s]\u001b[A\n",
      "Average Metric: 6.8500000000000005 / 17  (40.3):  53%|▌| 16/30 [00:14<00:06,  \u001b[A\n",
      "Average Metric: 6.8500000000000005 / 17  (40.3):  57%|▌| 17/30 [00:14<00:05,  \u001b[A\n",
      "Average Metric: 6.8500000000000005 / 18  (38.1):  57%|▌| 17/30 [00:15<00:05,  \u001b[A\n",
      "Average Metric: 6.8500000000000005 / 18  (38.1):  60%|▌| 18/30 [00:15<00:09,  \u001b[A\n",
      "Average Metric: 7.3500000000000005 / 19  (38.7):  60%|▌| 18/30 [00:16<00:09,  \u001b[A\n",
      "Average Metric: 7.3500000000000005 / 19  (38.7):  63%|▋| 19/30 [00:16<00:07,  \u001b[A\n",
      "Average Metric: 8.350000000000001 / 20  (41.8):  63%|▋| 19/30 [00:16<00:07,  1\u001b[A\n",
      "Average Metric: 8.350000000000001 / 20  (41.8):  67%|▋| 20/30 [00:16<00:05,  1\u001b[A\n",
      "Average Metric: 8.350000000000001 / 21  (39.8):  67%|▋| 20/30 [00:17<00:05,  1\u001b[A\n",
      "Average Metric: 8.350000000000001 / 21  (39.8):  70%|▋| 21/30 [00:17<00:06,  1\u001b[A\n",
      "Average Metric: 8.350000000000001 / 22  (38.0):  70%|▋| 21/30 [00:18<00:06,  1\u001b[A\n",
      "Average Metric: 8.350000000000001 / 22  (38.0):  73%|▋| 22/30 [00:18<00:05,  1\u001b[A\n",
      "Average Metric: 8.683333333333335 / 23  (37.8):  73%|▋| 22/30 [00:18<00:05,  1\u001b[A\n",
      "Average Metric: 9.683333333333335 / 24  (40.3):  77%|▊| 23/30 [00:19<00:04,  1\u001b[A\n",
      "Average Metric: 9.683333333333335 / 24  (40.3):  80%|▊| 24/30 [00:19<00:03,  1\u001b[A\n",
      "Average Metric: 10.683333333333335 / 25  (42.7):  80%|▊| 24/30 [00:19<00:03,  \u001b[A\n",
      "Average Metric: 10.683333333333335 / 25  (42.7):  83%|▊| 25/30 [00:19<00:02,  \u001b[A\n",
      "Average Metric: 11.01666666666667 / 26  (42.4):  83%|▊| 25/30 [00:19<00:02,  2\u001b[A\n",
      "Average Metric: 11.01666666666667 / 26  (42.4):  87%|▊| 26/30 [00:19<00:01,  2\u001b[A\n",
      "Average Metric: 11.51666666666667 / 27  (42.7):  87%|▊| 26/30 [00:20<00:01,  2\u001b[A\n",
      "Average Metric: 11.51666666666667 / 27  (42.7):  90%|▉| 27/30 [00:20<00:01,  1\u001b[A\n",
      "Average Metric: 12.51666666666667 / 28  (44.7):  90%|▉| 27/30 [00:21<00:01,  1\u001b[A\n",
      "Average Metric: 12.51666666666667 / 28  (44.7):  93%|▉| 28/30 [00:21<00:01,  1\u001b[A\n",
      "Average Metric: 12.51666666666667 / 29  (43.2):  93%|▉| 28/30 [00:22<00:01,  1\u001b[A\n",
      "Average Metric: 12.51666666666667 / 29  (43.2):  97%|▉| 29/30 [00:22<00:00,  1\u001b[A\n",
      "Average Metric: 12.51666666666667 / 30  (41.7):  97%|▉| 29/30 [00:24<00:00,  1\u001b[A\n",
      "Average Metric: 12.51666666666667 / 30  (41.7): 100%|█| 30/30 [00:24<00:00,  1\u001b[A\n",
      "[I 2024-04-30 09:04:04,410] Trial 9 finished with value: 41.72 and parameters: {'demo_index_for_generate_aspects.predictor': 5, 'demo_index_for_generate_reasons': 12, 'demo_index_for_generate_labels.predictor': 2}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.51666666666667 / 30  (41.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                 | 0/30 [00:05<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▎        | 1/30 [00:05<02:31,  5.23s/it]\u001b[A\n",
      "Average Metric: 0.7 / 2  (35.0):   3%|▎        | 1/30 [00:06<02:31,  5.23s/it]\u001b[A\n",
      "Average Metric: 0.7 / 2  (35.0):   7%|▌        | 2/30 [00:06<01:19,  2.84s/it]\u001b[A\n",
      "Average Metric: 0.7 / 3  (23.3):   7%|▌        | 2/30 [00:06<01:19,  2.84s/it]\u001b[A\n",
      "Average Metric: 0.7 / 3  (23.3):  10%|▉        | 3/30 [00:06<00:45,  1.69s/it]\u001b[A\n",
      "Average Metric: 1.1 / 4  (27.5):  10%|▉        | 3/30 [00:06<00:45,  1.69s/it]\u001b[A\n",
      "Average Metric: 1.1 / 5  (22.0):  13%|█▏       | 4/30 [00:06<00:43,  1.69s/it]\u001b[A\n",
      "Average Metric: 1.1 / 6  (18.3):  17%|█▌       | 5/30 [00:09<00:42,  1.69s/it]\u001b[A\n",
      "Average Metric: 1.1 / 6  (18.3):  20%|█▊       | 6/30 [00:09<00:26,  1.10s/it]\u001b[A\n",
      "Average Metric: 1.1 / 7  (15.7):  20%|█▊       | 6/30 [00:11<00:26,  1.10s/it]\u001b[A\n",
      "Average Metric: 1.1 / 7  (15.7):  23%|██       | 7/30 [00:11<00:33,  1.47s/it]\u001b[A\n",
      "Average Metric: 1.5 / 8  (18.8):  23%|██       | 7/30 [00:11<00:33,  1.47s/it]\u001b[A\n",
      "Average Metric: 1.5 / 8  (18.8):  27%|██▍      | 8/30 [00:11<00:24,  1.13s/it]\u001b[A\n",
      "Average Metric: 2.0 / 9  (22.2):  27%|██▍      | 8/30 [00:11<00:24,  1.13s/it]\u001b[A\n",
      "Average Metric: 2.3333333333333335 / 10  (23.3):  30%|▎| 9/30 [00:14<00:23,  1\u001b[A\n",
      "Average Metric: 2.3333333333333335 / 10  (23.3):  33%|▎| 10/30 [00:14<00:22,  \u001b[A\n",
      "Average Metric: 2.5833333333333335 / 11  (23.5):  33%|▎| 10/30 [00:14<00:22,  \u001b[A\n",
      "Average Metric: 2.5833333333333335 / 11  (23.5):  37%|▎| 11/30 [00:14<00:18,  \u001b[A\n",
      "Average Metric: 3.25 / 12  (27.1):  37%|██▏   | 11/30 [00:14<00:18,  1.05it/s]\u001b[A\n",
      "Average Metric: 3.25 / 12  (27.1):  40%|██▍   | 12/30 [00:14<00:14,  1.25it/s]\u001b[A\n",
      "Average Metric: 4.25 / 13  (32.7):  40%|██▍   | 12/30 [00:15<00:14,  1.25it/s]\u001b[A\n",
      "Average Metric: 4.25 / 13  (32.7):  43%|██▌   | 13/30 [00:15<00:12,  1.32it/s]\u001b[A\n",
      "Average Metric: 4.583333333333333 / 14  (32.7):  43%|▍| 13/30 [00:16<00:12,  1\u001b[A\n",
      "Average Metric: 4.583333333333333 / 14  (32.7):  47%|▍| 14/30 [00:16<00:13,  1\u001b[A\n",
      "Average Metric: 4.583333333333333 / 15  (30.6):  47%|▍| 14/30 [00:18<00:13,  1\u001b[A\n",
      "Average Metric: 4.583333333333333 / 15  (30.6):  50%|▌| 15/30 [00:18<00:16,  1\u001b[A\n",
      "Average Metric: 5.25 / 16  (32.8):  50%|███   | 15/30 [00:19<00:16,  1.11s/it]\u001b[A\n",
      "Average Metric: 5.25 / 16  (32.8):  53%|███▏  | 16/30 [00:19<00:14,  1.01s/it]\u001b[A\n",
      "Average Metric: 6.25 / 17  (36.8):  53%|███▏  | 16/30 [00:20<00:14,  1.01s/it]\u001b[A\n",
      "Average Metric: 6.25 / 17  (36.8):  57%|███▍  | 17/30 [00:20<00:12,  1.00it/s]\u001b[A\n",
      "Average Metric: 6.5 / 18  (36.1):  57%|███▉   | 17/30 [00:21<00:12,  1.00it/s]\u001b[A\n",
      "Average Metric: 6.5 / 18  (36.1):  60%|████▏  | 18/30 [00:21<00:13,  1.10s/it]\u001b[A\n",
      "Average Metric: 6.9 / 19  (36.3):  60%|████▏  | 18/30 [00:21<00:13,  1.10s/it]\u001b[A\n",
      "Average Metric: 6.9 / 19  (36.3):  63%|████▍  | 19/30 [00:21<00:09,  1.16it/s]\u001b[A\n",
      "Average Metric: 6.9 / 20  (34.5):  63%|████▍  | 19/30 [00:22<00:09,  1.16it/s]\u001b[A\n",
      "Average Metric: 6.9 / 20  (34.5):  67%|████▋  | 20/30 [00:22<00:07,  1.32it/s]\u001b[A\n",
      "Average Metric: 7.9 / 21  (37.6):  67%|████▋  | 20/30 [00:24<00:07,  1.32it/s]\u001b[A\n",
      "Average Metric: 7.9 / 21  (37.6):  70%|████▉  | 21/30 [00:24<00:09,  1.08s/it]\u001b[A\n",
      "Average Metric: 8.233333333333334 / 22  (37.4):  70%|▋| 21/30 [00:24<00:09,  1\u001b[A\n",
      "Average Metric: 8.233333333333334 / 22  (37.4):  73%|▋| 22/30 [00:24<00:06,  1\u001b[A\n",
      "Average Metric: 9.233333333333334 / 23  (40.1):  73%|▋| 22/30 [00:25<00:06,  1\u001b[A\n",
      "Average Metric: 9.233333333333334 / 23  (40.1):  77%|▊| 23/30 [00:25<00:06,  1\u001b[A\n",
      "Average Metric: 9.566666666666668 / 24  (39.9):  77%|▊| 23/30 [00:26<00:06,  1\u001b[A\n",
      "Average Metric: 9.566666666666668 / 24  (39.9):  80%|▊| 24/30 [00:26<00:05,  1\u001b[A\n",
      "Average Metric: 9.900000000000002 / 25  (39.6):  80%|▊| 24/30 [00:26<00:05,  1\u001b[A\n",
      "Average Metric: 9.900000000000002 / 25  (39.6):  83%|▊| 25/30 [00:26<00:03,  1\u001b[A\n",
      "Average Metric: 10.900000000000002 / 26  (41.9):  83%|▊| 25/30 [00:27<00:03,  \u001b[A\n",
      "Average Metric: 10.900000000000002 / 26  (41.9):  87%|▊| 26/30 [00:27<00:03,  \u001b[A\n",
      "Average Metric: 11.233333333333336 / 27  (41.6):  87%|▊| 26/30 [00:28<00:03,  \u001b[A\n",
      "Average Metric: 11.233333333333336 / 27  (41.6):  90%|▉| 27/30 [00:28<00:02,  \u001b[A\n",
      "Average Metric: 11.56666666666667 / 28  (41.3):  90%|▉| 27/30 [00:29<00:02,  1\u001b[A\n",
      "Average Metric: 11.56666666666667 / 28  (41.3):  93%|▉| 28/30 [00:29<00:01,  1\u001b[A\n",
      "Average Metric: 11.56666666666667 / 29  (39.9):  93%|▉| 28/30 [00:31<00:01,  1\u001b[A\n",
      "Average Metric: 11.56666666666667 / 29  (39.9):  97%|▉| 29/30 [00:31<00:01,  1\u001b[A\n",
      "Average Metric: 11.56666666666667 / 30  (38.6): 100%|█| 30/30 [00:31<00:00,  1\u001b[A\n",
      "[I 2024-04-30 09:04:35,905] Trial 10 finished with value: 38.56 and parameters: {'demo_index_for_generate_aspects.predictor': 0, 'demo_index_for_generate_reasons': 0, 'demo_index_for_generate_labels.predictor': 15}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.56666666666667 / 30  (38.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:04<02:15,  4.67s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▎         | 1/30 [00:06<02:15,  4.67s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|▋         | 2/30 [00:06<01:23,  2.99s/it]\u001b[A\n",
      "Average Metric: 0.2 / 3  (6.7):   7%|▋         | 2/30 [00:07<01:23,  2.99s/it]\u001b[A\n",
      "Average Metric: 0.2 / 3  (6.7):  10%|█         | 3/30 [00:07<00:59,  2.19s/it]\u001b[A\n",
      "Average Metric: 0.2 / 4  (5.0):  10%|█         | 3/30 [00:08<00:59,  2.19s/it]\u001b[A\n",
      "Average Metric: 0.2 / 4  (5.0):  13%|█▎        | 4/30 [00:08<00:46,  1.80s/it]\u001b[A\n",
      "Average Metric: 0.34285714285714286 / 5  (6.9):  13%|▏| 4/30 [00:09<00:46,  1.\u001b[A\n",
      "Average Metric: 0.34285714285714286 / 5  (6.9):  17%|▏| 5/30 [00:09<00:31,  1.\u001b[A\n",
      "Average Metric: 0.4197802197802198 / 6  (7.0):  17%|▏| 5/30 [00:12<00:31,  1.2\u001b[A\n",
      "Average Metric: 0.4197802197802198 / 6  (7.0):  20%|▏| 6/30 [00:12<00:46,  1.9\u001b[A\n",
      "Average Metric: 0.7531135531135531 / 7  (10.8):  20%|▏| 6/30 [00:12<00:46,  1.\u001b[A\n",
      "Average Metric: 0.7531135531135531 / 7  (10.8):  23%|▏| 7/30 [00:12<00:32,  1.\u001b[A\n",
      "Average Metric: 1.253113553113553 / 8  (15.7):  23%|▏| 7/30 [00:13<00:32,  1.4\u001b[A\n",
      "Average Metric: 1.253113553113553 / 8  (15.7):  27%|▎| 8/30 [00:13<00:28,  1.2\u001b[A\n",
      "Average Metric: 1.503113553113553 / 9  (16.7):  27%|▎| 8/30 [00:13<00:28,  1.2\u001b[A\n",
      "Average Metric: 2.003113553113553 / 10  (20.0):  30%|▎| 9/30 [00:13<00:27,  1.\u001b[A\n",
      "Average Metric: 2.003113553113553 / 10  (20.0):  33%|▎| 10/30 [00:13<00:14,  1\u001b[A\n",
      "Average Metric: 2.3364468864468866 / 11  (21.2):  33%|▎| 10/30 [00:14<00:14,  \u001b[A\n",
      "Average Metric: 2.3364468864468866 / 11  (21.2):  37%|▎| 11/30 [00:14<00:14,  \u001b[A\n",
      "Average Metric: 2.8364468864468866 / 12  (23.6):  37%|▎| 11/30 [00:18<00:14,  \u001b[A\n",
      "Average Metric: 2.8364468864468866 / 12  (23.6):  40%|▍| 12/30 [00:18<00:25,  \u001b[A\n",
      "Average Metric: 3.8364468864468866 / 13  (29.5):  40%|▍| 12/30 [00:18<00:25,  \u001b[A\n",
      "Average Metric: 3.8364468864468866 / 13  (29.5):  43%|▍| 13/30 [00:18<00:18,  \u001b[A\n",
      "Average Metric: 4.836446886446886 / 14  (34.5):  43%|▍| 13/30 [00:18<00:18,  1\u001b[A\n",
      "Average Metric: 4.836446886446886 / 14  (34.5):  47%|▍| 14/30 [00:18<00:13,  1\u001b[A\n",
      "Average Metric: 5.169780219780219 / 15  (34.5):  47%|▍| 14/30 [00:18<00:13,  1\u001b[A\n",
      "Average Metric: 5.169780219780219 / 15  (34.5):  50%|▌| 15/30 [00:18<00:10,  1\u001b[A\n",
      "Average Metric: 6.169780219780219 / 16  (38.6):  50%|▌| 15/30 [00:19<00:10,  1\u001b[A\n",
      "Average Metric: 6.169780219780219 / 16  (38.6):  53%|▌| 16/30 [00:19<00:07,  1\u001b[A\n",
      "Average Metric: 7.169780219780219 / 17  (42.2):  53%|▌| 16/30 [00:22<00:07,  1\u001b[A\n",
      "Average Metric: 7.169780219780219 / 17  (42.2):  57%|▌| 17/30 [00:22<00:16,  1\u001b[A\n",
      "Average Metric: 7.369780219780219 / 18  (40.9):  57%|▌| 17/30 [00:22<00:16,  1\u001b[A\n",
      "Average Metric: 7.369780219780219 / 18  (40.9):  60%|▌| 18/30 [00:22<00:11,  1\u001b[A\n",
      "Average Metric: 7.703113553113552 / 19  (40.5):  60%|▌| 18/30 [00:24<00:11,  1\u001b[A\n",
      "Average Metric: 7.703113553113552 / 19  (40.5):  63%|▋| 19/30 [00:24<00:13,  1\u001b[A\n",
      "Average Metric: 7.703113553113552 / 20  (38.5):  63%|▋| 19/30 [00:24<00:13,  1\u001b[A\n",
      "Average Metric: 7.703113553113552 / 20  (38.5):  67%|▋| 20/30 [00:24<00:10,  1\u001b[A\n",
      "Average Metric: 7.953113553113552 / 21  (37.9):  67%|▋| 20/30 [00:25<00:10,  1\u001b[A\n",
      "Average Metric: 7.953113553113552 / 21  (37.9):  70%|▋| 21/30 [00:25<00:07,  1\u001b[A\n",
      "Average Metric: 8.203113553113553 / 22  (37.3):  70%|▋| 21/30 [00:27<00:07,  1\u001b[A\n",
      "Average Metric: 8.203113553113553 / 22  (37.3):  73%|▋| 22/30 [00:27<00:08,  1\u001b[A\n",
      "Average Metric: 8.703113553113553 / 23  (37.8):  73%|▋| 22/30 [00:29<00:08,  1\u001b[A\n",
      "Average Metric: 8.703113553113553 / 23  (37.8):  77%|▊| 23/30 [00:29<00:11,  1\u001b[A\n",
      "Average Metric: 9.036446886446887 / 24  (37.7):  77%|▊| 23/30 [00:30<00:11,  1\u001b[A\n",
      "Average Metric: 9.036446886446887 / 24  (37.7):  80%|▊| 24/30 [00:30<00:07,  1\u001b[A\n",
      "Average Metric: 9.369780219780221 / 25  (37.5):  80%|▊| 24/30 [00:30<00:07,  1\u001b[A\n",
      "Average Metric: 9.369780219780221 / 25  (37.5):  83%|▊| 25/30 [00:30<00:04,  1\u001b[A\n",
      "Average Metric: 10.369780219780221 / 26  (39.9):  83%|▊| 25/30 [00:30<00:04,  \u001b[A\n",
      "Average Metric: 10.369780219780221 / 26  (39.9):  87%|▊| 26/30 [00:30<00:02,  \u001b[A\n",
      "Average Metric: 10.369780219780221 / 27  (38.4):  87%|▊| 26/30 [00:30<00:02,  \u001b[A\n",
      "Average Metric: 10.869780219780221 / 28  (38.8):  90%|▉| 27/30 [00:33<00:02,  \u001b[A\n",
      "Average Metric: 10.869780219780221 / 28  (38.8):  93%|▉| 28/30 [00:33<00:02,  \u001b[A\n",
      "Average Metric: 10.869780219780221 / 29  (37.5):  93%|▉| 28/30 [00:33<00:02,  \u001b[A\n",
      "Average Metric: 10.869780219780221 / 29  (37.5):  97%|▉| 29/30 [00:33<00:00,  \u001b[A\n",
      "Average Metric: 10.869780219780221 / 30  (36.2):  97%|▉| 29/30 [00:36<00:00,  \u001b[A\n",
      "Average Metric: 10.869780219780221 / 30  (36.2): 100%|█| 30/30 [00:36<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:05:12,234] Trial 11 finished with value: 36.23 and parameters: {'demo_index_for_generate_aspects.predictor': 12, 'demo_index_for_generate_reasons': 4, 'demo_index_for_generate_labels.predictor': 10}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.869780219780221 / 30  (36.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:04<02:02,  4.21s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▎        | 1/30 [00:04<02:02,  4.21s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|▌        | 2/30 [00:04<00:56,  2.01s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|▌        | 2/30 [00:04<00:56,  2.01s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):  10%|▉        | 3/30 [00:04<00:33,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):  10%|▉        | 3/30 [00:06<00:33,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):  13%|█▏       | 4/30 [00:06<00:37,  1.44s/it]\u001b[A\n",
      "Average Metric: 1.9 / 5  (38.0):  13%|█▏       | 4/30 [00:07<00:37,  1.44s/it]\u001b[A\n",
      "Average Metric: 1.9 / 5  (38.0):  17%|█▌       | 5/30 [00:07<00:27,  1.10s/it]\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 6  (37.2):  17%|▏| 5/30 [00:07<00:27,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 6  (37.2):  20%|▏| 6/30 [00:07<00:22,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):  20%|▏| 6/30 [00:08<00:22,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):  23%|▏| 7/30 [00:08<00:22,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 8  (27.9):  23%|▏| 7/30 [00:09<00:22,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 8  (27.9):  27%|▎| 8/30 [00:09<00:19,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 9  (24.8):  27%|▎| 8/30 [00:09<00:19,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 9  (24.8):  30%|▎| 9/30 [00:09<00:13,  1.\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 10  (22.3):  30%|▎| 9/30 [00:10<00:13,  1\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 10  (22.3):  33%|▎| 10/30 [00:10<00:12,  \u001b[A\n",
      "Average Metric: 3.2333333333333334 / 11  (29.4):  33%|▎| 10/30 [00:11<00:12,  \u001b[A\n",
      "Average Metric: 3.2333333333333334 / 11  (29.4):  37%|▎| 11/30 [00:11<00:16,  \u001b[A\n",
      "Average Metric: 3.566666666666667 / 12  (29.7):  37%|▎| 11/30 [00:12<00:16,  1\u001b[A\n",
      "Average Metric: 3.566666666666667 / 12  (29.7):  40%|▍| 12/30 [00:12<00:13,  1\u001b[A\n",
      "Average Metric: 3.566666666666667 / 13  (27.4):  40%|▍| 12/30 [00:13<00:13,  1\u001b[A\n",
      "Average Metric: 3.566666666666667 / 13  (27.4):  43%|▍| 13/30 [00:13<00:15,  1\u001b[A\n",
      "Average Metric: 3.9000000000000004 / 14  (27.9):  43%|▍| 13/30 [00:14<00:15,  \u001b[A\n",
      "Average Metric: 3.9000000000000004 / 14  (27.9):  47%|▍| 14/30 [00:14<00:13,  \u001b[A\n",
      "Average Metric: 4.9 / 15  (32.7):  47%|███▎   | 14/30 [00:14<00:13,  1.18it/s]\u001b[A\n",
      "Average Metric: 4.9 / 16  (30.6):  50%|███▌   | 15/30 [00:15<00:12,  1.18it/s]\u001b[A\n",
      "Average Metric: 4.9 / 16  (30.6):  53%|███▋   | 16/30 [00:15<00:10,  1.37it/s]\u001b[A\n",
      "Average Metric: 5.4 / 17  (31.8):  53%|███▋   | 16/30 [00:16<00:10,  1.37it/s]\u001b[A\n",
      "Average Metric: 5.4 / 17  (31.8):  57%|███▉   | 17/30 [00:16<00:11,  1.12it/s]\u001b[A\n",
      "Average Metric: 5.6000000000000005 / 18  (31.1):  57%|▌| 17/30 [00:17<00:11,  \u001b[A\n",
      "Average Metric: 5.6000000000000005 / 18  (31.1):  60%|▌| 18/30 [00:17<00:09,  \u001b[A\n",
      "Average Metric: 6.6000000000000005 / 19  (34.7):  60%|▌| 18/30 [00:17<00:09,  \u001b[A\n",
      "Average Metric: 6.6000000000000005 / 19  (34.7):  63%|▋| 19/30 [00:17<00:07,  \u001b[A\n",
      "Average Metric: 6.6000000000000005 / 20  (33.0):  63%|▋| 19/30 [00:18<00:07,  \u001b[A\n",
      "Average Metric: 6.6000000000000005 / 20  (33.0):  67%|▋| 20/30 [00:18<00:06,  \u001b[A\n",
      "Average Metric: 6.6000000000000005 / 21  (31.4):  67%|▋| 20/30 [00:18<00:06,  \u001b[A\n",
      "Average Metric: 7.6000000000000005 / 22  (34.5):  70%|▋| 21/30 [00:20<00:05,  \u001b[A\n",
      "Average Metric: 7.6000000000000005 / 22  (34.5):  73%|▋| 22/30 [00:20<00:06,  \u001b[A\n",
      "Average Metric: 7.7666666666666675 / 23  (33.8):  73%|▋| 22/30 [00:20<00:06,  \u001b[A\n",
      "Average Metric: 7.7666666666666675 / 23  (33.8):  77%|▊| 23/30 [00:20<00:04,  \u001b[A\n",
      "Average Metric: 8.766666666666667 / 24  (36.5):  77%|▊| 23/30 [00:20<00:04,  1\u001b[A\n",
      "Average Metric: 8.766666666666667 / 24  (36.5):  80%|▊| 24/30 [00:20<00:03,  1\u001b[A\n",
      "Average Metric: 9.766666666666667 / 25  (39.1):  80%|▊| 24/30 [00:21<00:03,  1\u001b[A\n",
      "Average Metric: 9.766666666666667 / 25  (39.1):  83%|▊| 25/30 [00:21<00:03,  1\u001b[A\n",
      "Average Metric: 10.266666666666667 / 26  (39.5):  83%|▊| 25/30 [00:22<00:03,  \u001b[A\n",
      "Average Metric: 10.266666666666667 / 26  (39.5):  87%|▊| 26/30 [00:22<00:02,  \u001b[A\n",
      "Average Metric: 10.266666666666667 / 27  (38.0):  87%|▊| 26/30 [00:22<00:02,  \u001b[A\n",
      "Average Metric: 10.266666666666667 / 27  (38.0):  90%|▉| 27/30 [00:22<00:01,  \u001b[A\n",
      "Average Metric: 10.266666666666667 / 28  (36.7):  90%|▉| 27/30 [00:25<00:01,  \u001b[A\n",
      "Average Metric: 10.266666666666667 / 28  (36.7):  93%|▉| 28/30 [00:25<00:02,  \u001b[A\n",
      "Average Metric: 10.933333333333334 / 29  (37.7):  93%|▉| 28/30 [00:26<00:02,  \u001b[A\n",
      "Average Metric: 10.933333333333334 / 29  (37.7):  97%|▉| 29/30 [00:26<00:01,  \u001b[A\n",
      "Average Metric: 10.933333333333334 / 30  (36.4):  97%|▉| 29/30 [00:28<00:01,  \u001b[A\n",
      "Average Metric: 10.933333333333334 / 30  (36.4): 100%|█| 30/30 [00:28<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:05:40,350] Trial 12 finished with value: 36.44 and parameters: {'demo_index_for_generate_aspects.predictor': 13, 'demo_index_for_generate_reasons': 3, 'demo_index_for_generate_labels.predictor': 10}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.933333333333334 / 30  (36.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:01<00:42,  1.46s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▎        | 1/30 [00:01<00:42,  1.46s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|▌        | 2/30 [00:01<00:40,  1.46s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|▉        | 3/30 [00:01<00:15,  1.78it/s]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):  10%|▉        | 3/30 [00:02<00:15,  1.78it/s]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):  13%|█▏       | 4/30 [00:02<00:11,  2.20it/s]\u001b[A\n",
      "Average Metric: 1.0 / 5  (20.0):  13%|█▏       | 4/30 [00:02<00:11,  2.20it/s]\u001b[A\n",
      "Average Metric: 1.0 / 5  (20.0):  17%|█▌       | 5/30 [00:02<00:08,  2.91it/s]\u001b[A\n",
      "Average Metric: 1.4 / 6  (23.3):  17%|█▌       | 5/30 [00:02<00:08,  2.91it/s]\u001b[A\n",
      "Average Metric: 1.9 / 7  (27.1):  20%|█▊       | 6/30 [00:02<00:08,  2.91it/s]\u001b[A\n",
      "Average Metric: 1.9 / 7  (27.1):  23%|██       | 7/30 [00:02<00:06,  3.68it/s]\u001b[A\n",
      "Average Metric: 2.15 / 8  (26.9):  23%|█▊      | 7/30 [00:03<00:06,  3.68it/s]\u001b[A\n",
      "Average Metric: 2.15 / 8  (26.9):  27%|██▏     | 8/30 [00:03<00:06,  3.35it/s]\u001b[A\n",
      "Average Metric: 2.4833333333333334 / 9  (27.6):  27%|▎| 8/30 [00:03<00:06,  3.\u001b[A\n",
      "Average Metric: 2.4833333333333334 / 9  (27.6):  30%|▎| 9/30 [00:03<00:05,  3.\u001b[A\n",
      "Average Metric: 2.9833333333333334 / 10  (29.8):  30%|▎| 9/30 [00:03<00:05,  3\u001b[A\n",
      "Average Metric: 2.9833333333333334 / 10  (29.8):  33%|▎| 10/30 [00:03<00:06,  \u001b[A\n",
      "Average Metric: 3.65 / 11  (33.2):  33%|██    | 10/30 [00:03<00:06,  3.32it/s]\u001b[A\n",
      "Average Metric: 3.65 / 11  (33.2):  37%|██▏   | 11/30 [00:03<00:05,  3.67it/s]\u001b[A\n",
      "Average Metric: 3.65 / 12  (30.4):  37%|██▏   | 11/30 [00:03<00:05,  3.67it/s]\u001b[A\n",
      "Average Metric: 4.65 / 13  (35.8):  40%|██▍   | 12/30 [00:04<00:04,  3.67it/s]\u001b[A\n",
      "Average Metric: 4.65 / 13  (35.8):  43%|██▌   | 13/30 [00:04<00:04,  4.21it/s]\u001b[A\n",
      "Average Metric: 5.65 / 14  (40.4):  43%|██▌   | 13/30 [00:04<00:04,  4.21it/s]\u001b[A\n",
      "Average Metric: 5.65 / 14  (40.4):  47%|██▊   | 14/30 [00:04<00:03,  4.27it/s]\u001b[A\n",
      "Average Metric: 6.65 / 15  (44.3):  47%|██▊   | 14/30 [00:04<00:03,  4.27it/s]\u001b[A\n",
      "Average Metric: 6.65 / 15  (44.3):  50%|███   | 15/30 [00:04<00:03,  4.42it/s]\u001b[A\n",
      "Average Metric: 6.65 / 16  (41.6):  50%|███   | 15/30 [00:05<00:03,  4.42it/s]\u001b[A\n",
      "Average Metric: 6.65 / 16  (41.6):  53%|███▏  | 16/30 [00:05<00:03,  3.89it/s]\u001b[A\n",
      "Average Metric: 6.983333333333333 / 17  (41.1):  53%|▌| 16/30 [00:05<00:03,  3\u001b[A\n",
      "Average Metric: 6.983333333333333 / 17  (41.1):  57%|▌| 17/30 [00:05<00:04,  3\u001b[A\n",
      "Average Metric: 6.983333333333333 / 18  (38.8):  57%|▌| 17/30 [00:05<00:04,  3\u001b[A\n",
      "Average Metric: 6.983333333333333 / 18  (38.8):  60%|▌| 18/30 [00:05<00:03,  3\u001b[A\n",
      "Average Metric: 6.983333333333333 / 19  (36.8):  60%|▌| 18/30 [00:05<00:03,  3\u001b[A\n",
      "Average Metric: 6.983333333333333 / 19  (36.8):  63%|▋| 19/30 [00:05<00:02,  3\u001b[A\n",
      "Average Metric: 7.183333333333334 / 20  (35.9):  63%|▋| 19/30 [00:05<00:02,  3\u001b[A\n",
      "Average Metric: 7.683333333333334 / 21  (36.6):  67%|▋| 20/30 [00:06<00:02,  3\u001b[A\n",
      "Average Metric: 7.683333333333334 / 21  (36.6):  70%|▋| 21/30 [00:06<00:01,  5\u001b[A\n",
      "Average Metric: 8.683333333333334 / 22  (39.5):  70%|▋| 21/30 [00:06<00:01,  5\u001b[A\n",
      "Average Metric: 8.683333333333334 / 22  (39.5):  73%|▋| 22/30 [00:06<00:01,  4\u001b[A\n",
      "Average Metric: 9.683333333333334 / 23  (42.1):  73%|▋| 22/30 [00:06<00:01,  4\u001b[A\n",
      "Average Metric: 9.683333333333334 / 23  (42.1):  77%|▊| 23/30 [00:06<00:02,  3\u001b[A\n",
      "Average Metric: 9.683333333333334 / 24  (40.3):  77%|▊| 23/30 [00:07<00:02,  3\u001b[A\n",
      "Average Metric: 9.683333333333334 / 24  (40.3):  80%|▊| 24/30 [00:07<00:01,  3\u001b[A\n",
      "Average Metric: 10.016666666666667 / 25  (40.1):  80%|▊| 24/30 [00:07<00:01,  \u001b[A\n",
      "Average Metric: 11.016666666666667 / 26  (42.4):  83%|▊| 25/30 [00:07<00:01,  \u001b[A\n",
      "Average Metric: 11.016666666666667 / 26  (42.4):  87%|▊| 26/30 [00:07<00:00,  \u001b[A\n",
      "Average Metric: 11.516666666666667 / 27  (42.7):  87%|▊| 26/30 [00:07<00:00,  \u001b[A\n",
      "Average Metric: 11.516666666666667 / 27  (42.7):  90%|▉| 27/30 [00:07<00:00,  \u001b[A\n",
      "Average Metric: 11.516666666666667 / 28  (41.1):  90%|▉| 27/30 [00:07<00:00,  \u001b[A\n",
      "Average Metric: 11.516666666666667 / 28  (41.1):  93%|▉| 28/30 [00:07<00:00,  \u001b[A\n",
      "Average Metric: 12.516666666666667 / 29  (43.2):  93%|▉| 28/30 [00:08<00:00,  \u001b[A\n",
      "Average Metric: 12.516666666666667 / 30  (41.7):  97%|▉| 29/30 [00:08<00:00,  \u001b[A\n",
      "Average Metric: 12.516666666666667 / 30  (41.7): 100%|█| 30/30 [00:08<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:05:48,758] Trial 13 finished with value: 41.72 and parameters: {'demo_index_for_generate_aspects.predictor': 5, 'demo_index_for_generate_reasons': 9, 'demo_index_for_generate_labels.predictor': 7}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.516666666666667 / 30  (41.7%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                  | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▎         | 1/30 [00:03<01:32,  3.19s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▎        | 1/30 [00:03<01:32,  3.19s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|▌        | 2/30 [00:03<00:46,  1.65s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|▌        | 2/30 [00:04<00:46,  1.65s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|▉        | 3/30 [00:04<00:33,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):  10%|▉        | 3/30 [00:05<00:33,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):  13%|█▏       | 4/30 [00:05<00:34,  1.32s/it]\u001b[A\n",
      "Average Metric: 1.4 / 5  (28.0):  13%|█▏       | 4/30 [00:06<00:34,  1.32s/it]\u001b[A\n",
      "Average Metric: 1.4 / 5  (28.0):  17%|█▌       | 5/30 [00:06<00:25,  1.01s/it]\u001b[A\n",
      "Average Metric: 1.9 / 6  (31.7):  17%|█▌       | 5/30 [00:07<00:25,  1.01s/it]\u001b[A\n",
      "Average Metric: 1.9 / 6  (31.7):  20%|█▊       | 6/30 [00:07<00:25,  1.06s/it]\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 7  (36.7):  20%|▏| 6/30 [00:07<00:25,  1.\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 7  (36.7):  23%|▏| 7/30 [00:07<00:18,  1.\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  23%|▏| 7/30 [00:08<00:18,  1.\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  27%|▎| 8/30 [00:08<00:13,  1.\u001b[A\n",
      "Average Metric: 2.9 / 9  (32.2):  27%|██▍      | 8/30 [00:08<00:13,  1.59it/s]\u001b[A\n",
      "Average Metric: 2.9 / 9  (32.2):  30%|██▋      | 9/30 [00:08<00:13,  1.51it/s]\u001b[A\n",
      "Average Metric: 3.4 / 10  (34.0):  30%|██▍     | 9/30 [00:10<00:13,  1.51it/s]\u001b[A\n",
      "Average Metric: 3.4 / 10  (34.0):  33%|██▎    | 10/30 [00:10<00:20,  1.02s/it]\u001b[A\n",
      "Average Metric: 3.7333333333333334 / 11  (33.9):  33%|▎| 10/30 [00:10<00:20,  \u001b[A\n",
      "Average Metric: 3.7333333333333334 / 11  (33.9):  37%|▎| 11/30 [00:10<00:14,  \u001b[A\n",
      "Average Metric: 4.233333333333333 / 12  (35.3):  37%|▎| 11/30 [00:11<00:14,  1\u001b[A\n",
      "Average Metric: 4.233333333333333 / 12  (35.3):  40%|▍| 12/30 [00:11<00:10,  1\u001b[A\n",
      "Average Metric: 4.233333333333333 / 13  (32.6):  40%|▍| 12/30 [00:12<00:10,  1\u001b[A\n",
      "Average Metric: 4.233333333333333 / 13  (32.6):  43%|▍| 13/30 [00:12<00:13,  1\u001b[A\n",
      "Average Metric: 4.233333333333333 / 14  (30.2):  43%|▍| 13/30 [00:12<00:13,  1\u001b[A\n",
      "Average Metric: 4.233333333333333 / 14  (30.2):  47%|▍| 14/30 [00:12<00:11,  1\u001b[A\n",
      "Average Metric: 4.233333333333333 / 15  (28.2):  47%|▍| 14/30 [00:14<00:11,  1\u001b[A\n",
      "Average Metric: 4.233333333333333 / 15  (28.2):  50%|▌| 15/30 [00:14<00:13,  1\u001b[A\n",
      "Average Metric: 5.233333333333333 / 16  (32.7):  50%|▌| 15/30 [00:14<00:13,  1\u001b[A\n",
      "Average Metric: 5.233333333333333 / 16  (32.7):  53%|▌| 16/30 [00:14<00:10,  1\u001b[A\n",
      "Average Metric: 6.233333333333333 / 17  (36.7):  53%|▌| 16/30 [00:15<00:10,  1\u001b[A\n",
      "Average Metric: 6.233333333333333 / 17  (36.7):  57%|▌| 17/30 [00:15<00:11,  1\u001b[A\n",
      "Average Metric: 6.233333333333333 / 18  (34.6):  57%|▌| 17/30 [00:16<00:11,  1\u001b[A\n",
      "Average Metric: 6.233333333333333 / 18  (34.6):  60%|▌| 18/30 [00:16<00:09,  1\u001b[A\n",
      "Average Metric: 6.233333333333333 / 19  (32.8):  60%|▌| 18/30 [00:17<00:09,  1\u001b[A\n",
      "Average Metric: 6.233333333333333 / 19  (32.8):  63%|▋| 19/30 [00:17<00:09,  1\u001b[A\n",
      "Average Metric: 7.233333333333333 / 20  (36.2):  63%|▋| 19/30 [00:17<00:09,  1\u001b[A\n",
      "Average Metric: 7.233333333333333 / 20  (36.2):  67%|▋| 20/30 [00:17<00:07,  1\u001b[A\n",
      "Average Metric: 8.233333333333334 / 21  (39.2):  67%|▋| 20/30 [00:18<00:07,  1\u001b[A\n",
      "Average Metric: 8.233333333333334 / 21  (39.2):  70%|▋| 21/30 [00:18<00:07,  1\u001b[A\n",
      "Average Metric: 8.633333333333335 / 22  (39.2):  70%|▋| 21/30 [00:19<00:07,  1\u001b[A\n",
      "Average Metric: 8.633333333333335 / 22  (39.2):  73%|▋| 22/30 [00:19<00:04,  1\u001b[A\n",
      "Average Metric: 9.633333333333335 / 23  (41.9):  73%|▋| 22/30 [00:20<00:04,  1\u001b[A\n",
      "Average Metric: 9.633333333333335 / 23  (41.9):  77%|▊| 23/30 [00:20<00:06,  1\u001b[A\n",
      "Average Metric: 10.633333333333335 / 24  (44.3):  77%|▊| 23/30 [00:20<00:06,  \u001b[A\n",
      "Average Metric: 10.633333333333335 / 24  (44.3):  80%|▊| 24/30 [00:20<00:04,  \u001b[A\n",
      "Average Metric: 10.966666666666669 / 25  (43.9):  80%|▊| 24/30 [00:21<00:04,  \u001b[A\n",
      "Average Metric: 10.966666666666669 / 25  (43.9):  83%|▊| 25/30 [00:21<00:03,  \u001b[A\n",
      "Average Metric: 11.966666666666669 / 26  (46.0):  83%|▊| 25/30 [00:22<00:03,  \u001b[A\n",
      "Average Metric: 11.966666666666669 / 26  (46.0):  87%|▊| 26/30 [00:22<00:03,  \u001b[A\n",
      "Average Metric: 12.966666666666669 / 27  (48.0):  87%|▊| 26/30 [00:23<00:03,  \u001b[A\n",
      "Average Metric: 12.966666666666669 / 27  (48.0):  90%|▉| 27/30 [00:23<00:02,  \u001b[A\n",
      "Average Metric: 12.966666666666669 / 28  (46.3):  90%|▉| 27/30 [00:24<00:02,  \u001b[A\n",
      "Average Metric: 12.966666666666669 / 28  (46.3):  93%|▉| 28/30 [00:24<00:01,  \u001b[A\n",
      "Average Metric: 13.300000000000002 / 29  (45.9):  93%|▉| 28/30 [00:24<00:01,  \u001b[A\n",
      "Average Metric: 13.300000000000002 / 29  (45.9):  97%|▉| 29/30 [00:24<00:00,  \u001b[A\n",
      "Average Metric: 13.300000000000002 / 30  (44.3):  97%|▉| 29/30 [00:25<00:00,  \u001b[A\n",
      "Average Metric: 13.300000000000002 / 30  (44.3): 100%|█| 30/30 [00:25<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:06:14,309] Trial 14 finished with value: 44.33 and parameters: {'demo_index_for_generate_aspects.predictor': 11, 'demo_index_for_generate_reasons': 5, 'demo_index_for_generate_labels.predictor': 13}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.300000000000002 / 30  (44.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                  | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▎       | 1/30 [00:03<01:38,  3.40s/it]\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 2  (83.3):   3%| | 1/30 [00:03<01:38,  3.\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 3  (72.2):   7%| | 2/30 [00:04<01:35,  3.\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 3  (72.2):  10%| | 3/30 [00:04<00:31,  1.\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 4  (66.7):  10%| | 3/30 [00:04<00:31,  1.\u001b[A\n",
      "Average Metric: 2.9166666666666665 / 5  (58.3):  13%|▏| 4/30 [00:05<00:29,  1.\u001b[A\n",
      "Average Metric: 2.9166666666666665 / 5  (58.3):  17%|▏| 5/30 [00:05<00:22,  1.\u001b[A\n",
      "Average Metric: 3.4166666666666665 / 6  (56.9):  17%|▏| 5/30 [00:05<00:22,  1.\u001b[A\n",
      "Average Metric: 3.4166666666666665 / 7  (48.8):  20%|▏| 6/30 [00:05<00:21,  1.\u001b[A\n",
      "Average Metric: 3.4166666666666665 / 7  (48.8):  23%|▏| 7/30 [00:05<00:12,  1.\u001b[A\n",
      "Average Metric: 3.8166666666666664 / 8  (47.7):  23%|▏| 7/30 [00:05<00:12,  1.\u001b[A\n",
      "Average Metric: 3.8166666666666664 / 8  (47.7):  27%|▎| 8/30 [00:05<00:09,  2.\u001b[A\n",
      "Average Metric: 3.8166666666666664 / 9  (42.4):  27%|▎| 8/30 [00:07<00:09,  2.\u001b[A\n",
      "Average Metric: 3.8166666666666664 / 9  (42.4):  30%|▎| 9/30 [00:07<00:14,  1.\u001b[A\n",
      "Average Metric: 4.816666666666666 / 10  (48.2):  30%|▎| 9/30 [00:07<00:14,  1.\u001b[A\n",
      "Average Metric: 5.216666666666667 / 11  (47.4):  33%|▎| 10/30 [00:07<00:14,  1\u001b[A\n",
      "Average Metric: 5.716666666666667 / 12  (47.6):  37%|▎| 11/30 [00:08<00:13,  1\u001b[A\n",
      "Average Metric: 5.716666666666667 / 12  (47.6):  40%|▍| 12/30 [00:08<00:09,  1\u001b[A\n",
      "Average Metric: 5.716666666666667 / 13  (44.0):  40%|▍| 12/30 [00:08<00:09,  1\u001b[A\n",
      "Average Metric: 6.716666666666667 / 14  (48.0):  43%|▍| 13/30 [00:11<00:09,  1\u001b[A\n",
      "Average Metric: 6.716666666666667 / 14  (48.0):  47%|▍| 14/30 [00:11<00:12,  1\u001b[A\n",
      "Average Metric: 7.716666666666667 / 15  (51.4):  47%|▍| 14/30 [00:11<00:12,  1\u001b[A\n",
      "Average Metric: 8.05 / 16  (50.3):  50%|███   | 15/30 [00:11<00:12,  1.23it/s]\u001b[A\n",
      "Average Metric: 8.05 / 16  (50.3):  53%|███▏  | 16/30 [00:11<00:08,  1.68it/s]\u001b[A\n",
      "Average Metric: 8.05 / 17  (47.4):  53%|███▏  | 16/30 [00:11<00:08,  1.68it/s]\u001b[A\n",
      "Average Metric: 9.05 / 18  (50.3):  57%|███▍  | 17/30 [00:11<00:07,  1.68it/s]\u001b[A\n",
      "Average Metric: 10.05 / 19  (52.9):  60%|███  | 18/30 [00:11<00:07,  1.68it/s]\u001b[A\n",
      "Average Metric: 10.55 / 20  (52.8):  63%|███▏ | 19/30 [00:11<00:06,  1.68it/s]\u001b[A\n",
      "Average Metric: 11.55 / 21  (55.0):  67%|███▎ | 20/30 [00:11<00:05,  1.68it/s]\u001b[A\n",
      "Average Metric: 11.55 / 21  (55.0):  70%|███▌ | 21/30 [00:11<00:02,  3.44it/s]\u001b[A\n",
      "Average Metric: 11.55 / 22  (52.5):  70%|███▌ | 21/30 [00:11<00:02,  3.44it/s]\u001b[A\n",
      "Average Metric: 12.55 / 23  (54.6):  73%|███▋ | 22/30 [00:11<00:02,  3.44it/s]\u001b[A\n",
      "Average Metric: 12.55 / 24  (52.3):  77%|███▊ | 23/30 [00:11<00:02,  3.44it/s]\u001b[A\n",
      "Average Metric: 12.55 / 24  (52.3):  80%|████ | 24/30 [00:11<00:01,  4.75it/s]\u001b[A\n",
      "Average Metric: 12.55 / 25  (50.2):  80%|████ | 24/30 [00:13<00:01,  4.75it/s]\u001b[A\n",
      "Average Metric: 13.05 / 26  (50.2):  83%|████▏| 25/30 [00:15<00:01,  4.75it/s]\u001b[A\n",
      "Average Metric: 13.05 / 26  (50.2):  87%|████▎| 26/30 [00:15<00:02,  1.69it/s]\u001b[A\n",
      "Average Metric: 13.55 / 27  (50.2):  87%|████▎| 26/30 [00:15<00:02,  1.69it/s]\u001b[A\n",
      "Average Metric: 13.883333333333335 / 28  (49.6):  90%|▉| 27/30 [00:15<00:01,  \u001b[A\n",
      "Average Metric: 13.883333333333335 / 28  (49.6):  93%|▉| 28/30 [00:15<00:00,  \u001b[A\n",
      "Average Metric: 13.883333333333335 / 29  (47.9):  93%|▉| 28/30 [00:15<00:00,  \u001b[A\n",
      "Average Metric: 14.383333333333335 / 30  (47.9):  97%|▉| 29/30 [00:16<00:00,  \u001b[A\n",
      "Average Metric: 14.383333333333335 / 30  (47.9): 100%|█| 30/30 [00:16<00:00,  \u001b[A\n",
      "[I 2024-04-30 09:06:30,593] Trial 15 finished with value: 47.94 and parameters: {'demo_index_for_generate_aspects.predictor': 3, 'demo_index_for_generate_reasons': 5, 'demo_index_for_generate_labels.predictor': 13}. Best is trial 5 with value: 49.44.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.383333333333335 / 30  (47.9%)\n",
      "Best score: 49.44\n",
      "Best program: generate_aspects.predictor = Predict(StringSignature(review -> reasoning, aspects_list\n",
      "    instructions='\\n    Identify aspects from a customer review. The aspects must be words or phrases in the review. The aspect\\n    is typically a noun, and it must be the narrowest word or phrase possible. The response must be a valid Python list,\\n    where each item is an aspect.\\n    '\n",
      "    review = Field(annotation=str required=True json_schema_extra={'desc': 'a customer review', '__dspy_field_type': 'input', 'prefix': 'Review:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the aspects_list}. We ...', '__dspy_field_type': 'output'})\n",
      "    aspects_list = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review. Must be a valid Python list.\\n', '__dspy_field_type': 'output', 'prefix': 'Aspects List:'})\n",
      "))\n",
      "generate_reasons = ChainOfThought(Aspects2Reasons(review, aspects_list -> reasons\n",
      "    instructions='\\n    Using the customer review and list of aspects, reason about whether each aspect is positive, neutral, or negative.\\n    Think deeply about each aspect in the context of the entire review.\\n    '\n",
      "    review = Field(annotation=str required=True json_schema_extra={'desc': 'a customer review', '__dspy_field_type': 'input', 'prefix': 'Review:'})\n",
      "    aspects_list = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review\\n', '__dspy_field_type': 'input', 'prefix': 'Aspects List:'})\n",
      "    reasons = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review. Under each aspect, there are some thoughts or reasons\\nabout whether the aspect is positive, neutral, or negative.\\n', '__dspy_field_type': 'output', 'prefix': 'Reasons:'})\n",
      "))\n",
      "generate_labels.predictor = Predict(StringSignature(aspects_list, reasons -> reasoning, aspects_with_label\n",
      "    instructions='\\n    Labels each aspect as 1 meaning positive, 0 meaning neutral, and -1 meaning negative. The response must be a \\n    valid Python dictionary, where each key is an aspect and the value is the integer label.\\n    '\n",
      "    aspects_list = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review\\n', '__dspy_field_type': 'input', 'prefix': 'Aspects List:'})\n",
      "    reasons = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review. Under each aspect, there are some thoughts or reasons\\nabout whether the aspect is positive, neutral, or negative.\\n', '__dspy_field_type': 'input', 'prefix': 'Reasons:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the aspects_with_label}. We ...', '__dspy_field_type': 'output'})\n",
      "    aspects_with_label = Field(annotation=dict required=True json_schema_extra={'format': <class 'dict'>, 'desc': '\\na single Python dictionary, where each key is an aspect and the value is the label,\\nwith label 1 indicating positive sentiment, 0 indicating neutral sentiment, and -1\\nindicating negative sentiment.\\n', '__dspy_field_type': 'output', 'prefix': 'Aspects With Label:'})\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "compiled_v2 = ABSAPipelineV2()\n",
    "ABSAPipelineV2.load(compiled_v2, \"./ABSAPipelineV2.json\")\n",
    "\n",
    "from dspy.teleprompt import BootstrapFewShotWithOptuna\n",
    "\n",
    "optimizer = BootstrapFewShotWithOptuna(metric=validate_venn)\n",
    "compiled_optuna = optimizer.compile(ABSAPipelineV2(), teacher=compiled_v2, trainset=dspy_train[30:60], max_demos=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d67e524d-d11c-4b84-8ef5-9b1647c38967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                 | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|               | 0/100 [00:05<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   1%|       | 1/100 [00:05<09:00,  5.45s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   1%|        | 1/100 [00:05<09:00,  5.45s/it]\u001b[A\n",
      "Average Metric: 1.4 / 3  (46.7):   2%|▏       | 2/100 [00:06<08:54,  5.45s/it]\u001b[A\n",
      "Average Metric: 1.4 / 3  (46.7):   3%|▏       | 3/100 [00:06<03:01,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.4 / 4  (35.0):   3%|▏       | 3/100 [00:08<03:01,  1.87s/it]\u001b[A\n",
      "Average Metric: 1.4 / 4  (35.0):   4%|▎       | 4/100 [00:08<02:52,  1.80s/it]\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 5  (41.3):   4%| | 4/100 [00:08<02:52,  1\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 5  (41.3):   5%| | 5/100 [00:08<02:07,  1\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.733333333333333 / 6  (45.6):   5%| | 5/100 [00:09<02:07,  1.\u001b[A\n",
      "Average Metric: 2.733333333333333 / 6  (45.6):   6%| | 6/100 [00:09<01:41,  1.\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.9555555555555553 / 7  (42.2):   6%| | 6/100 [00:11<01:41,  1\u001b[A\n",
      "Average Metric: 2.9555555555555553 / 7  (42.2):   7%| | 7/100 [00:11<02:13,  1\u001b[A\n",
      "Average Metric: 2.9555555555555553 / 8  (36.9):   7%| | 7/100 [00:11<02:13,  1\u001b[A\n",
      "Average Metric: 2.9555555555555553 / 8  (36.9):   8%| | 8/100 [00:11<01:37,  1\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.2055555555555553 / 9  (35.6):   8%| | 8/100 [00:14<01:37,  1\u001b[A\n",
      "Average Metric: 3.2055555555555553 / 9  (35.6):   9%| | 9/100 [00:14<02:36,  1\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.5388888888888888 / 10  (35.4):   9%| | 9/100 [00:16<02:36,  \u001b[A\n",
      "Average Metric: 3.5388888888888888 / 10  (35.4):  10%| | 10/100 [00:16<02:36, \u001b[A\n",
      "Average Metric: 4.338888888888889 / 11  (39.4):  10%| | 10/100 [00:16<02:36,  \u001b[A\n",
      "Average Metric: 4.338888888888889 / 11  (39.4):  11%| | 11/100 [00:16<01:52,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.196031746031745 / 12  (43.3):  11%| | 11/100 [00:17<01:52,  \u001b[A\n",
      "Average Metric: 5.196031746031745 / 12  (43.3):  12%| | 12/100 [00:17<01:35,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.696031746031745 / 13  (43.8):  12%| | 12/100 [00:18<01:35,  \u001b[A\n",
      "Average Metric: 5.696031746031745 / 13  (43.8):  13%|▏| 13/100 [00:18<01:27,  \u001b[A\n",
      "Average Metric: 6.696031746031745 / 14  (47.8):  13%|▏| 13/100 [00:18<01:27,  \u001b[A\n",
      "Average Metric: 6.696031746031745 / 14  (47.8):  14%|▏| 14/100 [00:18<01:04,  \u001b[A\n",
      "Average Metric: 6.696031746031745 / 15  (44.6):  14%|▏| 14/100 [00:18<01:04,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.584920634920634 / 16  (47.4):  15%|▏| 15/100 [00:19<01:03,  \u001b[A\n",
      "Average Metric: 7.584920634920634 / 16  (47.4):  16%|▏| 16/100 [00:19<00:53,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.084920634920634 / 17  (47.6):  16%|▏| 16/100 [00:22<00:53,  \u001b[A\n",
      "Average Metric: 8.084920634920634 / 17  (47.6):  17%|▏| 17/100 [00:22<01:49,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.084920634920634 / 18  (44.9):  17%|▏| 17/100 [00:23<01:49,  \u001b[A\n",
      "Average Metric: 8.084920634920634 / 18  (44.9):  18%|▏| 18/100 [00:23<01:27,  \u001b[A\n",
      "Average Metric: 9.084920634920634 / 19  (47.8):  18%|▏| 18/100 [00:23<01:27,  \u001b[A\n",
      "Average Metric: 9.084920634920634 / 19  (47.8):  19%|▏| 19/100 [00:23<01:09,  \u001b[A\n",
      "Average Metric: 10.084920634920634 / 20  (50.4):  19%|▏| 19/100 [00:24<01:09, \u001b[A\n",
      "Average Metric: 10.084920634920634 / 20  (50.4):  20%|▏| 20/100 [00:24<01:01, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.7515873015873 / 21  (51.2):  20%|▏| 20/100 [00:25<01:01,  1\u001b[A\n",
      "Average Metric: 10.7515873015873 / 21  (51.2):  21%|▏| 21/100 [00:25<01:17,  1\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.418253968253966 / 22  (51.9):  21%|▏| 21/100 [00:28<01:17, \u001b[A\n",
      "Average Metric: 11.418253968253966 / 22  (51.9):  22%|▏| 22/100 [00:28<01:57, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.418253968253966 / 23  (54.0):  22%|▏| 22/100 [00:29<01:57, \u001b[A\n",
      "Average Metric: 12.418253968253966 / 23  (54.0):  23%|▏| 23/100 [00:29<01:35, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.818253968253966 / 24  (53.4):  23%|▏| 23/100 [00:30<01:35, \u001b[A\n",
      "Average Metric: 12.818253968253966 / 24  (53.4):  24%|▏| 24/100 [00:30<01:36, \u001b[A\n",
      "Average Metric: 12.818253968253966 / 25  (51.3):  24%|▏| 24/100 [00:31<01:36, \u001b[A\n",
      "Average Metric: 12.818253968253966 / 25  (51.3):  25%|▎| 25/100 [00:31<01:38, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.068253968253966 / 26  (50.3):  25%|▎| 25/100 [00:32<01:38, \u001b[A\n",
      "Average Metric: 13.068253968253966 / 26  (50.3):  26%|▎| 26/100 [00:32<01:30, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.068253968253966 / 27  (48.4):  26%|▎| 26/100 [00:33<01:30, \u001b[A\n",
      "Average Metric: 13.068253968253966 / 27  (48.4):  27%|▎| 27/100 [00:33<01:15, \u001b[A\n",
      "Average Metric: 13.734920634920632 / 28  (49.1):  27%|▎| 27/100 [00:33<01:15, \u001b[A\n",
      "Average Metric: 13.734920634920632 / 28  (49.1):  28%|▎| 28/100 [00:33<00:57, \u001b[A\n",
      "Average Metric: 14.134920634920633 / 29  (48.7):  28%|▎| 28/100 [00:33<00:57, \u001b[A\n",
      "Average Metric: 14.134920634920633 / 29  (48.7):  29%|▎| 29/100 [00:33<00:47, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.801587301587299 / 30  (49.3):  29%|▎| 29/100 [00:35<00:47, \u001b[A\n",
      "Average Metric: 14.801587301587299 / 30  (49.3):  30%|▎| 30/100 [00:35<01:05, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.801587301587299 / 31  (51.0):  30%|▎| 30/100 [00:38<01:05, \u001b[A\n",
      "Average Metric: 15.801587301587299 / 31  (51.0):  31%|▎| 31/100 [00:38<01:41, \u001b[A\n",
      "Average Metric: 15.801587301587299 / 32  (49.4):  31%|▎| 31/100 [00:39<01:41, \u001b[A\n",
      "Average Metric: 15.801587301587299 / 32  (49.4):  32%|▎| 32/100 [00:39<01:31, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 16.301587301587297 / 33  (49.4):  32%|▎| 32/100 [00:41<01:31, \u001b[A\n",
      "Average Metric: 16.301587301587297 / 33  (49.4):  33%|▎| 33/100 [00:41<01:49, \u001b[A\n",
      "Average Metric: 17.051587301587297 / 34  (50.2):  33%|▎| 33/100 [00:41<01:49, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.718253968253965 / 35  (50.6):  34%|▎| 34/100 [00:42<01:48, \u001b[A\n",
      "Average Metric: 17.718253968253965 / 35  (50.6):  35%|▎| 35/100 [00:42<01:06, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.718253968253965 / 36  (52.0):  35%|▎| 35/100 [00:43<01:06, \u001b[A\n",
      "Average Metric: 18.718253968253965 / 36  (52.0):  36%|▎| 36/100 [00:43<01:04, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.718253968253965 / 37  (50.6):  36%|▎| 36/100 [00:43<01:04, \u001b[A\n",
      "Average Metric: 18.718253968253965 / 37  (50.6):  37%|▎| 37/100 [00:43<00:55, \u001b[A\n",
      "Average Metric: 19.718253968253965 / 38  (51.9):  37%|▎| 37/100 [00:43<00:55, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.718253968253965 / 39  (50.6):  38%|▍| 38/100 [00:44<00:54, \u001b[A\n",
      "Average Metric: 19.718253968253965 / 39  (50.6):  39%|▍| 39/100 [00:44<00:42, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.718253968253965 / 40  (49.3):  39%|▍| 39/100 [00:46<00:42, \u001b[A\n",
      "Average Metric: 19.718253968253965 / 40  (49.3):  40%|▍| 40/100 [00:46<00:52, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.718253968253965 / 41  (50.5):  40%|▍| 40/100 [00:48<00:52, \u001b[A\n",
      "Average Metric: 20.718253968253965 / 41  (50.5):  41%|▍| 41/100 [00:48<01:17, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.384920634920633 / 42  (50.9):  41%|▍| 41/100 [00:49<01:17, \u001b[A\n",
      "Average Metric: 21.384920634920633 / 42  (50.9):  42%|▍| 42/100 [00:49<01:12, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.384920634920633 / 43  (52.1):  42%|▍| 42/100 [00:51<01:12, \u001b[A\n",
      "Average Metric: 22.384920634920633 / 43  (52.1):  43%|▍| 43/100 [00:51<01:20, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.184920634920633 / 44  (52.7):  43%|▍| 43/100 [00:53<01:20, \u001b[A\n",
      "Average Metric: 23.184920634920633 / 44  (52.7):  44%|▍| 44/100 [00:53<01:19, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 23.8515873015873 / 45  (53.0):  44%|▍| 44/100 [00:53<01:19,  1\u001b[A\n",
      "Average Metric: 23.8515873015873 / 45  (53.0):  45%|▍| 45/100 [00:53<01:05,  1\u001b[A\n",
      "Average Metric: 24.651587301587302 / 46  (53.6):  45%|▍| 45/100 [00:53<01:05, \u001b[A\n",
      "Average Metric: 24.651587301587302 / 46  (53.6):  46%|▍| 46/100 [00:53<00:47, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.651587301587302 / 47  (52.5):  46%|▍| 46/100 [00:54<00:47, \u001b[A\n",
      "Average Metric: 24.651587301587302 / 47  (52.5):  47%|▍| 47/100 [00:54<00:36, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.31825396825397 / 48  (52.7):  47%|▍| 47/100 [00:57<00:36,  \u001b[A\n",
      "Average Metric: 25.31825396825397 / 48  (52.7):  48%|▍| 48/100 [00:57<01:16,  \u001b[A\n",
      "Average Metric: 25.31825396825397 / 49  (51.7):  48%|▍| 48/100 [00:57<01:16,  \u001b[A\n",
      "Average Metric: 25.31825396825397 / 49  (51.7):  49%|▍| 49/100 [00:57<00:55,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 25.984920634920638 / 50  (52.0):  49%|▍| 49/100 [00:59<00:55, \u001b[A\n",
      "Average Metric: 25.984920634920638 / 50  (52.0):  50%|▌| 50/100 [00:59<01:13, \u001b[A\n",
      "Average Metric: 26.984920634920638 / 51  (52.9):  50%|▌| 50/100 [00:59<01:13, \u001b[A\n",
      "Average Metric: 27.984920634920638 / 52  (53.8):  51%|▌| 51/100 [01:00<01:11, \u001b[A\n",
      "Average Metric: 27.984920634920638 / 52  (53.8):  52%|▌| 52/100 [01:00<00:39, \u001b[A\n",
      "Average Metric: 28.984920634920638 / 53  (54.7):  52%|▌| 52/100 [01:00<00:39, \u001b[A\n",
      "Average Metric: 28.984920634920638 / 53  (54.7):  53%|▌| 53/100 [01:00<00:33, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.984920634920638 / 54  (55.5):  53%|▌| 53/100 [01:03<00:33, \u001b[A\n",
      "Average Metric: 29.984920634920638 / 54  (55.5):  54%|▌| 54/100 [01:03<00:56, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.651587301587305 / 55  (55.7):  54%|▌| 54/100 [01:04<00:56, \u001b[A\n",
      "Average Metric: 30.651587301587305 / 55  (55.7):  55%|▌| 55/100 [01:04<00:55, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.651587301587305 / 56  (54.7):  55%|▌| 55/100 [01:05<00:55, \u001b[A\n",
      "Average Metric: 30.651587301587305 / 56  (54.7):  56%|▌| 56/100 [01:05<00:57, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.051587301587304 / 57  (54.5):  56%|▌| 56/100 [01:07<00:57, \u001b[A\n",
      "Average Metric: 31.051587301587304 / 57  (54.5):  57%|▌| 57/100 [01:07<00:55, \u001b[A\n",
      "Average Metric: 31.940476190476193 / 58  (55.1):  57%|▌| 57/100 [01:07<00:55, \u001b[A\n",
      "Average Metric: 31.940476190476193 / 58  (55.1):  58%|▌| 58/100 [01:07<00:43, \u001b[A\n",
      "Average Metric: 32.94047619047619 / 59  (55.8):  58%|▌| 58/100 [01:07<00:43,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.94047619047619 / 60  (54.9):  59%|▌| 59/100 [01:10<00:42,  \u001b[A\n",
      "Average Metric: 32.94047619047619 / 60  (54.9):  60%|▌| 60/100 [01:10<00:50,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 24.5 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 33.607142857142854 / 61  (55.1):  60%|▌| 60/100 [01:13<00:50, \u001b[A\n",
      "Average Metric: 33.607142857142854 / 61  (55.1):  61%|▌| 61/100 [01:13<01:00, \u001b[A\n",
      "Average Metric: 33.607142857142854 / 62  (54.2):  61%|▌| 61/100 [01:13<01:00, \u001b[A\n",
      "Average Metric: 33.607142857142854 / 62  (54.2):  62%|▌| 62/100 [01:13<00:49, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.107142857142854 / 63  (54.1):  62%|▌| 62/100 [01:13<00:49, \u001b[A\n",
      "Average Metric: 34.77380952380952 / 64  (54.3):  63%|▋| 63/100 [01:14<00:47,  \u001b[A\n",
      "Average Metric: 34.77380952380952 / 64  (54.3):  64%|▋| 64/100 [01:14<00:30,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.77380952380952 / 65  (53.5):  64%|▋| 64/100 [01:14<00:30,  \u001b[A\n",
      "Average Metric: 34.77380952380952 / 65  (53.5):  65%|▋| 65/100 [01:14<00:29,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 34.77380952380952 / 66  (52.7):  65%|▋| 65/100 [01:16<00:29,  \u001b[A\n",
      "Average Metric: 34.77380952380952 / 66  (52.7):  66%|▋| 66/100 [01:16<00:36,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.44047619047618 / 67  (52.9):  66%|▋| 66/100 [01:17<00:36,  \u001b[A\n",
      "Average Metric: 35.44047619047618 / 67  (52.9):  67%|▋| 67/100 [01:17<00:35,  \u001b[A\n",
      "Average Metric: 35.94047619047618 / 68  (52.9):  67%|▋| 67/100 [01:18<00:35,  \u001b[A\n",
      "Average Metric: 35.94047619047618 / 68  (52.9):  68%|▋| 68/100 [01:18<00:29,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.94047619047618 / 69  (52.1):  68%|▋| 68/100 [01:21<00:29,  \u001b[A\n",
      "Average Metric: 35.94047619047618 / 69  (52.1):  69%|▋| 69/100 [01:21<00:46,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 35.94047619047618 / 70  (51.3):  69%|▋| 69/100 [01:21<00:46,  \u001b[A\n",
      "Average Metric: 35.94047619047618 / 70  (51.3):  70%|▋| 70/100 [01:21<00:36,  \u001b[A\n",
      "Average Metric: 36.94047619047618 / 71  (52.0):  70%|▋| 70/100 [01:22<00:36,  \u001b[A\n",
      "Average Metric: 36.94047619047618 / 71  (52.0):  71%|▋| 71/100 [01:22<00:31,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 37.44047619047618 / 72  (52.0):  71%|▋| 71/100 [01:23<00:31,  \u001b[A\n",
      "Average Metric: 37.44047619047618 / 72  (52.0):  72%|▋| 72/100 [01:23<00:31,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.44047619047618 / 73  (52.7):  72%|▋| 72/100 [01:25<00:31,  \u001b[A\n",
      "Average Metric: 38.44047619047618 / 73  (52.7):  73%|▋| 73/100 [01:25<00:36,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 38.44047619047618 / 74  (51.9):  73%|▋| 73/100 [01:27<00:36,  \u001b[A\n",
      "Average Metric: 38.44047619047618 / 74  (51.9):  74%|▋| 74/100 [01:27<00:38,  \u001b[A\n",
      "Average Metric: 39.44047619047618 / 75  (52.6):  74%|▋| 74/100 [01:27<00:38,  \u001b[A\n",
      "Average Metric: 39.44047619047618 / 75  (52.6):  75%|▊| 75/100 [01:27<00:29,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 19.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.662698412698404 / 76  (52.2):  75%|▊| 75/100 [01:28<00:29, \u001b[A\n",
      "Average Metric: 39.662698412698404 / 76  (52.2):  76%|▊| 76/100 [01:28<00:24, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.662698412698404 / 77  (51.5):  76%|▊| 76/100 [01:30<00:24, \u001b[A\n",
      "Average Metric: 39.662698412698404 / 77  (51.5):  77%|▊| 77/100 [01:30<00:29, \u001b[A\n",
      "Average Metric: 39.662698412698404 / 78  (50.8):  77%|▊| 77/100 [01:30<00:29, \u001b[A\n",
      "Average Metric: 39.662698412698404 / 79  (50.2):  78%|▊| 78/100 [01:31<00:27, \u001b[A\n",
      "Average Metric: 39.662698412698404 / 79  (50.2):  79%|▊| 79/100 [01:31<00:18, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 39.662698412698404 / 80  (49.6):  79%|▊| 79/100 [01:33<00:18, \u001b[A\n",
      "Average Metric: 39.662698412698404 / 80  (49.6):  80%|▊| 80/100 [01:33<00:22, \u001b[A\n",
      "Average Metric: 40.662698412698404 / 81  (50.2):  80%|▊| 80/100 [01:33<00:22, \u001b[A\n",
      "Average Metric: 40.662698412698404 / 81  (50.2):  81%|▊| 81/100 [01:33<00:18, \u001b[A\n",
      "Average Metric: 41.0626984126984 / 82  (50.1):  81%|▊| 81/100 [01:34<00:18,  1\u001b[A\n",
      "Average Metric: 41.0626984126984 / 82  (50.1):  82%|▊| 82/100 [01:34<00:14,  1\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 41.72936507936507 / 83  (50.3):  82%|▊| 82/100 [01:35<00:14,  \u001b[A\n",
      "Average Metric: 41.72936507936507 / 83  (50.3):  83%|▊| 83/100 [01:35<00:16,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 11.8 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 42.72936507936507 / 84  (50.9):  83%|▊| 83/100 [01:37<00:16,  \u001b[A\n",
      "Average Metric: 42.72936507936507 / 84  (50.9):  84%|▊| 84/100 [01:37<00:21,  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 43.39603174603173 / 85  (51.1):  84%|▊| 84/100 [01:40<00:21,  \u001b[A\n",
      "Average Metric: 43.39603174603173 / 85  (51.1):  85%|▊| 85/100 [01:40<00:24,  \u001b[A\n",
      "Average Metric: 43.79603174603173 / 86  (50.9):  85%|▊| 85/100 [01:40<00:24,  \u001b[A\n",
      "Average Metric: 43.79603174603173 / 86  (50.9):  86%|▊| 86/100 [01:40<00:19,  \u001b[A\n",
      "Average Metric: 44.462698412698394 / 87  (51.1):  86%|▊| 86/100 [01:41<00:19, \u001b[A\n",
      "Average Metric: 44.462698412698394 / 87  (51.1):  87%|▊| 87/100 [01:41<00:14, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.462698412698394 / 88  (50.5):  87%|▊| 87/100 [01:42<00:14, \u001b[A\n",
      "Average Metric: 44.462698412698394 / 88  (50.5):  88%|▉| 88/100 [01:42<00:14, \u001b[A\n",
      "Average Metric: 44.962698412698394 / 89  (50.5):  88%|▉| 88/100 [01:43<00:14, \u001b[A\n",
      "Average Metric: 44.962698412698394 / 89  (50.5):  89%|▉| 89/100 [01:43<00:12, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 44.962698412698394 / 90  (50.0):  89%|▉| 89/100 [01:44<00:12, \u001b[A\n",
      "Average Metric: 44.962698412698394 / 90  (50.0):  90%|▉| 90/100 [01:44<00:09, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 91  (50.2):  90%|▉| 90/100 [01:45<00:09, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 91  (50.2):  91%|▉| 91/100 [01:45<00:08, \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 45.712698412698394 / 92  (49.7):  91%|▉| 91/100 [01:46<00:08, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 92  (49.7):  92%|▉| 92/100 [01:46<00:07, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 93  (49.2):  92%|▉| 92/100 [01:46<00:07, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 93  (49.2):  93%|▉| 93/100 [01:46<00:06, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 94  (48.6):  93%|▉| 93/100 [01:47<00:06, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 94  (48.6):  94%|▉| 94/100 [01:47<00:04, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 95  (48.1):  94%|▉| 94/100 [01:47<00:04, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 95  (48.1):  95%|▉| 95/100 [01:47<00:03, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 96  (47.6):  95%|▉| 95/100 [01:48<00:03, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 96  (47.6):  96%|▉| 96/100 [01:48<00:02, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 97  (47.1):  96%|▉| 96/100 [01:49<00:02, \u001b[A\n",
      "Average Metric: 45.712698412698394 / 97  (47.1):  97%|▉| 97/100 [01:49<00:02, \u001b[A\n",
      "Average Metric: 46.04603174603173 / 98  (47.0):  97%|▉| 97/100 [01:50<00:02,  \u001b[A\n",
      "Average Metric: 46.04603174603173 / 98  (47.0):  98%|▉| 98/100 [01:50<00:01,  \u001b[A\n",
      "Average Metric: 46.54603174603173 / 99  (47.0):  98%|▉| 98/100 [01:50<00:01,  \u001b[A\n",
      "Average Metric: 46.54603174603173 / 99  (47.0):  99%|▉| 99/100 [01:50<00:00,  \u001b[A\n",
      "Average Metric: 47.212698412698394 / 100  (47.2):  99%|▉| 99/100 [01:51<00:00,\u001b[A\n",
      "Average Metric: 47.212698412698394 / 100  (47.2): 100%|█| 100/100 [01:51<00:00\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 47.212698412698394 / 100  (47.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.4' '0.0' '0.0' '0.6666666666666666' '0.4']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ce451 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ce451 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_ce451_row0_col0, #T_ce451_row0_col1, #T_ce451_row0_col2, #T_ce451_row0_col3, #T_ce451_row0_col4, #T_ce451_row1_col0, #T_ce451_row1_col1, #T_ce451_row1_col2, #T_ce451_row1_col3, #T_ce451_row1_col4, #T_ce451_row2_col0, #T_ce451_row2_col1, #T_ce451_row2_col2, #T_ce451_row2_col3, #T_ce451_row2_col4, #T_ce451_row3_col0, #T_ce451_row3_col1, #T_ce451_row3_col2, #T_ce451_row3_col3, #T_ce451_row3_col4, #T_ce451_row4_col0, #T_ce451_row4_col1, #T_ce451_row4_col2, #T_ce451_row4_col3, #T_ce451_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ce451\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ce451_level0_col0\" class=\"col_heading level0 col0\" >review</th>\n",
       "      <th id=\"T_ce451_level0_col1\" class=\"col_heading level0 col1\" >example_aspects_with_label</th>\n",
       "      <th id=\"T_ce451_level0_col2\" class=\"col_heading level0 col2\" >aspects_list</th>\n",
       "      <th id=\"T_ce451_level0_col3\" class=\"col_heading level0 col3\" >pred_aspects_with_label</th>\n",
       "      <th id=\"T_ce451_level0_col4\" class=\"col_heading level0 col4\" >validate_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ce451_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ce451_row0_col0\" class=\"data row0 col0\" >\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.</td>\n",
       "      <td id=\"T_ce451_row0_col1\" class=\"data row0 col1\" >{'menu': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'pub fare': 0}</td>\n",
       "      <td id=\"T_ce451_row0_col2\" class=\"data row0 col2\" >dict_keys(['menu', 'burgers', 'steaks', 'shepherds pie', 'portabella lasagna', 'pub fare'])</td>\n",
       "      <td id=\"T_ce451_row0_col3\" class=\"data row0 col3\" >{'burgers': 0, 'steaks': 0, \"shepherd's pie\": 0, 'portabella lasagna': 1, 'vegetarian options': 1}</td>\n",
       "      <td id=\"T_ce451_row0_col4\" class=\"data row0 col4\" >0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce451_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ce451_row1_col0\" class=\"data row1 col0\" >(The sashimi is cut a little thinly.</td>\n",
       "      <td id=\"T_ce451_row1_col1\" class=\"data row1 col1\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_ce451_row1_col2\" class=\"data row1 col2\" >dict_keys(['sashimi'])</td>\n",
       "      <td id=\"T_ce451_row1_col3\" class=\"data row1 col3\" >{'thickness': -1}</td>\n",
       "      <td id=\"T_ce451_row1_col4\" class=\"data row1 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce451_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ce451_row2_col0\" class=\"data row2 col0\" >) It's not the best Japanese restaurant in the East Village, but it's a pretty solid one for its modest prices, and worth repeat visits.</td>\n",
       "      <td id=\"T_ce451_row2_col1\" class=\"data row2 col1\" >{'prices': 1}</td>\n",
       "      <td id=\"T_ce451_row2_col2\" class=\"data row2 col2\" >dict_keys(['prices'])</td>\n",
       "      <td id=\"T_ce451_row2_col3\" class=\"data row2 col3\" >{'Japanese restaurant': 0, 'East Village': 0, 'quality': 1, 'modest prices': 1, 'repeat visits': 1}</td>\n",
       "      <td id=\"T_ce451_row2_col4\" class=\"data row2 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce451_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ce451_row3_col0\" class=\"data row3 col0\" >15% gratuity automatically added to the bill.</td>\n",
       "      <td id=\"T_ce451_row3_col1\" class=\"data row3 col1\" >{'bill': -1, 'gratuity': -1}</td>\n",
       "      <td id=\"T_ce451_row3_col2\" class=\"data row3 col2\" >dict_keys(['bill', 'gratuity'])</td>\n",
       "      <td id=\"T_ce451_row3_col3\" class=\"data row3 col3\" >{'gratuity': -1}</td>\n",
       "      <td id=\"T_ce451_row3_col4\" class=\"data row3 col4\" >0.6666666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ce451_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ce451_row4_col0\" class=\"data row4 col0\" >A beautiful atmosphere, perfect for drinks and/or appetizers.</td>\n",
       "      <td id=\"T_ce451_row4_col1\" class=\"data row4 col1\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_ce451_row4_col2\" class=\"data row4 col2\" >dict_keys(['atmosphere', 'drinks', 'appetizers'])</td>\n",
       "      <td id=\"T_ce451_row4_col3\" class=\"data row4 col3\" >{'atmosphere': 1, 'drinks/appetizers': 1}</td>\n",
       "      <td id=\"T_ce451_row4_col4\" class=\"data row4 col4\" >0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x38d877710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "47.21"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_test(compiled_optuna, metric=validate_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "faa60d46-f312-4eb9-b263-9c4664eafbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_optuna.save(\"./ABSAPipelineV2Optuna.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05243a78-6436-410a-a78d-a1cbfc3fd997",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MIPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e20f4d98-106b-4a5d-9dc9-83e18b42c52f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m\u001b[1mWARNING: Projected Language Model (LM) Calls\u001b[0m\n",
      "\n",
      "Please be advised that based on the parameters you have set, the maximum number of LM calls is projected as follows:\n",
      "\n",
      "\u001b[93m- Task Model: \u001b[94m\u001b[1m30\u001b[0m\u001b[93m examples in dev set * \u001b[94m\u001b[1m50\u001b[0m\u001b[93m trials * \u001b[94m\u001b[1m# of LM calls in your program\u001b[0m\u001b[93m = (\u001b[94m\u001b[1m1500 * # of LM calls in your program\u001b[0m\u001b[93m) task model calls\u001b[0m\n",
      "\u001b[93m- Prompt Model: # data summarizer calls (max \u001b[94m\u001b[1m10\u001b[0m\u001b[93m) + \u001b[94m\u001b[1m10\u001b[0m\u001b[93m * \u001b[94m\u001b[1m3\u001b[0m\u001b[93m lm calls in program = \u001b[94m\u001b[1m40\u001b[0m\u001b[93m prompt model calls\u001b[0m\n",
      "\n",
      "\u001b[93m\u001b[1mEstimated Cost Calculation:\u001b[0m\n",
      "\n",
      "\u001b[93mTotal Cost = (Number of calls to task model * (Avg Input Token Length per Call * Task Model Price per Input Token + Avg Output Token Length per Call * Task Model Price per Output Token) \n",
      "            + (Number of calls to prompt model * (Avg Input Token Length per Call * Task Prompt Price per Input Token + Avg Output Token Length per Call * Prompt Model Price per Output Token).\u001b[0m\n",
      "\n",
      "For a preliminary estimate of potential costs, we recommend you perform your own calculations based on the task\n",
      "and prompt models you intend to use. If the projected costs exceed your budget or expectations, you may consider:\n",
      "\n",
      "\u001b[93m- Reducing the number of trials (`num_trials`), the size of the trainset, or the number of LM calls in your program.\u001b[0m\n",
      "\u001b[93m- Using a cheaper task model to optimize the prompt.\u001b[0m\n",
      "To proceed with the execution of this program, please confirm by typing \u001b[94m'y'\u001b[0m for yes or \u001b[94m'n'\u001b[0m for no.\n",
      "\n",
      "If you would like to bypass this confirmation step in future executions, set the \u001b[93m`requires_permission_to_run`\u001b[0m flag to \u001b[93m`False`.\u001b[0m\n",
      "\n",
      "\u001b[93mAwaiting your input...\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you wish to continue? (y/n):  y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:00<00:00, 34.82it/s]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:00<00:00, 45.57it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 51.83it/s]\u001b[A\n",
      " 57%|██████████████████████████▋                    | 17/30 [00:00<00:00, 54.59it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 18 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 57.29it/s]\u001b[A\n",
      " 53%|█████████████████████████                      | 16/30 [00:00<00:00, 54.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:00<00:00, 38.94it/s]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:00<00:00, 44.76it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:00<00:00, 47.87it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 7 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:00<00:00, 50.27it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:00<00:00, 46.06it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:00<00:00, 54.69it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:00<00:00, 57.44it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-04-28 22:29:36,591] A new study created in memory with name: no-name-e1d15797-10eb-4fb5-91f8-239a8aa691ae\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trial #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:26,  2.98s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:03<01:26,  2.98s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:03<00:49,  1.78s/it]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 3  (11.1):   7%| | 2/30 [00:04<00:49,  1.78s/it\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 3  (11.1):  10%| | 3/30 [00:04<00:32,  1.22s/it\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 4  (20.8):  10%| | 3/30 [00:05<00:32,  1.22s/it\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 4  (20.8):  13%|▏| 4/30 [00:05<00:32,  1.23s/it\u001b[A\n",
      "Average Metric: 1.6333333333333333 / 5  (32.7):  13%|▏| 4/30 [00:06<00:32,  1.23s/it\u001b[A\n",
      "Average Metric: 1.6333333333333333 / 5  (32.7):  17%|▏| 5/30 [00:06<00:23,  1.08it/s\u001b[A\n",
      "Average Metric: 2.033333333333333 / 6  (33.9):  17%|▏| 5/30 [00:06<00:23,  1.08it/s]\u001b[A\n",
      "Average Metric: 2.6999999999999997 / 7  (38.6):  20%|▏| 6/30 [00:06<00:22,  1.08it/s\u001b[A\n",
      "Average Metric: 2.6999999999999997 / 7  (38.6):  23%|▏| 7/30 [00:06<00:11,  1.95it/s\u001b[A\n",
      "Average Metric: 3.6999999999999997 / 8  (46.2):  23%|▏| 7/30 [00:07<00:11,  1.95it/s\u001b[A\n",
      "Average Metric: 3.6999999999999997 / 8  (46.2):  27%|▎| 8/30 [00:07<00:12,  1.71it/s\u001b[A\n",
      "Average Metric: 4.161538461538461 / 9  (46.2):  27%|▎| 8/30 [00:07<00:12,  1.71it/s]\u001b[A\n",
      "Average Metric: 4.161538461538461 / 9  (46.2):  30%|▎| 9/30 [00:07<00:10,  1.98it/s]\u001b[A\n",
      "Average Metric: 5.161538461538461 / 10  (51.6):  30%|▎| 9/30 [00:08<00:10,  1.98it/s\u001b[A\n",
      "Average Metric: 5.161538461538461 / 10  (51.6):  33%|▎| 10/30 [00:08<00:13,  1.53it/\u001b[A\n",
      "Average Metric: 5.623076923076923 / 11  (51.1):  33%|▎| 10/30 [00:09<00:13,  1.53it/\u001b[A\n",
      "Average Metric: 5.623076923076923 / 11  (51.1):  37%|▎| 11/30 [00:09<00:11,  1.59it/\u001b[A\n",
      "Average Metric: 6.123076923076923 / 12  (51.0):  37%|▎| 11/30 [00:09<00:11,  1.59it/\u001b[A\n",
      "Average Metric: 6.123076923076923 / 12  (51.0):  40%|▍| 12/30 [00:09<00:09,  1.98it/\u001b[A\n",
      "Average Metric: 6.623076923076923 / 13  (50.9):  40%|▍| 12/30 [00:09<00:09,  1.98it/\u001b[A\n",
      "Average Metric: 6.623076923076923 / 14  (47.3):  43%|▍| 13/30 [00:09<00:08,  1.98it/\u001b[A\n",
      "Average Metric: 6.623076923076923 / 14  (47.3):  47%|▍| 14/30 [00:09<00:05,  2.89it/\u001b[A\n",
      "Average Metric: 6.623076923076923 / 15  (44.2):  47%|▍| 14/30 [00:11<00:05,  2.89it/\u001b[A\n",
      "Average Metric: 6.623076923076923 / 15  (44.2):  50%|▌| 15/30 [00:11<00:10,  1.39it/\u001b[A\n",
      "Average Metric: 6.908791208791208 / 16  (43.2):  50%|▌| 15/30 [00:11<00:10,  1.39it/\u001b[A\n",
      "Average Metric: 6.908791208791208 / 16  (43.2):  53%|▌| 16/30 [00:11<00:08,  1.72it/\u001b[A\n",
      "Average Metric: 6.908791208791208 / 17  (40.6):  53%|▌| 16/30 [00:12<00:08,  1.72it/\u001b[A\n",
      "Average Metric: 6.908791208791208 / 17  (40.6):  57%|▌| 17/30 [00:12<00:09,  1.34it/\u001b[A\n",
      "Average Metric: 7.408791208791208 / 18  (41.2):  57%|▌| 17/30 [00:12<00:09,  1.34it/\u001b[A\n",
      "Average Metric: 7.408791208791208 / 18  (41.2):  60%|▌| 18/30 [00:12<00:06,  1.73it/\u001b[A\n",
      "Average Metric: 8.265934065934065 / 19  (43.5):  60%|▌| 18/30 [00:12<00:06,  1.73it/\u001b[A\n",
      "Average Metric: 8.765934065934065 / 20  (43.8):  63%|▋| 19/30 [00:13<00:06,  1.73it/\u001b[A\n",
      "Average Metric: 8.765934065934065 / 20  (43.8):  67%|▋| 20/30 [00:13<00:05,  1.85it/\u001b[A\n",
      "Average Metric: 8.765934065934065 / 21  (41.7):  67%|▋| 20/30 [00:14<00:05,  1.85it/\u001b[A\n",
      "Average Metric: 8.765934065934065 / 21  (41.7):  70%|▋| 21/30 [00:14<00:04,  1.92it/\u001b[A\n",
      "Average Metric: 9.623076923076923 / 22  (43.7):  70%|▋| 21/30 [00:14<00:04,  1.92it/\u001b[A\n",
      "Average Metric: 9.623076923076923 / 23  (41.8):  73%|▋| 22/30 [00:14<00:04,  1.92it/\u001b[A\n",
      "Average Metric: 9.623076923076923 / 23  (41.8):  77%|▊| 23/30 [00:14<00:02,  2.76it/\u001b[A\n",
      "Average Metric: 10.623076923076923 / 24  (44.3):  77%|▊| 23/30 [00:15<00:02,  2.76it\u001b[A\n",
      "Average Metric: 10.623076923076923 / 24  (44.3):  80%|▊| 24/30 [00:15<00:02,  2.06it\u001b[A\n",
      "Average Metric: 10.623076923076923 / 25  (42.5):  80%|▊| 24/30 [00:15<00:02,  2.06it\u001b[A\n",
      "Average Metric: 10.623076923076923 / 25  (42.5):  83%|▊| 25/30 [00:15<00:02,  2.10it\u001b[A\n",
      "Average Metric: 11.511965811965812 / 26  (44.3):  83%|▊| 25/30 [00:16<00:02,  2.10it\u001b[A\n",
      "Average Metric: 11.511965811965812 / 26  (44.3):  87%|▊| 26/30 [00:16<00:02,  1.73it\u001b[A\n",
      "Average Metric: 11.511965811965812 / 27  (42.6):  87%|▊| 26/30 [00:16<00:02,  1.73it\u001b[A\n",
      "Average Metric: 12.178632478632478 / 28  (43.5):  90%|▉| 27/30 [00:16<00:01,  1.73it\u001b[A\n",
      "Average Metric: 13.178632478632478 / 29  (45.4):  93%|▉| 28/30 [00:18<00:01,  1.73it\u001b[A\n",
      "Average Metric: 13.178632478632478 / 29  (45.4):  97%|▉| 29/30 [00:18<00:00,  2.09it\u001b[A\n",
      "Average Metric: 14.178632478632478 / 30  (47.3):  97%|▉| 29/30 [00:19<00:00,  2.09it\u001b[A\n",
      "Average Metric: 14.178632478632478 / 30  (47.3): 100%|█| 30/30 [00:19<00:00,  1.55it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:29:56,065] Trial 0 finished with value: 47.26 and parameters: {'14766014224_predictor_instruction': 1, '14766014224_predictor_demos': 1, '14707649168_predictor_instruction': 5, '14707649168_predictor_demos': 4, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 0}. Best is trial 0 with value: 47.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.178632478632478 / 30  (47.3%)\n",
      "Starting trial #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:03<01:46,  3.68s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:03<01:46,  3.68s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:03<00:46,  1.67s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):   7%|█              | 2/30 [00:04<00:46,  1.67s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):  10%|█▌             | 3/30 [00:04<00:36,  1.34s/it]\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 4  (29.2):  10%| | 3/30 [00:04<00:36,  1.34s/it\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 5  (23.3):  13%|▏| 4/30 [00:04<00:34,  1.34s/it\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 6  (19.4):  17%|▏| 5/30 [00:04<00:33,  1.34s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 7  (23.8):  20%|▏| 6/30 [00:05<00:32,  1.34s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 7  (23.8):  23%|▏| 7/30 [00:05<00:11,  2.02it/s\u001b[A\n",
      "Average Metric: 2.5555555555555554 / 8  (31.9):  23%|▏| 7/30 [00:05<00:11,  2.02it/s\u001b[A\n",
      "Average Metric: 3.017094017094017 / 9  (33.5):  27%|▎| 8/30 [00:07<00:10,  2.02it/s]\u001b[A\n",
      "Average Metric: 3.017094017094017 / 9  (33.5):  30%|▎| 9/30 [00:07<00:13,  1.59it/s]\u001b[A\n",
      "Average Metric: 3.767094017094017 / 10  (37.7):  30%|▎| 9/30 [00:07<00:13,  1.59it/s\u001b[A\n",
      "Average Metric: 3.767094017094017 / 10  (37.7):  33%|▎| 10/30 [00:07<00:11,  1.73it/\u001b[A\n",
      "Average Metric: 4.433760683760684 / 11  (40.3):  33%|▎| 10/30 [00:07<00:11,  1.73it/\u001b[A\n",
      "Average Metric: 4.433760683760684 / 12  (36.9):  37%|▎| 11/30 [00:07<00:11,  1.73it/\u001b[A\n",
      "Average Metric: 4.433760683760684 / 12  (36.9):  40%|▍| 12/30 [00:07<00:07,  2.41it/\u001b[A\n",
      "Average Metric: 5.433760683760684 / 13  (41.8):  40%|▍| 12/30 [00:08<00:07,  2.41it/\u001b[A\n",
      "Average Metric: 5.433760683760684 / 13  (41.8):  43%|▍| 13/30 [00:08<00:07,  2.14it/\u001b[A\n",
      "Average Metric: 6.290903540903541 / 14  (44.9):  43%|▍| 13/30 [00:09<00:07,  2.14it/\u001b[A\n",
      "Average Metric: 6.290903540903541 / 14  (44.9):  47%|▍| 14/30 [00:09<00:07,  2.07it/\u001b[A\n",
      "Average Metric: 6.690903540903541 / 15  (44.6):  47%|▍| 14/30 [00:10<00:07,  2.07it/\u001b[A\n",
      "Average Metric: 6.690903540903541 / 15  (44.6):  50%|▌| 15/30 [00:10<00:09,  1.66it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.690903540903541 / 16  (41.8):  50%|▌| 15/30 [00:10<00:09,  1.66it/\u001b[A\n",
      "Average Metric: 6.690903540903541 / 16  (41.8):  53%|▌| 16/30 [00:10<00:08,  1.58it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.190903540903541 / 17  (42.3):  53%|▌| 16/30 [00:11<00:08,  1.58it/\u001b[A\n",
      "Average Metric: 7.190903540903541 / 17  (42.3):  57%|▌| 17/30 [00:11<00:09,  1.32it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.5909035409035415 / 18  (42.2):  57%|▌| 17/30 [00:12<00:09,  1.32it\u001b[A\n",
      "Average Metric: 7.5909035409035415 / 18  (42.2):  60%|▌| 18/30 [00:12<00:07,  1.50it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.5909035409035415 / 19  (40.0):  60%|▌| 18/30 [00:13<00:07,  1.50it\u001b[A\n",
      "Average Metric: 7.5909035409035415 / 19  (40.0):  63%|▋| 19/30 [00:13<00:07,  1.48it\u001b[A\n",
      "Average Metric: 7.5909035409035415 / 20  (38.0):  63%|▋| 19/30 [00:13<00:07,  1.48it\u001b[A\n",
      "Average Metric: 7.5909035409035415 / 20  (38.0):  67%|▋| 20/30 [00:13<00:06,  1.58it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.5909035409035415 / 21  (36.1):  67%|▋| 20/30 [00:16<00:06,  1.58it\u001b[A\n",
      "Average Metric: 7.5909035409035415 / 21  (36.1):  70%|▋| 21/30 [00:16<00:10,  1.16s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.4480463980464 / 22  (38.4):  70%|▋| 21/30 [00:18<00:10,  1.16s/it]\u001b[A\n",
      "Average Metric: 8.4480463980464 / 22  (38.4):  73%|▋| 22/30 [00:18<00:11,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.4480463980464 / 23  (36.7):  73%|▋| 22/30 [00:19<00:11,  1.41s/it]\u001b[A\n",
      "Average Metric: 8.4480463980464 / 23  (36.7):  77%|▊| 23/30 [00:19<00:08,  1.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.4480463980464 / 24  (35.2):  77%|▊| 23/30 [00:20<00:08,  1.27s/it]\u001b[A\n",
      "Average Metric: 8.4480463980464 / 24  (35.2):  80%|▊| 24/30 [00:20<00:07,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.4480463980464 / 25  (33.8):  80%|▊| 24/30 [00:22<00:07,  1.24s/it]\u001b[A\n",
      "Average Metric: 8.4480463980464 / 25  (33.8):  83%|▊| 25/30 [00:22<00:08,  1.70s/it]\u001b[A\n",
      "Average Metric: 9.114713064713065 / 26  (35.1):  83%|▊| 25/30 [00:23<00:08,  1.70s/i\u001b[A\n",
      "Average Metric: 9.114713064713065 / 26  (35.1):  87%|▊| 26/30 [00:23<00:05,  1.45s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.971855921855923 / 27  (36.9):  87%|▊| 26/30 [00:24<00:05,  1.45s/i\u001b[A\n",
      "Average Metric: 9.971855921855923 / 27  (36.9):  90%|▉| 27/30 [00:24<00:03,  1.24s/i\u001b[A\n",
      "Average Metric: 10.971855921855923 / 28  (39.2):  90%|▉| 27/30 [00:27<00:03,  1.24s/\u001b[A\n",
      "Average Metric: 10.971855921855923 / 28  (39.2):  93%|▉| 28/30 [00:27<00:03,  1.78s/\u001b[A\n",
      "Average Metric: 11.471855921855923 / 29  (39.6):  93%|▉| 28/30 [00:28<00:03,  1.78s/\u001b[A\n",
      "Average Metric: 11.471855921855923 / 29  (39.6):  97%|▉| 29/30 [00:28<00:01,  1.44s/\u001b[A\n",
      "Average Metric: 11.75757020757021 / 30  (39.2):  97%|▉| 29/30 [00:29<00:01,  1.44s/i\u001b[A\n",
      "Average Metric: 11.75757020757021 / 30  (39.2): 100%|█| 30/30 [00:29<00:00,  1.02it/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:30:25,450] Trial 1 finished with value: 39.18999999999999 and parameters: {'14766014224_predictor_instruction': 9, '14766014224_predictor_demos': 3, '14707649168_predictor_instruction': 8, '14707649168_predictor_demos': 4, '14753105040_predictor_instruction': 4, '14753105040_predictor_demos': 2}. Best is trial 0 with value: 47.26.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.75757020757021 / 30  (39.2%)\n",
      "Starting trial #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:01<00:33,  1.17s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:01<00:33,  1.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:02<00:32,  1.17s/it]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):  10%|█▌             | 3/30 [00:02<00:17,  1.54it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.4 / 4  (60.0):  10%|█▌             | 3/30 [00:03<00:17,  1.54it/s]\u001b[A\n",
      "Average Metric: 2.4 / 4  (60.0):  13%|██             | 4/30 [00:03<00:24,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.4 / 5  (68.0):  13%|██             | 4/30 [00:04<00:24,  1.05it/s]\u001b[A\n",
      "Average Metric: 3.4 / 5  (68.0):  17%|██▌            | 5/30 [00:04<00:25,  1.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.9 / 6  (65.0):  17%|██▌            | 5/30 [00:06<00:25,  1.01s/it]\u001b[A\n",
      "Average Metric: 3.9 / 6  (65.0):  20%|███            | 6/30 [00:06<00:26,  1.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.4 / 7  (62.9):  20%|███            | 6/30 [00:07<00:26,  1.12s/it]\u001b[A\n",
      "Average Metric: 4.4 / 7  (62.9):  23%|███▌           | 7/30 [00:07<00:26,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.800000000000001 / 8  (60.0):  23%|▏| 7/30 [00:08<00:26,  1.15s/it]\u001b[A\n",
      "Average Metric: 4.800000000000001 / 8  (60.0):  27%|▎| 8/30 [00:08<00:24,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.800000000000001 / 9  (53.3):  27%|▎| 8/30 [00:09<00:24,  1.13s/it]\u001b[A\n",
      "Average Metric: 4.800000000000001 / 9  (53.3):  30%|▎| 9/30 [00:09<00:22,  1.07s/it]\u001b[A\n",
      "Average Metric: 5.300000000000001 / 10  (53.0):  30%|▎| 9/30 [00:10<00:22,  1.07s/it\u001b[A\n",
      "Average Metric: 5.300000000000001 / 10  (53.0):  33%|▎| 10/30 [00:10<00:23,  1.17s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.300000000000001 / 11  (48.2):  33%|▎| 10/30 [00:10<00:23,  1.17s/i\u001b[A\n",
      "Average Metric: 5.300000000000001 / 11  (48.2):  37%|▎| 11/30 [00:10<00:16,  1.18it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.966666666666668 / 12  (49.7):  37%|▎| 11/30 [00:11<00:16,  1.18it/\u001b[A\n",
      "Average Metric: 5.966666666666668 / 12  (49.7):  40%|▍| 12/30 [00:11<00:15,  1.16it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.966666666666668 / 13  (53.6):  40%|▍| 12/30 [00:13<00:15,  1.16it/\u001b[A\n",
      "Average Metric: 6.966666666666668 / 13  (53.6):  43%|▍| 13/30 [00:13<00:20,  1.19s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 7.466666666666668 / 14  (53.3):  43%|▍| 13/30 [00:14<00:20,  1.19s/i\u001b[A\n",
      "Average Metric: 7.466666666666668 / 14  (53.3):  47%|▍| 14/30 [00:14<00:15,  1.01it/\u001b[A\n",
      "Average Metric: 7.466666666666668 / 15  (49.8):  47%|▍| 14/30 [00:14<00:15,  1.01it/\u001b[A\n",
      "Average Metric: 7.466666666666668 / 15  (49.8):  50%|▌| 15/30 [00:14<00:13,  1.11it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.466666666666668 / 16  (46.7):  50%|▌| 15/30 [00:16<00:13,  1.11it/\u001b[A\n",
      "Average Metric: 7.466666666666668 / 16  (46.7):  53%|▌| 16/30 [00:16<00:14,  1.01s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.133333333333335 / 17  (47.8):  53%|▌| 16/30 [00:17<00:14,  1.01s/i\u001b[A\n",
      "Average Metric: 8.133333333333335 / 17  (47.8):  57%|▌| 17/30 [00:17<00:12,  1.02it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.133333333333335 / 18  (50.7):  57%|▌| 17/30 [00:17<00:12,  1.02it/\u001b[A\n",
      "Average Metric: 9.133333333333335 / 18  (50.7):  60%|▌| 18/30 [00:17<00:11,  1.09it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.133333333333335 / 19  (53.3):  60%|▌| 18/30 [00:18<00:11,  1.09it\u001b[A\n",
      "Average Metric: 10.133333333333335 / 19  (53.3):  63%|▋| 19/30 [00:18<00:09,  1.12it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 23.7 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.133333333333335 / 20  (50.7):  63%|▋| 19/30 [00:20<00:09,  1.12it\u001b[A\n",
      "Average Metric: 10.133333333333335 / 20  (50.7):  67%|▋| 20/30 [00:20<00:12,  1.28s/\u001b[A\n",
      "Average Metric: 10.133333333333335 / 21  (48.3):  67%|▋| 20/30 [00:21<00:12,  1.28s/\u001b[A\n",
      "Average Metric: 10.133333333333335 / 21  (48.3):  70%|▋| 21/30 [00:21<00:09,  1.10s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.990476190476192 / 22  (50.0):  70%|▋| 21/30 [00:23<00:09,  1.10s/\u001b[A\n",
      "Average Metric: 10.990476190476192 / 22  (50.0):  73%|▋| 22/30 [00:23<00:10,  1.26s/\u001b[A\n",
      "Average Metric: 11.84761904761905 / 23  (51.5):  73%|▋| 22/30 [00:23<00:10,  1.26s/i\u001b[A\n",
      "Average Metric: 11.84761904761905 / 23  (51.5):  77%|▊| 23/30 [00:24<00:07,  1.13s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.292063492063495 / 24  (51.2):  77%|▊| 23/30 [00:25<00:07,  1.13s/\u001b[A\n",
      "Average Metric: 12.292063492063495 / 24  (51.2):  80%|▊| 24/30 [00:25<00:07,  1.19s/\u001b[A\n",
      "Average Metric: 13.042063492063495 / 25  (52.2):  80%|▊| 24/30 [00:26<00:07,  1.19s/\u001b[A\n",
      "Average Metric: 13.042063492063495 / 25  (52.2):  83%|▊| 25/30 [00:26<00:05,  1.09s/\u001b[A\n",
      "Average Metric: 13.70873015873016 / 26  (52.7):  83%|▊| 25/30 [00:27<00:05,  1.09s/i\u001b[A\n",
      "Average Metric: 13.70873015873016 / 26  (52.7):  87%|▊| 26/30 [00:27<00:04,  1.03s/i\u001b[A\n",
      "Average Metric: 13.70873015873016 / 27  (50.8):  87%|▊| 26/30 [00:28<00:04,  1.03s/i\u001b[A\n",
      "Average Metric: 13.70873015873016 / 27  (50.8):  90%|▉| 27/30 [00:28<00:03,  1.06s/i\u001b[A\n",
      "Average Metric: 14.108730158730161 / 28  (50.4):  90%|▉| 27/30 [00:29<00:03,  1.06s/\u001b[A\n",
      "Average Metric: 14.108730158730161 / 28  (50.4):  93%|▉| 28/30 [00:29<00:02,  1.17s/\u001b[A\n",
      "Average Metric: 14.570268620268623 / 29  (50.2):  93%|▉| 28/30 [00:31<00:02,  1.17s/\u001b[A\n",
      "Average Metric: 14.570268620268623 / 29  (50.2):  97%|▉| 29/30 [00:31<00:01,  1.52s/\u001b[A\n",
      "Average Metric: 15.031807081807084 / 30  (50.1):  97%|▉| 29/30 [00:44<00:01,  1.52s/\u001b[A\n",
      "Average Metric: 15.031807081807084 / 30  (50.1): 100%|█| 30/30 [00:44<00:00,  1.50s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:31:10,421] Trial 2 finished with value: 50.11 and parameters: {'14766014224_predictor_instruction': 1, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 0, '14707649168_predictor_demos': 4, '14753105040_predictor_instruction': 5, '14753105040_predictor_demos': 8}. Best is trial 2 with value: 50.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.031807081807084 / 30  (50.1%)\n",
      "Starting trial #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:04<02:10,  4.51s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   3%|▌              | 1/30 [00:04<02:10,  4.51s/it]\u001b[A\n",
      "Average Metric: 0.4 / 2  (20.0):   7%|█              | 2/30 [00:04<00:57,  2.06s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):   7%|█              | 2/30 [00:05<00:57,  2.06s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):  10%|█▌             | 3/30 [00:05<00:34,  1.29s/it]\u001b[A\n",
      "Average Metric: 1.2000000000000002 / 4  (30.0):  10%| | 3/30 [00:05<00:34,  1.29s/it\u001b[A\n",
      "Average Metric: 1.2000000000000002 / 4  (30.0):  13%|▏| 4/30 [00:05<00:21,  1.22it/s\u001b[A\n",
      "Average Metric: 1.7000000000000002 / 5  (34.0):  13%|▏| 4/30 [00:06<00:21,  1.22it/s\u001b[A\n",
      "Average Metric: 1.7000000000000002 / 5  (34.0):  17%|▏| 5/30 [00:06<00:20,  1.24it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.1285714285714286 / 6  (35.5):  17%|▏| 5/30 [00:09<00:20,  1.24it/s\u001b[A\n",
      "Average Metric: 2.1285714285714286 / 6  (35.5):  20%|▏| 6/30 [00:09<00:43,  1.80s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.6285714285714286 / 7  (37.6):  20%|▏| 6/30 [00:10<00:43,  1.80s/it\u001b[A\n",
      "Average Metric: 2.6285714285714286 / 7  (37.6):  23%|▏| 7/30 [00:10<00:34,  1.49s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.295238095238095 / 8  (41.2):  23%|▏| 7/30 [00:11<00:34,  1.49s/it]\u001b[A\n",
      "Average Metric: 3.295238095238095 / 8  (41.2):  27%|▎| 8/30 [00:11<00:28,  1.28s/it]\u001b[A\n",
      "Average Metric: 3.7567765567765568 / 9  (41.7):  27%|▎| 8/30 [00:11<00:28,  1.28s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.756776556776557 / 10  (47.6):  30%|▎| 9/30 [00:13<00:26,  1.28s/it\u001b[A\n",
      "Average Metric: 4.756776556776557 / 10  (47.6):  33%|▎| 10/30 [00:13<00:24,  1.23s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.256776556776557 / 11  (47.8):  33%|▎| 10/30 [00:18<00:24,  1.23s/i\u001b[A\n",
      "Average Metric: 5.256776556776557 / 11  (47.8):  37%|▎| 11/30 [00:18<00:41,  2.17s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.1139194139194135 / 12  (50.9):  37%|▎| 11/30 [00:20<00:41,  2.17s/\u001b[A\n",
      "Average Metric: 6.1139194139194135 / 12  (50.9):  40%|▍| 12/30 [00:20<00:36,  2.04s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.1139194139194135 / 13  (47.0):  40%|▍| 12/30 [00:20<00:36,  2.04s/\u001b[A\n",
      "Average Metric: 6.1139194139194135 / 13  (47.0):  43%|▍| 13/30 [00:20<00:26,  1.58s/\u001b[A\n",
      "Average Metric: 6.4472527472527466 / 14  (46.1):  43%|▍| 13/30 [00:21<00:26,  1.58s/\u001b[A\n",
      "Average Metric: 6.4472527472527466 / 14  (46.1):  47%|▍| 14/30 [00:21<00:20,  1.28s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 14.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.4472527472527466 / 15  (43.0):  47%|▍| 14/30 [00:22<00:20,  1.28s/\u001b[A\n",
      "Average Metric: 6.4472527472527466 / 15  (43.0):  50%|▌| 15/30 [00:22<00:16,  1.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.304395604395603 / 16  (45.7):  50%|▌| 15/30 [00:24<00:16,  1.12s/i\u001b[A\n",
      "Average Metric: 7.304395604395603 / 16  (45.7):  53%|▌| 16/30 [00:24<00:21,  1.56s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.304395604395603 / 17  (43.0):  53%|▌| 16/30 [00:27<00:21,  1.56s/i\u001b[A\n",
      "Average Metric: 7.304395604395603 / 17  (43.0):  57%|▌| 17/30 [00:27<00:25,  1.99s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.804395604395603 / 18  (43.4):  57%|▌| 17/30 [00:30<00:25,  1.99s/i\u001b[A\n",
      "Average Metric: 7.804395604395603 / 18  (43.4):  60%|▌| 18/30 [00:30<00:25,  2.11s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 26.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.248840048840048 / 19  (43.4):  60%|▌| 18/30 [00:33<00:25,  2.11s/i\u001b[A\n",
      "Average Metric: 8.248840048840048 / 19  (43.4):  63%|▋| 19/30 [00:33<00:26,  2.41s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.248840048840048 / 20  (41.2):  63%|▋| 19/30 [00:34<00:26,  2.41s/i\u001b[A\n",
      "Average Metric: 8.248840048840048 / 20  (41.2):  67%|▋| 20/30 [00:34<00:19,  1.94s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.105982905982906 / 21  (43.4):  67%|▋| 20/30 [00:34<00:19,  1.94s/i\u001b[A\n",
      "Average Metric: 9.105982905982906 / 21  (43.4):  70%|▋| 21/30 [00:34<00:13,  1.45s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.105982905982906 / 22  (41.4):  70%|▋| 21/30 [00:35<00:13,  1.45s/i\u001b[A\n",
      "Average Metric: 9.105982905982906 / 22  (41.4):  73%|▋| 22/30 [00:35<00:10,  1.35s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.772649572649572 / 23  (42.5):  73%|▋| 22/30 [00:38<00:10,  1.35s/i\u001b[A\n",
      "Average Metric: 9.772649572649572 / 23  (42.5):  77%|▊| 23/30 [00:38<00:12,  1.72s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.772649572649572 / 24  (44.9):  77%|▊| 23/30 [00:38<00:12,  1.72s/\u001b[A\n",
      "Average Metric: 10.772649572649572 / 24  (44.9):  80%|▊| 24/30 [00:38<00:08,  1.35s/\u001b[A\n",
      "Average Metric: 11.772649572649572 / 25  (47.1):  80%|▊| 24/30 [00:38<00:08,  1.35s/\u001b[A\n",
      "Average Metric: 11.772649572649572 / 25  (47.1):  83%|▊| 25/30 [00:38<00:04,  1.02it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.772649572649572 / 26  (45.3):  83%|▊| 25/30 [00:41<00:04,  1.02it\u001b[A\n",
      "Average Metric: 11.772649572649572 / 26  (45.3):  87%|▊| 26/30 [00:41<00:06,  1.55s/\u001b[A\n",
      "Average Metric: 12.058363858363858 / 27  (44.7):  87%|▊| 26/30 [00:43<00:06,  1.55s/\u001b[A\n",
      "Average Metric: 12.058363858363858 / 27  (44.7):  90%|▉| 27/30 [00:43<00:05,  1.75s/\u001b[A\n",
      "Average Metric: 13.058363858363858 / 28  (46.6):  90%|▉| 27/30 [00:44<00:05,  1.75s/\u001b[A\n",
      "Average Metric: 13.058363858363858 / 28  (46.6):  93%|▉| 28/30 [00:44<00:02,  1.42s/\u001b[A\n",
      "Average Metric: 13.915506715506716 / 29  (48.0):  93%|▉| 28/30 [00:47<00:02,  1.42s/\u001b[A\n",
      "Average Metric: 13.915506715506716 / 29  (48.0):  97%|▉| 29/30 [00:47<00:01,  1.77s/\u001b[A\n",
      "Average Metric: 13.915506715506716 / 30  (46.4):  97%|▉| 29/30 [01:03<00:01,  1.77s/\u001b[A\n",
      "Average Metric: 13.915506715506716 / 30  (46.4): 100%|█| 30/30 [01:03<00:00,  2.11s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:32:13,890] Trial 3 finished with value: 46.39 and parameters: {'14766014224_predictor_instruction': 2, '14766014224_predictor_demos': 2, '14707649168_predictor_instruction': 3, '14707649168_predictor_demos': 9, '14753105040_predictor_instruction': 6, '14753105040_predictor_demos': 0}. Best is trial 2 with value: 50.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.915506715506716 / 30  (46.4%)\n",
      "Starting trial #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:03<01:52,  3.87s/it]\u001b[A\n",
      "Average Metric: 1.3 / 2  (65.0):   3%|▌              | 1/30 [00:04<01:52,  3.87s/it]\u001b[A\n",
      "Average Metric: 1.3 / 2  (65.0):   7%|█              | 2/30 [00:04<00:52,  1.88s/it]\u001b[A\n",
      "Average Metric: 2.3 / 3  (76.7):   7%|█              | 2/30 [00:04<00:52,  1.88s/it]\u001b[A\n",
      "Average Metric: 2.3 / 3  (76.7):  10%|█▌             | 3/30 [00:04<00:29,  1.10s/it]\u001b[A\n",
      "Average Metric: 2.3 / 4  (57.5):  10%|█▌             | 3/30 [00:04<00:29,  1.10s/it]\u001b[A\n",
      "Average Metric: 2.3 / 5  (46.0):  13%|██             | 4/30 [00:04<00:28,  1.10s/it]\u001b[A\n",
      "Average Metric: 2.3 / 5  (46.0):  17%|██▌            | 5/30 [00:04<00:13,  1.89it/s]\u001b[A\n",
      "Average Metric: 2.6999999999999997 / 6  (45.0):  17%|▏| 5/30 [00:04<00:13,  1.89it/s\u001b[A\n",
      "Average Metric: 2.6999999999999997 / 6  (45.0):  20%|▏| 6/30 [00:04<00:10,  2.27it/s\u001b[A\n",
      "Average Metric: 2.6999999999999997 / 7  (38.6):  20%|▏| 6/30 [00:05<00:10,  2.27it/s\u001b[A\n",
      "Average Metric: 2.6999999999999997 / 7  (38.6):  23%|▏| 7/30 [00:05<00:09,  2.30it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.6999999999999997 / 8  (46.2):  23%|▏| 7/30 [00:08<00:09,  2.30it/s\u001b[A\n",
      "Average Metric: 3.6999999999999997 / 8  (46.2):  27%|▎| 8/30 [00:08<00:25,  1.14s/it\u001b[A\n",
      "Average Metric: 4.199999999999999 / 9  (46.7):  27%|▎| 8/30 [00:09<00:25,  1.14s/it]\u001b[A\n",
      "Average Metric: 4.199999999999999 / 9  (46.7):  30%|▎| 9/30 [00:09<00:22,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.699999999999999 / 10  (47.0):  30%|▎| 9/30 [00:10<00:22,  1.06s/it\u001b[A\n",
      "Average Metric: 4.699999999999999 / 10  (47.0):  33%|▎| 10/30 [00:10<00:24,  1.22s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.499999999999999 / 11  (50.0):  33%|▎| 10/30 [00:12<00:24,  1.22s/i\u001b[A\n",
      "Average Metric: 5.499999999999999 / 11  (50.0):  37%|▎| 11/30 [00:12<00:24,  1.28s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.499999999999999 / 12  (45.8):  37%|▎| 11/30 [00:13<00:24,  1.28s/i\u001b[A\n",
      "Average Metric: 5.499999999999999 / 12  (45.8):  40%|▍| 12/30 [00:13<00:25,  1.41s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.499999999999999 / 13  (42.3):  40%|▍| 12/30 [00:15<00:25,  1.41s/i\u001b[A\n",
      "Average Metric: 5.499999999999999 / 13  (42.3):  43%|▍| 13/30 [00:15<00:27,  1.64s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.499999999999999 / 14  (39.3):  43%|▍| 13/30 [00:18<00:27,  1.64s/i\u001b[A\n",
      "Average Metric: 5.499999999999999 / 14  (39.3):  47%|▍| 14/30 [00:18<00:31,  1.95s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.499999999999999 / 15  (36.7):  47%|▍| 14/30 [00:19<00:31,  1.95s/i\u001b[A\n",
      "Average Metric: 5.499999999999999 / 15  (36.7):  50%|▌| 15/30 [00:19<00:23,  1.60s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.499999999999999 / 16  (34.4):  50%|▌| 15/30 [00:20<00:23,  1.60s/i\u001b[A\n",
      "Average Metric: 5.499999999999999 / 16  (34.4):  53%|▌| 16/30 [00:20<00:20,  1.44s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.785714285714285 / 17  (34.0):  53%|▌| 16/30 [00:21<00:20,  1.44s/i\u001b[A\n",
      "Average Metric: 5.785714285714285 / 17  (34.0):  57%|▌| 17/30 [00:21<00:18,  1.40s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.285714285714285 / 18  (34.9):  57%|▌| 17/30 [00:25<00:18,  1.40s/i\u001b[A\n",
      "Average Metric: 6.285714285714285 / 18  (34.9):  60%|▌| 18/30 [00:25<00:23,  1.96s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.952380952380952 / 19  (36.6):  60%|▌| 18/30 [00:25<00:23,  1.96s/i\u001b[A\n",
      "Average Metric: 6.952380952380952 / 19  (36.6):  63%|▋| 19/30 [00:25<00:16,  1.52s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.952380952380952 / 20  (39.8):  63%|▋| 19/30 [00:27<00:16,  1.52s/i\u001b[A\n",
      "Average Metric: 7.952380952380952 / 20  (39.8):  67%|▋| 20/30 [00:27<00:17,  1.73s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 10.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 29.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.327380952380953 / 21  (39.7):  67%|▋| 20/30 [00:29<00:17,  1.73s/i\u001b[A\n",
      "Average Metric: 8.327380952380953 / 21  (39.7):  70%|▋| 21/30 [00:29<00:16,  1.85s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.327380952380953 / 22  (37.9):  70%|▋| 21/30 [00:32<00:16,  1.85s/i\u001b[A\n",
      "Average Metric: 8.327380952380953 / 22  (37.9):  73%|▋| 22/30 [00:32<00:16,  2.02s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.327380952380953 / 23  (36.2):  73%|▋| 22/30 [00:34<00:16,  2.02s/i\u001b[A\n",
      "Average Metric: 8.327380952380953 / 23  (36.2):  77%|▊| 23/30 [00:34<00:13,  1.93s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.18452380952381 / 24  (38.3):  77%|▊| 23/30 [00:35<00:13,  1.93s/it\u001b[A\n",
      "Average Metric: 9.18452380952381 / 24  (38.3):  80%|▊| 24/30 [00:35<00:10,  1.68s/it\u001b[A\n",
      "Average Metric: 9.18452380952381 / 25  (36.7):  80%|▊| 24/30 [00:35<00:10,  1.68s/it\u001b[A\n",
      "Average Metric: 9.18452380952381 / 25  (36.7):  83%|▊| 25/30 [00:35<00:06,  1.27s/it\u001b[A\n",
      "Average Metric: 10.041666666666668 / 26  (38.6):  83%|▊| 25/30 [00:36<00:06,  1.27s/\u001b[A\n",
      "Average Metric: 10.041666666666668 / 26  (38.6):  87%|▊| 26/30 [00:36<00:04,  1.18s/\u001b[A\n",
      "Average Metric: 11.041666666666668 / 27  (40.9):  87%|▊| 26/30 [00:37<00:04,  1.18s/\u001b[A\n",
      "Average Metric: 11.041666666666668 / 27  (40.9):  90%|▉| 27/30 [00:37<00:03,  1.09s/\u001b[A\n",
      "Average Metric: 11.405303030303031 / 28  (40.7):  90%|▉| 27/30 [00:39<00:03,  1.09s/\u001b[A\n",
      "Average Metric: 11.405303030303031 / 28  (40.7):  93%|▉| 28/30 [00:39<00:03,  1.56s/\u001b[A\n",
      "Average Metric: 11.83387445887446 / 29  (40.8):  93%|▉| 28/30 [00:44<00:03,  1.56s/i\u001b[A\n",
      "Average Metric: 11.83387445887446 / 29  (40.8):  97%|▉| 29/30 [00:44<00:02,  2.32s/i\u001b[A\n",
      "Average Metric: 12.33387445887446 / 30  (41.1):  97%|▉| 29/30 [00:58<00:02,  2.32s/i\u001b[A\n",
      "Average Metric: 12.33387445887446 / 30  (41.1): 100%|█| 30/30 [00:58<00:00,  1.96s/i\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:33:12,754] Trial 4 finished with value: 41.11 and parameters: {'14766014224_predictor_instruction': 7, '14766014224_predictor_demos': 6, '14707649168_predictor_instruction': 1, '14707649168_predictor_demos': 3, '14753105040_predictor_instruction': 0, '14753105040_predictor_demos': 2}. Best is trial 2 with value: 50.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.33387445887446 / 30  (41.1%)\n",
      "Starting trial #5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:28,  3.06s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:03<01:28,  3.06s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):   7%|█              | 2/30 [00:03<01:25,  3.06s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):  10%|█▌             | 3/30 [00:03<00:29,  1.09s/it]\u001b[A\n",
      "Average Metric: 0.5 / 4  (12.5):  10%|█▌             | 3/30 [00:03<00:29,  1.09s/it]\u001b[A\n",
      "Average Metric: 0.5 / 5  (10.0):  13%|██             | 4/30 [00:03<00:28,  1.09s/it]\u001b[A\n",
      "Average Metric: 1.3888888888888888 / 6  (23.1):  17%|▏| 5/30 [00:04<00:27,  1.09s/it\u001b[A\n",
      "Average Metric: 1.3888888888888888 / 6  (23.1):  20%|▏| 6/30 [00:04<00:10,  2.20it/s\u001b[A\n",
      "Average Metric: 2.0555555555555554 / 7  (29.4):  20%|▏| 6/30 [00:04<00:10,  2.20it/s\u001b[A\n",
      "Average Metric: 2.0555555555555554 / 7  (29.4):  23%|▏| 7/30 [00:04<00:10,  2.11it/s\u001b[A\n",
      "Average Metric: 2.5555555555555554 / 8  (31.9):  23%|▏| 7/30 [00:04<00:10,  2.11it/s\u001b[A\n",
      "Average Metric: 3.444444444444444 / 9  (38.3):  27%|▎| 8/30 [00:05<00:10,  2.11it/s]\u001b[A\n",
      "Average Metric: 3.444444444444444 / 9  (38.3):  30%|▎| 9/30 [00:05<00:09,  2.32it/s]\u001b[A\n",
      "Average Metric: 4.444444444444445 / 10  (44.4):  30%|▎| 9/30 [00:05<00:09,  2.32it/s\u001b[A\n",
      "Average Metric: 4.444444444444445 / 10  (44.4):  33%|▎| 10/30 [00:05<00:08,  2.28it/\u001b[A\n",
      "Average Metric: 5.111111111111112 / 11  (46.5):  33%|▎| 10/30 [00:06<00:08,  2.28it/\u001b[A\n",
      "Average Metric: 5.111111111111112 / 11  (46.5):  37%|▎| 11/30 [00:06<00:11,  1.63it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.611111111111112 / 12  (46.8):  37%|▎| 11/30 [00:08<00:11,  1.63it/\u001b[A\n",
      "Average Metric: 5.611111111111112 / 12  (46.8):  40%|▍| 12/30 [00:08<00:13,  1.30it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.611111111111112 / 13  (43.2):  40%|▍| 12/30 [00:09<00:13,  1.30it/\u001b[A\n",
      "Average Metric: 5.611111111111112 / 13  (43.2):  43%|▍| 13/30 [00:09<00:16,  1.05it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.468253968253968 / 14  (46.2):  43%|▍| 13/30 [00:10<00:16,  1.05it/\u001b[A\n",
      "Average Metric: 6.468253968253968 / 14  (46.2):  47%|▍| 14/30 [00:10<00:13,  1.20it/\u001b[A\n",
      "Average Metric: 6.468253968253968 / 15  (43.1):  47%|▍| 14/30 [00:10<00:13,  1.20it/\u001b[A\n",
      "Average Metric: 6.468253968253968 / 15  (43.1):  50%|▌| 15/30 [00:10<00:10,  1.37it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.468253968253968 / 16  (40.4):  50%|▌| 15/30 [00:11<00:10,  1.37it/\u001b[A\n",
      "Average Metric: 6.468253968253968 / 16  (40.4):  53%|▌| 16/30 [00:11<00:09,  1.44it/\u001b[A\n",
      "Average Metric: 7.0396825396825395 / 17  (41.4):  53%|▌| 16/30 [00:11<00:09,  1.44it\u001b[A\n",
      "Average Metric: 7.0396825396825395 / 17  (41.4):  57%|▌| 17/30 [00:11<00:07,  1.70it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.7063492063492065 / 18  (42.8):  57%|▌| 17/30 [00:13<00:07,  1.70it\u001b[A\n",
      "Average Metric: 7.7063492063492065 / 18  (42.8):  60%|▌| 18/30 [00:13<00:13,  1.11s/\u001b[A\n",
      "Average Metric: 8.706349206349206 / 19  (45.8):  60%|▌| 18/30 [00:15<00:13,  1.11s/i\u001b[A\n",
      "Average Metric: 8.706349206349206 / 19  (45.8):  63%|▋| 19/30 [00:15<00:13,  1.25s/i\u001b[A\n",
      "Average Metric: 9.373015873015872 / 20  (46.9):  63%|▋| 19/30 [00:15<00:13,  1.25s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.658730158730158 / 21  (46.0):  67%|▋| 20/30 [00:16<00:12,  1.25s/i\u001b[A\n",
      "Average Metric: 9.658730158730158 / 21  (46.0):  70%|▋| 21/30 [00:16<00:08,  1.09it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.515873015873016 / 22  (47.8):  70%|▋| 21/30 [00:18<00:08,  1.09it\u001b[A\n",
      "Average Metric: 10.515873015873016 / 22  (47.8):  73%|▋| 22/30 [00:18<00:09,  1.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.515873015873016 / 23  (45.7):  73%|▋| 22/30 [00:19<00:09,  1.23s/\u001b[A\n",
      "Average Metric: 10.515873015873016 / 23  (45.7):  77%|▊| 23/30 [00:19<00:08,  1.15s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.801587301587302 / 24  (45.0):  77%|▊| 23/30 [00:21<00:08,  1.15s/\u001b[A\n",
      "Average Metric: 10.801587301587302 / 24  (45.0):  80%|▊| 24/30 [00:21<00:08,  1.34s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.801587301587302 / 25  (43.2):  80%|▊| 24/30 [00:21<00:08,  1.34s/\u001b[A\n",
      "Average Metric: 10.801587301587302 / 25  (43.2):  83%|▊| 25/30 [00:21<00:05,  1.10s/\u001b[A\n",
      "Average Metric: 11.65873015873016 / 26  (44.8):  83%|▊| 25/30 [00:23<00:05,  1.10s/i\u001b[A\n",
      "Average Metric: 11.65873015873016 / 26  (44.8):  87%|▊| 26/30 [00:23<00:04,  1.09s/i\u001b[A\n",
      "Average Metric: 11.65873015873016 / 27  (43.2):  87%|▊| 26/30 [00:24<00:04,  1.09s/i\u001b[A\n",
      "Average Metric: 11.65873015873016 / 27  (43.2):  90%|▉| 27/30 [00:24<00:03,  1.14s/i\u001b[A\n",
      "Average Metric: 12.05873015873016 / 28  (43.1):  90%|▉| 27/30 [00:24<00:03,  1.14s/i\u001b[A\n",
      "Average Metric: 12.05873015873016 / 29  (41.6):  93%|▉| 28/30 [00:26<00:02,  1.14s/i\u001b[A\n",
      "Average Metric: 12.05873015873016 / 29  (41.6):  97%|▉| 29/30 [00:26<00:01,  1.03s/i\u001b[A\n",
      "Average Metric: 12.55873015873016 / 30  (41.9):  97%|▉| 29/30 [00:29<00:01,  1.03s/i\u001b[A\n",
      "Average Metric: 12.55873015873016 / 30  (41.9): 100%|█| 30/30 [00:29<00:00,  1.00it/\u001b[A\n",
      "[I 2024-04-28 22:33:42,681] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.55873015873016 / 30  (41.9%)\n",
      "Trial pruned.\n",
      "Starting trial #6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.4 / 1  (40.0):   0%|                       | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4 / 1  (40.0):   3%|▌              | 1/30 [00:03<01:43,  3.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.7636363636363637 / 2  (38.2):   3%| | 1/30 [00:04<01:43,  3.58s/it\u001b[A\n",
      "Average Metric: 0.7636363636363637 / 2  (38.2):   7%| | 2/30 [00:04<01:03,  2.27s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.5636363636363637 / 3  (52.1):   7%| | 2/30 [00:05<01:03,  2.27s/it\u001b[A\n",
      "Average Metric: 1.5636363636363637 / 3  (52.1):  10%| | 3/30 [00:05<00:42,  1.59s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.5636363636363637 / 4  (39.1):  10%| | 3/30 [00:06<00:42,  1.59s/it\u001b[A\n",
      "Average Metric: 1.5636363636363637 / 4  (39.1):  13%|▏| 4/30 [00:06<00:36,  1.39s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.9636363636363638 / 5  (39.3):  13%|▏| 4/30 [00:06<00:36,  1.39s/it\u001b[A\n",
      "Average Metric: 1.9636363636363638 / 5  (39.3):  17%|▏| 5/30 [00:06<00:23,  1.07it/s\u001b[A\n",
      "Average Metric: 2.2713286713286713 / 6  (37.9):  17%|▏| 5/30 [00:06<00:23,  1.07it/s\u001b[A\n",
      "Average Metric: 2.2713286713286713 / 7  (32.4):  20%|▏| 6/30 [00:07<00:22,  1.07it/s\u001b[A\n",
      "Average Metric: 2.2713286713286713 / 7  (32.4):  23%|▏| 7/30 [00:07<00:15,  1.45it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.2713286713286713 / 8  (28.4):  23%|▏| 7/30 [00:10<00:15,  1.45it/s\u001b[A\n",
      "Average Metric: 2.2713286713286713 / 8  (28.4):  27%|▎| 8/30 [00:10<00:24,  1.12s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.071328671328671 / 9  (34.1):  27%|▎| 8/30 [00:11<00:24,  1.12s/it]\u001b[A\n",
      "Average Metric: 3.071328671328671 / 9  (34.1):  30%|▎| 9/30 [00:11<00:26,  1.24s/it]\u001b[A\n",
      "Average Metric: 3.3570429570429567 / 10  (33.6):  30%|▎| 9/30 [00:12<00:26,  1.24s/i\u001b[A\n",
      "Average Metric: 3.3570429570429567 / 10  (33.6):  33%|▎| 10/30 [00:12<00:22,  1.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.6427572427572423 / 11  (33.1):  33%|▎| 10/30 [00:13<00:22,  1.12s/\u001b[A\n",
      "Average Metric: 3.6427572427572423 / 11  (33.1):  37%|▎| 11/30 [00:13<00:20,  1.09s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.142757242757242 / 12  (34.5):  37%|▎| 11/30 [00:15<00:20,  1.09s/i\u001b[A\n",
      "Average Metric: 4.142757242757242 / 12  (34.5):  40%|▍| 12/30 [00:15<00:21,  1.22s/i\u001b[A\n",
      "Average Metric: 4.142757242757242 / 13  (31.9):  40%|▍| 12/30 [00:15<00:21,  1.22s/i\u001b[A\n",
      "Average Metric: 4.142757242757242 / 13  (31.9):  43%|▍| 13/30 [00:15<00:18,  1.07s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.142757242757242 / 14  (36.7):  43%|▍| 13/30 [00:16<00:18,  1.07s/i\u001b[A\n",
      "Average Metric: 5.142757242757242 / 14  (36.7):  47%|▍| 14/30 [00:16<00:15,  1.00it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.142757242757242 / 15  (34.3):  47%|▍| 14/30 [00:18<00:15,  1.00it/\u001b[A\n",
      "Average Metric: 5.142757242757242 / 15  (34.3):  50%|▌| 15/30 [00:18<00:18,  1.21s/i\u001b[A\n",
      "Average Metric: 5.142757242757242 / 16  (32.1):  50%|▌| 15/30 [00:19<00:18,  1.21s/i\u001b[A\n",
      "Average Metric: 5.142757242757242 / 16  (32.1):  53%|▌| 16/30 [00:19<00:16,  1.16s/i\u001b[A\n",
      "Average Metric: 5.999900099900099 / 17  (35.3):  53%|▌| 16/30 [00:19<00:16,  1.16s/i\u001b[A\n",
      "Average Metric: 5.999900099900099 / 17  (35.3):  57%|▌| 17/30 [00:19<00:12,  1.08it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.666566766566766 / 18  (37.0):  57%|▌| 17/30 [00:22<00:12,  1.08it/\u001b[A\n",
      "Average Metric: 6.666566766566766 / 18  (37.0):  60%|▌| 18/30 [00:22<00:16,  1.34s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.666566766566766 / 19  (35.1):  60%|▌| 18/30 [00:23<00:16,  1.34s/i\u001b[A\n",
      "Average Metric: 6.666566766566766 / 19  (35.1):  63%|▋| 19/30 [00:23<00:15,  1.37s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 20.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.666566766566766 / 20  (38.3):  63%|▋| 19/30 [00:25<00:15,  1.37s/i\u001b[A\n",
      "Average Metric: 7.666566766566766 / 20  (38.3):  67%|▋| 20/30 [00:25<00:14,  1.45s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.166566766566767 / 21  (38.9):  67%|▋| 20/30 [00:25<00:14,  1.45s/i\u001b[A\n",
      "Average Metric: 8.166566766566767 / 21  (38.9):  70%|▋| 21/30 [00:25<00:10,  1.19s/i\u001b[A\n",
      "Average Metric: 9.166566766566767 / 22  (41.7):  70%|▋| 21/30 [00:26<00:10,  1.19s/i\u001b[A\n",
      "Average Metric: 9.166566766566767 / 22  (41.7):  73%|▋| 22/30 [00:26<00:09,  1.16s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.023709623709625 / 23  (43.6):  73%|▋| 22/30 [00:27<00:09,  1.16s/\u001b[A\n",
      "Average Metric: 10.023709623709625 / 23  (43.6):  77%|▊| 23/30 [00:27<00:07,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 17.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.69037629037629 / 24  (44.5):  77%|▊| 23/30 [00:28<00:07,  1.05s/i\u001b[A\n",
      "Average Metric: 10.69037629037629 / 24  (44.5):  80%|▊| 24/30 [00:28<00:06,  1.08s/i\u001b[A\n",
      "Average Metric: 11.69037629037629 / 25  (46.8):  80%|▊| 24/30 [00:29<00:06,  1.08s/i\u001b[A\n",
      "Average Metric: 11.69037629037629 / 25  (46.8):  83%|▊| 25/30 [00:29<00:04,  1.20it/\u001b[A\n",
      "Average Metric: 12.69037629037629 / 26  (48.8):  83%|▊| 25/30 [00:30<00:04,  1.20it/\u001b[A\n",
      "Average Metric: 12.69037629037629 / 26  (48.8):  87%|▊| 26/30 [00:30<00:03,  1.08it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.9 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.69037629037629 / 27  (47.0):  87%|▊| 26/30 [00:31<00:03,  1.08it/\u001b[A\n",
      "Average Metric: 12.69037629037629 / 27  (47.0):  90%|▉| 27/30 [00:31<00:02,  1.09it/\u001b[A\n",
      "Average Metric: 13.160964525670408 / 28  (47.0):  90%|▉| 27/30 [00:41<00:02,  1.09it\u001b[A\n",
      "Average Metric: 13.160964525670408 / 28  (47.0):  93%|▉| 28/30 [00:41<00:07,  3.69s/\u001b[A\n",
      "Average Metric: 13.160964525670408 / 29  (45.4):  93%|▉| 28/30 [00:44<00:07,  3.69s/\u001b[A\n",
      "Average Metric: 13.160964525670408 / 29  (45.4):  97%|▉| 29/30 [00:44<00:03,  3.70s/\u001b[A\n",
      "Average Metric: 13.160964525670408 / 30  (43.9):  97%|▉| 29/30 [00:47<00:03,  3.70s/\u001b[A\n",
      "Average Metric: 13.160964525670408 / 30  (43.9): 100%|█| 30/30 [00:47<00:00,  1.58s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:34:30,080] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.160964525670408 / 30  (43.9%)\n",
      "Trial pruned.\n",
      "Starting trial #7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:01<00:48,  1.66s/it]\u001b[A\n",
      "Average Metric: 1.3 / 2  (65.0):   3%|▌              | 1/30 [00:02<00:48,  1.66s/it]\u001b[A\n",
      "Average Metric: 1.3 / 2  (65.0):   7%|█              | 2/30 [00:02<00:24,  1.13it/s]\u001b[A\n",
      "Average Metric: 2.3 / 3  (76.7):   7%|█              | 2/30 [00:02<00:24,  1.13it/s]\u001b[A\n",
      "Average Metric: 2.3 / 3  (76.7):  10%|█▌             | 3/30 [00:02<00:16,  1.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.8 / 4  (70.0):  10%|█▌             | 3/30 [00:03<00:16,  1.65it/s]\u001b[A\n",
      "Average Metric: 2.8 / 4  (70.0):  13%|██             | 4/30 [00:03<00:25,  1.03it/s]\u001b[A\n",
      "Average Metric: 3.3 / 5  (66.0):  13%|██             | 4/30 [00:04<00:25,  1.03it/s]\u001b[A\n",
      "Average Metric: 3.3 / 5  (66.0):  17%|██▌            | 5/30 [00:04<00:17,  1.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.3 / 6  (55.0):  17%|██▌            | 5/30 [00:04<00:17,  1.41it/s]\u001b[A\n",
      "Average Metric: 3.3 / 6  (55.0):  20%|███            | 6/30 [00:04<00:16,  1.49it/s]\u001b[A\n",
      "Average Metric: 3.3 / 7  (47.1):  20%|███            | 6/30 [00:04<00:16,  1.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8 / 8  (47.5):  23%|███▌           | 7/30 [00:06<00:15,  1.49it/s]\u001b[A\n",
      "Average Metric: 3.8 / 8  (47.5):  27%|████           | 8/30 [00:06<00:17,  1.23it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.3 / 9  (47.8):  27%|████           | 8/30 [00:06<00:17,  1.23it/s]\u001b[A\n",
      "Average Metric: 4.3 / 9  (47.8):  30%|████▌          | 9/30 [00:06<00:14,  1.47it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.7615384615384615 / 10  (47.6):  30%|▎| 9/30 [00:07<00:14,  1.47it/\u001b[A\n",
      "Average Metric: 4.7615384615384615 / 10  (47.6):  33%|▎| 10/30 [00:07<00:12,  1.62it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.7615384615384615 / 11  (43.3):  33%|▎| 10/30 [00:08<00:12,  1.62it\u001b[A\n",
      "Average Metric: 4.7615384615384615 / 11  (43.3):  37%|▎| 11/30 [00:08<00:16,  1.15it\u001b[A\n",
      "Average Metric: 5.618681318681318 / 12  (46.8):  37%|▎| 11/30 [00:09<00:16,  1.15it/\u001b[A\n",
      "Average Metric: 5.618681318681318 / 12  (46.8):  40%|▍| 12/30 [00:09<00:12,  1.46it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.618681318681318 / 13  (50.9):  40%|▍| 12/30 [00:10<00:12,  1.46it/\u001b[A\n",
      "Average Metric: 6.618681318681318 / 13  (50.9):  43%|▍| 13/30 [00:10<00:17,  1.02s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.618681318681318 / 14  (47.3):  43%|▍| 13/30 [00:12<00:17,  1.02s/i\u001b[A\n",
      "Average Metric: 6.618681318681318 / 14  (47.3):  47%|▍| 14/30 [00:12<00:18,  1.18s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.118681318681318 / 15  (47.5):  47%|▍| 14/30 [00:15<00:18,  1.18s/i\u001b[A\n",
      "Average Metric: 7.118681318681318 / 15  (47.5):  50%|▌| 15/30 [00:15<00:25,  1.68s/i\u001b[A\n",
      "Average Metric: 7.975824175824175 / 16  (49.8):  50%|▌| 15/30 [00:16<00:25,  1.68s/i\u001b[A\n",
      "Average Metric: 7.975824175824175 / 16  (49.8):  53%|▌| 16/30 [00:16<00:21,  1.51s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.975824175824175 / 17  (46.9):  53%|▌| 16/30 [00:17<00:21,  1.51s/i\u001b[A\n",
      "Average Metric: 7.975824175824175 / 17  (46.9):  57%|▌| 17/30 [00:17<00:19,  1.48s/i\u001b[A\n",
      "Average Metric: 8.642490842490842 / 18  (48.0):  57%|▌| 17/30 [00:17<00:19,  1.48s/i\u001b[A\n",
      "Average Metric: 9.642490842490842 / 19  (50.7):  60%|▌| 18/30 [00:18<00:17,  1.48s/i\u001b[A\n",
      "Average Metric: 9.642490842490842 / 19  (50.7):  63%|▋| 19/30 [00:18<00:10,  1.05it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.642490842490842 / 20  (48.2):  63%|▋| 19/30 [00:19<00:10,  1.05it/\u001b[A\n",
      "Average Metric: 9.642490842490842 / 20  (48.2):  67%|▋| 20/30 [00:19<00:09,  1.09it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.309157509157508 / 21  (49.1):  67%|▋| 20/30 [00:21<00:09,  1.09it\u001b[A\n",
      "Average Metric: 10.309157509157508 / 21  (49.1):  70%|▋| 21/30 [00:21<00:11,  1.26s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.309157509157508 / 22  (46.9):  70%|▋| 21/30 [00:22<00:11,  1.26s/\u001b[A\n",
      "Average Metric: 10.309157509157508 / 22  (46.9):  73%|▋| 22/30 [00:22<00:10,  1.28s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.309157509157508 / 23  (49.2):  73%|▋| 22/30 [00:24<00:10,  1.28s/\u001b[A\n",
      "Average Metric: 11.309157509157508 / 23  (49.2):  77%|▊| 23/30 [00:24<00:09,  1.40s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.594871794871795 / 24  (48.3):  77%|▊| 23/30 [00:26<00:09,  1.40s/\u001b[A\n",
      "Average Metric: 11.594871794871795 / 24  (48.3):  80%|▊| 24/30 [00:26<00:10,  1.67s/\u001b[A\n",
      "Average Metric: 12.056410256410256 / 25  (48.2):  80%|▊| 24/30 [00:27<00:10,  1.67s/\u001b[A\n",
      "Average Metric: 12.056410256410256 / 25  (48.2):  83%|▊| 25/30 [00:27<00:06,  1.33s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.056410256410256 / 26  (46.4):  83%|▊| 25/30 [00:28<00:06,  1.33s/\u001b[A\n",
      "Average Metric: 12.056410256410256 / 26  (46.4):  87%|▊| 26/30 [00:28<00:04,  1.20s/\u001b[A\n",
      "Average Metric: 12.056410256410256 / 27  (44.7):  87%|▊| 26/30 [00:28<00:04,  1.20s/\u001b[A\n",
      "Average Metric: 12.913553113553114 / 28  (46.1):  90%|▉| 27/30 [00:30<00:03,  1.20s/\u001b[A\n",
      "Average Metric: 12.913553113553114 / 28  (46.1):  93%|▉| 28/30 [00:30<00:02,  1.17s/\u001b[A\n",
      "Average Metric: 13.913553113553114 / 29  (48.0):  93%|▉| 28/30 [00:31<00:02,  1.17s/\u001b[A\n",
      "Average Metric: 13.913553113553114 / 29  (48.0):  97%|▉| 29/30 [00:31<00:01,  1.04s/\u001b[A\n",
      "Average Metric: 14.357997557997559 / 30  (47.9):  97%|▉| 29/30 [00:36<00:01,  1.04s/\u001b[A\n",
      "Average Metric: 14.357997557997559 / 30  (47.9): 100%|█| 30/30 [00:36<00:00,  1.21s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:35:06,564] Trial 7 finished with value: 47.86 and parameters: {'14766014224_predictor_instruction': 7, '14766014224_predictor_demos': 7, '14707649168_predictor_instruction': 1, '14707649168_predictor_demos': 3, '14753105040_predictor_instruction': 9, '14753105040_predictor_demos': 5}. Best is trial 2 with value: 50.11.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.357997557997559 / 30  (47.9%)\n",
      "Starting trial #8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:02<01:08,  2.37s/it]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:03<01:08,  2.37s/it]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   7%|▉             | 2/30 [00:03<00:46,  1.68s/it]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:04<00:46,  1.68s/it]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):  10%|█▌             | 3/30 [00:04<00:30,  1.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0 / 4  (75.0):  10%|█▌             | 3/30 [00:04<00:30,  1.13s/it]\u001b[A\n",
      "Average Metric: 3.0 / 4  (75.0):  13%|██             | 4/30 [00:04<00:19,  1.31it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.5 / 5  (70.0):  13%|██             | 4/30 [00:05<00:19,  1.31it/s]\u001b[A\n",
      "Average Metric: 3.5 / 5  (70.0):  17%|██▌            | 5/30 [00:05<00:20,  1.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8333333333333335 / 6  (63.9):  17%|▏| 5/30 [00:08<00:20,  1.24it/s\u001b[A\n",
      "Average Metric: 3.8333333333333335 / 6  (63.9):  20%|▏| 6/30 [00:08<00:39,  1.65s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8333333333333335 / 7  (54.8):  20%|▏| 6/30 [00:09<00:39,  1.65s/it\u001b[A\n",
      "Average Metric: 3.8333333333333335 / 7  (54.8):  23%|▏| 7/30 [00:09<00:35,  1.56s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.333333333333334 / 8  (54.2):  23%|▏| 7/30 [00:10<00:35,  1.56s/it]\u001b[A\n",
      "Average Metric: 4.333333333333334 / 8  (54.2):  27%|▎| 8/30 [00:10<00:31,  1.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.000000000000001 / 9  (55.6):  27%|▎| 8/30 [00:13<00:31,  1.44s/it]\u001b[A\n",
      "Average Metric: 5.000000000000001 / 9  (55.6):  30%|▎| 9/30 [00:13<00:37,  1.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.857142857142858 / 10  (58.6):  30%|▎| 9/30 [00:14<00:37,  1.77s/it\u001b[A\n",
      "Average Metric: 5.857142857142858 / 10  (58.6):  33%|▎| 10/30 [00:14<00:33,  1.65s/i\u001b[A\n",
      "Average Metric: 6.301587301587302 / 11  (57.3):  33%|▎| 10/30 [00:15<00:33,  1.65s/i\u001b[A\n",
      "Average Metric: 6.301587301587302 / 11  (57.3):  37%|▎| 11/30 [00:15<00:25,  1.34s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.763125763125764 / 12  (56.4):  37%|▎| 11/30 [00:16<00:25,  1.34s/i\u001b[A\n",
      "Average Metric: 6.763125763125764 / 12  (56.4):  40%|▍| 12/30 [00:16<00:22,  1.27s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.263125763125764 / 13  (55.9):  40%|▍| 12/30 [00:17<00:22,  1.27s/i\u001b[A\n",
      "Average Metric: 7.263125763125764 / 13  (55.9):  43%|▍| 13/30 [00:17<00:18,  1.10s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.763125763125764 / 14  (55.5):  43%|▍| 13/30 [00:19<00:18,  1.10s/i\u001b[A\n",
      "Average Metric: 7.763125763125764 / 14  (55.5):  47%|▍| 14/30 [00:19<00:21,  1.34s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.763125763125764 / 15  (51.8):  47%|▍| 14/30 [00:19<00:21,  1.34s/i\u001b[A\n",
      "Average Metric: 7.763125763125764 / 15  (51.8):  50%|▌| 15/30 [00:19<00:17,  1.14s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.763125763125764 / 16  (48.5):  50%|▌| 15/30 [00:23<00:17,  1.14s/i\u001b[A\n",
      "Average Metric: 7.763125763125764 / 16  (48.5):  53%|▌| 16/30 [00:23<00:25,  1.82s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.42979242979243 / 17  (49.6):  53%|▌| 16/30 [00:24<00:25,  1.82s/it\u001b[A\n",
      "Average Metric: 8.42979242979243 / 17  (49.6):  57%|▌| 17/30 [00:24<00:21,  1.69s/it\u001b[A\n",
      "Average Metric: 8.42979242979243 / 18  (46.8):  57%|▌| 17/30 [00:25<00:21,  1.69s/it\u001b[A\n",
      "Average Metric: 8.42979242979243 / 18  (46.8):  60%|▌| 18/30 [00:25<00:15,  1.32s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.92979242979243 / 19  (47.0):  60%|▌| 18/30 [00:25<00:15,  1.32s/it\u001b[A\n",
      "Average Metric: 8.92979242979243 / 19  (47.0):  63%|▋| 19/30 [00:25<00:12,  1.09s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.596459096459096 / 20  (48.0):  63%|▋| 19/30 [00:26<00:12,  1.09s/i\u001b[A\n",
      "Average Metric: 9.596459096459096 / 20  (48.0):  67%|▋| 20/30 [00:26<00:10,  1.07s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.453601953601954 / 21  (49.8):  67%|▋| 20/30 [00:30<00:10,  1.07s/\u001b[A\n",
      "Average Metric: 10.453601953601954 / 21  (49.8):  70%|▋| 21/30 [00:30<00:17,  1.96s/\u001b[A\n",
      "Average Metric: 10.853601953601954 / 22  (49.3):  70%|▋| 21/30 [00:30<00:17,  1.96s/\u001b[A\n",
      "Average Metric: 10.853601953601954 / 22  (49.3):  73%|▋| 22/30 [00:30<00:11,  1.43s/\u001b[A\n",
      "Average Metric: 11.853601953601954 / 23  (51.5):  73%|▋| 22/30 [00:31<00:11,  1.43s/\u001b[A\n",
      "Average Metric: 11.853601953601954 / 23  (51.5):  77%|▊| 23/30 [00:31<00:07,  1.06s/\u001b[A\n",
      "Average Metric: 12.853601953601954 / 24  (53.6):  77%|▊| 23/30 [00:32<00:07,  1.06s/\u001b[A\n",
      "Average Metric: 12.853601953601954 / 24  (53.6):  80%|▊| 24/30 [00:32<00:06,  1.04s/\u001b[A\n",
      "Average Metric: 13.742490842490843 / 25  (55.0):  80%|▊| 24/30 [00:32<00:06,  1.04s/\u001b[A\n",
      "Average Metric: 13.742490842490843 / 25  (55.0):  83%|▊| 25/30 [00:32<00:03,  1.28it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 10.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.742490842490843 / 26  (56.7):  83%|▊| 25/30 [00:33<00:03,  1.28it\u001b[A\n",
      "Average Metric: 14.742490842490843 / 26  (56.7):  87%|▊| 26/30 [00:33<00:03,  1.23it\u001b[A\n",
      "Average Metric: 15.742490842490843 / 27  (58.3):  87%|▊| 26/30 [00:33<00:03,  1.23it\u001b[A\n",
      "Average Metric: 15.742490842490843 / 27  (58.3):  90%|▉| 27/30 [00:33<00:02,  1.44it\u001b[A\n",
      "Average Metric: 16.142490842490844 / 28  (57.7):  90%|▉| 27/30 [00:34<00:02,  1.44it\u001b[A\n",
      "Average Metric: 16.142490842490844 / 28  (57.7):  93%|▉| 28/30 [00:34<00:01,  1.28it\u001b[A\n",
      "Average Metric: 16.9996336996337 / 29  (58.6):  93%|▉| 28/30 [00:35<00:01,  1.28it/s\u001b[A\n",
      "Average Metric: 16.9996336996337 / 29  (58.6):  97%|▉| 29/30 [00:35<00:00,  1.10it/s\u001b[A\n",
      "Average Metric: 17.85677655677656 / 30  (59.5):  97%|▉| 29/30 [00:44<00:00,  1.10it/\u001b[A\n",
      "Average Metric: 17.85677655677656 / 30  (59.5): 100%|█| 30/30 [00:44<00:00,  1.48s/i\u001b[A\n",
      "[I 2024-04-28 22:35:50,926] Trial 8 finished with value: 59.52 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 8, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 2, '14753105040_predictor_demos': 1}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.85677655677656 / 30  (59.5%)\n",
      "Starting trial #9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:02<01:14,  2.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.5 / 2  (75.0):   3%|▌              | 1/30 [00:03<01:14,  2.58s/it]\u001b[A\n",
      "Average Metric: 1.5 / 2  (75.0):   7%|█              | 2/30 [00:03<00:43,  1.56s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:03<00:43,  1.56s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):  10%|█▌             | 3/30 [00:03<00:25,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.5 / 4  (37.5):  10%|█▌             | 3/30 [00:04<00:25,  1.08it/s]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):  13%|██             | 4/30 [00:04<00:19,  1.33it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.5 / 5  (30.0):  13%|██             | 4/30 [00:04<00:19,  1.33it/s]\u001b[A\n",
      "Average Metric: 1.5 / 5  (30.0):  17%|██▌            | 5/30 [00:04<00:18,  1.35it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.1666666666666665 / 6  (36.1):  17%|▏| 5/30 [00:05<00:18,  1.35it/s\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 6  (36.1):  20%|▏| 6/30 [00:05<00:19,  1.25it/s\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 7  (31.0):  20%|▏| 6/30 [00:05<00:19,  1.25it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  23%|▏| 7/30 [00:07<00:18,  1.25it/s\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  27%|▎| 8/30 [00:07<00:16,  1.34it/s\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  27%|▎| 8/30 [00:07<00:16,  1.34it/s\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  30%|▎| 9/30 [00:07<00:13,  1.56it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0666666666666664 / 10  (30.7):  30%|▎| 9/30 [00:08<00:13,  1.56it/\u001b[A\n",
      "Average Metric: 3.0666666666666664 / 10  (30.7):  33%|▎| 10/30 [00:08<00:17,  1.16it\u001b[A\n",
      "Average Metric: 3.495238095238095 / 11  (31.8):  33%|▎| 10/30 [00:09<00:17,  1.16it/\u001b[A\n",
      "Average Metric: 3.495238095238095 / 11  (31.8):  37%|▎| 11/30 [00:09<00:13,  1.39it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.495238095238095 / 12  (29.1):  37%|▎| 11/30 [00:10<00:13,  1.39it/\u001b[A\n",
      "Average Metric: 3.495238095238095 / 12  (29.1):  40%|▍| 12/30 [00:10<00:13,  1.37it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.352380952380952 / 13  (33.5):  40%|▍| 12/30 [00:10<00:13,  1.37it/\u001b[A\n",
      "Average Metric: 4.352380952380952 / 13  (33.5):  43%|▍| 13/30 [00:10<00:12,  1.36it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.019047619047619 / 14  (35.9):  43%|▍| 13/30 [00:13<00:12,  1.36it/\u001b[A\n",
      "Average Metric: 5.019047619047619 / 14  (35.9):  47%|▍| 14/30 [00:13<00:19,  1.24s/i\u001b[A\n",
      "Average Metric: 6.019047619047619 / 15  (40.1):  47%|▍| 14/30 [00:13<00:19,  1.24s/i\u001b[A\n",
      "Average Metric: 6.019047619047619 / 15  (40.1):  50%|▌| 15/30 [00:13<00:16,  1.07s/i\u001b[A\n",
      "Average Metric: 7.019047619047619 / 16  (43.9):  50%|▌| 15/30 [00:13<00:16,  1.07s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.200865800865801 / 17  (42.4):  53%|▌| 16/30 [00:16<00:14,  1.07s/i\u001b[A\n",
      "Average Metric: 7.200865800865801 / 17  (42.4):  57%|▌| 17/30 [00:16<00:15,  1.21s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.2008658008658 / 18  (45.6):  57%|▌| 17/30 [00:17<00:15,  1.21s/it]\u001b[A\n",
      "Average Metric: 8.2008658008658 / 18  (45.6):  60%|▌| 18/30 [00:17<00:14,  1.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.2008658008658 / 19  (43.2):  60%|▌| 18/30 [00:19<00:14,  1.21s/it]\u001b[A\n",
      "Average Metric: 8.2008658008658 / 19  (43.2):  63%|▋| 19/30 [00:19<00:13,  1.27s/it]\u001b[A\n",
      "Average Metric: 8.2008658008658 / 20  (41.0):  63%|▋| 19/30 [00:19<00:13,  1.27s/it]\u001b[A\n",
      "Average Metric: 9.058008658008658 / 21  (43.1):  67%|▋| 20/30 [00:19<00:12,  1.27s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.724675324675324 / 22  (44.2):  70%|▋| 21/30 [00:20<00:11,  1.27s/i\u001b[A\n",
      "Average Metric: 9.724675324675324 / 22  (44.2):  73%|▋| 22/30 [00:20<00:06,  1.23it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.724675324675324 / 23  (46.6):  73%|▋| 22/30 [00:21<00:06,  1.23it\u001b[A\n",
      "Average Metric: 10.724675324675324 / 23  (46.6):  77%|▊| 23/30 [00:21<00:06,  1.09it\u001b[A\n",
      "Average Metric: 10.724675324675324 / 24  (44.7):  77%|▊| 23/30 [00:21<00:06,  1.09it\u001b[A\n",
      "Average Metric: 10.724675324675324 / 25  (42.9):  80%|▊| 24/30 [00:23<00:05,  1.09it\u001b[A\n",
      "Average Metric: 10.724675324675324 / 25  (42.9):  83%|▊| 25/30 [00:23<00:04,  1.22it\u001b[A\n",
      "Average Metric: 11.224675324675324 / 26  (43.2):  83%|▊| 25/30 [00:24<00:04,  1.22it\u001b[A\n",
      "Average Metric: 11.224675324675324 / 26  (43.2):  87%|▊| 26/30 [00:24<00:03,  1.18it\u001b[A\n",
      "Average Metric: 11.224675324675324 / 27  (41.6):  87%|▊| 26/30 [00:25<00:03,  1.18it\u001b[A\n",
      "Average Metric: 11.224675324675324 / 27  (41.6):  90%|▉| 27/30 [00:25<00:02,  1.06it\u001b[A\n",
      "Average Metric: 12.224675324675324 / 28  (43.7):  90%|▉| 27/30 [00:25<00:02,  1.06it\u001b[A\n",
      "Average Metric: 12.224675324675324 / 28  (43.7):  93%|▉| 28/30 [00:25<00:01,  1.23it\u001b[A\n",
      "Average Metric: 12.558008658008658 / 29  (43.3):  93%|▉| 28/30 [00:26<00:01,  1.23it\u001b[A\n",
      "Average Metric: 12.558008658008658 / 29  (43.3):  97%|▉| 29/30 [00:26<00:00,  1.27it\u001b[A\n",
      "Average Metric: 13.558008658008658 / 30  (45.2):  97%|▉| 29/30 [00:28<00:00,  1.27it\u001b[A\n",
      "Average Metric: 13.558008658008658 / 30  (45.2): 100%|█| 30/30 [00:28<00:00,  1.04it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:36:19,745] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.558008658008658 / 30  (45.2%)\n",
      "Trial pruned.\n",
      "Starting trial #10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:33,  3.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:05<01:33,  3.24s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:05<01:10,  2.51s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):   7%|█               | 2/30 [00:05<01:10,  2.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 4  (0.0):  10%|█▌              | 3/30 [00:07<01:07,  2.51s/it]\u001b[A\n",
      "Average Metric: 0.0 / 4  (0.0):  13%|██▏             | 4/30 [00:07<00:43,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.4 / 5  (8.0):  13%|██▏             | 4/30 [00:08<00:43,  1.68s/it]\u001b[A\n",
      "Average Metric: 0.4 / 5  (8.0):  17%|██▋             | 5/30 [00:08<00:33,  1.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.9 / 6  (15.0):  17%|██▌            | 5/30 [00:10<00:33,  1.35s/it]\u001b[A\n",
      "Average Metric: 0.9 / 6  (15.0):  20%|███            | 6/30 [00:10<00:37,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.9 / 7  (12.9):  20%|███            | 6/30 [00:10<00:37,  1.55s/it]\u001b[A\n",
      "Average Metric: 0.9 / 7  (12.9):  23%|███▌           | 7/30 [00:10<00:29,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.9 / 8  (23.8):  23%|███▌           | 7/30 [00:13<00:29,  1.29s/it]\u001b[A\n",
      "Average Metric: 1.9 / 8  (23.8):  27%|████           | 8/30 [00:13<00:40,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  27%|▎| 8/30 [00:14<00:40,  1.83s/it\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  30%|▎| 9/30 [00:14<00:31,  1.52s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.9666666666666663 / 10  (29.7):  30%|▎| 9/30 [00:15<00:31,  1.52s/i\u001b[A\n",
      "Average Metric: 2.9666666666666663 / 10  (29.7):  33%|▎| 10/30 [00:15<00:26,  1.31s/\u001b[A\n",
      "Average Metric: 2.9666666666666663 / 11  (27.0):  33%|▎| 10/30 [00:16<00:26,  1.31s/\u001b[A\n",
      "Average Metric: 2.9666666666666663 / 11  (27.0):  37%|▎| 11/30 [00:16<00:25,  1.32s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.3 / 12  (27.5):  37%|████▊        | 11/30 [00:17<00:25,  1.32s/it]\u001b[A\n",
      "Average Metric: 3.3 / 12  (27.5):  40%|█████▏       | 12/30 [00:17<00:19,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8 / 13  (29.2):  40%|█████▏       | 12/30 [00:18<00:19,  1.09s/it]\u001b[A\n",
      "Average Metric: 3.8 / 13  (29.2):  43%|█████▋       | 13/30 [00:18<00:17,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8 / 14  (27.1):  43%|█████▋       | 13/30 [00:21<00:17,  1.04s/it]\u001b[A\n",
      "Average Metric: 3.8 / 14  (27.1):  47%|██████       | 14/30 [00:21<00:24,  1.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.2 / 15  (28.0):  47%|██████       | 14/30 [00:22<00:24,  1.53s/it]\u001b[A\n",
      "Average Metric: 4.2 / 15  (28.0):  50%|██████▌      | 15/30 [00:22<00:20,  1.39s/it]\u001b[A\n",
      "Average Metric: 4.2 / 16  (26.2):  50%|██████▌      | 15/30 [00:23<00:20,  1.39s/it]\u001b[A\n",
      "Average Metric: 4.2 / 16  (26.2):  53%|██████▉      | 16/30 [00:23<00:17,  1.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.866666666666667 / 17  (28.6):  53%|▌| 16/30 [00:25<00:17,  1.22s/i\u001b[A\n",
      "Average Metric: 4.866666666666667 / 17  (28.6):  57%|▌| 17/30 [00:25<00:21,  1.66s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 12.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.866666666666667 / 18  (27.0):  57%|▌| 17/30 [00:26<00:21,  1.66s/i\u001b[A\n",
      "Average Metric: 4.866666666666667 / 18  (27.0):  60%|▌| 18/30 [00:26<00:17,  1.45s/i\u001b[A\n",
      "Average Metric: 5.048484848484849 / 19  (26.6):  60%|▌| 18/30 [00:27<00:17,  1.45s/i\u001b[A\n",
      "Average Metric: 5.048484848484849 / 19  (26.6):  63%|▋| 19/30 [00:27<00:12,  1.16s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 13.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.048484848484849 / 20  (25.2):  63%|▋| 19/30 [00:29<00:12,  1.16s/i\u001b[A\n",
      "Average Metric: 5.048484848484849 / 20  (25.2):  67%|▋| 20/30 [00:29<00:14,  1.41s/i\u001b[A\n",
      "Average Metric: 6.048484848484849 / 21  (28.8):  67%|▋| 20/30 [00:29<00:14,  1.41s/i\u001b[A\n",
      "Average Metric: 6.048484848484849 / 21  (28.8):  70%|▋| 21/30 [00:29<00:09,  1.03s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.048484848484849 / 22  (32.0):  70%|▋| 21/30 [00:30<00:09,  1.03s/i\u001b[A\n",
      "Average Metric: 7.048484848484849 / 22  (32.0):  73%|▋| 22/30 [00:30<00:08,  1.10s/i\u001b[A\n",
      "Average Metric: 8.048484848484849 / 23  (35.0):  73%|▋| 22/30 [00:31<00:08,  1.10s/i\u001b[A\n",
      "Average Metric: 8.048484848484849 / 23  (35.0):  77%|▊| 23/30 [00:31<00:06,  1.05it/\u001b[A\n",
      "Average Metric: 8.048484848484849 / 24  (33.5):  77%|▊| 23/30 [00:32<00:06,  1.05it/\u001b[A\n",
      "Average Metric: 8.048484848484849 / 24  (33.5):  80%|▊| 24/30 [00:32<00:06,  1.05s/i\u001b[A\n",
      "Average Metric: 8.905627705627706 / 25  (35.6):  80%|▊| 24/30 [00:32<00:06,  1.05s/i\u001b[A\n",
      "Average Metric: 8.905627705627706 / 25  (35.6):  83%|▊| 25/30 [00:32<00:04,  1.19it/\u001b[A\n",
      "Average Metric: 8.905627705627706 / 26  (34.3):  83%|▊| 25/30 [00:33<00:04,  1.19it/\u001b[A\n",
      "Average Metric: 8.905627705627706 / 26  (34.3):  87%|▊| 26/30 [00:33<00:03,  1.05it/\u001b[A\n",
      "Average Metric: 9.405627705627706 / 27  (34.8):  87%|▊| 26/30 [00:34<00:03,  1.05it/\u001b[A\n",
      "Average Metric: 9.405627705627706 / 27  (34.8):  90%|▉| 27/30 [00:34<00:02,  1.25it/\u001b[A\n",
      "Average Metric: 10.072294372294373 / 28  (36.0):  90%|▉| 27/30 [00:36<00:02,  1.25it\u001b[A\n",
      "Average Metric: 10.072294372294373 / 28  (36.0):  93%|▉| 28/30 [00:36<00:02,  1.31s/\u001b[A\n",
      "Average Metric: 10.92943722943723 / 29  (37.7):  93%|▉| 28/30 [00:39<00:02,  1.31s/i\u001b[A\n",
      "Average Metric: 10.92943722943723 / 29  (37.7):  97%|▉| 29/30 [00:39<00:01,  1.71s/i\u001b[A\n",
      "Average Metric: 11.262770562770564 / 30  (37.5):  97%|▉| 29/30 [00:41<00:01,  1.71s/\u001b[A\n",
      "Average Metric: 11.262770562770564 / 30  (37.5): 100%|█| 30/30 [00:41<00:00,  1.39s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:37:01,665] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.262770562770564 / 30  (37.5%)\n",
      "Trial pruned.\n",
      "Starting trial #11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:00,  2.09s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:02<01:00,  2.09s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:02<00:26,  1.05it/s]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:03<00:26,  1.05it/s]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):  10%|█▌             | 3/30 [00:03<00:24,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5 / 4  (62.5):  10%|█▌             | 3/30 [00:04<00:24,  1.10it/s]\u001b[A\n",
      "Average Metric: 2.5 / 4  (62.5):  13%|██             | 4/30 [00:04<00:33,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.071428571428571 / 5  (61.4):  13%|▏| 4/30 [00:06<00:33,  1.29s/it]\u001b[A\n",
      "Average Metric: 3.071428571428571 / 5  (61.4):  17%|▏| 5/30 [00:06<00:30,  1.23s/it]\u001b[A\n",
      "Average Metric: 3.071428571428571 / 6  (51.2):  17%|▏| 5/30 [00:06<00:30,  1.23s/it]\u001b[A\n",
      "Average Metric: 3.071428571428571 / 6  (51.2):  20%|▏| 6/30 [00:06<00:25,  1.04s/it]\u001b[A\n",
      "Average Metric: 3.571428571428571 / 7  (51.0):  20%|▏| 6/30 [00:07<00:25,  1.04s/it]\u001b[A\n",
      "Average Metric: 3.571428571428571 / 7  (51.0):  23%|▏| 7/30 [00:07<00:18,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.571428571428571 / 8  (57.1):  23%|▏| 7/30 [00:08<00:18,  1.21it/s]\u001b[A\n",
      "Average Metric: 4.571428571428571 / 8  (57.1):  27%|▎| 8/30 [00:08<00:20,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.071428571428571 / 9  (56.3):  27%|▎| 8/30 [00:12<00:20,  1.05it/s]\u001b[A\n",
      "Average Metric: 5.071428571428571 / 9  (56.3):  30%|▎| 9/30 [00:12<00:41,  1.96s/it]\u001b[A\n",
      "Average Metric: 5.071428571428571 / 10  (50.7):  30%|▎| 9/30 [00:12<00:41,  1.96s/it\u001b[A\n",
      "Average Metric: 5.071428571428571 / 10  (50.7):  33%|▎| 10/30 [00:12<00:29,  1.46s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.738095238095238 / 11  (52.2):  33%|▎| 10/30 [00:15<00:29,  1.46s/i\u001b[A\n",
      "Average Metric: 5.738095238095238 / 11  (52.2):  37%|▎| 11/30 [00:15<00:34,  1.81s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.738095238095238 / 12  (47.8):  37%|▎| 11/30 [00:15<00:34,  1.81s/i\u001b[A\n",
      "Average Metric: 5.738095238095238 / 12  (47.8):  40%|▍| 12/30 [00:15<00:24,  1.33s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.1380952380952385 / 13  (47.2):  40%|▍| 12/30 [00:16<00:24,  1.33s/\u001b[A\n",
      "Average Metric: 6.1380952380952385 / 13  (47.2):  43%|▍| 13/30 [00:16<00:20,  1.21s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 14.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.8047619047619055 / 14  (48.6):  43%|▍| 13/30 [00:18<00:20,  1.21s/\u001b[A\n",
      "Average Metric: 6.8047619047619055 / 14  (48.6):  47%|▍| 14/30 [00:18<00:21,  1.35s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.8047619047619055 / 15  (45.4):  47%|▍| 14/30 [00:18<00:21,  1.35s/\u001b[A\n",
      "Average Metric: 6.8047619047619055 / 15  (45.4):  50%|▌| 15/30 [00:18<00:16,  1.10s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.5547619047619055 / 16  (47.2):  50%|▌| 15/30 [00:21<00:16,  1.10s/\u001b[A\n",
      "Average Metric: 7.5547619047619055 / 16  (47.2):  53%|▌| 16/30 [00:21<00:21,  1.53s/\u001b[A\n",
      "Average Metric: 7.5547619047619055 / 17  (44.4):  53%|▌| 16/30 [00:22<00:21,  1.53s/\u001b[A\n",
      "Average Metric: 7.5547619047619055 / 17  (44.4):  57%|▌| 17/30 [00:22<00:16,  1.29s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.5547619047619055 / 18  (42.0):  57%|▌| 17/30 [00:23<00:16,  1.29s/\u001b[A\n",
      "Average Metric: 7.5547619047619055 / 18  (42.0):  60%|▌| 18/30 [00:23<00:16,  1.36s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.054761904761905 / 19  (42.4):  60%|▌| 18/30 [00:24<00:16,  1.36s/i\u001b[A\n",
      "Average Metric: 8.054761904761905 / 19  (42.4):  63%|▋| 19/30 [00:24<00:13,  1.19s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.454761904761906 / 20  (42.3):  63%|▋| 19/30 [00:26<00:13,  1.19s/i\u001b[A\n",
      "Average Metric: 8.454761904761906 / 20  (42.3):  67%|▋| 20/30 [00:26<00:14,  1.40s/i\u001b[A\n",
      "Average Metric: 8.454761904761906 / 21  (40.3):  67%|▋| 20/30 [00:26<00:14,  1.40s/i\u001b[A\n",
      "Average Metric: 8.454761904761906 / 21  (40.3):  70%|▋| 21/30 [00:26<00:10,  1.11s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.454761904761906 / 22  (43.0):  70%|▋| 21/30 [00:28<00:10,  1.11s/i\u001b[A\n",
      "Average Metric: 9.454761904761906 / 22  (43.0):  73%|▋| 22/30 [00:28<00:09,  1.20s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.454761904761906 / 23  (45.5):  73%|▋| 22/30 [00:29<00:09,  1.20s/\u001b[A\n",
      "Average Metric: 10.454761904761906 / 23  (45.5):  77%|▊| 23/30 [00:29<00:07,  1.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.121428571428572 / 24  (46.3):  77%|▊| 23/30 [00:30<00:07,  1.12s/\u001b[A\n",
      "Average Metric: 11.121428571428572 / 24  (46.3):  80%|▊| 24/30 [00:30<00:06,  1.14s/\u001b[A\n",
      "Average Metric: 11.121428571428572 / 25  (44.5):  80%|▊| 24/30 [00:30<00:06,  1.14s/\u001b[A\n",
      "Average Metric: 11.121428571428572 / 25  (44.5):  83%|▊| 25/30 [00:30<00:04,  1.01it\u001b[A\n",
      "Average Metric: 11.565873015873017 / 26  (44.5):  83%|▊| 25/30 [00:32<00:04,  1.01it\u001b[A\n",
      "Average Metric: 11.565873015873017 / 26  (44.5):  87%|▊| 26/30 [00:32<00:04,  1.04s/\u001b[A\n",
      "Average Metric: 12.423015873015874 / 27  (46.0):  87%|▊| 26/30 [00:32<00:04,  1.04s/\u001b[A\n",
      "Average Metric: 12.823015873015875 / 28  (45.8):  90%|▉| 27/30 [00:35<00:03,  1.04s/\u001b[A\n",
      "Average Metric: 12.823015873015875 / 28  (45.8):  93%|▉| 28/30 [00:35<00:02,  1.33s/\u001b[A\n",
      "Average Metric: 13.284554334554336 / 29  (45.8):  93%|▉| 28/30 [00:40<00:02,  1.33s/\u001b[A\n",
      "Average Metric: 13.284554334554336 / 29  (45.8):  97%|▉| 29/30 [00:40<00:02,  2.29s/\u001b[A\n",
      "Average Metric: 13.951221001221002 / 30  (46.5):  97%|▉| 29/30 [00:42<00:02,  2.29s/\u001b[A\n",
      "Average Metric: 13.951221001221002 / 30  (46.5): 100%|█| 30/30 [00:42<00:00,  1.41s/\u001b[A\n",
      "[I 2024-04-28 22:37:44,014] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.951221001221002 / 30  (46.5%)\n",
      "Trial pruned.\n",
      "Starting trial #12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:16,  2.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.6666666666666666 / 2  (33.3):   3%| | 1/30 [00:03<01:16,  2.65s/it\u001b[A\n",
      "Average Metric: 0.6666666666666666 / 2  (33.3):   7%| | 2/30 [00:03<00:46,  1.65s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 3  (55.6):   7%| | 2/30 [00:03<00:46,  1.65s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.6666666666666665 / 4  (41.7):  10%| | 3/30 [00:04<00:44,  1.65s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 4  (41.7):  13%|▏| 4/30 [00:04<00:21,  1.21it/s\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 5  (53.3):  13%|▏| 4/30 [00:04<00:21,  1.21it/s\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 5  (53.3):  17%|▏| 5/30 [00:04<00:15,  1.65it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.238095238095238 / 6  (54.0):  17%|▏| 5/30 [00:08<00:15,  1.65it/s]\u001b[A\n",
      "Average Metric: 3.238095238095238 / 6  (54.0):  20%|▏| 6/30 [00:08<00:38,  1.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.638095238095238 / 7  (52.0):  20%|▏| 6/30 [00:09<00:38,  1.59s/it]\u001b[A\n",
      "Average Metric: 3.638095238095238 / 7  (52.0):  23%|▏| 7/30 [00:09<00:31,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.638095238095238 / 8  (58.0):  23%|▏| 7/30 [00:10<00:31,  1.37s/it]\u001b[A\n",
      "Average Metric: 4.638095238095238 / 8  (58.0):  27%|▎| 8/30 [00:10<00:28,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.138095238095238 / 9  (57.1):  27%|▎| 8/30 [00:10<00:28,  1.29s/it]\u001b[A\n",
      "Average Metric: 5.138095238095238 / 9  (57.1):  30%|▎| 9/30 [00:10<00:23,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.638095238095238 / 10  (56.4):  30%|▎| 9/30 [00:12<00:23,  1.10s/it\u001b[A\n",
      "Average Metric: 5.638095238095238 / 10  (56.4):  33%|▎| 10/30 [00:12<00:25,  1.27s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.495238095238094 / 11  (59.0):  33%|▎| 10/30 [00:13<00:25,  1.27s/i\u001b[A\n",
      "Average Metric: 6.495238095238094 / 11  (59.0):  37%|▎| 11/30 [00:13<00:21,  1.14s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.495238095238094 / 12  (54.1):  37%|▎| 11/30 [00:14<00:21,  1.14s/i\u001b[A\n",
      "Average Metric: 6.495238095238094 / 12  (54.1):  40%|▍| 12/30 [00:14<00:20,  1.13s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.895238095238095 / 13  (53.0):  40%|▍| 12/30 [00:15<00:20,  1.13s/i\u001b[A\n",
      "Average Metric: 6.895238095238095 / 13  (53.0):  43%|▍| 13/30 [00:15<00:17,  1.04s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.895238095238095 / 14  (49.3):  43%|▍| 13/30 [00:17<00:17,  1.04s/i\u001b[A\n",
      "Average Metric: 6.895238095238095 / 14  (49.3):  47%|▍| 14/30 [00:17<00:21,  1.32s/i\u001b[A\n",
      "Average Metric: 7.895238095238095 / 15  (52.6):  47%|▍| 14/30 [00:17<00:21,  1.32s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.561904761904762 / 16  (53.5):  50%|▌| 15/30 [00:19<00:19,  1.32s/i\u001b[A\n",
      "Average Metric: 8.561904761904762 / 16  (53.5):  53%|▌| 16/30 [00:19<00:17,  1.21s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.561904761904762 / 17  (50.4):  53%|▌| 16/30 [00:21<00:17,  1.21s/i\u001b[A\n",
      "Average Metric: 8.561904761904762 / 17  (50.4):  57%|▌| 17/30 [00:21<00:17,  1.36s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 14.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.228571428571428 / 18  (51.3):  57%|▌| 17/30 [00:22<00:17,  1.36s/i\u001b[A\n",
      "Average Metric: 9.228571428571428 / 18  (51.3):  60%|▌| 18/30 [00:22<00:15,  1.27s/i\u001b[A\n",
      "Average Metric: 9.728571428571428 / 19  (51.2):  60%|▌| 18/30 [00:22<00:15,  1.27s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.728571428571428 / 20  (53.6):  63%|▋| 19/30 [00:24<00:14,  1.27s/\u001b[A\n",
      "Average Metric: 10.728571428571428 / 20  (53.6):  67%|▋| 20/30 [00:24<00:12,  1.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.728571428571428 / 21  (51.1):  67%|▋| 20/30 [00:24<00:12,  1.23s/\u001b[A\n",
      "Average Metric: 10.728571428571428 / 21  (51.1):  70%|▋| 21/30 [00:24<00:08,  1.02it\u001b[A\n",
      "Average Metric: 11.728571428571428 / 22  (53.3):  70%|▋| 21/30 [00:25<00:08,  1.02it\u001b[A\n",
      "Average Metric: 11.728571428571428 / 22  (53.3):  73%|▋| 22/30 [00:25<00:06,  1.18it\u001b[A\n",
      "Average Metric: 11.728571428571428 / 23  (51.0):  73%|▋| 22/30 [00:26<00:06,  1.18it\u001b[A\n",
      "Average Metric: 11.728571428571428 / 23  (51.0):  77%|▊| 23/30 [00:26<00:07,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.395238095238094 / 24  (51.6):  77%|▊| 23/30 [00:27<00:07,  1.03s/\u001b[A\n",
      "Average Metric: 12.395238095238094 / 24  (51.6):  80%|▊| 24/30 [00:27<00:05,  1.19it\u001b[A\n",
      "Average Metric: 13.395238095238094 / 25  (53.6):  80%|▊| 24/30 [00:29<00:05,  1.19it\u001b[A\n",
      "Average Metric: 13.395238095238094 / 25  (53.6):  83%|▊| 25/30 [00:29<00:06,  1.29s/\u001b[A\n",
      "Average Metric: 13.856776556776556 / 26  (53.3):  83%|▊| 25/30 [00:29<00:06,  1.29s/\u001b[A\n",
      "Average Metric: 13.856776556776556 / 26  (53.3):  87%|▊| 26/30 [00:29<00:03,  1.03it\u001b[A\n",
      "Average Metric: 14.713919413919413 / 27  (54.5):  87%|▊| 26/30 [00:30<00:03,  1.03it\u001b[A\n",
      "Average Metric: 14.713919413919413 / 27  (54.5):  90%|▉| 27/30 [00:30<00:02,  1.04it\u001b[A\n",
      "Average Metric: 15.113919413919414 / 28  (54.0):  90%|▉| 27/30 [00:35<00:02,  1.04it\u001b[A\n",
      "Average Metric: 15.113919413919414 / 28  (54.0):  93%|▉| 28/30 [00:35<00:04,  2.01s/\u001b[A\n",
      "Average Metric: 15.113919413919414 / 29  (52.1):  93%|▉| 28/30 [00:37<00:04,  2.01s/\u001b[A\n",
      "Average Metric: 15.113919413919414 / 29  (52.1):  97%|▉| 29/30 [00:37<00:02,  2.22s/\u001b[A\n",
      "Average Metric: 15.558363858363858 / 30  (51.9): 100%|█| 30/30 [00:37<00:00,  1.26s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:38:22,032] Trial 12 finished with value: 51.86 and parameters: {'14766014224_predictor_instruction': 1, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 0, '14707649168_predictor_demos': 2, '14753105040_predictor_instruction': 5, '14753105040_predictor_demos': 9}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.558363858363858 / 30  (51.9%)\n",
      "Starting trial #13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:11,  2.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:03<01:11,  2.47s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:03<00:40,  1.45s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:04<00:40,  1.45s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:04<00:35,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.6666666666666665 / 4  (41.7):  10%| | 3/30 [00:05<00:35,  1.32s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 4  (41.7):  13%|▏| 4/30 [00:05<00:32,  1.24s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 5  (33.3):  13%|▏| 4/30 [00:06<00:32,  1.24s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 5  (33.3):  17%|▏| 5/30 [00:06<00:25,  1.02s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.6666666666666665 / 6  (44.4):  17%|▏| 5/30 [00:07<00:25,  1.02s/it\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 6  (44.4):  20%|▏| 6/30 [00:07<00:25,  1.05s/it\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 7  (52.4):  20%|▏| 6/30 [00:07<00:25,  1.05s/it\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 7  (52.4):  23%|▏| 7/30 [00:07<00:18,  1.27it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.6666666666666665 / 8  (45.8):  23%|▏| 7/30 [00:08<00:18,  1.27it/s\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 8  (45.8):  27%|▎| 8/30 [00:08<00:17,  1.23it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.6666666666666665 / 9  (40.7):  27%|▎| 8/30 [00:10<00:17,  1.23it/s\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 9  (40.7):  30%|▎| 9/30 [00:10<00:24,  1.16s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.666666666666666 / 10  (46.7):  30%|▎| 9/30 [00:11<00:24,  1.16s/it\u001b[A\n",
      "Average Metric: 4.666666666666666 / 10  (46.7):  33%|▎| 10/30 [00:11<00:21,  1.07s/i\u001b[A\n",
      "Average Metric: 5.066666666666666 / 11  (46.1):  33%|▎| 10/30 [00:11<00:21,  1.07s/i\u001b[A\n",
      "Average Metric: 5.066666666666666 / 11  (46.1):  37%|▎| 11/30 [00:11<00:16,  1.12it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.733333333333333 / 12  (47.8):  37%|▎| 11/30 [00:12<00:16,  1.12it/\u001b[A\n",
      "Average Metric: 5.733333333333333 / 12  (47.8):  40%|▍| 12/30 [00:12<00:15,  1.15it/\u001b[A\n",
      "Average Metric: 6.194871794871795 / 13  (47.7):  40%|▍| 12/30 [00:13<00:15,  1.15it/\u001b[A\n",
      "Average Metric: 6.194871794871795 / 13  (47.7):  43%|▍| 13/30 [00:13<00:13,  1.26it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.194871794871795 / 14  (44.2):  43%|▍| 13/30 [00:15<00:13,  1.26it/\u001b[A\n",
      "Average Metric: 6.194871794871795 / 14  (44.2):  47%|▍| 14/30 [00:15<00:20,  1.28s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.194871794871795 / 15  (41.3):  47%|▍| 14/30 [00:16<00:20,  1.28s/i\u001b[A\n",
      "Average Metric: 6.194871794871795 / 15  (41.3):  50%|▌| 15/30 [00:16<00:18,  1.22s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.861538461538462 / 16  (42.9):  50%|▌| 15/30 [00:17<00:18,  1.22s/i\u001b[A\n",
      "Average Metric: 6.861538461538462 / 16  (42.9):  53%|▌| 16/30 [00:17<00:15,  1.14s/i\u001b[A\n",
      "Average Metric: 7.261538461538462 / 17  (42.7):  53%|▌| 16/30 [00:17<00:15,  1.14s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 17.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.928205128205129 / 18  (44.0):  57%|▌| 17/30 [00:20<00:14,  1.14s/i\u001b[A\n",
      "Average Metric: 7.928205128205129 / 18  (44.0):  60%|▌| 18/30 [00:20<00:14,  1.24s/i\u001b[A\n",
      "Average Metric: 8.928205128205128 / 19  (47.0):  60%|▌| 18/30 [00:21<00:14,  1.24s/i\u001b[A\n",
      "Average Metric: 8.928205128205128 / 19  (47.0):  63%|▋| 19/30 [00:21<00:14,  1.30s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.928205128205128 / 20  (44.6):  63%|▋| 19/30 [00:23<00:14,  1.30s/i\u001b[A\n",
      "Average Metric: 8.928205128205128 / 20  (44.6):  67%|▋| 20/30 [00:23<00:15,  1.53s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.928205128205128 / 21  (42.5):  67%|▋| 20/30 [00:25<00:15,  1.53s/i\u001b[A\n",
      "Average Metric: 8.928205128205128 / 21  (42.5):  70%|▋| 21/30 [00:25<00:14,  1.56s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.928205128205128 / 22  (45.1):  70%|▋| 21/30 [00:27<00:14,  1.56s/i\u001b[A\n",
      "Average Metric: 9.928205128205128 / 22  (45.1):  73%|▋| 22/30 [00:27<00:12,  1.61s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.817094017094018 / 23  (47.0):  73%|▋| 22/30 [00:27<00:12,  1.61s/\u001b[A\n",
      "Average Metric: 10.817094017094018 / 23  (47.0):  77%|▊| 23/30 [00:27<00:09,  1.29s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.674236874236875 / 24  (48.6):  77%|▊| 23/30 [00:28<00:09,  1.29s/\u001b[A\n",
      "Average Metric: 11.674236874236875 / 24  (48.6):  80%|▊| 24/30 [00:28<00:07,  1.19s/\u001b[A\n",
      "Average Metric: 12.531379731379733 / 25  (50.1):  80%|▊| 24/30 [00:30<00:07,  1.19s/\u001b[A\n",
      "Average Metric: 12.531379731379733 / 25  (50.1):  83%|▊| 25/30 [00:30<00:06,  1.36s/\u001b[A\n",
      "Average Metric: 13.531379731379733 / 26  (52.0):  83%|▊| 25/30 [00:32<00:06,  1.36s/\u001b[A\n",
      "Average Metric: 13.531379731379733 / 26  (52.0):  87%|▊| 26/30 [00:32<00:06,  1.68s/\u001b[A\n",
      "Average Metric: 13.531379731379733 / 27  (50.1):  87%|▊| 26/30 [00:34<00:06,  1.68s/\u001b[A\n",
      "Average Metric: 13.531379731379733 / 27  (50.1):  90%|▉| 27/30 [00:34<00:04,  1.52s/\u001b[A\n",
      "Average Metric: 13.992918192918195 / 28  (50.0):  90%|▉| 27/30 [00:35<00:04,  1.52s/\u001b[A\n",
      "Average Metric: 13.992918192918195 / 28  (50.0):  93%|▉| 28/30 [00:35<00:03,  1.64s/\u001b[A\n",
      "Average Metric: 14.992918192918195 / 29  (51.7):  93%|▉| 28/30 [00:37<00:03,  1.64s/\u001b[A\n",
      "Average Metric: 14.992918192918195 / 29  (51.7):  97%|▉| 29/30 [00:37<00:01,  1.58s/\u001b[A\n",
      "Average Metric: 15.43736263736264 / 30  (51.5):  97%|▉| 29/30 [00:42<00:01,  1.58s/i\u001b[A\n",
      "Average Metric: 15.43736263736264 / 30  (51.5): 100%|█| 30/30 [00:42<00:00,  1.42s/i\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:39:04,634] Trial 13 finished with value: 51.46 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 2, '14753105040_predictor_instruction': 2, '14753105040_predictor_demos': 9}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.43736263736264 / 30  (51.5%)\n",
      "Starting trial #14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:04<01:58,  4.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.4444444444444444 / 2  (22.2):   3%| | 1/30 [00:07<01:58,  4.09s/it\u001b[A\n",
      "Average Metric: 0.4444444444444444 / 2  (22.2):   7%| | 2/30 [00:07<01:41,  3.64s/it\u001b[A\n",
      "Average Metric: 1.1111111111111112 / 3  (37.0):   7%| | 2/30 [00:07<01:41,  3.64s/it\u001b[A\n",
      "Average Metric: 1.1111111111111112 / 3  (37.0):  10%| | 3/30 [00:07<00:56,  2.08s/it\u001b[A\n",
      "Average Metric: 1.1111111111111112 / 4  (27.8):  10%| | 3/30 [00:08<00:56,  2.08s/it\u001b[A\n",
      "Average Metric: 1.1111111111111112 / 4  (27.8):  13%|▏| 4/30 [00:08<00:36,  1.42s/it\u001b[A\n",
      "Average Metric: 1.1111111111111112 / 5  (22.2):  13%|▏| 4/30 [00:08<00:36,  1.42s/it\u001b[A\n",
      "Average Metric: 1.1111111111111112 / 5  (22.2):  17%|▏| 5/30 [00:08<00:24,  1.04it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.111111111111111 / 6  (35.2):  17%|▏| 5/30 [00:09<00:24,  1.04it/s]\u001b[A\n",
      "Average Metric: 2.111111111111111 / 6  (35.2):  20%|▏| 6/30 [00:09<00:22,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.9111111111111114 / 7  (41.6):  20%|▏| 6/30 [00:11<00:22,  1.05it/s\u001b[A\n",
      "Average Metric: 2.9111111111111114 / 7  (41.6):  23%|▏| 7/30 [00:11<00:30,  1.34s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.3111111111111113 / 8  (41.4):  23%|▏| 7/30 [00:13<00:30,  1.34s/it\u001b[A\n",
      "Average Metric: 3.3111111111111113 / 8  (41.4):  27%|▎| 8/30 [00:13<00:32,  1.49s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.3111111111111113 / 9  (36.8):  27%|▎| 8/30 [00:15<00:32,  1.49s/it\u001b[A\n",
      "Average Metric: 3.3111111111111113 / 9  (36.8):  30%|▎| 9/30 [00:15<00:34,  1.65s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 31.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.977777777777778 / 10  (39.8):  30%|▎| 9/30 [00:17<00:34,  1.65s/it\u001b[A\n",
      "Average Metric: 3.977777777777778 / 10  (39.8):  33%|▎| 10/30 [00:17<00:35,  1.77s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.977777777777778 / 11  (45.3):  33%|▎| 10/30 [00:18<00:35,  1.77s/i\u001b[A\n",
      "Average Metric: 4.977777777777778 / 11  (45.3):  37%|▎| 11/30 [00:18<00:31,  1.65s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.977777777777778 / 12  (41.5):  37%|▎| 11/30 [00:19<00:31,  1.65s/i\u001b[A\n",
      "Average Metric: 4.977777777777778 / 12  (41.5):  40%|▍| 12/30 [00:19<00:28,  1.58s/i\u001b[A\n",
      "Average Metric: 5.4393162393162395 / 13  (41.8):  40%|▍| 12/30 [00:21<00:28,  1.58s/\u001b[A\n",
      "Average Metric: 5.4393162393162395 / 13  (41.8):  43%|▍| 13/30 [00:21<00:28,  1.70s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.4393162393162395 / 14  (38.9):  43%|▍| 13/30 [00:24<00:28,  1.70s/\u001b[A\n",
      "Average Metric: 5.4393162393162395 / 14  (38.9):  47%|▍| 14/30 [00:24<00:29,  1.83s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.4393162393162395 / 15  (42.9):  47%|▍| 14/30 [00:26<00:29,  1.83s/\u001b[A\n",
      "Average Metric: 6.4393162393162395 / 15  (42.9):  50%|▌| 15/30 [00:26<00:31,  2.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.9393162393162395 / 16  (43.4):  50%|▌| 15/30 [00:28<00:31,  2.12s/\u001b[A\n",
      "Average Metric: 6.9393162393162395 / 16  (43.4):  53%|▌| 16/30 [00:28<00:28,  2.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.272649572649573 / 17  (42.8):  53%|▌| 16/30 [00:30<00:28,  2.02s/i\u001b[A\n",
      "Average Metric: 7.272649572649573 / 17  (42.8):  57%|▌| 17/30 [00:30<00:24,  1.87s/i\u001b[A\n",
      "Average Metric: 8.12979242979243 / 18  (45.2):  57%|▌| 17/30 [00:31<00:24,  1.87s/it\u001b[A\n",
      "Average Metric: 8.12979242979243 / 18  (45.2):  60%|▌| 18/30 [00:31<00:22,  1.86s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 20.8 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.796459096459095 / 19  (46.3):  60%|▌| 18/30 [00:33<00:22,  1.86s/i\u001b[A\n",
      "Average Metric: 8.796459096459095 / 19  (46.3):  63%|▋| 19/30 [00:33<00:17,  1.63s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 16.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.796459096459095 / 20  (49.0):  63%|▋| 19/30 [00:35<00:17,  1.63s/i\u001b[A\n",
      "Average Metric: 9.796459096459095 / 20  (49.0):  67%|▋| 20/30 [00:35<00:17,  1.74s/i\u001b[A\n",
      "Average Metric: 9.796459096459095 / 21  (46.6):  67%|▋| 20/30 [00:36<00:17,  1.74s/i\u001b[A\n",
      "Average Metric: 9.796459096459095 / 21  (46.6):  70%|▋| 21/30 [00:36<00:13,  1.53s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.796459096459095 / 22  (44.5):  70%|▋| 21/30 [00:37<00:13,  1.53s/i\u001b[A\n",
      "Average Metric: 9.796459096459095 / 22  (44.5):  73%|▋| 22/30 [00:37<00:11,  1.42s/i\u001b[A\n",
      "Average Metric: 10.796459096459095 / 23  (46.9):  73%|▋| 22/30 [00:39<00:11,  1.42s/\u001b[A\n",
      "Average Metric: 10.796459096459095 / 23  (46.9):  77%|▊| 23/30 [00:39<00:11,  1.71s/\u001b[A\n",
      "Average Metric: 11.653601953601953 / 24  (48.6):  77%|▊| 23/30 [00:39<00:11,  1.71s/\u001b[A\n",
      "Average Metric: 11.653601953601953 / 24  (48.6):  80%|▊| 24/30 [00:39<00:07,  1.23s/\u001b[A\n",
      "Average Metric: 12.653601953601953 / 25  (50.6):  80%|▊| 24/30 [00:41<00:07,  1.23s/\u001b[A\n",
      "Average Metric: 12.653601953601953 / 25  (50.6):  83%|▊| 25/30 [00:41<00:06,  1.35s/\u001b[A\n",
      "Average Metric: 13.51074481074481 / 26  (52.0):  83%|▊| 25/30 [00:48<00:06,  1.35s/i\u001b[A\n",
      "Average Metric: 13.51074481074481 / 26  (52.0):  87%|▊| 26/30 [00:48<00:12,  3.15s/i\u001b[A\n",
      "Average Metric: 14.01074481074481 / 27  (51.9):  87%|▊| 26/30 [00:49<00:12,  3.15s/i\u001b[A\n",
      "Average Metric: 14.01074481074481 / 27  (51.9):  90%|▉| 27/30 [00:49<00:07,  2.56s/i\u001b[A\n",
      "Average Metric: 14.51074481074481 / 28  (51.8):  90%|▉| 27/30 [00:50<00:07,  2.56s/i\u001b[A\n",
      "Average Metric: 14.51074481074481 / 28  (51.8):  93%|▉| 28/30 [00:50<00:03,  1.85s/i\u001b[A\n",
      "Average Metric: 14.51074481074481 / 29  (50.0):  93%|▉| 28/30 [00:51<00:03,  1.85s/i\u001b[A\n",
      "Average Metric: 14.51074481074481 / 29  (50.0):  97%|▉| 29/30 [00:51<00:01,  1.66s/i\u001b[A\n",
      "Average Metric: 14.818437118437119 / 30  (49.4):  97%|▉| 29/30 [00:59<00:01,  1.66s/\u001b[A\n",
      "Average Metric: 14.818437118437119 / 30  (49.4): 100%|█| 30/30 [00:59<00:00,  1.99s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:40:04,267] Trial 14 finished with value: 49.39 and parameters: {'14766014224_predictor_instruction': 3, '14766014224_predictor_demos': 8, '14707649168_predictor_instruction': 9, '14707649168_predictor_demos': 2, '14753105040_predictor_instruction': 7, '14753105040_predictor_demos': 1}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.818437118437119 / 30  (49.4%)\n",
      "Starting trial #15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:14,  2.55s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:02<01:14,  2.55s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:02<00:32,  1.16s/it]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:02<00:32,  1.16s/it]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  10%|█▌             | 3/30 [00:03<00:31,  1.16s/it]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  13%|██             | 4/30 [00:03<00:19,  1.33it/s]\u001b[A\n",
      "Average Metric: 3.0 / 5  (60.0):  13%|██             | 4/30 [00:03<00:19,  1.33it/s]\u001b[A\n",
      "Average Metric: 3.5 / 6  (58.3):  17%|██▌            | 5/30 [00:04<00:18,  1.33it/s]\u001b[A\n",
      "Average Metric: 3.5 / 6  (58.3):  20%|███            | 6/30 [00:04<00:12,  1.86it/s]\u001b[A\n",
      "Average Metric: 4.166666666666667 / 7  (59.5):  20%|▏| 6/30 [00:06<00:12,  1.86it/s]\u001b[A\n",
      "Average Metric: 4.166666666666667 / 7  (59.5):  23%|▏| 7/30 [00:06<00:22,  1.04it/s]\u001b[A\n",
      "Average Metric: 5.166666666666667 / 8  (64.6):  23%|▏| 7/30 [00:06<00:22,  1.04it/s]\u001b[A\n",
      "Average Metric: 5.166666666666667 / 9  (57.4):  27%|▎| 8/30 [00:06<00:21,  1.04it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.566666666666667 / 10  (55.7):  30%|▎| 9/30 [00:07<00:20,  1.04it/s\u001b[A\n",
      "Average Metric: 5.566666666666667 / 10  (55.7):  33%|▎| 10/30 [00:07<00:12,  1.66it/\u001b[A\n",
      "Average Metric: 6.011111111111112 / 11  (54.6):  33%|▎| 10/30 [00:07<00:12,  1.66it/\u001b[A\n",
      "Average Metric: 6.011111111111112 / 11  (54.6):  37%|▎| 11/30 [00:07<00:11,  1.71it/\u001b[A\n",
      "Average Metric: 6.868253968253969 / 12  (57.2):  37%|▎| 11/30 [00:07<00:11,  1.71it/\u001b[A\n",
      "Average Metric: 7.868253968253969 / 13  (60.5):  40%|▍| 12/30 [00:07<00:10,  1.71it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.868253968253969 / 14  (56.2):  43%|▍| 13/30 [00:10<00:09,  1.71it/\u001b[A\n",
      "Average Metric: 7.868253968253969 / 14  (56.2):  47%|▍| 14/30 [00:10<00:11,  1.45it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.268253968253969 / 15  (55.1):  47%|▍| 14/30 [00:11<00:11,  1.45it/\u001b[A\n",
      "Average Metric: 8.268253968253969 / 15  (55.1):  50%|▌| 15/30 [00:11<00:10,  1.37it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.768253968253969 / 16  (54.8):  50%|▌| 15/30 [00:11<00:10,  1.37it/\u001b[A\n",
      "Average Metric: 8.768253968253969 / 16  (54.8):  53%|▌| 16/30 [00:11<00:09,  1.54it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.22979242979243 / 17  (54.3):  53%|▌| 16/30 [00:12<00:09,  1.54it/s\u001b[A\n",
      "Average Metric: 9.22979242979243 / 17  (54.3):  57%|▌| 17/30 [00:12<00:09,  1.32it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.086935286935288 / 18  (56.0):  57%|▌| 17/30 [00:13<00:09,  1.32it\u001b[A\n",
      "Average Metric: 10.086935286935288 / 18  (56.0):  60%|▌| 18/30 [00:13<00:09,  1.23it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.086935286935288 / 19  (53.1):  60%|▌| 18/30 [00:17<00:09,  1.23it\u001b[A\n",
      "Average Metric: 10.086935286935288 / 19  (53.1):  63%|▋| 19/30 [00:17<00:17,  1.55s/\u001b[A\n",
      "Average Metric: 10.54847374847375 / 20  (52.7):  63%|▋| 19/30 [00:17<00:17,  1.55s/i\u001b[A\n",
      "Average Metric: 11.54847374847375 / 21  (55.0):  67%|▋| 20/30 [00:17<00:15,  1.55s/i\u001b[A\n",
      "Average Metric: 11.54847374847375 / 21  (55.0):  70%|▋| 21/30 [00:17<00:08,  1.05it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.54847374847375 / 22  (57.0):  70%|▋| 21/30 [00:18<00:08,  1.05it/\u001b[A\n",
      "Average Metric: 12.54847374847375 / 22  (57.0):  73%|▋| 22/30 [00:18<00:07,  1.05it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.54847374847375 / 23  (58.9):  73%|▋| 22/30 [00:18<00:07,  1.05it/\u001b[A\n",
      "Average Metric: 13.54847374847375 / 23  (58.9):  77%|▊| 23/30 [00:18<00:05,  1.27it/\u001b[A\n",
      "Average Metric: 14.215140415140416 / 24  (59.2):  77%|▊| 23/30 [00:19<00:05,  1.27it\u001b[A\n",
      "Average Metric: 14.215140415140416 / 24  (59.2):  80%|▊| 24/30 [00:19<00:04,  1.24it\u001b[A\n",
      "Average Metric: 14.965140415140416 / 25  (59.9):  80%|▊| 24/30 [00:19<00:04,  1.24it\u001b[A\n",
      "Average Metric: 14.965140415140416 / 25  (59.9):  83%|▊| 25/30 [00:19<00:03,  1.59it\u001b[A\n",
      "Average Metric: 15.631807081807082 / 26  (60.1):  83%|▊| 25/30 [00:20<00:03,  1.59it\u001b[A\n",
      "Average Metric: 15.631807081807082 / 26  (60.1):  87%|▊| 26/30 [00:20<00:03,  1.31it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.631807081807082 / 27  (57.9):  87%|▊| 26/30 [00:22<00:03,  1.31it\u001b[A\n",
      "Average Metric: 15.631807081807082 / 27  (57.9):  90%|▉| 27/30 [00:22<00:02,  1.10it\u001b[A\n",
      "Average Metric: 16.48894993894994 / 28  (58.9):  90%|▉| 27/30 [00:24<00:02,  1.10it/\u001b[A\n",
      "Average Metric: 16.48894993894994 / 28  (58.9):  93%|▉| 28/30 [00:24<00:02,  1.42s/i\u001b[A\n",
      "Average Metric: 16.98894993894994 / 29  (58.6):  93%|▉| 28/30 [00:26<00:02,  1.42s/i\u001b[A\n",
      "Average Metric: 16.98894993894994 / 29  (58.6):  97%|▉| 29/30 [00:26<00:01,  1.51s/i\u001b[A\n",
      "Average Metric: 16.98894993894994 / 30  (56.6):  97%|▉| 29/30 [00:26<00:01,  1.51s/i\u001b[A\n",
      "Average Metric: 16.98894993894994 / 30  (56.6): 100%|█| 30/30 [00:26<00:00,  1.12it/\u001b[A\n",
      "[I 2024-04-28 22:40:31,184] Trial 15 finished with value: 56.63 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 6, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 5, '14753105040_predictor_demos': 9}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.98894993894994 / 30  (56.6%)\n",
      "Starting trial #16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:26,  1.11it/s]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:00<00:26,  1.11it/s]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:01<00:25,  1.11it/s]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):  10%|█▌             | 3/30 [00:01<00:08,  3.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0 / 4  (50.0):  10%|█▌             | 3/30 [00:01<00:08,  3.19it/s]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  13%|██             | 4/30 [00:01<00:12,  2.09it/s]\u001b[A\n",
      "Average Metric: 2.4 / 5  (48.0):  13%|██             | 4/30 [00:02<00:12,  2.09it/s]\u001b[A\n",
      "Average Metric: 2.4 / 5  (48.0):  17%|██▌            | 5/30 [00:02<00:10,  2.37it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.4 / 6  (40.0):  17%|██▌            | 5/30 [00:03<00:10,  2.37it/s]\u001b[A\n",
      "Average Metric: 2.4 / 6  (40.0):  20%|███            | 6/30 [00:03<00:13,  1.84it/s]\u001b[A\n",
      "Average Metric: 3.4 / 7  (48.6):  20%|███            | 6/30 [00:03<00:13,  1.84it/s]\u001b[A\n",
      "Average Metric: 3.4 / 8  (42.5):  23%|███▌           | 7/30 [00:04<00:12,  1.84it/s]\u001b[A\n",
      "Average Metric: 3.4 / 8  (42.5):  27%|████           | 8/30 [00:04<00:12,  1.83it/s]\u001b[A\n",
      "Average Metric: 3.844444444444444 / 9  (42.7):  27%|▎| 8/30 [00:04<00:12,  1.83it/s]\u001b[A\n",
      "Average Metric: 3.844444444444444 / 9  (42.7):  30%|▎| 9/30 [00:04<00:09,  2.16it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.344444444444444 / 10  (43.4):  30%|▎| 9/30 [00:05<00:09,  2.16it/s\u001b[A\n",
      "Average Metric: 4.344444444444444 / 10  (43.4):  33%|▎| 10/30 [00:05<00:11,  1.70it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.344444444444444 / 11  (39.5):  33%|▎| 10/30 [00:05<00:11,  1.70it/\u001b[A\n",
      "Average Metric: 4.344444444444444 / 11  (39.5):  37%|▎| 11/30 [00:05<00:10,  1.84it/\u001b[A\n",
      "Average Metric: 5.344444444444444 / 12  (44.5):  37%|▎| 11/30 [00:06<00:10,  1.84it/\u001b[A\n",
      "Average Metric: 5.344444444444444 / 12  (44.5):  40%|▍| 12/30 [00:06<00:12,  1.45it/\u001b[A\n",
      "Average Metric: 6.011111111111111 / 13  (46.2):  40%|▍| 12/30 [00:06<00:12,  1.45it/\u001b[A\n",
      "Average Metric: 6.011111111111111 / 13  (46.2):  43%|▍| 13/30 [00:06<00:09,  1.81it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.011111111111111 / 14  (42.9):  43%|▍| 13/30 [00:08<00:09,  1.81it/\u001b[A\n",
      "Average Metric: 6.011111111111111 / 14  (42.9):  47%|▍| 14/30 [00:08<00:12,  1.31it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.472649572649573 / 15  (43.2):  47%|▍| 14/30 [00:09<00:12,  1.31it/\u001b[A\n",
      "Average Metric: 6.472649572649573 / 15  (43.2):  50%|▌| 15/30 [00:09<00:11,  1.26it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.872649572649573 / 16  (43.0):  50%|▌| 15/30 [00:10<00:11,  1.26it/\u001b[A\n",
      "Average Metric: 6.872649572649573 / 16  (43.0):  53%|▌| 16/30 [00:10<00:11,  1.20it/\u001b[A\n",
      "Average Metric: 7.872649572649573 / 17  (46.3):  53%|▌| 16/30 [00:10<00:11,  1.20it/\u001b[A\n",
      "Average Metric: 7.872649572649573 / 17  (46.3):  57%|▌| 17/30 [00:10<00:09,  1.37it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.53931623931624 / 18  (47.4):  57%|▌| 17/30 [00:11<00:09,  1.37it/s\u001b[A\n",
      "Average Metric: 8.53931623931624 / 18  (47.4):  60%|▌| 18/30 [00:11<00:07,  1.50it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.53931623931624 / 19  (50.2):  60%|▌| 18/30 [00:11<00:07,  1.50it/s\u001b[A\n",
      "Average Metric: 9.53931623931624 / 19  (50.2):  63%|▋| 19/30 [00:11<00:06,  1.71it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.53931623931624 / 20  (47.7):  63%|▋| 19/30 [00:12<00:06,  1.71it/s\u001b[A\n",
      "Average Metric: 9.53931623931624 / 20  (47.7):  67%|▋| 20/30 [00:12<00:06,  1.52it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.53931623931624 / 21  (50.2):  67%|▋| 20/30 [00:12<00:06,  1.52it/\u001b[A\n",
      "Average Metric: 10.53931623931624 / 21  (50.2):  70%|▋| 21/30 [00:12<00:05,  1.62it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.396459096459097 / 22  (51.8):  70%|▋| 21/30 [00:13<00:05,  1.62it\u001b[A\n",
      "Average Metric: 11.396459096459097 / 22  (51.8):  73%|▋| 22/30 [00:13<00:06,  1.30it\u001b[A\n",
      "Average Metric: 12.396459096459097 / 23  (53.9):  73%|▋| 22/30 [00:14<00:06,  1.30it\u001b[A\n",
      "Average Metric: 12.396459096459097 / 23  (53.9):  77%|▊| 23/30 [00:14<00:04,  1.45it\u001b[A\n",
      "Average Metric: 13.253601953601954 / 24  (55.2):  77%|▊| 23/30 [00:15<00:04,  1.45it\u001b[A\n",
      "Average Metric: 13.253601953601954 / 24  (55.2):  80%|▊| 24/30 [00:15<00:04,  1.38it\u001b[A\n",
      "Average Metric: 13.253601953601954 / 25  (53.0):  80%|▊| 24/30 [00:15<00:04,  1.38it\u001b[A\n",
      "Average Metric: 13.253601953601954 / 25  (53.0):  83%|▊| 25/30 [00:15<00:03,  1.44it\u001b[A\n",
      "Average Metric: 14.003601953601954 / 26  (53.9):  83%|▊| 25/30 [00:17<00:03,  1.44it\u001b[A\n",
      "Average Metric: 14.003601953601954 / 26  (53.9):  87%|▊| 26/30 [00:17<00:04,  1.01s/\u001b[A\n",
      "Average Metric: 15.003601953601954 / 27  (55.6):  87%|▊| 26/30 [00:17<00:04,  1.01s/\u001b[A\n",
      "Average Metric: 15.860744810744812 / 28  (56.6):  90%|▉| 27/30 [00:19<00:03,  1.01s/\u001b[A\n",
      "Average Metric: 15.860744810744812 / 28  (56.6):  93%|▉| 28/30 [00:19<00:01,  1.13it\u001b[A\n",
      "Average Metric: 16.322283272283272 / 29  (56.3):  93%|▉| 28/30 [00:20<00:01,  1.13it\u001b[A\n",
      "Average Metric: 16.322283272283272 / 29  (56.3):  97%|▉| 29/30 [00:20<00:00,  1.10it\u001b[A\n",
      "Average Metric: 16.98894993894994 / 30  (56.6):  97%|▉| 29/30 [00:20<00:00,  1.10it/\u001b[A\n",
      "Average Metric: 16.98894993894994 / 30  (56.6): 100%|█| 30/30 [00:20<00:00,  1.48it/\u001b[A\n",
      "[I 2024-04-28 22:40:51,494] Trial 16 finished with value: 56.63 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 6, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 2, '14753105040_predictor_demos': 6}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.98894993894994 / 30  (56.6%)\n",
      "Starting trial #17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:06<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:06<03:17,  6.81s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:07<03:17,  6.81s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:07<01:22,  2.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.9615384615384616 / 3  (32.1):   7%| | 2/30 [00:11<01:22,  2.93s/it\u001b[A\n",
      "Average Metric: 0.9615384615384616 / 3  (32.1):  10%| | 3/30 [00:11<01:37,  3.60s/it\u001b[A\n",
      "Average Metric: 1.3615384615384616 / 4  (34.0):  10%| | 3/30 [00:11<01:37,  3.60s/it\u001b[A\n",
      "Average Metric: 1.3615384615384616 / 4  (34.0):  13%|▏| 4/30 [00:11<01:02,  2.41s/it\u001b[A\n",
      "Average Metric: 2.161538461538462 / 5  (43.2):  13%|▏| 4/30 [00:12<01:02,  2.41s/it]\u001b[A\n",
      "Average Metric: 2.161538461538462 / 5  (43.2):  17%|▏| 5/30 [00:12<00:46,  1.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.661538461538462 / 6  (44.4):  17%|▏| 5/30 [00:16<00:46,  1.87s/it]\u001b[A\n",
      "Average Metric: 2.661538461538462 / 6  (44.4):  20%|▏| 6/30 [00:16<00:58,  2.46s/it]\u001b[A\n",
      "Average Metric: 3.518681318681319 / 7  (50.3):  20%|▏| 6/30 [00:17<00:58,  2.46s/it]\u001b[A\n",
      "Average Metric: 3.518681318681319 / 7  (50.3):  23%|▏| 7/30 [00:17<00:44,  1.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.518681318681319 / 8  (56.5):  23%|▏| 7/30 [00:17<00:44,  1.94s/it]\u001b[A\n",
      "Average Metric: 4.518681318681319 / 8  (56.5):  27%|▎| 8/30 [00:17<00:32,  1.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.826373626373626 / 9  (53.6):  27%|▎| 8/30 [00:19<00:32,  1.49s/it]\u001b[A\n",
      "Average Metric: 4.826373626373626 / 9  (53.6):  30%|▎| 9/30 [00:19<00:28,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 13.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 31.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.826373626373626 / 10  (58.3):  30%|▎| 9/30 [00:22<00:28,  1.37s/it\u001b[A\n",
      "Average Metric: 5.826373626373626 / 10  (58.3):  33%|▎| 10/30 [00:22<00:42,  2.12s/i\u001b[A\n",
      "Average Metric: 5.826373626373626 / 11  (53.0):  33%|▎| 10/30 [00:23<00:42,  2.12s/i\u001b[A\n",
      "Average Metric: 5.826373626373626 / 11  (53.0):  37%|▎| 11/30 [00:23<00:33,  1.77s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 15.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.826373626373626 / 12  (48.6):  37%|▎| 11/30 [00:25<00:33,  1.77s/i\u001b[A\n",
      "Average Metric: 5.826373626373626 / 12  (48.6):  40%|▍| 12/30 [00:25<00:30,  1.72s/i\u001b[A\n",
      "Average Metric: 5.826373626373626 / 13  (44.8):  40%|▍| 12/30 [00:25<00:30,  1.72s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.159706959706959 / 14  (44.0):  43%|▍| 13/30 [00:26<00:29,  1.72s/i\u001b[A\n",
      "Average Metric: 6.159706959706959 / 14  (44.0):  47%|▍| 14/30 [00:26<00:20,  1.29s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.159706959706959 / 15  (41.1):  47%|▍| 14/30 [00:28<00:20,  1.29s/i\u001b[A\n",
      "Average Metric: 6.159706959706959 / 15  (41.1):  50%|▌| 15/30 [00:28<00:18,  1.26s/i\u001b[A\n",
      "Average Metric: 7.016849816849816 / 16  (43.9):  50%|▌| 15/30 [00:29<00:18,  1.26s/i\u001b[A\n",
      "Average Metric: 7.016849816849816 / 16  (43.9):  53%|▌| 16/30 [00:29<00:16,  1.16s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.016849816849816 / 17  (41.3):  53%|▌| 16/30 [00:32<00:16,  1.16s/i\u001b[A\n",
      "Average Metric: 7.016849816849816 / 17  (41.3):  57%|▌| 17/30 [00:32<00:21,  1.68s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.683516483516483 / 18  (42.7):  57%|▌| 17/30 [00:33<00:21,  1.68s/i\u001b[A\n",
      "Average Metric: 7.683516483516483 / 18  (42.7):  60%|▌| 18/30 [00:33<00:18,  1.53s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 19.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.54065934065934 / 19  (45.0):  60%|▌| 18/30 [00:34<00:18,  1.53s/it\u001b[A\n",
      "Average Metric: 8.54065934065934 / 19  (45.0):  63%|▋| 19/30 [00:34<00:15,  1.38s/it\u001b[A\n",
      "Average Metric: 9.54065934065934 / 20  (47.7):  63%|▋| 19/30 [00:34<00:15,  1.38s/it\u001b[A\n",
      "Average Metric: 9.54065934065934 / 20  (47.7):  67%|▋| 20/30 [00:34<00:11,  1.18s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.54065934065934 / 21  (50.2):  67%|▋| 20/30 [00:36<00:11,  1.18s/i\u001b[A\n",
      "Average Metric: 10.54065934065934 / 21  (50.2):  70%|▋| 21/30 [00:36<00:11,  1.33s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.397802197802198 / 22  (51.8):  70%|▋| 21/30 [00:38<00:11,  1.33s/\u001b[A\n",
      "Average Metric: 11.397802197802198 / 22  (51.8):  73%|▋| 22/30 [00:38<00:11,  1.48s/\u001b[A\n",
      "Average Metric: 12.064468864468864 / 23  (52.5):  73%|▋| 22/30 [00:39<00:11,  1.48s/\u001b[A\n",
      "Average Metric: 12.064468864468864 / 23  (52.5):  77%|▊| 23/30 [00:39<00:08,  1.21s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.064468864468864 / 24  (54.4):  77%|▊| 23/30 [00:39<00:08,  1.21s/\u001b[A\n",
      "Average Metric: 13.064468864468864 / 24  (54.4):  80%|▊| 24/30 [00:39<00:06,  1.07s/\u001b[A\n",
      "Average Metric: 13.064468864468864 / 25  (52.3):  80%|▊| 24/30 [00:40<00:06,  1.07s/\u001b[A\n",
      "Average Metric: 13.064468864468864 / 25  (52.3):  83%|▊| 25/30 [00:40<00:05,  1.02s/\u001b[A\n",
      "Average Metric: 13.064468864468864 / 26  (50.2):  83%|▊| 25/30 [00:41<00:05,  1.02s/\u001b[A\n",
      "Average Metric: 13.064468864468864 / 26  (50.2):  87%|▊| 26/30 [00:41<00:03,  1.12it\u001b[A\n",
      "Average Metric: 13.564468864468864 / 27  (50.2):  87%|▊| 26/30 [00:42<00:03,  1.12it\u001b[A\n",
      "Average Metric: 13.564468864468864 / 27  (50.2):  90%|▉| 27/30 [00:42<00:03,  1.07s/\u001b[A\n",
      "Average Metric: 14.564468864468864 / 28  (52.0):  90%|▉| 27/30 [00:50<00:03,  1.07s/\u001b[A\n",
      "Average Metric: 14.564468864468864 / 28  (52.0):  93%|▉| 28/30 [00:50<00:06,  3.07s/\u001b[A\n",
      "Average Metric: 15.23113553113553 / 29  (52.5):  93%|▉| 28/30 [00:54<00:06,  3.07s/i\u001b[A\n",
      "Average Metric: 15.23113553113553 / 29  (52.5):  97%|▉| 29/30 [00:54<00:03,  3.46s/i\u001b[A\n",
      "Average Metric: 15.675579975579975 / 30  (52.3):  97%|▉| 29/30 [00:56<00:03,  3.46s/\u001b[A\n",
      "Average Metric: 15.675579975579975 / 30  (52.3): 100%|█| 30/30 [00:56<00:00,  1.87s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:41:47,666] Trial 17 finished with value: 52.25 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 2, '14707649168_predictor_instruction': 6, '14707649168_predictor_demos': 7, '14753105040_predictor_instruction': 8, '14753105040_predictor_demos': 3}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.675579975579975 / 30  (52.3%)\n",
      "Starting trial #18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:01<00:44,  1.53s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:01<00:44,  1.53s/it]\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 3  (48.1):   7%| | 2/30 [00:02<00:42,  1.53s/it\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 3  (48.1):  10%| | 3/30 [00:02<00:21,  1.28it/s\u001b[A\n",
      "Average Metric: 2.4444444444444446 / 4  (61.1):  10%| | 3/30 [00:02<00:21,  1.28it/s\u001b[A\n",
      "Average Metric: 2.9444444444444446 / 5  (58.9):  13%|▏| 4/30 [00:03<00:20,  1.28it/s\u001b[A\n",
      "Average Metric: 2.9444444444444446 / 5  (58.9):  17%|▏| 5/30 [00:03<00:15,  1.57it/s\u001b[A\n",
      "Average Metric: 3.9444444444444446 / 6  (65.7):  17%|▏| 5/30 [00:04<00:15,  1.57it/s\u001b[A\n",
      "Average Metric: 3.9444444444444446 / 6  (65.7):  20%|▏| 6/30 [00:04<00:14,  1.64it/s\u001b[A\n",
      "Average Metric: 3.9444444444444446 / 7  (56.3):  20%|▏| 6/30 [00:04<00:14,  1.64it/s\u001b[A\n",
      "Average Metric: 3.9444444444444446 / 7  (56.3):  23%|▏| 7/30 [00:04<00:11,  2.04it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.944444444444445 / 8  (61.8):  23%|▏| 7/30 [00:08<00:11,  2.04it/s]\u001b[A\n",
      "Average Metric: 4.944444444444445 / 8  (61.8):  27%|▎| 8/30 [00:08<00:32,  1.47s/it]\u001b[A\n",
      "Average Metric: 5.405982905982906 / 9  (60.1):  27%|▎| 8/30 [00:08<00:32,  1.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.405982905982906 / 10  (54.1):  30%|▎| 9/30 [00:09<00:30,  1.47s/it\u001b[A\n",
      "Average Metric: 5.405982905982906 / 10  (54.1):  33%|▎| 10/30 [00:09<00:20,  1.04s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.405982905982906 / 11  (58.2):  33%|▎| 10/30 [00:09<00:20,  1.04s/i\u001b[A\n",
      "Average Metric: 6.405982905982906 / 11  (58.2):  37%|▎| 11/30 [00:09<00:16,  1.16it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.263125763125763 / 12  (60.5):  37%|▎| 11/30 [00:10<00:16,  1.16it/\u001b[A\n",
      "Average Metric: 7.263125763125763 / 12  (60.5):  40%|▍| 12/30 [00:10<00:16,  1.11it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.763125763125763 / 13  (59.7):  40%|▍| 12/30 [00:12<00:16,  1.11it/\u001b[A\n",
      "Average Metric: 7.763125763125763 / 13  (59.7):  43%|▍| 13/30 [00:12<00:17,  1.05s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.263125763125764 / 14  (59.0):  43%|▍| 13/30 [00:13<00:17,  1.05s/i\u001b[A\n",
      "Average Metric: 8.263125763125764 / 14  (59.0):  47%|▍| 14/30 [00:13<00:16,  1.04s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.120268620268622 / 15  (60.8):  47%|▍| 14/30 [00:14<00:16,  1.04s/i\u001b[A\n",
      "Average Metric: 9.120268620268622 / 15  (60.8):  50%|▌| 15/30 [00:14<00:16,  1.08s/i\u001b[A\n",
      "Average Metric: 9.120268620268622 / 16  (57.0):  50%|▌| 15/30 [00:14<00:16,  1.08s/i\u001b[A\n",
      "Average Metric: 9.120268620268622 / 16  (57.0):  53%|▌| 16/30 [00:14<00:11,  1.20it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.97741147741148 / 17  (58.7):  53%|▌| 16/30 [00:18<00:11,  1.20it/s\u001b[A\n",
      "Average Metric: 9.97741147741148 / 17  (58.7):  57%|▌| 17/30 [00:18<00:21,  1.65s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.97741147741148 / 18  (61.0):  57%|▌| 17/30 [00:18<00:21,  1.65s/i\u001b[A\n",
      "Average Metric: 10.97741147741148 / 18  (61.0):  60%|▌| 18/30 [00:18<00:16,  1.36s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.310744810744813 / 19  (59.5):  60%|▌| 18/30 [00:20<00:16,  1.36s/\u001b[A\n",
      "Average Metric: 11.310744810744813 / 19  (59.5):  63%|▋| 19/30 [00:20<00:15,  1.37s/\u001b[A\n",
      "Average Metric: 12.310744810744813 / 20  (61.6):  63%|▋| 19/30 [00:20<00:15,  1.37s/\u001b[A\n",
      "Average Metric: 12.310744810744813 / 20  (61.6):  67%|▋| 20/30 [00:20<00:10,  1.10s/\u001b[A\n",
      "Average Metric: 13.310744810744813 / 21  (63.4):  67%|▋| 20/30 [00:20<00:10,  1.10s/\u001b[A\n",
      "Average Metric: 13.310744810744813 / 21  (63.4):  70%|▋| 21/30 [00:20<00:07,  1.24it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.310744810744813 / 22  (60.5):  70%|▋| 21/30 [00:21<00:07,  1.24it\u001b[A\n",
      "Average Metric: 13.310744810744813 / 22  (60.5):  73%|▋| 22/30 [00:21<00:06,  1.28it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 11.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.97741147741148 / 23  (60.8):  73%|▋| 22/30 [00:22<00:06,  1.28it/\u001b[A\n",
      "Average Metric: 13.97741147741148 / 23  (60.8):  77%|▊| 23/30 [00:22<00:05,  1.24it/\u001b[A\n",
      "Average Metric: 13.97741147741148 / 24  (58.2):  77%|▊| 23/30 [00:22<00:05,  1.24it/\u001b[A\n",
      "Average Metric: 13.97741147741148 / 24  (58.2):  80%|▊| 24/30 [00:22<00:03,  1.50it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.834554334554337 / 25  (59.3):  80%|▊| 24/30 [00:24<00:03,  1.50it\u001b[A\n",
      "Average Metric: 14.834554334554337 / 25  (59.3):  83%|▊| 25/30 [00:24<00:04,  1.12it\u001b[A\n",
      "Average Metric: 15.334554334554337 / 26  (59.0):  83%|▊| 25/30 [00:25<00:04,  1.12it\u001b[A\n",
      "Average Metric: 15.334554334554337 / 26  (59.0):  87%|▊| 26/30 [00:25<00:04,  1.03s/\u001b[A\n",
      "Average Metric: 15.834554334554337 / 27  (58.6):  87%|▊| 26/30 [00:25<00:04,  1.03s/\u001b[A\n",
      "Average Metric: 15.834554334554337 / 27  (58.6):  90%|▉| 27/30 [00:25<00:02,  1.11it\u001b[A\n",
      "Average Metric: 16.334554334554337 / 28  (58.3):  90%|▉| 27/30 [00:30<00:02,  1.11it\u001b[A\n",
      "Average Metric: 16.334554334554337 / 28  (58.3):  93%|▉| 28/30 [00:30<00:03,  1.83s/\u001b[A\n",
      "Average Metric: 16.796092796092797 / 29  (57.9):  93%|▉| 28/30 [00:35<00:03,  1.83s/\u001b[A\n",
      "Average Metric: 16.796092796092797 / 29  (57.9):  97%|▉| 29/30 [00:35<00:02,  2.87s/\u001b[A\n",
      "Average Metric: 16.796092796092797 / 30  (56.0):  97%|▉| 29/30 [00:36<00:02,  2.87s/\u001b[A\n",
      "Average Metric: 16.796092796092797 / 30  (56.0): 100%|█| 30/30 [00:36<00:00,  1.23s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:42:24,685] Trial 18 finished with value: 55.99 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 8, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 1, '14753105040_predictor_demos': 9}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.796092796092797 / 30  (56.0%)\n",
      "Starting trial #19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:00<00:25,  1.15it/s]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:01<00:25,  1.15it/s]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:01<00:16,  1.72it/s]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:01<00:16,  1.72it/s]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  10%|█▌             | 3/30 [00:01<00:15,  1.72it/s]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  13%|██             | 4/30 [00:01<00:10,  2.57it/s]\u001b[A\n",
      "Average Metric: 2.4615384615384617 / 5  (49.2):  13%|▏| 4/30 [00:01<00:10,  2.57it/s\u001b[A\n",
      "Average Metric: 2.4615384615384617 / 5  (49.2):  17%|▏| 5/30 [00:01<00:07,  3.18it/s\u001b[A\n",
      "Average Metric: 2.9059829059829063 / 6  (48.4):  17%|▏| 5/30 [00:02<00:07,  3.18it/s\u001b[A\n",
      "Average Metric: 2.9059829059829063 / 6  (48.4):  20%|▏| 6/30 [00:02<00:09,  2.47it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 7  (55.8):  20%|▏| 6/30 [00:02<00:09,  2.47it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 7  (55.8):  23%|▏| 7/30 [00:02<00:07,  2.99it/s\u001b[A\n",
      "Average Metric: 4.405982905982906 / 8  (55.1):  23%|▏| 7/30 [00:02<00:07,  2.99it/s]\u001b[A\n",
      "Average Metric: 4.405982905982906 / 8  (55.1):  27%|▎| 8/30 [00:02<00:06,  3.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.405982905982906 / 9  (49.0):  27%|▎| 8/30 [00:03<00:06,  3.48it/s]\u001b[A\n",
      "Average Metric: 4.405982905982906 / 9  (49.0):  30%|▎| 9/30 [00:03<00:07,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.867521367521368 / 10  (48.7):  30%|▎| 9/30 [00:04<00:07,  2.65it/s\u001b[A\n",
      "Average Metric: 4.867521367521368 / 10  (48.7):  33%|▎| 10/30 [00:04<00:09,  2.13it/\u001b[A\n",
      "Average Metric: 4.867521367521368 / 11  (44.3):  33%|▎| 10/30 [00:05<00:09,  2.13it/\u001b[A\n",
      "Average Metric: 4.867521367521368 / 11  (44.3):  37%|▎| 11/30 [00:05<00:12,  1.55it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.867521367521368 / 12  (40.6):  37%|▎| 11/30 [00:06<00:12,  1.55it/\u001b[A\n",
      "Average Metric: 4.867521367521368 / 12  (40.6):  40%|▍| 12/30 [00:06<00:16,  1.06it/\u001b[A\n",
      "Average Metric: 5.367521367521368 / 13  (41.3):  40%|▍| 12/30 [00:07<00:16,  1.06it/\u001b[A\n",
      "Average Metric: 5.367521367521368 / 13  (41.3):  43%|▍| 13/30 [00:07<00:12,  1.34it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.367521367521368 / 14  (45.5):  43%|▍| 13/30 [00:07<00:12,  1.34it/\u001b[A\n",
      "Average Metric: 6.367521367521368 / 14  (45.5):  47%|▍| 14/30 [00:07<00:09,  1.62it/\u001b[A\n",
      "Average Metric: 6.367521367521368 / 15  (42.5):  47%|▍| 14/30 [00:07<00:09,  1.62it/\u001b[A\n",
      "Average Metric: 6.367521367521368 / 15  (42.5):  50%|▌| 15/30 [00:07<00:07,  2.03it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.034188034188035 / 16  (44.0):  50%|▌| 15/30 [00:08<00:07,  2.03it/\u001b[A\n",
      "Average Metric: 7.034188034188035 / 16  (44.0):  53%|▌| 16/30 [00:08<00:08,  1.72it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.700854700854702 / 17  (45.3):  53%|▌| 16/30 [00:09<00:08,  1.72it/\u001b[A\n",
      "Average Metric: 7.700854700854702 / 17  (45.3):  57%|▌| 17/30 [00:09<00:08,  1.46it/\u001b[A\n",
      "Average Metric: 8.700854700854702 / 18  (48.3):  57%|▌| 17/30 [00:09<00:08,  1.46it/\u001b[A\n",
      "Average Metric: 9.700854700854702 / 19  (51.1):  60%|▌| 18/30 [00:09<00:08,  1.46it/\u001b[A\n",
      "Average Metric: 10.700854700854702 / 20  (53.5):  63%|▋| 19/30 [00:09<00:07,  1.46it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.55799755799756 / 21  (55.0):  67%|▋| 20/30 [00:10<00:06,  1.46it/\u001b[A\n",
      "Average Metric: 11.55799755799756 / 21  (55.0):  70%|▋| 21/30 [00:10<00:03,  2.44it/\u001b[A\n",
      "Average Metric: 11.843711843711846 / 22  (53.8):  70%|▋| 21/30 [00:11<00:03,  2.44it\u001b[A\n",
      "Average Metric: 11.843711843711846 / 22  (53.8):  73%|▋| 22/30 [00:11<00:04,  1.75it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.843711843711846 / 23  (55.8):  73%|▋| 22/30 [00:12<00:04,  1.75it\u001b[A\n",
      "Average Metric: 12.843711843711846 / 23  (55.8):  77%|▊| 23/30 [00:12<00:04,  1.53it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.700854700854704 / 24  (57.1):  77%|▊| 23/30 [00:13<00:04,  1.53it\u001b[A\n",
      "Average Metric: 13.700854700854704 / 24  (57.1):  80%|▊| 24/30 [00:13<00:04,  1.49it\u001b[A\n",
      "Average Metric: 14.557997557997561 / 25  (58.2):  80%|▊| 24/30 [00:14<00:04,  1.49it\u001b[A\n",
      "Average Metric: 14.557997557997561 / 25  (58.2):  83%|▊| 25/30 [00:14<00:03,  1.49it\u001b[A\n",
      "Average Metric: 14.557997557997561 / 26  (56.0):  83%|▊| 25/30 [00:14<00:03,  1.49it\u001b[A\n",
      "Average Metric: 14.557997557997561 / 26  (56.0):  87%|▊| 26/30 [00:14<00:02,  1.71it\u001b[A\n",
      "Average Metric: 14.557997557997561 / 27  (53.9):  87%|▊| 26/30 [00:15<00:02,  1.71it\u001b[A\n",
      "Average Metric: 14.557997557997561 / 27  (53.9):  90%|▉| 27/30 [00:15<00:02,  1.40it\u001b[A\n",
      "Average Metric: 14.843711843711848 / 28  (53.0):  90%|▉| 27/30 [00:16<00:02,  1.40it\u001b[A\n",
      "Average Metric: 14.843711843711848 / 28  (53.0):  93%|▉| 28/30 [00:16<00:01,  1.26it\u001b[A\n",
      "Average Metric: 15.510378510378514 / 29  (53.5):  93%|▉| 28/30 [00:17<00:01,  1.26it\u001b[A\n",
      "Average Metric: 15.510378510378514 / 29  (53.5):  97%|▉| 29/30 [00:17<00:00,  1.30it\u001b[A\n",
      "Average Metric: 16.310378510378513 / 30  (54.4):  97%|▉| 29/30 [00:17<00:00,  1.30it\u001b[A\n",
      "Average Metric: 16.310378510378513 / 30  (54.4): 100%|█| 30/30 [00:17<00:00,  1.71it\u001b[A\n",
      "[I 2024-04-28 22:42:42,299] Trial 19 finished with value: 54.37 and parameters: {'14766014224_predictor_instruction': 9, '14766014224_predictor_demos': 7, '14707649168_predictor_instruction': 6, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 4, '14753105040_predictor_demos': 1}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.310378510378513 / 30  (54.4%)\n",
      "Starting trial #20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:04<01:58,  4.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:05<01:58,  4.08s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:05<01:05,  2.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 3  (0.0):   7%|█               | 2/30 [00:09<01:05,  2.34s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):  10%|█▌              | 3/30 [00:09<01:31,  3.37s/it]\u001b[A\n",
      "Average Metric: 0.5 / 4  (12.5):  10%|█▌             | 3/30 [00:10<01:31,  3.37s/it]\u001b[A\n",
      "Average Metric: 0.5 / 4  (12.5):  13%|██             | 4/30 [00:10<01:02,  2.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.9615384615384616 / 5  (19.2):  13%|▏| 4/30 [00:11<01:02,  2.40s/it\u001b[A\n",
      "Average Metric: 0.9615384615384616 / 5  (19.2):  17%|▏| 5/30 [00:11<00:46,  1.86s/it\u001b[A\n",
      "Average Metric: 1.9615384615384617 / 6  (32.7):  17%|▏| 5/30 [00:11<00:46,  1.86s/it\u001b[A\n",
      "Average Metric: 1.9615384615384617 / 6  (32.7):  20%|▏| 6/30 [00:11<00:32,  1.35s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.818681318681319 / 7  (40.3):  20%|▏| 6/30 [00:14<00:32,  1.35s/it]\u001b[A\n",
      "Average Metric: 2.818681318681319 / 7  (40.3):  23%|▏| 7/30 [00:14<00:36,  1.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.218681318681319 / 8  (40.2):  23%|▏| 7/30 [00:14<00:36,  1.59s/it]\u001b[A\n",
      "Average Metric: 3.218681318681319 / 8  (40.2):  27%|▎| 8/30 [00:14<00:29,  1.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.0758241758241756 / 9  (45.3):  27%|▎| 8/30 [00:16<00:29,  1.34s/it\u001b[A\n",
      "Average Metric: 4.0758241758241756 / 9  (45.3):  30%|▎| 9/30 [00:16<00:31,  1.52s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.7424908424908425 / 10  (47.4):  30%|▎| 9/30 [00:18<00:31,  1.52s/i\u001b[A\n",
      "Average Metric: 4.7424908424908425 / 10  (47.4):  33%|▎| 10/30 [00:18<00:30,  1.54s/\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 5.028205128205128 / 11  (45.7):  33%|▎| 10/30 [00:18<00:30,  1.54s/i\u001b[A\n",
      "Average Metric: 5.028205128205128 / 11  (45.7):  37%|▎| 11/30 [00:18<00:22,  1.16s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.828205128205128 / 12  (48.6):  37%|▎| 11/30 [00:19<00:22,  1.16s/i\u001b[A\n",
      "Average Metric: 5.828205128205128 / 12  (48.6):  40%|▍| 12/30 [00:19<00:18,  1.01s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.828205128205128 / 13  (44.8):  40%|▍| 12/30 [00:20<00:18,  1.01s/i\u001b[A\n",
      "Average Metric: 5.828205128205128 / 13  (44.8):  43%|▍| 13/30 [00:20<00:15,  1.10it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.328205128205128 / 14  (45.2):  43%|▍| 13/30 [00:21<00:15,  1.10it/\u001b[A\n",
      "Average Metric: 6.328205128205128 / 14  (45.2):  47%|▍| 14/30 [00:21<00:15,  1.05it/\u001b[A\n",
      "Average Metric: 6.328205128205128 / 15  (42.2):  47%|▍| 14/30 [00:23<00:15,  1.05it/\u001b[A\n",
      "Average Metric: 6.328205128205128 / 15  (42.2):  50%|▌| 15/30 [00:23<00:21,  1.40s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.328205128205128 / 16  (39.6):  50%|▌| 15/30 [00:25<00:21,  1.40s/i\u001b[A\n",
      "Average Metric: 6.328205128205128 / 16  (39.6):  53%|▌| 16/30 [00:25<00:22,  1.58s/i\u001b[A\n",
      "Average Metric: 7.185347985347985 / 17  (42.3):  53%|▌| 16/30 [00:25<00:22,  1.58s/i\u001b[A\n",
      "Average Metric: 7.185347985347985 / 17  (42.3):  57%|▌| 17/30 [00:25<00:15,  1.18s/i\u001b[A\n",
      "Average Metric: 7.185347985347985 / 18  (39.9):  57%|▌| 17/30 [00:26<00:15,  1.18s/i\u001b[A\n",
      "Average Metric: 7.185347985347985 / 18  (39.9):  60%|▌| 18/30 [00:26<00:11,  1.04it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.685347985347985 / 19  (40.4):  60%|▌| 18/30 [00:27<00:11,  1.04it/\u001b[A\n",
      "Average Metric: 7.685347985347985 / 19  (40.4):  63%|▋| 19/30 [00:27<00:10,  1.08it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.685347985347985 / 20  (38.4):  63%|▋| 19/30 [00:29<00:10,  1.08it/\u001b[A\n",
      "Average Metric: 7.685347985347985 / 20  (38.4):  67%|▋| 20/30 [00:29<00:14,  1.46s/i\u001b[A\n",
      "Average Metric: 8.35201465201465 / 21  (39.8):  67%|▋| 20/30 [00:30<00:14,  1.46s/it\u001b[A\n",
      "Average Metric: 8.35201465201465 / 21  (39.8):  70%|▋| 21/30 [00:30<00:11,  1.27s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 24.7 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.35201465201465 / 22  (42.5):  70%|▋| 21/30 [00:31<00:11,  1.27s/it\u001b[A\n",
      "Average Metric: 9.35201465201465 / 22  (42.5):  73%|▋| 22/30 [00:31<00:09,  1.20s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.35201465201465 / 23  (45.0):  73%|▋| 22/30 [00:33<00:09,  1.20s/i\u001b[A\n",
      "Average Metric: 10.35201465201465 / 23  (45.0):  77%|▊| 23/30 [00:33<00:10,  1.44s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.35201465201465 / 24  (47.3):  77%|▊| 23/30 [00:34<00:10,  1.44s/i\u001b[A\n",
      "Average Metric: 11.35201465201465 / 24  (47.3):  80%|▊| 24/30 [00:34<00:07,  1.21s/i\u001b[A\n",
      "Average Metric: 12.35201465201465 / 25  (49.4):  80%|▊| 24/30 [00:35<00:07,  1.21s/i\u001b[A\n",
      "Average Metric: 12.35201465201465 / 25  (49.4):  83%|▊| 25/30 [00:35<00:05,  1.09s/i\u001b[A\n",
      "Average Metric: 12.35201465201465 / 26  (47.5):  83%|▊| 25/30 [00:36<00:05,  1.09s/i\u001b[A\n",
      "Average Metric: 12.35201465201465 / 26  (47.5):  87%|▊| 26/30 [00:36<00:04,  1.07s/i\u001b[A\n",
      "Average Metric: 12.85201465201465 / 27  (47.6):  87%|▊| 26/30 [00:36<00:04,  1.07s/i\u001b[A\n",
      "Average Metric: 12.85201465201465 / 27  (47.6):  90%|▉| 27/30 [00:36<00:02,  1.24it/\u001b[A\n",
      "Average Metric: 13.85201465201465 / 28  (49.5):  90%|▉| 27/30 [00:37<00:02,  1.24it/\u001b[A\n",
      "Average Metric: 13.85201465201465 / 28  (49.5):  93%|▉| 28/30 [00:37<00:01,  1.11it/\u001b[A\n",
      "Average Metric: 14.423443223443222 / 29  (49.7):  93%|▉| 28/30 [00:38<00:01,  1.11it\u001b[A\n",
      "Average Metric: 14.423443223443222 / 29  (49.7):  97%|▉| 29/30 [00:38<00:00,  1.23it\u001b[A\n",
      "Average Metric: 14.994871794871793 / 30  (50.0):  97%|▉| 29/30 [01:02<00:00,  1.23it\u001b[A\n",
      "Average Metric: 14.994871794871793 / 30  (50.0): 100%|█| 30/30 [01:02<00:00,  2.08s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:43:44,700] Trial 20 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.994871794871793 / 30  (50.0%)\n",
      "Trial pruned.\n",
      "Starting trial #21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:00<00:03,  7.30it/s]\u001b[A\n",
      "Average Metric: 0.6666666666666666 / 2  (33.3):   3%| | 1/30 [00:00<00:03,  7.30it/s\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 3  (38.9):   7%| | 2/30 [00:00<00:03,  7.30it/s\u001b[A\n",
      "Average Metric: 1.6282051282051282 / 4  (40.7):  10%| | 3/30 [00:00<00:03,  7.30it/s\u001b[A\n",
      "Average Metric: 2.0726495726495724 / 5  (41.5):  13%|▏| 4/30 [00:00<00:03,  7.30it/s\u001b[A\n",
      "Average Metric: 3.0726495726495724 / 6  (51.2):  17%|▏| 5/30 [00:00<00:03,  7.30it/s\u001b[A\n",
      "Average Metric: 3.0726495726495724 / 6  (51.2):  20%|▏| 6/30 [00:00<00:00, 26.73it/s\u001b[A\n",
      "Average Metric: 3.0726495726495724 / 7  (43.9):  20%|▏| 6/30 [00:00<00:00, 26.73it/s\u001b[A\n",
      "Average Metric: 4.072649572649572 / 8  (50.9):  23%|▏| 7/30 [00:00<00:00, 26.73it/s]\u001b[A\n",
      "Average Metric: 5.072649572649572 / 9  (56.4):  27%|▎| 8/30 [00:00<00:00, 26.73it/s]\u001b[A\n",
      "Average Metric: 5.534188034188034 / 10  (55.3):  30%|▎| 9/30 [00:00<00:00, 26.73it/s\u001b[A\n",
      "Average Metric: 6.534188034188034 / 11  (59.4):  33%|▎| 10/30 [00:00<00:00, 26.73it/\u001b[A\n",
      "Average Metric: 6.534188034188034 / 11  (59.4):  37%|▎| 11/30 [00:00<00:00, 34.86it/\u001b[A\n",
      "Average Metric: 7.034188034188034 / 12  (58.6):  37%|▎| 11/30 [00:00<00:00, 34.86it/\u001b[A\n",
      "Average Metric: 7.034188034188034 / 13  (54.1):  40%|▍| 12/30 [00:00<00:00, 34.86it/\u001b[A\n",
      "Average Metric: 7.891330891330891 / 14  (56.4):  43%|▍| 13/30 [00:00<00:00, 34.86it/\u001b[A\n",
      "Average Metric: 8.29133089133089 / 15  (55.3):  47%|▍| 14/30 [00:00<00:00, 34.86it/s\u001b[A\n",
      "Average Metric: 9.29133089133089 / 16  (58.1):  50%|▌| 15/30 [00:00<00:00, 34.86it/s\u001b[A\n",
      "Average Metric: 9.69133089133089 / 17  (57.0):  53%|▌| 16/30 [00:00<00:00, 34.86it/s\u001b[A\n",
      "Average Metric: 10.548473748473748 / 18  (58.6):  57%|▌| 17/30 [00:00<00:00, 34.86it\u001b[A\n",
      "Average Metric: 11.048473748473748 / 19  (58.1):  60%|▌| 18/30 [00:00<00:00, 34.86it\u001b[A\n",
      "Average Metric: 11.048473748473748 / 19  (58.1):  63%|▋| 19/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 11.048473748473748 / 20  (55.2):  63%|▋| 19/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 11.798473748473748 / 21  (56.2):  67%|▋| 20/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 11.798473748473748 / 22  (53.6):  70%|▋| 21/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 11.798473748473748 / 23  (51.3):  73%|▋| 22/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 24  (51.9):  77%|▊| 23/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 25  (49.9):  80%|▊| 24/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 13.465140415140414 / 26  (51.8):  83%|▊| 25/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 14.13180708180708 / 27  (52.3):  87%|▊| 26/30 [00:00<00:00, 50.73it/\u001b[A\n",
      "Average Metric: 15.13180708180708 / 28  (54.0):  90%|▉| 27/30 [00:00<00:00, 50.73it/\u001b[A\n",
      "Average Metric: 15.988949938949938 / 29  (55.1):  93%|▉| 28/30 [00:00<00:00, 50.73it\u001b[A\n",
      "Average Metric: 16.988949938949936 / 30  (56.6): 100%|█| 30/30 [00:00<00:00, 63.24it\u001b[A\n",
      "[I 2024-04-28 22:43:45,231] Trial 21 finished with value: 56.63 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 6, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 2, '14753105040_predictor_demos': 6}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.988949938949936 / 30  (56.6%)\n",
      "Starting trial #22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:00<00:03,  8.34it/s]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:00<00:03,  8.34it/s]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):   7%|█              | 2/30 [00:00<00:03,  8.34it/s]\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 4  (29.2):  10%| | 3/30 [00:00<00:03,  8.34it/s\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 5  (43.3):  13%|▏| 4/30 [00:00<00:03,  8.34it/s\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 5  (43.3):  17%|▏| 5/30 [00:00<00:01, 23.99it/s\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 6  (52.8):  17%|▏| 5/30 [00:00<00:01, 23.99it/s\u001b[A\n",
      "Average Metric: 3.628205128205128 / 7  (51.8):  20%|▏| 6/30 [00:00<00:01, 23.99it/s]\u001b[A\n",
      "Average Metric: 4.072649572649572 / 8  (50.9):  23%|▏| 7/30 [00:00<00:00, 23.99it/s]\u001b[A\n",
      "Average Metric: 5.072649572649572 / 9  (56.4):  27%|▎| 8/30 [00:00<00:00, 23.99it/s]\u001b[A\n",
      "Average Metric: 5.534188034188034 / 10  (55.3):  30%|▎| 9/30 [00:00<00:00, 23.99it/s\u001b[A\n",
      "Average Metric: 6.034188034188034 / 11  (54.9):  33%|▎| 10/30 [00:00<00:00, 23.99it/\u001b[A\n",
      "Average Metric: 6.434188034188034 / 12  (53.6):  37%|▎| 11/30 [00:00<00:00, 23.99it/\u001b[A\n",
      "Average Metric: 6.434188034188034 / 12  (53.6):  40%|▍| 12/30 [00:00<00:00, 41.65it/\u001b[A\n",
      "Average Metric: 6.434188034188034 / 13  (49.5):  40%|▍| 12/30 [00:00<00:00, 41.65it/\u001b[A\n",
      "Average Metric: 7.291330891330891 / 14  (52.1):  43%|▍| 13/30 [00:00<00:00, 41.65it/\u001b[A\n",
      "Average Metric: 8.29133089133089 / 15  (55.3):  47%|▍| 14/30 [00:00<00:00, 41.65it/s\u001b[A\n",
      "Average Metric: 9.29133089133089 / 16  (58.1):  50%|▌| 15/30 [00:00<00:00, 41.65it/s\u001b[A\n",
      "Average Metric: 10.148473748473748 / 17  (59.7):  53%|▌| 16/30 [00:00<00:00, 41.65it\u001b[A\n",
      "Average Metric: 10.648473748473748 / 18  (59.2):  57%|▌| 17/30 [00:00<00:00, 41.65it\u001b[A\n",
      "Average Metric: 10.648473748473748 / 19  (56.0):  60%|▌| 18/30 [00:00<00:00, 41.65it\u001b[A\n",
      "Average Metric: 11.048473748473748 / 20  (55.2):  63%|▋| 19/30 [00:00<00:00, 41.65it\u001b[A\n",
      "Average Metric: 11.048473748473748 / 20  (55.2):  67%|▋| 20/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 11.798473748473748 / 21  (56.2):  67%|▋| 20/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 22  (56.7):  70%|▋| 21/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 23  (54.2):  73%|▋| 22/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 24  (51.9):  77%|▊| 23/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 25  (49.9):  80%|▊| 24/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 13.465140415140414 / 26  (51.8):  83%|▊| 25/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 14.465140415140414 / 27  (53.6):  87%|▊| 26/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 15.322283272283272 / 28  (54.7):  90%|▉| 27/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 15.988949938949938 / 29  (55.1):  93%|▉| 28/30 [00:00<00:00, 55.35it\u001b[A\n",
      "Average Metric: 16.988949938949936 / 30  (56.6): 100%|█| 30/30 [00:00<00:00, 66.51it\u001b[A\n",
      "[I 2024-04-28 22:43:45,740] Trial 22 finished with value: 56.63 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 6, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 2, '14753105040_predictor_demos': 6}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.988949938949936 / 30  (56.6%)\n",
      "Starting trial #23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4444444444444444 / 1  (44.4):   0%|        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4444444444444444 / 1  (44.4):   3%| | 1/30 [00:00<00:03,  8.69it/s\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  8.69it/s\u001b[A\n",
      "Average Metric: 2.111111111111111 / 3  (70.4):   7%| | 2/30 [00:00<00:03,  8.69it/s]\u001b[A\n",
      "Average Metric: 3.111111111111111 / 4  (77.8):  10%| | 3/30 [00:00<00:03,  8.69it/s]\u001b[A\n",
      "Average Metric: 3.111111111111111 / 5  (62.2):  13%|▏| 4/30 [00:00<00:02,  8.69it/s]\u001b[A\n",
      "Average Metric: 3.111111111111111 / 6  (51.9):  17%|▏| 5/30 [00:00<00:02,  8.69it/s]\u001b[A\n",
      "Average Metric: 3.611111111111111 / 7  (51.6):  20%|▏| 6/30 [00:00<00:02,  8.69it/s]\u001b[A\n",
      "Average Metric: 4.611111111111111 / 8  (57.6):  23%|▏| 7/30 [00:00<00:02,  8.69it/s]\u001b[A\n",
      "Average Metric: 5.072649572649572 / 9  (56.4):  27%|▎| 8/30 [00:00<00:02,  8.69it/s]\u001b[A\n",
      "Average Metric: 5.072649572649572 / 9  (56.4):  30%|▎| 9/30 [00:00<00:00, 45.48it/s]\u001b[A\n",
      "Average Metric: 5.534188034188034 / 10  (55.3):  30%|▎| 9/30 [00:00<00:00, 45.48it/s\u001b[A\n",
      "Average Metric: 6.034188034188034 / 11  (54.9):  33%|▎| 10/30 [00:00<00:00, 45.48it/\u001b[A\n",
      "Average Metric: 6.891330891330891 / 12  (57.4):  37%|▎| 11/30 [00:00<00:00, 45.48it/\u001b[A\n",
      "Average Metric: 7.291330891330891 / 13  (56.1):  40%|▍| 12/30 [00:00<00:00, 45.48it/\u001b[A\n",
      "Average Metric: 8.148473748473748 / 14  (58.2):  43%|▍| 13/30 [00:00<00:00, 45.48it/\u001b[A\n",
      "Average Metric: 8.148473748473748 / 14  (58.2):  47%|▍| 14/30 [00:00<00:00, 43.65it/\u001b[A\n",
      "Average Metric: 9.148473748473748 / 15  (61.0):  47%|▍| 14/30 [00:00<00:00, 43.65it/\u001b[A\n",
      "Average Metric: 9.148473748473748 / 16  (57.2):  50%|▌| 15/30 [00:00<00:00, 43.65it/\u001b[A\n",
      "Average Metric: 10.148473748473748 / 17  (59.7):  53%|▌| 16/30 [00:00<00:00, 43.65it\u001b[A\n",
      "Average Metric: 10.148473748473748 / 18  (56.4):  57%|▌| 17/30 [00:00<00:00, 43.65it\u001b[A\n",
      "Average Metric: 10.648473748473748 / 19  (56.0):  60%|▌| 18/30 [00:00<00:00, 43.65it\u001b[A\n",
      "Average Metric: 11.048473748473748 / 20  (55.2):  63%|▋| 19/30 [00:00<00:00, 43.65it\u001b[A\n",
      "Average Metric: 11.048473748473748 / 20  (55.2):  67%|▋| 20/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 11.715140415140414 / 21  (55.8):  67%|▋| 20/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 11.715140415140414 / 22  (53.3):  70%|▋| 21/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 23  (54.2):  73%|▋| 22/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 12.465140415140414 / 24  (51.9):  77%|▊| 23/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 13.465140415140414 / 25  (53.9):  80%|▊| 24/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 13.465140415140414 / 26  (51.8):  83%|▊| 25/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 14.465140415140414 / 27  (53.6):  87%|▊| 26/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 15.465140415140414 / 28  (55.2):  90%|▉| 27/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 16.131807081807082 / 29  (55.6):  93%|▉| 28/30 [00:00<00:00, 47.86it\u001b[A\n",
      "Average Metric: 16.98894993894994 / 30  (56.6): 100%|█| 30/30 [00:00<00:00, 61.31it/\u001b[A\n",
      "[I 2024-04-28 22:43:46,279] Trial 23 finished with value: 56.63 and parameters: {'14766014224_predictor_instruction': 8, '14766014224_predictor_demos': 9, '14707649168_predictor_instruction': 6, '14707649168_predictor_demos': 8, '14753105040_predictor_instruction': 2, '14753105040_predictor_demos': 6}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 16.98894993894994 / 30  (56.6%)\n",
      "Starting trial #24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:02<01:25,  2.96s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:03<01:25,  2.96s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:03<00:40,  1.45s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:03<00:40,  1.45s/it]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  10%|█▌             | 3/30 [00:03<00:39,  1.45s/it]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):  13%|██             | 4/30 [00:03<00:37,  1.45s/it]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):  17%|██▌            | 5/30 [00:03<00:11,  2.20it/s]\u001b[A\n",
      "Average Metric: 2.0 / 6  (33.3):  17%|██▌            | 5/30 [00:03<00:11,  2.20it/s]\u001b[A\n",
      "Average Metric: 2.0 / 6  (33.3):  20%|███            | 6/30 [00:03<00:10,  2.24it/s]\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 7  (38.1):  20%|▏| 6/30 [00:04<00:10,  2.24it/s\u001b[A\n",
      "Average Metric: 2.6666666666666665 / 7  (38.1):  23%|▏| 7/30 [00:04<00:11,  1.93it/s\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 8  (45.8):  23%|▏| 7/30 [00:05<00:11,  1.93it/s\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 8  (45.8):  27%|▎| 8/30 [00:05<00:10,  2.09it/s\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 9  (40.7):  27%|▎| 8/30 [00:05<00:10,  2.09it/s\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 9  (40.7):  30%|▎| 9/30 [00:05<00:08,  2.49it/s\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 10  (36.7):  30%|▎| 9/30 [00:06<00:08,  2.49it/\u001b[A\n",
      "Average Metric: 3.6666666666666665 / 10  (36.7):  33%|▎| 10/30 [00:06<00:12,  1.65it\u001b[A\n",
      "Average Metric: 4.666666666666666 / 11  (42.4):  33%|▎| 10/30 [00:07<00:12,  1.65it/\u001b[A\n",
      "Average Metric: 4.666666666666666 / 11  (42.4):  37%|▎| 11/30 [00:07<00:12,  1.57it/\u001b[A\n",
      "Average Metric: 5.066666666666666 / 12  (42.2):  37%|▎| 11/30 [00:07<00:12,  1.57it/\u001b[A\n",
      "Average Metric: 5.066666666666666 / 12  (42.2):  40%|▍| 12/30 [00:07<00:09,  1.87it/\u001b[A\n",
      "Average Metric: 5.495238095238095 / 13  (42.3):  40%|▍| 12/30 [00:07<00:09,  1.87it/\u001b[A\n",
      "Average Metric: 5.495238095238095 / 13  (42.3):  43%|▍| 13/30 [00:07<00:07,  2.23it/\u001b[A\n",
      "Average Metric: 5.895238095238096 / 14  (42.1):  43%|▍| 13/30 [00:07<00:07,  2.23it/\u001b[A\n",
      "Average Metric: 6.395238095238096 / 15  (42.6):  47%|▍| 14/30 [00:08<00:07,  2.23it/\u001b[A\n",
      "Average Metric: 6.395238095238096 / 15  (42.6):  50%|▌| 15/30 [00:08<00:05,  2.74it/\u001b[A\n",
      "Average Metric: 6.728571428571429 / 16  (42.1):  50%|▌| 15/30 [00:09<00:05,  2.74it/\u001b[A\n",
      "Average Metric: 6.728571428571429 / 16  (42.1):  53%|▌| 16/30 [00:09<00:07,  1.88it/\u001b[A\n",
      "Average Metric: 6.728571428571429 / 17  (39.6):  53%|▌| 16/30 [00:09<00:07,  1.88it/\u001b[A\n",
      "Average Metric: 6.728571428571429 / 17  (39.6):  57%|▌| 17/30 [00:09<00:06,  2.09it/\u001b[A\n",
      "Average Metric: 7.728571428571429 / 18  (42.9):  57%|▌| 17/30 [00:10<00:06,  2.09it/\u001b[A\n",
      "Average Metric: 7.728571428571429 / 18  (42.9):  60%|▌| 18/30 [00:10<00:05,  2.06it/\u001b[A\n",
      "Average Metric: 7.728571428571429 / 19  (40.7):  60%|▌| 18/30 [00:10<00:05,  2.06it/\u001b[A\n",
      "Average Metric: 8.585714285714285 / 20  (42.9):  63%|▋| 19/30 [00:10<00:05,  2.06it/\u001b[A\n",
      "Average Metric: 8.585714285714285 / 21  (40.9):  67%|▋| 20/30 [00:10<00:04,  2.06it/\u001b[A\n",
      "Average Metric: 8.585714285714285 / 21  (40.9):  70%|▋| 21/30 [00:10<00:03,  2.99it/\u001b[A\n",
      "Average Metric: 8.585714285714285 / 22  (39.0):  70%|▋| 21/30 [00:10<00:03,  2.99it/\u001b[A\n",
      "Average Metric: 9.252380952380951 / 23  (40.2):  73%|▋| 22/30 [00:10<00:02,  2.99it/\u001b[A\n",
      "Average Metric: 9.252380952380951 / 23  (40.2):  77%|▊| 23/30 [00:10<00:01,  3.68it/\u001b[A\n",
      "Average Metric: 10.252380952380951 / 24  (42.7):  77%|▊| 23/30 [00:11<00:01,  3.68it\u001b[A\n",
      "Average Metric: 10.252380952380951 / 24  (42.7):  80%|▊| 24/30 [00:11<00:01,  4.14it\u001b[A\n",
      "Average Metric: 10.252380952380951 / 25  (41.0):  80%|▊| 24/30 [00:11<00:01,  4.14it\u001b[A\n",
      "Average Metric: 10.252380952380951 / 25  (41.0):  83%|▊| 25/30 [00:11<00:01,  3.63it\u001b[A\n",
      "Average Metric: 10.919047619047618 / 26  (42.0):  83%|▊| 25/30 [00:12<00:01,  3.63it\u001b[A\n",
      "Average Metric: 10.919047619047618 / 26  (42.0):  87%|▊| 26/30 [00:12<00:01,  2.23it\u001b[A\n",
      "Average Metric: 10.919047619047618 / 27  (40.4):  87%|▊| 26/30 [00:12<00:01,  2.23it\u001b[A\n",
      "Average Metric: 10.919047619047618 / 27  (40.4):  90%|▉| 27/30 [00:12<00:01,  2.28it\u001b[A\n",
      "Average Metric: 11.1008658008658 / 28  (39.6):  90%|▉| 27/30 [00:13<00:01,  2.28it/s\u001b[A\n",
      "Average Metric: 11.1008658008658 / 28  (39.6):  93%|▉| 28/30 [00:13<00:00,  2.18it/s\u001b[A\n",
      "Average Metric: 12.1008658008658 / 29  (41.7):  93%|▉| 28/30 [00:14<00:00,  2.18it/s\u001b[A\n",
      "Average Metric: 12.1008658008658 / 29  (41.7):  97%|▉| 29/30 [00:14<00:00,  1.57it/s\u001b[A\n",
      "Average Metric: 13.1008658008658 / 30  (43.7):  97%|▉| 29/30 [00:18<00:00,  1.57it/s\u001b[A\n",
      "Average Metric: 13.1008658008658 / 30  (43.7): 100%|█| 30/30 [00:18<00:00,  1.61it/s\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:44:05,028] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.1008658008658 / 30  (43.7%)\n",
      "Trial pruned.\n",
      "Starting trial #25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:28,  3.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:04<01:28,  3.07s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:04<00:51,  1.84s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):   7%|█               | 2/30 [00:04<00:51,  1.84s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):  10%|█▌              | 3/30 [00:04<00:37,  1.40s/it]\u001b[A\n",
      "Average Metric: 0.0 / 4  (0.0):  10%|█▌              | 3/30 [00:05<00:37,  1.40s/it]\u001b[A\n",
      "Average Metric: 0.0 / 4  (0.0):  13%|██▏             | 4/30 [00:05<00:24,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 5  (0.0):  13%|██▏             | 4/30 [00:05<00:24,  1.05it/s]\u001b[A\n",
      "Average Metric: 0.0 / 5  (0.0):  17%|██▋             | 5/30 [00:05<00:18,  1.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.4 / 6  (6.7):  17%|██▋             | 5/30 [00:08<00:18,  1.34it/s]\u001b[A\n",
      "Average Metric: 0.4 / 6  (6.7):  20%|███▏            | 6/30 [00:08<00:39,  1.66s/it]\u001b[A\n",
      "Average Metric: 0.9 / 7  (12.9):  20%|███            | 6/30 [00:09<00:39,  1.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.2333333333333334 / 8  (15.4):  23%|▏| 7/30 [00:09<00:38,  1.66s/it\u001b[A\n",
      "Average Metric: 1.2333333333333334 / 8  (15.4):  27%|▎| 8/30 [00:09<00:23,  1.08s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.2333333333333334 / 9  (13.7):  27%|▎| 8/30 [00:11<00:23,  1.08s/it\u001b[A\n",
      "Average Metric: 1.2333333333333334 / 9  (13.7):  30%|▎| 9/30 [00:11<00:22,  1.07s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.2333333333333334 / 10  (22.3):  30%|▎| 9/30 [00:13<00:22,  1.07s/i\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 10  (22.3):  33%|▎| 10/30 [00:13<00:28,  1.44s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.9 / 11  (26.4):  33%|████▎        | 10/30 [00:14<00:28,  1.44s/it]\u001b[A\n",
      "Average Metric: 2.9 / 11  (26.4):  37%|████▊        | 11/30 [00:14<00:25,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.5666666666666664 / 12  (29.7):  37%|▎| 11/30 [00:16<00:25,  1.37s/\u001b[A\n",
      "Average Metric: 3.5666666666666664 / 12  (29.7):  40%|▍| 12/30 [00:16<00:29,  1.65s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.5666666666666664 / 13  (27.4):  40%|▍| 12/30 [00:17<00:29,  1.65s/\u001b[A\n",
      "Average Metric: 3.5666666666666664 / 13  (27.4):  43%|▍| 13/30 [00:17<00:21,  1.26s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.566666666666666 / 14  (32.6):  43%|▍| 13/30 [00:18<00:21,  1.26s/i\u001b[A\n",
      "Average Metric: 4.566666666666666 / 14  (32.6):  47%|▍| 14/30 [00:18<00:20,  1.25s/i\u001b[A\n",
      "Average Metric: 4.566666666666666 / 15  (30.4):  47%|▍| 14/30 [00:19<00:20,  1.25s/i\u001b[A\n",
      "Average Metric: 4.566666666666666 / 15  (30.4):  50%|▌| 15/30 [00:19<00:17,  1.14s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.966666666666667 / 16  (31.0):  50%|▌| 15/30 [00:20<00:17,  1.14s/i\u001b[A\n",
      "Average Metric: 4.966666666666667 / 16  (31.0):  53%|▌| 16/30 [00:20<00:15,  1.09s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 13.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.148484848484848 / 17  (30.3):  53%|▌| 16/30 [00:22<00:15,  1.09s/i\u001b[A\n",
      "Average Metric: 5.148484848484848 / 17  (30.3):  57%|▌| 17/30 [00:22<00:20,  1.55s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.148484848484848 / 18  (28.6):  57%|▌| 17/30 [00:23<00:20,  1.55s/i\u001b[A\n",
      "Average Metric: 5.148484848484848 / 18  (28.6):  60%|▌| 18/30 [00:23<00:16,  1.34s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.148484848484848 / 19  (27.1):  60%|▌| 18/30 [00:26<00:16,  1.34s/i\u001b[A\n",
      "Average Metric: 5.148484848484848 / 19  (27.1):  63%|▋| 19/30 [00:26<00:17,  1.59s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.148484848484848 / 20  (30.7):  63%|▋| 19/30 [00:26<00:17,  1.59s/i\u001b[A\n",
      "Average Metric: 6.148484848484848 / 20  (30.7):  67%|▋| 20/30 [00:26<00:12,  1.28s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.548484848484849 / 21  (31.2):  67%|▋| 20/30 [00:27<00:12,  1.28s/i\u001b[A\n",
      "Average Metric: 6.548484848484849 / 21  (31.2):  70%|▋| 21/30 [00:27<00:10,  1.17s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.548484848484849 / 22  (34.3):  70%|▋| 21/30 [00:29<00:10,  1.17s/i\u001b[A\n",
      "Average Metric: 7.548484848484849 / 22  (34.3):  73%|▋| 22/30 [00:29<00:11,  1.44s/i\u001b[A\n",
      "Average Metric: 8.548484848484849 / 23  (37.2):  73%|▋| 22/30 [00:29<00:11,  1.44s/i\u001b[A\n",
      "Average Metric: 8.548484848484849 / 23  (37.2):  77%|▊| 23/30 [00:29<00:07,  1.09s/i\u001b[A\n",
      "Average Metric: 9.215151515151515 / 24  (38.4):  77%|▊| 23/30 [00:30<00:07,  1.09s/i\u001b[A\n",
      "Average Metric: 9.215151515151515 / 24  (38.4):  80%|▊| 24/30 [00:30<00:05,  1.06it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.215151515151515 / 25  (36.9):  80%|▊| 24/30 [00:31<00:05,  1.06it/\u001b[A\n",
      "Average Metric: 9.215151515151515 / 25  (36.9):  83%|▊| 25/30 [00:31<00:04,  1.00it/\u001b[A\n",
      "Average Metric: 9.215151515151515 / 26  (35.4):  83%|▊| 25/30 [00:31<00:04,  1.00it/\u001b[A\n",
      "Average Metric: 10.072294372294373 / 27  (37.3):  87%|▊| 26/30 [00:32<00:03,  1.00it\u001b[A\n",
      "Average Metric: 10.072294372294373 / 27  (37.3):  90%|▉| 27/30 [00:32<00:02,  1.21it\u001b[A\n",
      "Average Metric: 10.072294372294373 / 28  (36.0):  90%|▉| 27/30 [00:34<00:02,  1.21it\u001b[A\n",
      "Average Metric: 10.072294372294373 / 28  (36.0):  93%|▉| 28/30 [00:34<00:02,  1.05s/\u001b[A\n",
      "Average Metric: 10.405627705627706 / 29  (35.9):  93%|▉| 28/30 [00:35<00:02,  1.05s/\u001b[A\n",
      "Average Metric: 10.405627705627706 / 29  (35.9):  97%|▉| 29/30 [00:35<00:00,  1.06it\u001b[A\n",
      "Average Metric: 10.905627705627706 / 30  (36.4):  97%|▉| 29/30 [00:37<00:00,  1.06it\u001b[A\n",
      "Average Metric: 10.905627705627706 / 30  (36.4): 100%|█| 30/30 [00:37<00:00,  1.25s/\u001b[A\n",
      "[I 2024-04-28 22:44:42,741] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.905627705627706 / 30  (36.4%)\n",
      "Trial pruned.\n",
      "Starting trial #26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:01<00:51,  1.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:04<00:51,  1.79s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:04<00:57,  2.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:05<00:57,  2.05s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:05<00:45,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.8 / 4  (45.0):  10%|█▌             | 3/30 [00:06<00:45,  1.69s/it]\u001b[A\n",
      "Average Metric: 1.8 / 4  (45.0):  13%|██             | 4/30 [00:06<00:37,  1.43s/it]\u001b[A\n",
      "Average Metric: 2.1333333333333333 / 5  (42.7):  13%|▏| 4/30 [00:06<00:37,  1.43s/it\u001b[A\n",
      "Average Metric: 2.1333333333333333 / 5  (42.7):  17%|▏| 5/30 [00:06<00:26,  1.08s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.1333333333333333 / 6  (52.2):  17%|▏| 5/30 [00:07<00:26,  1.08s/it\u001b[A\n",
      "Average Metric: 3.1333333333333333 / 6  (52.2):  20%|▏| 6/30 [00:07<00:23,  1.02it/s\u001b[A\n",
      "Average Metric: 4.133333333333333 / 7  (59.0):  20%|▏| 6/30 [00:08<00:23,  1.02it/s]\u001b[A\n",
      "Average Metric: 4.133333333333333 / 7  (59.0):  23%|▏| 7/30 [00:08<00:21,  1.09it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.5777777777777775 / 8  (57.2):  23%|▏| 7/30 [00:08<00:21,  1.09it/s\u001b[A\n",
      "Average Metric: 4.5777777777777775 / 8  (57.2):  27%|▎| 8/30 [00:08<00:16,  1.30it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.0777777777777775 / 9  (56.4):  27%|▎| 8/30 [00:09<00:16,  1.30it/s\u001b[A\n",
      "Average Metric: 5.0777777777777775 / 9  (56.4):  30%|▎| 9/30 [00:09<00:13,  1.55it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.0777777777777775 / 10  (60.8):  30%|▎| 9/30 [00:09<00:13,  1.55it/\u001b[A\n",
      "Average Metric: 6.0777777777777775 / 10  (60.8):  33%|▎| 10/30 [00:09<00:11,  1.80it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.7444444444444445 / 11  (61.3):  33%|▎| 10/30 [00:09<00:11,  1.80it\u001b[A\n",
      "Average Metric: 6.7444444444444445 / 11  (61.3):  37%|▎| 11/30 [00:09<00:08,  2.16it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.7444444444444445 / 12  (56.2):  37%|▎| 11/30 [00:12<00:08,  2.16it\u001b[A\n",
      "Average Metric: 6.7444444444444445 / 12  (56.2):  40%|▍| 12/30 [00:12<00:18,  1.02s/\u001b[A\n",
      "Average Metric: 7.601587301587301 / 13  (58.5):  40%|▍| 12/30 [00:12<00:18,  1.02s/i\u001b[A\n",
      "Average Metric: 7.601587301587301 / 13  (58.5):  43%|▍| 13/30 [00:12<00:16,  1.04it/\u001b[A\n",
      "Average Metric: 8.101587301587301 / 14  (57.9):  43%|▍| 13/30 [00:13<00:16,  1.04it/\u001b[A\n",
      "Average Metric: 8.101587301587301 / 14  (57.9):  47%|▍| 14/30 [00:13<00:11,  1.35it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.101587301587301 / 15  (54.0):  47%|▍| 14/30 [00:13<00:11,  1.35it/\u001b[A\n",
      "Average Metric: 8.101587301587301 / 15  (54.0):  50%|▌| 15/30 [00:13<00:10,  1.40it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.101587301587301 / 16  (56.9):  50%|▌| 15/30 [00:16<00:10,  1.40it/\u001b[A\n",
      "Average Metric: 9.101587301587301 / 16  (56.9):  53%|▌| 16/30 [00:16<00:17,  1.28s/i\u001b[A\n",
      "Average Metric: 10.101587301587301 / 17  (59.4):  53%|▌| 16/30 [00:16<00:17,  1.28s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.434920634920635 / 18  (58.0):  57%|▌| 17/30 [00:18<00:16,  1.28s/\u001b[A\n",
      "Average Metric: 10.434920634920635 / 18  (58.0):  60%|▌| 18/30 [00:18<00:12,  1.07s/\u001b[A\n",
      "Average Metric: 11.434920634920635 / 19  (60.2):  60%|▌| 18/30 [00:18<00:12,  1.07s/\u001b[A\n",
      "Average Metric: 11.434920634920635 / 19  (60.2):  63%|▋| 19/30 [00:18<00:09,  1.19it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.101587301587301 / 20  (60.5):  63%|▋| 19/30 [00:19<00:09,  1.19it\u001b[A\n",
      "Average Metric: 12.101587301587301 / 20  (60.5):  67%|▋| 20/30 [00:19<00:08,  1.14it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.101587301587301 / 21  (62.4):  67%|▋| 20/30 [00:20<00:08,  1.14it\u001b[A\n",
      "Average Metric: 13.101587301587301 / 21  (62.4):  70%|▋| 21/30 [00:20<00:09,  1.04s/\u001b[A\n",
      "Average Metric: 14.101587301587301 / 22  (64.1):  70%|▋| 21/30 [00:21<00:09,  1.04s/\u001b[A\n",
      "Average Metric: 14.101587301587301 / 22  (64.1):  73%|▋| 22/30 [00:21<00:08,  1.09s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.101587301587301 / 23  (61.3):  73%|▋| 22/30 [00:22<00:08,  1.09s/\u001b[A\n",
      "Average Metric: 14.101587301587301 / 23  (61.3):  77%|▊| 23/30 [00:22<00:07,  1.07s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.434920634920635 / 24  (60.1):  77%|▊| 23/30 [00:23<00:07,  1.07s/\u001b[A\n",
      "Average Metric: 14.434920634920635 / 24  (60.1):  80%|▊| 24/30 [00:23<00:05,  1.19it\u001b[A\n",
      "Average Metric: 15.101587301587301 / 25  (60.4):  80%|▊| 24/30 [00:24<00:05,  1.19it\u001b[A\n",
      "Average Metric: 15.101587301587301 / 25  (60.4):  83%|▊| 25/30 [00:24<00:04,  1.06it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 14.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 15.601587301587301 / 26  (60.0):  83%|▊| 25/30 [00:25<00:04,  1.06it\u001b[A\n",
      "Average Metric: 15.601587301587301 / 26  (60.0):  87%|▊| 26/30 [00:25<00:03,  1.01it\u001b[A\n",
      "Average Metric: 16.45873015873016 / 27  (61.0):  87%|▊| 26/30 [00:26<00:03,  1.01it/\u001b[A\n",
      "Average Metric: 16.45873015873016 / 27  (61.0):  90%|▉| 27/30 [00:26<00:02,  1.10it/\u001b[A\n",
      "Average Metric: 17.25873015873016 / 28  (61.6):  90%|▉| 27/30 [00:28<00:02,  1.10it/\u001b[A\n",
      "Average Metric: 17.25873015873016 / 28  (61.6):  93%|▉| 28/30 [00:28<00:02,  1.35s/i\u001b[A\n",
      "Average Metric: 17.25873015873016 / 29  (59.5):  93%|▉| 28/30 [00:34<00:02,  1.35s/i\u001b[A\n",
      "Average Metric: 17.25873015873016 / 29  (59.5):  97%|▉| 29/30 [00:34<00:02,  2.73s/i\u001b[A\n",
      "Average Metric: 17.72026862026862 / 30  (59.1):  97%|▉| 29/30 [00:40<00:02,  2.73s/i\u001b[A\n",
      "Average Metric: 17.72026862026862 / 30  (59.1): 100%|█| 30/30 [00:40<00:00,  1.36s/i\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:45:23,683] Trial 26 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.72026862026862 / 30  (59.1%)\n",
      "Starting trial #27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  7.93it/s]\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  7.93it/s\u001b[A\n",
      "Average Metric: 2.4444444444444446 / 3  (81.5):   7%| | 2/30 [00:00<00:03,  7.93it/s\u001b[A\n",
      "Average Metric: 2.9059829059829063 / 4  (72.6):  10%| | 3/30 [00:00<00:03,  7.93it/s\u001b[A\n",
      "Average Metric: 3.23931623931624 / 5  (64.8):  13%|▎ | 4/30 [00:00<00:03,  7.93it/s]\u001b[A\n",
      "Average Metric: 4.23931623931624 / 6  (70.7):  17%|▎ | 5/30 [00:00<00:03,  7.93it/s]\u001b[A\n",
      "Average Metric: 4.23931623931624 / 7  (60.6):  20%|▍ | 6/30 [00:00<00:03,  7.93it/s]\u001b[A\n",
      "Average Metric: 4.23931623931624 / 7  (60.6):  23%|▍ | 7/30 [00:00<00:00, 34.37it/s]\u001b[A\n",
      "Average Metric: 5.03931623931624 / 8  (63.0):  23%|▍ | 7/30 [00:00<00:00, 34.37it/s]\u001b[A\n",
      "Average Metric: 5.372649572649573 / 9  (59.7):  27%|▎| 8/30 [00:00<00:00, 34.37it/s]\u001b[A\n",
      "Average Metric: 5.372649572649573 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 34.37it/s\u001b[A\n",
      "Average Metric: 5.872649572649573 / 11  (53.4):  33%|▎| 10/30 [00:00<00:00, 34.37it/\u001b[A\n",
      "Average Metric: 5.872649572649573 / 11  (53.4):  37%|▎| 11/30 [00:00<00:00, 35.77it/\u001b[A\n",
      "Average Metric: 5.872649572649573 / 12  (48.9):  37%|▎| 11/30 [00:00<00:00, 35.77it/\u001b[A\n",
      "Average Metric: 6.53931623931624 / 13  (50.3):  40%|▍| 12/30 [00:00<00:00, 35.77it/s\u001b[A\n",
      "Average Metric: 6.53931623931624 / 14  (46.7):  43%|▍| 13/30 [00:00<00:00, 35.77it/s\u001b[A\n",
      "Average Metric: 7.396459096459097 / 15  (49.3):  47%|▍| 14/30 [00:00<00:00, 35.77it/\u001b[A\n",
      "Average Metric: 8.396459096459097 / 16  (52.5):  50%|▌| 15/30 [00:00<00:00, 35.77it/\u001b[A\n",
      "Average Metric: 8.396459096459097 / 16  (52.5):  53%|▌| 16/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 8.896459096459097 / 17  (52.3):  53%|▌| 16/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 19  (52.1):  60%|▌| 18/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 21  (48.7):  67%|▋| 20/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 22  (48.8):  70%|▋| 21/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 11.586935286935288 / 23  (50.4):  73%|▋| 22/30 [00:00<00:00, 40.09it\u001b[A\n",
      "Average Metric: 12.38693528693529 / 24  (51.6):  77%|▊| 23/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 13.053601953601955 / 25  (52.2):  80%|▊| 24/30 [00:00<00:00, 40.09it\u001b[A\n",
      "Average Metric: 14.053601953601955 / 26  (54.1):  83%|▊| 25/30 [00:00<00:00, 40.09it\u001b[A\n",
      "Average Metric: 14.720268620268621 / 27  (54.5):  87%|▊| 26/30 [00:00<00:00, 40.09it\u001b[A\n",
      "Average Metric: 15.720268620268621 / 28  (56.1):  90%|▉| 27/30 [00:00<00:00, 40.09it\u001b[A\n",
      "Average Metric: 16.72026862026862 / 29  (57.7):  93%|▉| 28/30 [00:00<00:00, 40.09it/\u001b[A\n",
      "Average Metric: 17.72026862026862 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 63.97it/\u001b[A\n",
      "[I 2024-04-28 22:45:24,219] Trial 27 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.72026862026862 / 30  (59.1%)\n",
      "Starting trial #28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  7.51it/s]\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  7.51it/s\u001b[A\n",
      "Average Metric: 1.9059829059829059 / 3  (63.5):   7%| | 2/30 [00:00<00:03,  7.51it/s\u001b[A\n",
      "Average Metric: 2.905982905982906 / 4  (72.6):  10%| | 3/30 [00:00<00:03,  7.51it/s]\u001b[A\n",
      "Average Metric: 3.905982905982906 / 5  (78.1):  13%|▏| 4/30 [00:00<00:03,  7.51it/s]\u001b[A\n",
      "Average Metric: 3.905982905982906 / 6  (65.1):  17%|▏| 5/30 [00:00<00:03,  7.51it/s]\u001b[A\n",
      "Average Metric: 3.905982905982906 / 6  (65.1):  20%|▏| 6/30 [00:00<00:00, 27.55it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  20%|▏| 6/30 [00:00<00:00, 27.55it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 8  (53.0):  23%|▏| 7/30 [00:00<00:00, 27.55it/s]\u001b[A\n",
      "Average Metric: 4.572649572649572 / 9  (50.8):  27%|▎| 8/30 [00:00<00:00, 27.55it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 27.55it/s\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 27.55it/\u001b[A\n",
      "Average Metric: 6.372649572649572 / 12  (53.1):  37%|▎| 11/30 [00:00<00:00, 27.55it/\u001b[A\n",
      "Average Metric: 6.372649572649572 / 12  (53.1):  40%|▍| 12/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 13  (52.9):  40%|▍| 12/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 7.539316239316239 / 14  (53.9):  43%|▍| 13/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 7.539316239316239 / 15  (50.3):  47%|▍| 14/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 8.396459096459097 / 16  (52.5):  50%|▌| 15/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 9.396459096459097 / 17  (55.3):  53%|▌| 16/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 40.23it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 19  (53.8):  63%|▋| 19/30 [00:00<00:00, 49.70it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 49.70it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 49.70it/\u001b[A\n",
      "Average Metric: 11.529792429792431 / 22  (52.4):  70%|▋| 21/30 [00:00<00:00, 49.70it\u001b[A\n",
      "Average Metric: 12.38693528693529 / 23  (53.9):  73%|▋| 22/30 [00:00<00:00, 49.70it/\u001b[A\n",
      "Average Metric: 13.38693528693529 / 24  (55.8):  77%|▊| 23/30 [00:00<00:00, 49.70it/\u001b[A\n",
      "Average Metric: 13.38693528693529 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 49.70it/\u001b[A\n",
      "Average Metric: 14.053601953601955 / 26  (54.1):  83%|▊| 25/30 [00:00<00:00, 49.70it\u001b[A\n",
      "Average Metric: 15.053601953601955 / 27  (55.8):  87%|▊| 26/30 [00:00<00:00, 49.70it\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 49.70it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 49.70it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 62.08it\u001b[A\n",
      "[I 2024-04-28 22:45:24,754] Trial 28 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  7.79it/s]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:00<00:03,  7.79it/s]\u001b[A\n",
      "Average Metric: 2.4444444444444446 / 3  (81.5):   7%| | 2/30 [00:00<00:03,  7.79it/s\u001b[A\n",
      "Average Metric: 2.9059829059829063 / 4  (72.6):  10%| | 3/30 [00:00<00:03,  7.79it/s\u001b[A\n",
      "Average Metric: 3.23931623931624 / 5  (64.8):  13%|▎ | 4/30 [00:00<00:03,  7.79it/s]\u001b[A\n",
      "Average Metric: 4.23931623931624 / 6  (70.7):  17%|▎ | 5/30 [00:00<00:03,  7.79it/s]\u001b[A\n",
      "Average Metric: 4.23931623931624 / 6  (70.7):  20%|▍ | 6/30 [00:00<00:00, 27.84it/s]\u001b[A\n",
      "Average Metric: 4.572649572649573 / 7  (65.3):  20%|▏| 6/30 [00:00<00:00, 27.84it/s]\u001b[A\n",
      "Average Metric: 4.572649572649573 / 8  (57.2):  23%|▏| 7/30 [00:00<00:00, 27.84it/s]\u001b[A\n",
      "Average Metric: 4.572649572649573 / 9  (50.8):  27%|▎| 8/30 [00:00<00:00, 27.84it/s]\u001b[A\n",
      "Average Metric: 5.372649572649573 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 27.84it/s\u001b[A\n",
      "Average Metric: 5.372649572649573 / 10  (53.7):  33%|▎| 10/30 [00:00<00:00, 32.69it/\u001b[A\n",
      "Average Metric: 5.372649572649573 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 32.69it/\u001b[A\n",
      "Average Metric: 6.372649572649573 / 12  (53.1):  37%|▎| 11/30 [00:00<00:00, 32.69it/\u001b[A\n",
      "Average Metric: 7.22979242979243 / 13  (55.6):  40%|▍| 12/30 [00:00<00:00, 32.69it/s\u001b[A\n",
      "Average Metric: 7.72979242979243 / 14  (55.2):  43%|▍| 13/30 [00:00<00:00, 32.69it/s\u001b[A\n",
      "Average Metric: 8.229792429792429 / 15  (54.9):  47%|▍| 14/30 [00:00<00:00, 32.69it/\u001b[A\n",
      "Average Metric: 8.229792429792429 / 16  (51.4):  50%|▌| 15/30 [00:00<00:00, 32.69it/\u001b[A\n",
      "Average Metric: 8.229792429792429 / 16  (51.4):  53%|▌| 16/30 [00:00<00:00, 42.24it/\u001b[A\n",
      "Average Metric: 8.896459096459095 / 17  (52.3):  53%|▌| 16/30 [00:00<00:00, 42.24it/\u001b[A\n",
      "Average Metric: 9.896459096459095 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 42.24it/\u001b[A\n",
      "Average Metric: 10.229792429792429 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 10.229792429792429 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 10.729792429792429 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 11.52979242979243 / 22  (52.4):  70%|▋| 21/30 [00:00<00:00, 42.24it/\u001b[A\n",
      "Average Metric: 12.386935286935287 / 23  (53.9):  73%|▋| 22/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 12.386935286935287 / 24  (51.6):  77%|▊| 23/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 13.386935286935287 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 14.053601953601953 / 26  (54.1):  83%|▊| 25/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 15.053601953601953 / 27  (55.8):  87%|▊| 26/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 42.24it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 63.69it\u001b[A\n",
      "[I 2024-04-28 22:45:25,277] Trial 29 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  7.75it/s]\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  7.75it/s\u001b[A\n",
      "Average Metric: 1.7777777777777777 / 3  (59.3):   7%| | 2/30 [00:00<00:03,  7.75it/s\u001b[A\n",
      "Average Metric: 2.7777777777777777 / 4  (69.4):  10%| | 3/30 [00:00<00:03,  7.75it/s\u001b[A\n",
      "Average Metric: 3.2393162393162394 / 5  (64.8):  13%|▏| 4/30 [00:00<00:03,  7.75it/s\u001b[A\n",
      "Average Metric: 4.239316239316239 / 6  (70.7):  17%|▏| 5/30 [00:00<00:03,  7.75it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  20%|▏| 6/30 [00:00<00:03,  7.75it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  23%|▏| 7/30 [00:00<00:00, 34.83it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 8  (53.0):  23%|▏| 7/30 [00:00<00:00, 34.83it/s]\u001b[A\n",
      "Average Metric: 4.572649572649572 / 9  (50.8):  27%|▎| 8/30 [00:00<00:00, 34.83it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 34.83it/s\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 34.83it/\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  37%|▎| 11/30 [00:00<00:00, 36.99it/\u001b[A\n",
      "Average Metric: 5.872649572649572 / 12  (48.9):  37%|▎| 11/30 [00:00<00:00, 36.99it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 13  (52.9):  40%|▍| 12/30 [00:00<00:00, 36.99it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 14  (49.1):  43%|▍| 13/30 [00:00<00:00, 36.99it/\u001b[A\n",
      "Average Metric: 7.539316239316239 / 15  (50.3):  47%|▍| 14/30 [00:00<00:00, 36.99it/\u001b[A\n",
      "Average Metric: 8.03931623931624 / 16  (50.2):  50%|▌| 15/30 [00:00<00:00, 36.99it/s\u001b[A\n",
      "Average Metric: 8.03931623931624 / 16  (50.2):  53%|▌| 16/30 [00:00<00:00, 41.66it/s\u001b[A\n",
      "Average Metric: 8.372649572649573 / 17  (49.3):  53%|▌| 16/30 [00:00<00:00, 41.66it/\u001b[A\n",
      "Average Metric: 9.22979242979243 / 18  (51.3):  57%|▌| 17/30 [00:00<00:00, 41.66it/s\u001b[A\n",
      "Average Metric: 10.22979242979243 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 41.66it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 41.66it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 41.66it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 22  (48.8):  70%|▋| 21/30 [00:00<00:00, 41.66it/\u001b[A\n",
      "Average Metric: 11.586935286935288 / 23  (50.4):  73%|▋| 22/30 [00:00<00:00, 41.66it\u001b[A\n",
      "Average Metric: 12.38693528693529 / 24  (51.6):  77%|▊| 23/30 [00:00<00:00, 41.66it/\u001b[A\n",
      "Average Metric: 13.38693528693529 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 41.66it/\u001b[A\n",
      "Average Metric: 14.053601953601955 / 26  (54.1):  83%|▊| 25/30 [00:00<00:00, 41.66it\u001b[A\n",
      "Average Metric: 15.053601953601955 / 27  (55.8):  87%|▊| 26/30 [00:00<00:00, 41.66it\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 41.66it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 41.66it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 61.40it\u001b[A\n",
      "[I 2024-04-28 22:45:25,819] Trial 30 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  7.28it/s]\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  7.28it/s\u001b[A\n",
      "Average Metric: 2.4444444444444446 / 3  (81.5):   7%| | 2/30 [00:00<00:03,  7.28it/s\u001b[A\n",
      "Average Metric: 3.4444444444444446 / 4  (86.1):  10%| | 3/30 [00:00<00:03,  7.28it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 5  (78.1):  13%|▏| 4/30 [00:00<00:03,  7.28it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 5  (78.1):  17%|▏| 5/30 [00:00<00:01, 23.11it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 6  (65.1):  17%|▏| 5/30 [00:00<00:01, 23.11it/s\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  20%|▏| 6/30 [00:00<00:01, 23.11it/s]\u001b[A\n",
      "Average Metric: 5.039316239316239 / 8  (63.0):  23%|▏| 7/30 [00:00<00:00, 23.11it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 9  (59.7):  27%|▎| 8/30 [00:00<00:00, 23.11it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 23.11it/s\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  33%|▎| 10/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 6.372649572649572 / 12  (53.1):  37%|▎| 11/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 13  (52.9):  40%|▍| 12/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 7.729792429792429 / 14  (55.2):  43%|▍| 13/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 8.229792429792429 / 15  (54.9):  47%|▍| 14/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 8.896459096459095 / 16  (55.6):  50%|▌| 15/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 8.896459096459095 / 17  (52.3):  53%|▌| 16/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 9.896459096459095 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 10.229792429792429 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 10.229792429792429 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 10.729792429792429 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 11.52979242979243 / 22  (52.4):  70%|▋| 21/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 11.52979242979243 / 23  (50.1):  73%|▋| 22/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 12.52979242979243 / 24  (52.2):  77%|▊| 23/30 [00:00<00:00, 31.63it/\u001b[A\n",
      "Average Metric: 13.386935286935287 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 14.386935286935287 / 26  (55.3):  83%|▊| 25/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 15.053601953601953 / 27  (55.8):  87%|▊| 26/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1):  97%|▉| 29/30 [00:00<00:00, 31.63it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 64.47it\u001b[A\n",
      "[I 2024-04-28 22:45:26,334] Trial 31 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4444444444444444 / 1  (44.4):   0%|        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.4444444444444444 / 1  (44.4):   3%| | 1/30 [00:00<00:03,  7.47it/s\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  7.47it/s\u001b[A\n",
      "Average Metric: 1.9059829059829059 / 3  (63.5):   7%| | 2/30 [00:00<00:03,  7.47it/s\u001b[A\n",
      "Average Metric: 2.905982905982906 / 4  (72.6):  10%| | 3/30 [00:00<00:03,  7.47it/s]\u001b[A\n",
      "Average Metric: 3.2393162393162394 / 5  (64.8):  13%|▏| 4/30 [00:00<00:03,  7.47it/s\u001b[A\n",
      "Average Metric: 3.2393162393162394 / 5  (64.8):  17%|▏| 5/30 [00:00<00:01, 23.36it/s\u001b[A\n",
      "Average Metric: 4.239316239316239 / 6  (70.7):  17%|▏| 5/30 [00:00<00:01, 23.36it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  20%|▏| 6/30 [00:00<00:01, 23.36it/s]\u001b[A\n",
      "Average Metric: 4.572649572649572 / 8  (57.2):  23%|▏| 7/30 [00:00<00:00, 23.36it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 9  (59.7):  27%|▎| 8/30 [00:00<00:00, 23.36it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 23.36it/s\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 23.36it/\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  37%|▎| 11/30 [00:00<00:00, 36.92it/\u001b[A\n",
      "Average Metric: 5.872649572649572 / 12  (48.9):  37%|▎| 11/30 [00:00<00:00, 36.92it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 13  (52.9):  40%|▍| 12/30 [00:00<00:00, 36.92it/\u001b[A\n",
      "Average Metric: 7.539316239316239 / 14  (53.9):  43%|▍| 13/30 [00:00<00:00, 36.92it/\u001b[A\n",
      "Average Metric: 8.53931623931624 / 15  (56.9):  47%|▍| 14/30 [00:00<00:00, 36.92it/s\u001b[A\n",
      "Average Metric: 9.03931623931624 / 16  (56.5):  50%|▌| 15/30 [00:00<00:00, 36.92it/s\u001b[A\n",
      "Average Metric: 9.03931623931624 / 17  (53.2):  53%|▌| 16/30 [00:00<00:00, 36.92it/s\u001b[A\n",
      "Average Metric: 9.896459096459097 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 36.92it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 18  (55.0):  60%|▌| 18/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 19  (52.1):  60%|▌| 18/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 11.529792429792431 / 22  (52.4):  70%|▋| 21/30 [00:00<00:00, 48.74it\u001b[A\n",
      "Average Metric: 12.38693528693529 / 23  (53.9):  73%|▋| 22/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 12.38693528693529 / 24  (51.6):  77%|▊| 23/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 13.38693528693529 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 14.38693528693529 / 26  (55.3):  83%|▊| 25/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 15.38693528693529 / 27  (57.0):  87%|▊| 26/30 [00:00<00:00, 48.74it/\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 48.74it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 48.74it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 63.85it\u001b[A\n",
      "[I 2024-04-28 22:45:26,851] Trial 32 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  8.85it/s]\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  8.85it/s\u001b[A\n",
      "Average Metric: 1.9059829059829059 / 3  (63.5):   7%| | 2/30 [00:00<00:03,  8.85it/s\u001b[A\n",
      "Average Metric: 1.9059829059829059 / 4  (47.6):  10%| | 3/30 [00:00<00:03,  8.85it/s\u001b[A\n",
      "Average Metric: 2.2393162393162394 / 5  (44.8):  13%|▏| 4/30 [00:00<00:02,  8.85it/s\u001b[A\n",
      "Average Metric: 3.2393162393162394 / 6  (54.0):  17%|▏| 5/30 [00:00<00:02,  8.85it/s\u001b[A\n",
      "Average Metric: 3.2393162393162394 / 6  (54.0):  20%|▏| 6/30 [00:00<00:00, 28.22it/s\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  20%|▏| 6/30 [00:00<00:00, 28.22it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 8  (53.0):  23%|▏| 7/30 [00:00<00:00, 28.22it/s]\u001b[A\n",
      "Average Metric: 5.039316239316239 / 9  (56.0):  27%|▎| 8/30 [00:00<00:00, 28.22it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 28.22it/s\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 28.22it/\u001b[A\n",
      "Average Metric: 5.872649572649572 / 12  (48.9):  37%|▎| 11/30 [00:00<00:00, 28.22it/\u001b[A\n",
      "Average Metric: 5.872649572649572 / 13  (45.2):  40%|▍| 12/30 [00:00<00:00, 28.22it/\u001b[A\n",
      "Average Metric: 5.872649572649572 / 13  (45.2):  43%|▍| 13/30 [00:00<00:00, 45.14it/\u001b[A\n",
      "Average Metric: 6.729792429792429 / 14  (48.1):  43%|▍| 13/30 [00:00<00:00, 45.14it/\u001b[A\n",
      "Average Metric: 7.229792429792429 / 15  (48.2):  47%|▍| 14/30 [00:00<00:00, 45.14it/\u001b[A\n",
      "Average Metric: 8.229792429792429 / 16  (51.4):  50%|▌| 15/30 [00:00<00:00, 45.14it/\u001b[A\n",
      "Average Metric: 8.896459096459095 / 17  (52.3):  53%|▌| 16/30 [00:00<00:00, 45.14it/\u001b[A\n",
      "Average Metric: 9.896459096459095 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 45.14it/\u001b[A\n",
      "Average Metric: 10.229792429792429 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 45.14it\u001b[A\n",
      "Average Metric: 10.229792429792429 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 45.14it\u001b[A\n",
      "Average Metric: 10.229792429792429 / 20  (51.1):  67%|▋| 20/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 10.729792429792429 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 11.729792429792429 / 22  (53.3):  70%|▋| 21/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 11.729792429792429 / 23  (51.0):  73%|▋| 22/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 12.586935286935287 / 24  (52.4):  77%|▊| 23/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 13.386935286935287 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 14.386935286935287 / 26  (55.3):  83%|▊| 25/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 15.386935286935287 / 27  (57.0):  87%|▊| 26/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 53.57it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 65.09it\u001b[A\n",
      "[I 2024-04-28 22:45:27,366] Trial 33 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:10,  2.44s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:02<01:10,  2.44s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:02<00:34,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:03<00:34,  1.23s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:03<00:21,  1.27it/s]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):  10%|█▌             | 3/30 [00:03<00:21,  1.27it/s]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):  13%|██             | 4/30 [00:03<00:17,  1.48it/s]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):  13%|██             | 4/30 [00:04<00:17,  1.48it/s]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):  17%|██▌            | 5/30 [00:04<00:15,  1.66it/s]\u001b[A\n",
      "Average Metric: 3.0 / 6  (50.0):  17%|██▌            | 5/30 [00:04<00:15,  1.66it/s]\u001b[A\n",
      "Average Metric: 3.0 / 6  (50.0):  20%|███            | 6/30 [00:04<00:15,  1.59it/s]\u001b[A\n",
      "Average Metric: 3.4444444444444446 / 7  (49.2):  20%|▏| 6/30 [00:04<00:15,  1.59it/s\u001b[A\n",
      "Average Metric: 3.4444444444444446 / 7  (49.2):  23%|▏| 7/30 [00:04<00:10,  2.13it/s\u001b[A\n",
      "Average Metric: 4.2444444444444445 / 8  (53.1):  23%|▏| 7/30 [00:05<00:10,  2.13it/s\u001b[A\n",
      "Average Metric: 4.2444444444444445 / 8  (53.1):  27%|▎| 8/30 [00:05<00:13,  1.58it/s\u001b[A\n",
      "Average Metric: 4.7444444444444445 / 9  (52.7):  27%|▎| 8/30 [00:06<00:13,  1.58it/s\u001b[A\n",
      "Average Metric: 4.7444444444444445 / 9  (52.7):  30%|▎| 9/30 [00:06<00:11,  1.87it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.2444444444444445 / 10  (52.4):  30%|▎| 9/30 [00:06<00:11,  1.87it/\u001b[A\n",
      "Average Metric: 5.705982905982906 / 11  (51.9):  33%|▎| 10/30 [00:06<00:10,  1.87it/\u001b[A\n",
      "Average Metric: 5.705982905982906 / 11  (51.9):  37%|▎| 11/30 [00:06<00:05,  3.22it/\u001b[A\n",
      "Average Metric: 6.167521367521368 / 12  (51.4):  37%|▎| 11/30 [00:06<00:05,  3.22it/\u001b[A\n",
      "Average Metric: 6.167521367521368 / 12  (51.4):  40%|▍| 12/30 [00:06<00:06,  2.69it/\u001b[A\n",
      "Average Metric: 7.024664224664225 / 13  (54.0):  40%|▍| 12/30 [00:06<00:06,  2.69it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.024664224664225 / 14  (57.3):  43%|▍| 13/30 [00:08<00:06,  2.69it/\u001b[A\n",
      "Average Metric: 8.024664224664225 / 14  (57.3):  47%|▍| 14/30 [00:08<00:07,  2.10it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.024664224664225 / 15  (53.5):  47%|▍| 14/30 [00:09<00:07,  2.10it/\u001b[A\n",
      "Average Metric: 8.024664224664225 / 15  (53.5):  50%|▌| 15/30 [00:09<00:10,  1.48it/\u001b[A\n",
      "Average Metric: 8.357997557997559 / 16  (52.2):  50%|▌| 15/30 [00:10<00:10,  1.48it/\u001b[A\n",
      "Average Metric: 8.357997557997559 / 16  (52.2):  53%|▌| 16/30 [00:10<00:09,  1.49it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.215140415140416 / 17  (54.2):  53%|▌| 16/30 [00:11<00:09,  1.49it/\u001b[A\n",
      "Average Metric: 9.215140415140416 / 17  (54.2):  57%|▌| 17/30 [00:11<00:10,  1.29it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.500854700854703 / 18  (52.8):  57%|▌| 17/30 [00:11<00:10,  1.29it/\u001b[A\n",
      "Average Metric: 9.500854700854703 / 18  (52.8):  60%|▌| 18/30 [00:11<00:09,  1.29it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.500854700854703 / 19  (50.0):  60%|▌| 18/30 [00:11<00:09,  1.29it/\u001b[A\n",
      "Average Metric: 10.000854700854703 / 20  (50.0):  63%|▋| 19/30 [00:12<00:08,  1.29it\u001b[A\n",
      "Average Metric: 10.000854700854703 / 20  (50.0):  67%|▋| 20/30 [00:12<00:05,  1.97it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.000854700854703 / 21  (47.6):  67%|▋| 20/30 [00:14<00:05,  1.97it\u001b[A\n",
      "Average Metric: 10.000854700854703 / 21  (47.6):  70%|▋| 21/30 [00:14<00:07,  1.25it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.000854700854703 / 22  (50.0):  70%|▋| 21/30 [00:15<00:07,  1.25it\u001b[A\n",
      "Average Metric: 11.000854700854703 / 22  (50.0):  73%|▋| 22/30 [00:15<00:07,  1.05it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.000854700854703 / 23  (47.8):  73%|▋| 22/30 [00:15<00:07,  1.05it\u001b[A\n",
      "Average Metric: 11.000854700854703 / 23  (47.8):  77%|▊| 23/30 [00:15<00:05,  1.28it\u001b[A\n",
      "Average Metric: 11.667521367521369 / 24  (48.6):  77%|▊| 23/30 [00:15<00:05,  1.28it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.667521367521369 / 25  (50.7):  80%|▊| 24/30 [00:16<00:04,  1.28it\u001b[A\n",
      "Average Metric: 12.667521367521369 / 25  (50.7):  83%|▊| 25/30 [00:16<00:03,  1.55it\u001b[A\n",
      "Average Metric: 13.167521367521369 / 26  (50.6):  83%|▊| 25/30 [00:17<00:03,  1.55it\u001b[A\n",
      "Average Metric: 13.167521367521369 / 26  (50.6):  87%|▊| 26/30 [00:17<00:03,  1.27it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.167521367521369 / 27  (48.8):  87%|▊| 26/30 [00:19<00:03,  1.27it\u001b[A\n",
      "Average Metric: 13.167521367521369 / 27  (48.8):  90%|▉| 27/30 [00:19<00:03,  1.04s/\u001b[A\n",
      "Average Metric: 14.024664224664226 / 28  (50.1):  90%|▉| 27/30 [00:21<00:03,  1.04s/\u001b[A\n",
      "Average Metric: 14.024664224664226 / 28  (50.1):  93%|▉| 28/30 [00:21<00:02,  1.19s/\u001b[A\n",
      "Average Metric: 14.881807081807084 / 29  (51.3):  93%|▉| 28/30 [00:21<00:02,  1.19s/\u001b[A\n",
      "Average Metric: 14.881807081807084 / 29  (51.3):  97%|▉| 29/30 [00:21<00:01,  1.00s/\u001b[A\n",
      "Average Metric: 14.881807081807084 / 30  (49.6):  97%|▉| 29/30 [00:22<00:01,  1.00s/\u001b[A\n",
      "Average Metric: 14.881807081807084 / 30  (49.6): 100%|█| 30/30 [00:22<00:00,  1.31it\u001b[A\n",
      "[I 2024-04-28 22:45:50,307] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.881807081807084 / 30  (49.6%)\n",
      "Trial pruned.\n",
      "Starting trial #35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:04<02:11,  4.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.1666666666666665 / 2  (58.3):   3%| | 1/30 [00:06<02:11,  4.55s/it\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 2  (58.3):   7%| | 2/30 [00:06<01:17,  2.77s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.1666666666666665 / 3  (72.2):   7%| | 2/30 [00:07<01:17,  2.77s/it\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 3  (72.2):  10%| | 3/30 [00:07<00:55,  2.05s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.6111111111111107 / 4  (65.3):  10%| | 3/30 [00:08<00:55,  2.05s/it\u001b[A\n",
      "Average Metric: 2.6111111111111107 / 4  (65.3):  13%|▏| 4/30 [00:08<00:42,  1.64s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.6111111111111107 / 5  (52.2):  13%|▏| 4/30 [00:10<00:42,  1.64s/it\u001b[A\n",
      "Average Metric: 2.6111111111111107 / 5  (52.2):  17%|▏| 5/30 [00:10<00:46,  1.85s/it\u001b[A\n",
      "Average Metric: 3.4111111111111105 / 6  (56.9):  17%|▏| 5/30 [00:11<00:46,  1.85s/it\u001b[A\n",
      "Average Metric: 3.4111111111111105 / 6  (56.9):  20%|▏| 6/30 [00:11<00:39,  1.64s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.718803418803418 / 7  (53.1):  20%|▏| 6/30 [00:12<00:39,  1.64s/it]\u001b[A\n",
      "Average Metric: 3.718803418803418 / 7  (53.1):  23%|▏| 7/30 [00:12<00:28,  1.25s/it]\u001b[A\n",
      "Average Metric: 4.118803418803418 / 8  (51.5):  23%|▏| 7/30 [00:12<00:28,  1.25s/it]\u001b[A\n",
      "Average Metric: 4.118803418803418 / 8  (51.5):  27%|▎| 8/30 [00:12<00:22,  1.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.118803418803418 / 9  (56.9):  27%|▎| 8/30 [00:12<00:22,  1.00s/it]\u001b[A\n",
      "Average Metric: 5.118803418803418 / 10  (51.2):  30%|▎| 9/30 [00:12<00:21,  1.00s/it\u001b[A\n",
      "Average Metric: 5.118803418803418 / 10  (51.2):  33%|▎| 10/30 [00:12<00:12,  1.66it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.118803418803418 / 11  (46.5):  33%|▎| 10/30 [00:19<00:12,  1.66it/\u001b[A\n",
      "Average Metric: 5.118803418803418 / 11  (46.5):  37%|▎| 11/30 [00:19<00:40,  2.15s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.118803418803418 / 12  (51.0):  37%|▎| 11/30 [00:20<00:40,  2.15s/i\u001b[A\n",
      "Average Metric: 6.118803418803418 / 12  (51.0):  40%|▍| 12/30 [00:20<00:30,  1.68s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.518803418803419 / 13  (50.1):  40%|▍| 12/30 [00:21<00:30,  1.68s/i\u001b[A\n",
      "Average Metric: 6.518803418803419 / 13  (50.1):  43%|▍| 13/30 [00:21<00:28,  1.70s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.3759462759462755 / 14  (52.7):  43%|▍| 13/30 [00:22<00:28,  1.70s/\u001b[A\n",
      "Average Metric: 7.3759462759462755 / 14  (52.7):  47%|▍| 14/30 [00:22<00:24,  1.54s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.3759462759462755 / 15  (49.2):  47%|▍| 14/30 [00:23<00:24,  1.54s/\u001b[A\n",
      "Average Metric: 7.3759462759462755 / 15  (49.2):  50%|▌| 15/30 [00:23<00:18,  1.20s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.3759462759462755 / 16  (46.1):  50%|▌| 15/30 [00:24<00:18,  1.20s/\u001b[A\n",
      "Average Metric: 7.3759462759462755 / 16  (46.1):  53%|▌| 16/30 [00:24<00:16,  1.19s/\u001b[A\n",
      "Average Metric: 7.3759462759462755 / 17  (43.4):  53%|▌| 16/30 [00:24<00:16,  1.19s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.8759462759462755 / 18  (43.8):  57%|▌| 17/30 [00:26<00:15,  1.19s/\u001b[A\n",
      "Average Metric: 7.8759462759462755 / 18  (43.8):  60%|▌| 18/30 [00:26<00:14,  1.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.375946275946276 / 19  (44.1):  60%|▌| 18/30 [00:27<00:14,  1.17s/i\u001b[A\n",
      "Average Metric: 8.375946275946276 / 19  (44.1):  63%|▋| 19/30 [00:27<00:11,  1.02s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.875946275946276 / 20  (44.4):  63%|▋| 19/30 [00:28<00:11,  1.02s/i\u001b[A\n",
      "Average Metric: 8.875946275946276 / 20  (44.4):  67%|▋| 20/30 [00:28<00:09,  1.04it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.875946275946276 / 21  (47.0):  67%|▋| 20/30 [00:28<00:09,  1.04it/\u001b[A\n",
      "Average Metric: 9.875946275946276 / 21  (47.0):  70%|▋| 21/30 [00:28<00:07,  1.18it/\u001b[A\n",
      "Average Metric: 10.542612942612942 / 22  (47.9):  70%|▋| 21/30 [00:28<00:07,  1.18it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 22.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.542612942612942 / 23  (50.2):  73%|▋| 22/30 [00:31<00:06,  1.18it\u001b[A\n",
      "Average Metric: 11.542612942612942 / 23  (50.2):  77%|▊| 23/30 [00:31<00:08,  1.21s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.875946275946276 / 24  (49.5):  77%|▊| 23/30 [00:32<00:08,  1.21s/\u001b[A\n",
      "Average Metric: 11.875946275946276 / 24  (49.5):  80%|▊| 24/30 [00:32<00:05,  1.01it\u001b[A\n",
      "Average Metric: 11.875946275946276 / 25  (47.5):  80%|▊| 24/30 [00:32<00:05,  1.01it\u001b[A\n",
      "Average Metric: 11.875946275946276 / 25  (47.5):  83%|▊| 25/30 [00:32<00:04,  1.18it\u001b[A\n",
      "Average Metric: 12.733089133089134 / 26  (49.0):  83%|▊| 25/30 [00:34<00:04,  1.18it\u001b[A\n",
      "Average Metric: 12.733089133089134 / 26  (49.0):  87%|▊| 26/30 [00:34<00:04,  1.09s/\u001b[A\n",
      "Average Metric: 12.733089133089134 / 27  (47.2):  87%|▊| 26/30 [00:35<00:04,  1.09s/\u001b[A\n",
      "Average Metric: 12.733089133089134 / 27  (47.2):  90%|▉| 27/30 [00:35<00:03,  1.11s/\u001b[A\n",
      "Average Metric: 13.01880341880342 / 28  (46.5):  90%|▉| 27/30 [00:37<00:03,  1.11s/i\u001b[A\n",
      "Average Metric: 13.01880341880342 / 28  (46.5):  93%|▉| 28/30 [00:37<00:02,  1.30s/i\u001b[A\n",
      "Average Metric: 13.875946275946278 / 29  (47.8):  93%|▉| 28/30 [00:39<00:02,  1.30s/\u001b[A\n",
      "Average Metric: 13.875946275946278 / 29  (47.8):  97%|▉| 29/30 [00:39<00:01,  1.63s/\u001b[A\n",
      "Average Metric: 14.33748473748474 / 30  (47.8):  97%|▉| 29/30 [00:59<00:01,  1.63s/i\u001b[A\n",
      "Average Metric: 14.33748473748474 / 30  (47.8): 100%|█| 30/30 [00:59<00:00,  1.97s/i\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:46:49,539] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.33748473748474 / 30  (47.8%)\n",
      "Trial pruned.\n",
      "Starting trial #36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:03,  2.20s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:02<01:03,  2.20s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):   7%|█              | 2/30 [00:02<01:01,  2.20s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):  10%|█▌             | 3/30 [00:02<00:17,  1.54it/s]\u001b[A\n",
      "Average Metric: 1.3 / 4  (32.5):  10%|█▌             | 3/30 [00:03<00:17,  1.54it/s]\u001b[A\n",
      "Average Metric: 1.3 / 4  (32.5):  13%|██             | 4/30 [00:03<00:16,  1.57it/s]\u001b[A\n",
      "Average Metric: 1.3 / 5  (26.0):  13%|██             | 4/30 [00:03<00:16,  1.57it/s]\u001b[A\n",
      "Average Metric: 1.3 / 5  (26.0):  17%|██▌            | 5/30 [00:03<00:12,  2.06it/s]\u001b[A\n",
      "Average Metric: 1.7000000000000002 / 6  (28.3):  17%|▏| 5/30 [00:03<00:12,  2.06it/s\u001b[A\n",
      "Average Metric: 1.7000000000000002 / 6  (28.3):  20%|▏| 6/30 [00:03<00:10,  2.40it/s\u001b[A\n",
      "Average Metric: 2.3666666666666667 / 7  (33.8):  20%|▏| 6/30 [00:04<00:10,  2.40it/s\u001b[A\n",
      "Average Metric: 2.3666666666666667 / 7  (33.8):  23%|▏| 7/30 [00:04<00:10,  2.14it/s\u001b[A\n",
      "Average Metric: 3.3666666666666667 / 8  (42.1):  23%|▏| 7/30 [00:04<00:10,  2.14it/s\u001b[A\n",
      "Average Metric: 3.3666666666666667 / 8  (42.1):  27%|▎| 8/30 [00:04<00:08,  2.48it/s\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 9  (43.0):  27%|▎| 8/30 [00:04<00:08,  2.48it/s\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 9  (43.0):  30%|▎| 9/30 [00:04<00:10,  2.08it/s\u001b[A\n",
      "Average Metric: 4.366666666666667 / 10  (43.7):  30%|▎| 9/30 [00:04<00:10,  2.08it/s\u001b[A\n",
      "Average Metric: 4.366666666666667 / 11  (39.7):  33%|▎| 10/30 [00:05<00:09,  2.08it/\u001b[A\n",
      "Average Metric: 4.366666666666667 / 11  (39.7):  37%|▎| 11/30 [00:05<00:05,  3.47it/\u001b[A\n",
      "Average Metric: 4.828205128205129 / 12  (40.2):  37%|▎| 11/30 [00:05<00:05,  3.47it/\u001b[A\n",
      "Average Metric: 4.828205128205129 / 12  (40.2):  40%|▍| 12/30 [00:05<00:05,  3.13it/\u001b[A\n",
      "Average Metric: 5.2897435897435905 / 13  (40.7):  40%|▍| 12/30 [00:06<00:05,  3.13it\u001b[A\n",
      "Average Metric: 5.2897435897435905 / 13  (40.7):  43%|▍| 13/30 [00:06<00:08,  1.93it\u001b[A\n",
      "Average Metric: 6.146886446886447 / 14  (43.9):  43%|▍| 13/30 [00:07<00:08,  1.93it/\u001b[A\n",
      "Average Metric: 6.146886446886447 / 14  (43.9):  47%|▍| 14/30 [00:07<00:08,  1.84it/\u001b[A\n",
      "Average Metric: 6.146886446886447 / 15  (41.0):  47%|▍| 14/30 [00:07<00:08,  1.84it/\u001b[A\n",
      "Average Metric: 7.146886446886447 / 16  (44.7):  50%|▌| 15/30 [00:07<00:08,  1.84it/\u001b[A\n",
      "Average Metric: 7.146886446886447 / 16  (44.7):  53%|▌| 16/30 [00:07<00:05,  2.57it/\u001b[A\n",
      "Average Metric: 7.432600732600733 / 17  (43.7):  53%|▌| 16/30 [00:07<00:05,  2.57it/\u001b[A\n",
      "Average Metric: 7.432600732600733 / 17  (43.7):  57%|▌| 17/30 [00:07<00:04,  2.79it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.28974358974359 / 18  (46.1):  57%|▌| 17/30 [00:08<00:04,  2.79it/s\u001b[A\n",
      "Average Metric: 8.28974358974359 / 18  (46.1):  60%|▌| 18/30 [00:08<00:06,  1.86it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.78974358974359 / 19  (46.3):  60%|▌| 18/30 [00:09<00:06,  1.86it/s\u001b[A\n",
      "Average Metric: 8.78974358974359 / 19  (46.3):  63%|▋| 19/30 [00:09<00:04,  2.24it/s\u001b[A\n",
      "Average Metric: 8.78974358974359 / 20  (43.9):  63%|▋| 19/30 [00:09<00:04,  2.24it/s\u001b[A\n",
      "Average Metric: 8.78974358974359 / 20  (43.9):  67%|▋| 20/30 [00:09<00:04,  2.33it/s\u001b[A\n",
      "Average Metric: 9.78974358974359 / 21  (46.6):  67%|▋| 20/30 [00:09<00:04,  2.33it/s\u001b[A\n",
      "Average Metric: 9.78974358974359 / 21  (46.6):  70%|▋| 21/30 [00:09<00:03,  2.34it/s\u001b[A\n",
      "Average Metric: 9.78974358974359 / 22  (44.5):  70%|▋| 21/30 [00:10<00:03,  2.34it/s\u001b[A\n",
      "Average Metric: 9.78974358974359 / 22  (44.5):  73%|▋| 22/30 [00:10<00:02,  2.84it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.78974358974359 / 23  (42.6):  73%|▋| 22/30 [00:11<00:02,  2.84it/s\u001b[A\n",
      "Average Metric: 9.78974358974359 / 23  (42.6):  77%|▊| 23/30 [00:11<00:04,  1.57it/s\u001b[A\n",
      "Average Metric: 10.28974358974359 / 24  (42.9):  77%|▊| 23/30 [00:11<00:04,  1.57it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.575457875457877 / 25  (42.3):  80%|▊| 24/30 [00:12<00:03,  1.57it\u001b[A\n",
      "Average Metric: 10.575457875457877 / 25  (42.3):  83%|▊| 25/30 [00:12<00:02,  1.67it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.575457875457877 / 26  (44.5):  83%|▊| 25/30 [00:14<00:02,  1.67it\u001b[A\n",
      "Average Metric: 11.575457875457877 / 26  (44.5):  87%|▊| 26/30 [00:14<00:03,  1.18it\u001b[A\n",
      "Average Metric: 11.575457875457877 / 27  (42.9):  87%|▊| 26/30 [00:14<00:03,  1.18it\u001b[A\n",
      "Average Metric: 11.575457875457877 / 27  (42.9):  90%|▉| 27/30 [00:14<00:02,  1.49it\u001b[A\n",
      "Average Metric: 12.242124542124543 / 28  (43.7):  90%|▉| 27/30 [00:15<00:02,  1.49it\u001b[A\n",
      "Average Metric: 12.242124542124543 / 28  (43.7):  93%|▉| 28/30 [00:15<00:01,  1.37it\u001b[A\n",
      "Average Metric: 13.242124542124543 / 29  (45.7):  93%|▉| 28/30 [00:15<00:01,  1.37it\u001b[A\n",
      "Average Metric: 13.242124542124543 / 29  (45.7):  97%|▉| 29/30 [00:15<00:00,  1.38it\u001b[A\n",
      "Average Metric: 13.992124542124543 / 30  (46.6):  97%|▉| 29/30 [00:19<00:00,  1.38it\u001b[A\n",
      "Average Metric: 13.992124542124543 / 30  (46.6): 100%|█| 30/30 [00:19<00:00,  1.56it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:47:08,965] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.992124542124543 / 30  (46.6%)\n",
      "Trial pruned.\n",
      "Starting trial #37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:40,  3.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.8888888888888888 / 2  (44.4):   3%| | 1/30 [00:04<01:40,  3.47s/it\u001b[A\n",
      "Average Metric: 0.8888888888888888 / 2  (44.4):   7%| | 2/30 [00:04<01:00,  2.15s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.8888888888888888 / 3  (29.6):   7%| | 2/30 [00:05<01:00,  2.15s/it\u001b[A\n",
      "Average Metric: 0.8888888888888888 / 3  (29.6):  10%| | 3/30 [00:05<00:42,  1.58s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.5555555555555554 / 4  (38.9):  10%| | 3/30 [00:06<00:42,  1.58s/it\u001b[A\n",
      "Average Metric: 1.5555555555555554 / 4  (38.9):  13%|▏| 4/30 [00:06<00:34,  1.31s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.5555555555555554 / 5  (31.1):  13%|▏| 4/30 [00:07<00:34,  1.31s/it\u001b[A\n",
      "Average Metric: 1.5555555555555554 / 5  (31.1):  17%|▏| 5/30 [00:07<00:30,  1.21s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0555555555555554 / 6  (34.3):  17%|▏| 5/30 [00:08<00:30,  1.21s/it\u001b[A\n",
      "Average Metric: 2.0555555555555554 / 6  (34.3):  20%|▏| 6/30 [00:08<00:29,  1.22s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.8055555555555554 / 7  (40.1):  20%|▏| 6/30 [00:10<00:29,  1.22s/it\u001b[A\n",
      "Average Metric: 2.8055555555555554 / 7  (40.1):  23%|▏| 7/30 [00:10<00:29,  1.29s/it\u001b[A\n",
      "Average Metric: 3.6626984126984126 / 8  (45.8):  23%|▏| 7/30 [00:10<00:29,  1.29s/it\u001b[A\n",
      "Average Metric: 3.6626984126984126 / 8  (45.8):  27%|▎| 8/30 [00:10<00:23,  1.08s/it\u001b[A\n",
      "Average Metric: 3.6626984126984126 / 9  (40.7):  27%|▎| 8/30 [00:11<00:23,  1.08s/it\u001b[A\n",
      "Average Metric: 3.6626984126984126 / 9  (40.7):  30%|▎| 9/30 [00:11<00:19,  1.06it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.662698412698413 / 10  (46.6):  30%|▎| 9/30 [00:12<00:19,  1.06it/s\u001b[A\n",
      "Average Metric: 4.662698412698413 / 10  (46.6):  33%|▎| 10/30 [00:12<00:17,  1.15it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.662698412698413 / 11  (42.4):  33%|▎| 10/30 [00:15<00:17,  1.15it/\u001b[A\n",
      "Average Metric: 4.662698412698413 / 11  (42.4):  37%|▎| 11/30 [00:15<00:28,  1.52s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.32936507936508 / 12  (44.4):  37%|▎| 11/30 [00:16<00:28,  1.52s/it\u001b[A\n",
      "Average Metric: 5.32936507936508 / 12  (44.4):  40%|▍| 12/30 [00:16<00:25,  1.39s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.32936507936508 / 13  (41.0):  40%|▍| 12/30 [00:16<00:25,  1.39s/it\u001b[A\n",
      "Average Metric: 5.32936507936508 / 13  (41.0):  43%|▍| 13/30 [00:16<00:18,  1.09s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.32936507936508 / 14  (38.1):  43%|▍| 13/30 [00:17<00:18,  1.09s/it\u001b[A\n",
      "Average Metric: 5.32936507936508 / 14  (38.1):  47%|▍| 14/30 [00:17<00:18,  1.15s/it\u001b[A\n",
      "Average Metric: 5.72936507936508 / 15  (38.2):  47%|▍| 14/30 [00:18<00:18,  1.15s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 27.5 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.72936507936508 / 16  (35.8):  50%|▌| 15/30 [00:20<00:17,  1.15s/it\u001b[A\n",
      "Average Metric: 5.72936507936508 / 16  (35.8):  53%|▌| 16/30 [00:20<00:15,  1.13s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.72936507936508 / 17  (33.7):  53%|▌| 16/30 [00:21<00:15,  1.13s/it\u001b[A\n",
      "Average Metric: 5.72936507936508 / 17  (33.7):  57%|▌| 17/30 [00:21<00:16,  1.23s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.72936507936508 / 18  (31.8):  57%|▌| 17/30 [00:22<00:16,  1.23s/it\u001b[A\n",
      "Average Metric: 5.72936507936508 / 18  (31.8):  60%|▌| 18/30 [00:22<00:13,  1.14s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.396031746031747 / 19  (33.7):  60%|▌| 18/30 [00:23<00:13,  1.14s/i\u001b[A\n",
      "Average Metric: 6.396031746031747 / 19  (33.7):  63%|▋| 19/30 [00:23<00:11,  1.02s/i\u001b[A\n",
      "Average Metric: 7.062698412698414 / 20  (35.3):  63%|▋| 19/30 [00:23<00:11,  1.02s/i\u001b[A\n",
      "Average Metric: 7.062698412698414 / 20  (35.3):  67%|▋| 20/30 [00:23<00:09,  1.10it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.062698412698413 / 21  (38.4):  67%|▋| 20/30 [00:26<00:09,  1.10it/\u001b[A\n",
      "Average Metric: 8.062698412698413 / 21  (38.4):  70%|▋| 21/30 [00:26<00:11,  1.25s/i\u001b[A\n",
      "Average Metric: 8.062698412698413 / 22  (36.6):  70%|▋| 21/30 [00:26<00:11,  1.25s/i\u001b[A\n",
      "Average Metric: 8.062698412698413 / 22  (36.6):  73%|▋| 22/30 [00:26<00:09,  1.15s/i\u001b[A\n",
      "Average Metric: 9.062698412698413 / 23  (39.4):  73%|▋| 22/30 [00:27<00:09,  1.15s/i\u001b[A\n",
      "Average Metric: 9.062698412698413 / 23  (39.4):  77%|▊| 23/30 [00:27<00:06,  1.16it/\u001b[A\n",
      "Average Metric: 9.72936507936508 / 24  (40.5):  77%|▊| 23/30 [00:27<00:06,  1.16it/s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 9.72936507936508 / 24  (40.5):  80%|▊| 24/30 [00:27<00:04,  1.25it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.72936507936508 / 25  (42.9):  80%|▊| 24/30 [00:28<00:04,  1.25it/\u001b[A\n",
      "Average Metric: 10.72936507936508 / 25  (42.9):  83%|▊| 25/30 [00:28<00:04,  1.14it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.586507936507937 / 26  (44.6):  83%|▊| 25/30 [00:29<00:04,  1.14it\u001b[A\n",
      "Average Metric: 11.586507936507937 / 26  (44.6):  87%|▊| 26/30 [00:29<00:03,  1.06it\u001b[A\n",
      "Average Metric: 12.443650793650795 / 27  (46.1):  87%|▊| 26/30 [00:31<00:03,  1.06it\u001b[A\n",
      "Average Metric: 12.443650793650795 / 27  (46.1):  90%|▉| 27/30 [00:31<00:03,  1.28s/\u001b[A\n",
      "Average Metric: 12.905189255189256 / 28  (46.1):  90%|▉| 27/30 [00:32<00:03,  1.28s/\u001b[A\n",
      "Average Metric: 12.905189255189256 / 28  (46.1):  93%|▉| 28/30 [00:32<00:02,  1.04s/\u001b[A\n",
      "Average Metric: 13.405189255189256 / 29  (46.2):  93%|▉| 28/30 [00:33<00:02,  1.04s/\u001b[A\n",
      "Average Metric: 13.405189255189256 / 29  (46.2):  97%|▉| 29/30 [00:33<00:00,  1.03it\u001b[A\n",
      "Average Metric: 13.905189255189256 / 30  (46.4):  97%|▉| 29/30 [00:47<00:00,  1.03it\u001b[A\n",
      "Average Metric: 13.905189255189256 / 30  (46.4): 100%|█| 30/30 [00:47<00:00,  1.60s/\u001b[A\n",
      "[I 2024-04-28 22:47:56,975] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.905189255189256 / 30  (46.4%)\n",
      "Trial pruned.\n",
      "Starting trial #38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:07,  2.32s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:02<01:07,  2.32s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:02<00:30,  1.07s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:02<00:30,  1.07s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:02<00:18,  1.46it/s]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  10%|█▌             | 3/30 [00:03<00:18,  1.46it/s]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  13%|██             | 4/30 [00:03<00:16,  1.62it/s]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):  13%|██             | 4/30 [00:03<00:16,  1.62it/s]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):  17%|██▌            | 5/30 [00:03<00:13,  1.82it/s]\u001b[A\n",
      "Average Metric: 3.0 / 6  (50.0):  17%|██▌            | 5/30 [00:03<00:13,  1.82it/s]\u001b[A\n",
      "Average Metric: 3.8 / 7  (54.3):  20%|███            | 6/30 [00:04<00:13,  1.82it/s]\u001b[A\n",
      "Average Metric: 3.8 / 7  (54.3):  23%|███▌           | 7/30 [00:04<00:09,  2.40it/s]\u001b[A\n",
      "Average Metric: 4.3 / 8  (53.8):  23%|███▌           | 7/30 [00:05<00:09,  2.40it/s]\u001b[A\n",
      "Average Metric: 4.3 / 8  (53.8):  27%|████           | 8/30 [00:05<00:12,  1.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.7615384615384615 / 9  (52.9):  27%|▎| 8/30 [00:05<00:12,  1.70it/s\u001b[A\n",
      "Average Metric: 4.7615384615384615 / 9  (52.9):  30%|▎| 9/30 [00:05<00:11,  1.80it/s\u001b[A\n",
      "Average Metric: 4.7615384615384615 / 10  (47.6):  30%|▎| 9/30 [00:05<00:11,  1.80it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.205982905982906 / 11  (47.3):  33%|▎| 10/30 [00:06<00:11,  1.80it/\u001b[A\n",
      "Average Metric: 5.205982905982906 / 11  (47.3):  37%|▎| 11/30 [00:06<00:09,  2.05it/\u001b[A\n",
      "Average Metric: 6.063125763125763 / 12  (50.5):  37%|▎| 11/30 [00:07<00:09,  2.05it/\u001b[A\n",
      "Average Metric: 6.063125763125763 / 12  (50.5):  40%|▍| 12/30 [00:07<00:08,  2.01it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.563125763125763 / 13  (50.5):  40%|▍| 12/30 [00:08<00:08,  2.01it/\u001b[A\n",
      "Average Metric: 6.563125763125763 / 13  (50.5):  43%|▍| 13/30 [00:08<00:13,  1.24it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.896459096459096 / 14  (49.3):  43%|▍| 13/30 [00:09<00:13,  1.24it/\u001b[A\n",
      "Average Metric: 6.896459096459096 / 14  (49.3):  47%|▍| 14/30 [00:09<00:13,  1.17it/\u001b[A\n",
      "Average Metric: 7.753601953601953 / 15  (51.7):  47%|▍| 14/30 [00:09<00:13,  1.17it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.253601953601953 / 16  (51.6):  50%|▌| 15/30 [00:11<00:12,  1.17it/\u001b[A\n",
      "Average Metric: 8.253601953601953 / 16  (51.6):  53%|▌| 16/30 [00:11<00:10,  1.33it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.253601953601953 / 17  (48.6):  53%|▌| 16/30 [00:13<00:10,  1.33it/\u001b[A\n",
      "Average Metric: 8.253601953601953 / 17  (48.6):  57%|▌| 17/30 [00:13<00:13,  1.05s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.253601953601953 / 18  (45.9):  57%|▌| 17/30 [00:13<00:13,  1.05s/i\u001b[A\n",
      "Average Metric: 8.253601953601953 / 18  (45.9):  60%|▌| 18/30 [00:13<00:11,  1.03it/\u001b[A\n",
      "Average Metric: 8.53931623931624 / 19  (44.9):  60%|▌| 18/30 [00:15<00:11,  1.03it/s\u001b[A\n",
      "Average Metric: 8.53931623931624 / 19  (44.9):  63%|▋| 19/30 [00:15<00:11,  1.07s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.53931623931624 / 20  (47.7):  63%|▋| 19/30 [00:16<00:11,  1.07s/it\u001b[A\n",
      "Average Metric: 9.53931623931624 / 20  (47.7):  67%|▋| 20/30 [00:16<00:11,  1.17s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.53931623931624 / 21  (45.4):  67%|▋| 20/30 [00:17<00:11,  1.17s/it\u001b[A\n",
      "Average Metric: 9.53931623931624 / 21  (45.4):  70%|▋| 21/30 [00:17<00:10,  1.19s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.0008547008547 / 22  (45.5):  70%|▋| 21/30 [00:19<00:10,  1.19s/it\u001b[A\n",
      "Average Metric: 10.0008547008547 / 22  (45.5):  73%|▋| 22/30 [00:19<00:10,  1.28s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 16.0 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.857997557997559 / 23  (47.2):  73%|▋| 22/30 [00:20<00:10,  1.28s/\u001b[A\n",
      "Average Metric: 10.857997557997559 / 23  (47.2):  77%|▊| 23/30 [00:20<00:09,  1.37s/\u001b[A\n",
      "Average Metric: 10.857997557997559 / 24  (45.2):  77%|▊| 23/30 [00:21<00:09,  1.37s/\u001b[A\n",
      "Average Metric: 10.857997557997559 / 24  (45.2):  80%|▊| 24/30 [00:21<00:06,  1.06s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.715140415140416 / 25  (46.9):  80%|▊| 24/30 [00:22<00:06,  1.06s/\u001b[A\n",
      "Average Metric: 11.715140415140416 / 25  (46.9):  83%|▊| 25/30 [00:22<00:06,  1.22s/\u001b[A\n",
      "Average Metric: 12.715140415140416 / 26  (48.9):  83%|▊| 25/30 [00:23<00:06,  1.22s/\u001b[A\n",
      "Average Metric: 12.715140415140416 / 26  (48.9):  87%|▊| 26/30 [00:23<00:04,  1.13s/\u001b[A\n",
      "Average Metric: 13.215140415140416 / 27  (48.9):  87%|▊| 26/30 [00:24<00:04,  1.13s/\u001b[A\n",
      "Average Metric: 13.215140415140416 / 27  (48.9):  90%|▉| 27/30 [00:24<00:02,  1.13it\u001b[A\n",
      "Average Metric: 13.881807081807082 / 28  (49.6):  90%|▉| 27/30 [00:27<00:02,  1.13it\u001b[A\n",
      "Average Metric: 13.881807081807082 / 28  (49.6):  93%|▉| 28/30 [00:27<00:03,  1.74s/\u001b[A\n",
      "Average Metric: 13.881807081807082 / 29  (47.9):  93%|▉| 28/30 [00:34<00:03,  1.74s/\u001b[A\n",
      "Average Metric: 13.881807081807082 / 29  (47.9):  97%|▉| 29/30 [00:34<00:03,  3.19s/\u001b[A\n",
      "Average Metric: 14.881807081807082 / 30  (49.6):  97%|▉| 29/30 [00:37<00:03,  3.19s/\u001b[A\n",
      "Average Metric: 14.881807081807082 / 30  (49.6): 100%|█| 30/30 [00:37<00:00,  1.25s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:48:34,640] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.881807081807082 / 30  (49.6%)\n",
      "Trial pruned.\n",
      "Starting trial #39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.8 / 1  (80.0):   0%|                       | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.8 / 1  (80.0):   3%|▌              | 1/30 [00:02<01:07,  2.33s/it]\u001b[A\n",
      "Average Metric: 0.8 / 2  (40.0):   3%|▌              | 1/30 [00:02<01:07,  2.33s/it]\u001b[A\n",
      "Average Metric: 0.8 / 2  (40.0):   7%|█              | 2/30 [00:02<00:35,  1.27s/it]\u001b[A\n",
      "Average Metric: 0.8 / 3  (26.7):   7%|█              | 2/30 [00:03<00:35,  1.27s/it]\u001b[A\n",
      "Average Metric: 0.8 / 3  (26.7):  10%|█▌             | 3/30 [00:03<00:28,  1.06s/it]\u001b[A\n",
      "Average Metric: 1.8 / 4  (45.0):  10%|█▌             | 3/30 [00:03<00:28,  1.06s/it]\u001b[A\n",
      "Average Metric: 1.8 / 4  (45.0):  13%|██             | 4/30 [00:03<00:18,  1.40it/s]\u001b[A\n",
      "Average Metric: 1.8 / 5  (36.0):  13%|██             | 4/30 [00:03<00:18,  1.40it/s]\u001b[A\n",
      "Average Metric: 2.2 / 6  (36.7):  17%|██▌            | 5/30 [00:04<00:17,  1.40it/s]\u001b[A\n",
      "Average Metric: 2.2 / 6  (36.7):  20%|███            | 6/30 [00:04<00:09,  2.65it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.2 / 7  (31.4):  20%|███            | 6/30 [00:05<00:09,  2.65it/s]\u001b[A\n",
      "Average Metric: 2.2 / 7  (31.4):  23%|███▌           | 7/30 [00:05<00:14,  1.57it/s]\u001b[A\n",
      "Average Metric: 2.2 / 8  (27.5):  23%|███▌           | 7/30 [00:05<00:14,  1.57it/s]\u001b[A\n",
      "Average Metric: 2.2 / 9  (24.4):  27%|████           | 8/30 [00:05<00:13,  1.57it/s]\u001b[A\n",
      "Average Metric: 2.2 / 9  (24.4):  30%|████▌          | 9/30 [00:05<00:09,  2.12it/s]\u001b[A\n",
      "Average Metric: 2.563636363636364 / 10  (25.6):  30%|▎| 9/30 [00:06<00:09,  2.12it/s\u001b[A\n",
      "Average Metric: 2.563636363636364 / 10  (25.6):  33%|▎| 10/30 [00:06<00:08,  2.25it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.063636363636364 / 11  (27.9):  33%|▎| 10/30 [00:06<00:08,  2.25it/\u001b[A\n",
      "Average Metric: 3.063636363636364 / 11  (27.9):  37%|▎| 11/30 [00:06<00:08,  2.15it/\u001b[A\n",
      "Average Metric: 4.063636363636364 / 12  (33.9):  37%|▎| 11/30 [00:07<00:08,  2.15it/\u001b[A\n",
      "Average Metric: 4.063636363636364 / 12  (33.9):  40%|▍| 12/30 [00:07<00:07,  2.38it/\u001b[A\n",
      "Average Metric: 5.063636363636364 / 13  (39.0):  40%|▍| 12/30 [00:07<00:07,  2.38it/\u001b[A\n",
      "Average Metric: 5.063636363636364 / 13  (39.0):  43%|▍| 13/30 [00:07<00:05,  2.96it/\u001b[A\n",
      "Average Metric: 5.492207792207793 / 14  (39.2):  43%|▍| 13/30 [00:07<00:05,  2.96it/\u001b[A\n",
      "Average Metric: 5.492207792207793 / 14  (39.2):  47%|▍| 14/30 [00:07<00:06,  2.41it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.492207792207793 / 15  (36.6):  47%|▍| 14/30 [00:09<00:06,  2.41it/\u001b[A\n",
      "Average Metric: 5.492207792207793 / 15  (36.6):  50%|▌| 15/30 [00:09<00:13,  1.08it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.292207792207793 / 16  (39.3):  50%|▌| 15/30 [00:11<00:13,  1.08it/\u001b[A\n",
      "Average Metric: 6.292207792207793 / 16  (39.3):  53%|▌| 16/30 [00:11<00:15,  1.07s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.292207792207793 / 17  (37.0):  53%|▌| 16/30 [00:12<00:15,  1.07s/i\u001b[A\n",
      "Average Metric: 6.292207792207793 / 17  (37.0):  57%|▌| 17/30 [00:12<00:15,  1.21s/i\u001b[A\n",
      "Average Metric: 6.667207792207793 / 18  (37.0):  57%|▌| 17/30 [00:13<00:15,  1.21s/i\u001b[A\n",
      "Average Metric: 6.667207792207793 / 18  (37.0):  60%|▌| 18/30 [00:13<00:12,  1.06s/i\u001b[A\n",
      "Average Metric: 6.667207792207793 / 19  (35.1):  60%|▌| 18/30 [00:13<00:12,  1.06s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.667207792207793 / 20  (33.3):  63%|▋| 19/30 [00:15<00:11,  1.06s/i\u001b[A\n",
      "Average Metric: 6.667207792207793 / 20  (33.3):  67%|▋| 20/30 [00:15<00:10,  1.04s/i\u001b[A\n",
      "Average Metric: 7.667207792207793 / 21  (36.5):  67%|▋| 20/30 [00:15<00:10,  1.04s/i\u001b[A\n",
      "Average Metric: 7.667207792207793 / 21  (36.5):  70%|▋| 21/30 [00:15<00:07,  1.16it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.667207792207794 / 22  (39.4):  70%|▋| 21/30 [00:17<00:07,  1.16it/\u001b[A\n",
      "Average Metric: 8.667207792207794 / 22  (39.4):  73%|▋| 22/30 [00:17<00:08,  1.05s/i\u001b[A\n",
      "Average Metric: 9.33387445887446 / 23  (40.6):  73%|▋| 22/30 [00:18<00:08,  1.05s/it\u001b[A\n",
      "Average Metric: 9.33387445887446 / 23  (40.6):  77%|▊| 23/30 [00:18<00:07,  1.06s/it\u001b[A\n",
      "Average Metric: 9.33387445887446 / 24  (38.9):  77%|▊| 23/30 [00:18<00:07,  1.06s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.000541125541126 / 25  (40.0):  80%|▊| 24/30 [00:20<00:06,  1.06s/\u001b[A\n",
      "Average Metric: 10.000541125541126 / 25  (40.0):  83%|▊| 25/30 [00:20<00:05,  1.01s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.857683982683984 / 26  (41.8):  83%|▊| 25/30 [00:21<00:05,  1.01s/\u001b[A\n",
      "Average Metric: 10.857683982683984 / 26  (41.8):  87%|▊| 26/30 [00:21<00:04,  1.04s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.857683982683984 / 27  (43.9):  87%|▊| 26/30 [00:22<00:04,  1.04s/\u001b[A\n",
      "Average Metric: 11.857683982683984 / 27  (43.9):  90%|▉| 27/30 [00:22<00:02,  1.08it\u001b[A\n",
      "Average Metric: 12.14339826839827 / 28  (43.4):  90%|▉| 27/30 [00:24<00:02,  1.08it/\u001b[A\n",
      "Average Metric: 12.14339826839827 / 28  (43.4):  93%|▉| 28/30 [00:24<00:02,  1.16s/i\u001b[A\n",
      "Average Metric: 13.000541125541128 / 29  (44.8):  93%|▉| 28/30 [00:29<00:02,  1.16s/\u001b[A\n",
      "Average Metric: 13.000541125541128 / 29  (44.8):  97%|▉| 29/30 [00:29<00:02,  2.32s/\u001b[A\n",
      "Average Metric: 13.000541125541128 / 30  (43.3):  97%|▉| 29/30 [00:29<00:02,  2.32s/\u001b[A\n",
      "Average Metric: 13.000541125541128 / 30  (43.3): 100%|█| 30/30 [00:29<00:00,  1.01it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:49:04,279] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.000541125541128 / 30  (43.3%)\n",
      "Trial pruned.\n",
      "Starting trial #40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:27,  3.02s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:03<01:27,  3.02s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:03<00:47,  1.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.8 / 3  (60.0):   7%|█              | 2/30 [00:05<00:47,  1.71s/it]\u001b[A\n",
      "Average Metric: 1.8 / 3  (60.0):  10%|█▌             | 3/30 [00:05<00:50,  1.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.8 / 4  (45.0):  10%|█▌             | 3/30 [00:07<00:50,  1.88s/it]\u001b[A\n",
      "Average Metric: 1.8 / 4  (45.0):  13%|██             | 4/30 [00:07<00:46,  1.78s/it]\u001b[A\n",
      "Average Metric: 2.8 / 5  (56.0):  13%|██             | 4/30 [00:07<00:46,  1.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.3 / 6  (55.0):  17%|██▌            | 5/30 [00:08<00:44,  1.78s/it]\u001b[A\n",
      "Average Metric: 3.3 / 6  (55.0):  20%|███            | 6/30 [00:08<00:25,  1.06s/it]\u001b[A\n",
      "Average Metric: 3.728571428571428 / 7  (53.3):  20%|▏| 6/30 [00:09<00:25,  1.06s/it]\u001b[A\n",
      "Average Metric: 3.728571428571428 / 7  (53.3):  23%|▏| 7/30 [00:09<00:21,  1.06it/s]\u001b[A\n",
      "Average Metric: 4.228571428571428 / 8  (52.9):  23%|▏| 7/30 [00:09<00:21,  1.06it/s]\u001b[A\n",
      "Average Metric: 4.228571428571428 / 8  (52.9):  27%|▎| 8/30 [00:09<00:17,  1.28it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.628571428571428 / 9  (51.4):  27%|▎| 8/30 [00:09<00:17,  1.28it/s]\u001b[A\n",
      "Average Metric: 4.628571428571428 / 9  (51.4):  30%|▎| 9/30 [00:09<00:13,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.628571428571428 / 10  (46.3):  30%|▎| 9/30 [00:10<00:13,  1.58it/s\u001b[A\n",
      "Average Metric: 4.628571428571428 / 10  (46.3):  33%|▎| 10/30 [00:10<00:11,  1.77it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.073015873015873 / 11  (46.1):  33%|▎| 10/30 [00:10<00:11,  1.77it/\u001b[A\n",
      "Average Metric: 5.073015873015873 / 11  (46.1):  37%|▎| 11/30 [00:10<00:08,  2.18it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.073015873015873 / 12  (42.3):  37%|▎| 11/30 [00:12<00:08,  2.18it/\u001b[A\n",
      "Average Metric: 5.073015873015873 / 12  (42.3):  40%|▍| 12/30 [00:12<00:15,  1.13it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.9301587301587295 / 13  (45.6):  40%|▍| 12/30 [00:12<00:15,  1.13it\u001b[A\n",
      "Average Metric: 5.9301587301587295 / 13  (45.6):  43%|▍| 13/30 [00:12<00:11,  1.49it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.4301587301587295 / 14  (45.9):  43%|▍| 13/30 [00:13<00:11,  1.49it\u001b[A\n",
      "Average Metric: 6.4301587301587295 / 14  (45.9):  47%|▍| 14/30 [00:13<00:11,  1.44it\u001b[A\n",
      "Average Metric: 7.0968253968253965 / 15  (47.3):  47%|▍| 14/30 [00:13<00:11,  1.44it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.0968253968253965 / 16  (44.4):  50%|▌| 15/30 [00:14<00:10,  1.44it\u001b[A\n",
      "Average Metric: 7.0968253968253965 / 16  (44.4):  53%|▌| 16/30 [00:14<00:09,  1.44it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.0968253968253965 / 17  (41.7):  53%|▌| 16/30 [00:16<00:09,  1.44it\u001b[A\n",
      "Average Metric: 7.0968253968253965 / 17  (41.7):  57%|▌| 17/30 [00:16<00:13,  1.05s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.558363858363858 / 18  (42.0):  57%|▌| 17/30 [00:17<00:13,  1.05s/i\u001b[A\n",
      "Average Metric: 7.558363858363858 / 18  (42.0):  60%|▌| 18/30 [00:17<00:11,  1.07it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.225030525030524 / 19  (43.3):  60%|▌| 18/30 [00:18<00:11,  1.07it/\u001b[A\n",
      "Average Metric: 8.225030525030524 / 19  (43.3):  63%|▋| 19/30 [00:18<00:10,  1.00it/\u001b[A\n",
      "Average Metric: 9.225030525030524 / 20  (46.1):  63%|▋| 19/30 [00:18<00:10,  1.00it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.558363858363858 / 21  (45.5):  67%|▋| 20/30 [00:19<00:09,  1.00it/\u001b[A\n",
      "Average Metric: 9.558363858363858 / 21  (45.5):  70%|▋| 21/30 [00:19<00:07,  1.19it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.558363858363858 / 22  (48.0):  70%|▋| 21/30 [00:20<00:07,  1.19it\u001b[A\n",
      "Average Metric: 10.558363858363858 / 22  (48.0):  73%|▋| 22/30 [00:20<00:06,  1.19it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.558363858363858 / 23  (45.9):  73%|▋| 22/30 [00:21<00:06,  1.19it\u001b[A\n",
      "Average Metric: 10.558363858363858 / 23  (45.9):  77%|▊| 23/30 [00:21<00:06,  1.09it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.558363858363858 / 24  (44.0):  77%|▊| 23/30 [00:22<00:06,  1.09it\u001b[A\n",
      "Average Metric: 10.558363858363858 / 24  (44.0):  80%|▊| 24/30 [00:22<00:05,  1.10it\u001b[A\n",
      "Average Metric: 11.415506715506716 / 25  (45.7):  80%|▊| 24/30 [00:22<00:05,  1.10it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.415506715506716 / 26  (43.9):  83%|▊| 25/30 [00:23<00:04,  1.10it\u001b[A\n",
      "Average Metric: 11.415506715506716 / 26  (43.9):  87%|▊| 26/30 [00:23<00:03,  1.23it\u001b[A\n",
      "Average Metric: 11.815506715506716 / 27  (43.8):  87%|▊| 26/30 [00:24<00:03,  1.23it\u001b[A\n",
      "Average Metric: 11.815506715506716 / 27  (43.8):  90%|▉| 27/30 [00:24<00:02,  1.40it\u001b[A\n",
      "Average Metric: 12.315506715506716 / 28  (44.0):  90%|▉| 27/30 [00:25<00:02,  1.40it\u001b[A\n",
      "Average Metric: 12.315506715506716 / 28  (44.0):  93%|▉| 28/30 [00:25<00:01,  1.25it\u001b[A\n",
      "Average Metric: 13.172649572649574 / 29  (45.4):  93%|▉| 28/30 [00:26<00:01,  1.25it\u001b[A\n",
      "Average Metric: 13.172649572649574 / 29  (45.4):  97%|▉| 29/30 [00:26<00:00,  1.07it\u001b[A\n",
      "Average Metric: 13.172649572649574 / 30  (43.9):  97%|▉| 29/30 [00:29<00:00,  1.07it\u001b[A\n",
      "Average Metric: 13.172649572649574 / 30  (43.9): 100%|█| 30/30 [00:29<00:00,  1.00it\u001b[A\n",
      "[I 2024-04-28 22:49:34,271] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.172649572649574 / 30  (43.9%)\n",
      "Trial pruned.\n",
      "Starting trial #41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  8.28it/s]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:00<00:03,  8.28it/s]\u001b[A\n",
      "Average Metric: 2.4444444444444446 / 3  (81.5):   7%| | 2/30 [00:00<00:03,  8.28it/s\u001b[A\n",
      "Average Metric: 2.777777777777778 / 4  (69.4):  10%| | 3/30 [00:00<00:03,  8.28it/s]\u001b[A\n",
      "Average Metric: 3.23931623931624 / 5  (64.8):  13%|▎ | 4/30 [00:00<00:03,  8.28it/s]\u001b[A\n",
      "Average Metric: 3.23931623931624 / 6  (54.0):  17%|▎ | 5/30 [00:00<00:03,  8.28it/s]\u001b[A\n",
      "Average Metric: 3.23931623931624 / 6  (54.0):  20%|▍ | 6/30 [00:00<00:00, 29.12it/s]\u001b[A\n",
      "Average Metric: 4.23931623931624 / 7  (60.6):  20%|▍ | 6/30 [00:00<00:00, 29.12it/s]\u001b[A\n",
      "Average Metric: 4.23931623931624 / 8  (53.0):  23%|▍ | 7/30 [00:00<00:00, 29.12it/s]\u001b[A\n",
      "Average Metric: 4.572649572649573 / 9  (50.8):  27%|▎| 8/30 [00:00<00:00, 29.12it/s]\u001b[A\n",
      "Average Metric: 5.372649572649573 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 29.12it/s\u001b[A\n",
      "Average Metric: 5.372649572649573 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 29.12it/\u001b[A\n",
      "Average Metric: 5.372649572649573 / 11  (48.8):  37%|▎| 11/30 [00:00<00:00, 34.88it/\u001b[A\n",
      "Average Metric: 5.872649572649573 / 12  (48.9):  37%|▎| 11/30 [00:00<00:00, 34.88it/\u001b[A\n",
      "Average Metric: 6.372649572649573 / 13  (49.0):  40%|▍| 12/30 [00:00<00:00, 34.88it/\u001b[A\n",
      "Average Metric: 7.372649572649573 / 14  (52.7):  43%|▍| 13/30 [00:00<00:00, 34.88it/\u001b[A\n",
      "Average Metric: 8.03931623931624 / 15  (53.6):  47%|▍| 14/30 [00:00<00:00, 34.88it/s\u001b[A\n",
      "Average Metric: 8.03931623931624 / 16  (50.2):  50%|▌| 15/30 [00:00<00:00, 34.88it/s\u001b[A\n",
      "Average Metric: 8.03931623931624 / 16  (50.2):  53%|▌| 16/30 [00:00<00:00, 39.72it/s\u001b[A\n",
      "Average Metric: 8.896459096459097 / 17  (52.3):  53%|▌| 16/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 22  (48.8):  70%|▋| 21/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 11.529792429792431 / 23  (50.1):  73%|▋| 22/30 [00:00<00:00, 39.72it\u001b[A\n",
      "Average Metric: 12.38693528693529 / 24  (51.6):  77%|▊| 23/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 13.38693528693529 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 14.38693528693529 / 26  (55.3):  83%|▊| 25/30 [00:00<00:00, 39.72it/\u001b[A\n",
      "Average Metric: 15.053601953601955 / 27  (55.8):  87%|▊| 26/30 [00:00<00:00, 39.72it\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 39.72it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 39.72it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 57.39it\u001b[A\n",
      "[I 2024-04-28 22:49:34,857] Trial 41 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:04,  6.17it/s]\u001b[A\n",
      "Average Metric: 1.4615384615384617 / 2  (73.1):   3%| | 1/30 [00:00<00:04,  6.17it/s\u001b[A\n",
      "Average Metric: 1.905982905982906 / 3  (63.5):   7%| | 2/30 [00:00<00:04,  6.17it/s]\u001b[A\n",
      "Average Metric: 2.9059829059829063 / 4  (72.6):  10%| | 3/30 [00:00<00:04,  6.17it/s\u001b[A\n",
      "Average Metric: 2.9059829059829063 / 5  (58.1):  13%|▏| 4/30 [00:00<00:04,  6.17it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 6  (65.1):  17%|▏| 5/30 [00:00<00:04,  6.17it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 6  (65.1):  20%|▏| 6/30 [00:00<00:00, 24.85it/s\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  20%|▏| 6/30 [00:00<00:00, 24.85it/s]\u001b[A\n",
      "Average Metric: 4.239316239316239 / 8  (53.0):  23%|▏| 7/30 [00:00<00:00, 24.85it/s]\u001b[A\n",
      "Average Metric: 5.039316239316239 / 9  (56.0):  27%|▎| 8/30 [00:00<00:00, 24.85it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 24.85it/s\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 24.85it/\u001b[A\n",
      "Average Metric: 5.872649572649572 / 12  (48.9):  37%|▎| 11/30 [00:00<00:00, 24.85it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 13  (52.9):  40%|▍| 12/30 [00:00<00:00, 24.85it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 13  (52.9):  43%|▍| 13/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 7.372649572649572 / 14  (52.7):  43%|▍| 13/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 8.03931623931624 / 15  (53.6):  47%|▍| 14/30 [00:00<00:00, 38.76it/s\u001b[A\n",
      "Average Metric: 8.896459096459097 / 16  (55.6):  50%|▌| 15/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 17  (58.2):  53%|▌| 16/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 38.76it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 21  (51.1):  70%|▋| 21/30 [00:00<00:00, 51.80it/\u001b[A\n",
      "Average Metric: 11.529792429792431 / 22  (52.4):  70%|▋| 21/30 [00:00<00:00, 51.80it\u001b[A\n",
      "Average Metric: 11.529792429792431 / 23  (50.1):  73%|▋| 22/30 [00:00<00:00, 51.80it\u001b[A\n",
      "Average Metric: 12.38693528693529 / 24  (51.6):  77%|▊| 23/30 [00:00<00:00, 51.80it/\u001b[A\n",
      "Average Metric: 13.38693528693529 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 51.80it/\u001b[A\n",
      "Average Metric: 14.38693528693529 / 26  (55.3):  83%|▊| 25/30 [00:00<00:00, 51.80it/\u001b[A\n",
      "Average Metric: 15.38693528693529 / 27  (57.0):  87%|▊| 26/30 [00:00<00:00, 51.80it/\u001b[A\n",
      "Average Metric: 16.38693528693529 / 28  (58.5):  90%|▉| 27/30 [00:00<00:00, 51.80it/\u001b[A\n",
      "Average Metric: 17.05360195360196 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 51.80it/\u001b[A\n",
      "Average Metric: 17.05360195360196 / 29  (58.8):  97%|▉| 29/30 [00:00<00:00, 59.88it/\u001b[A\n",
      "Average Metric: 17.720268620268627 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 47.88it\u001b[A\n",
      "[I 2024-04-28 22:49:35,544] Trial 42 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268627 / 30  (59.1%)\n",
      "Starting trial #43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:03,  7.69it/s]\u001b[A\n",
      "Average Metric: 1.4444444444444444 / 2  (72.2):   3%| | 1/30 [00:00<00:03,  7.69it/s\u001b[A\n",
      "Average Metric: 2.4444444444444446 / 3  (81.5):   7%| | 2/30 [00:00<00:03,  7.69it/s\u001b[A\n",
      "Average Metric: 2.9059829059829063 / 4  (72.6):  10%| | 3/30 [00:00<00:03,  7.69it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 5  (78.1):  13%|▏| 4/30 [00:00<00:03,  7.69it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 6  (65.1):  17%|▏| 5/30 [00:00<00:03,  7.69it/s\u001b[A\n",
      "Average Metric: 3.9059829059829063 / 6  (65.1):  20%|▏| 6/30 [00:00<00:00, 27.80it/s\u001b[A\n",
      "Average Metric: 4.239316239316239 / 7  (60.6):  20%|▏| 6/30 [00:00<00:00, 27.80it/s]\u001b[A\n",
      "Average Metric: 5.039316239316239 / 8  (63.0):  23%|▏| 7/30 [00:00<00:00, 27.80it/s]\u001b[A\n",
      "Average Metric: 5.039316239316239 / 9  (56.0):  27%|▎| 8/30 [00:00<00:00, 27.80it/s]\u001b[A\n",
      "Average Metric: 5.372649572649572 / 10  (53.7):  30%|▎| 9/30 [00:00<00:00, 27.80it/s\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  33%|▎| 10/30 [00:00<00:00, 27.80it/\u001b[A\n",
      "Average Metric: 5.372649572649572 / 11  (48.8):  37%|▎| 11/30 [00:00<00:00, 35.59it/\u001b[A\n",
      "Average Metric: 5.872649572649572 / 12  (48.9):  37%|▎| 11/30 [00:00<00:00, 35.59it/\u001b[A\n",
      "Average Metric: 6.872649572649572 / 13  (52.9):  40%|▍| 12/30 [00:00<00:00, 35.59it/\u001b[A\n",
      "Average Metric: 7.372649572649572 / 14  (52.7):  43%|▍| 13/30 [00:00<00:00, 35.59it/\u001b[A\n",
      "Average Metric: 7.372649572649572 / 15  (49.2):  47%|▍| 14/30 [00:00<00:00, 35.59it/\u001b[A\n",
      "Average Metric: 8.03931623931624 / 16  (50.2):  50%|▌| 15/30 [00:00<00:00, 35.59it/s\u001b[A\n",
      "Average Metric: 8.03931623931624 / 16  (50.2):  53%|▌| 16/30 [00:00<00:00, 39.30it/s\u001b[A\n",
      "Average Metric: 8.896459096459097 / 17  (52.3):  53%|▌| 16/30 [00:00<00:00, 39.30it/\u001b[A\n",
      "Average Metric: 9.896459096459097 / 18  (55.0):  57%|▌| 17/30 [00:00<00:00, 39.30it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 19  (53.8):  60%|▌| 18/30 [00:00<00:00, 39.30it/\u001b[A\n",
      "Average Metric: 10.22979242979243 / 20  (51.1):  63%|▋| 19/30 [00:00<00:00, 39.30it/\u001b[A\n",
      "Average Metric: 10.72979242979243 / 21  (51.1):  67%|▋| 20/30 [00:00<00:00, 39.30it/\u001b[A\n",
      "Average Metric: 11.529792429792431 / 22  (52.4):  70%|▋| 21/30 [00:00<00:00, 39.30it\u001b[A\n",
      "Average Metric: 11.529792429792431 / 23  (50.1):  73%|▋| 22/30 [00:00<00:00, 39.30it\u001b[A\n",
      "Average Metric: 12.529792429792431 / 24  (52.2):  77%|▊| 23/30 [00:00<00:00, 39.30it\u001b[A\n",
      "Average Metric: 13.38693528693529 / 25  (53.5):  80%|▊| 24/30 [00:00<00:00, 39.30it/\u001b[A\n",
      "Average Metric: 14.053601953601955 / 26  (54.1):  83%|▊| 25/30 [00:00<00:00, 39.30it\u001b[A\n",
      "Average Metric: 15.053601953601955 / 27  (55.8):  87%|▊| 26/30 [00:00<00:00, 39.30it\u001b[A\n",
      "Average Metric: 16.053601953601955 / 28  (57.3):  90%|▉| 27/30 [00:00<00:00, 39.30it\u001b[A\n",
      "Average Metric: 17.053601953601955 / 29  (58.8):  93%|▉| 28/30 [00:00<00:00, 39.30it\u001b[A\n",
      "Average Metric: 17.720268620268623 / 30  (59.1): 100%|█| 30/30 [00:00<00:00, 57.82it\u001b[A\n",
      "[I 2024-04-28 22:49:36,121] Trial 43 finished with value: 59.07 and parameters: {'14766014224_predictor_instruction': 4, '14766014224_predictor_demos': 5, '14707649168_predictor_instruction': 7, '14707649168_predictor_demos': 0, '14753105040_predictor_instruction': 3, '14753105040_predictor_demos': 5}. Best is trial 8 with value: 59.52.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.720268620268623 / 30  (59.1%)\n",
      "Starting trial #44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:03<01:50,  3.82s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:04<01:50,  3.82s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:04<01:02,  2.23s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:05<01:02,  2.23s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:05<00:42,  1.58s/it]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  10%|█▌             | 3/30 [00:06<00:42,  1.58s/it]\u001b[A\n",
      "Average Metric: 2.0 / 4  (50.0):  13%|██             | 4/30 [00:06<00:27,  1.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0 / 5  (40.0):  13%|██             | 4/30 [00:06<00:27,  1.08s/it]\u001b[A\n",
      "Average Metric: 2.0 / 5  (40.0):  17%|██▌            | 5/30 [00:06<00:23,  1.06it/s]\u001b[A\n",
      "Average Metric: 2.5 / 6  (41.7):  17%|██▌            | 5/30 [00:07<00:23,  1.06it/s]\u001b[A\n",
      "Average Metric: 2.5 / 6  (41.7):  20%|███            | 6/30 [00:07<00:17,  1.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0 / 7  (42.9):  20%|███            | 6/30 [00:09<00:17,  1.41it/s]\u001b[A\n",
      "Average Metric: 3.0 / 7  (42.9):  23%|███▌           | 7/30 [00:09<00:30,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.0 / 8  (50.0):  23%|███▌           | 7/30 [00:10<00:30,  1.32s/it]\u001b[A\n",
      "Average Metric: 4.0 / 8  (50.0):  27%|████           | 8/30 [00:10<00:25,  1.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.857142857142857 / 9  (54.0):  27%|▎| 8/30 [00:11<00:25,  1.18s/it]\u001b[A\n",
      "Average Metric: 4.857142857142857 / 9  (54.0):  30%|▎| 9/30 [00:11<00:25,  1.21s/it]\u001b[A\n",
      "Average Metric: 5.857142857142857 / 10  (58.6):  30%|▎| 9/30 [00:12<00:25,  1.21s/it\u001b[A\n",
      "Average Metric: 5.857142857142857 / 10  (58.6):  33%|▎| 10/30 [00:12<00:21,  1.07s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.7142857142857135 / 11  (61.0):  33%|▎| 10/30 [00:13<00:21,  1.07s/\u001b[A\n",
      "Average Metric: 6.7142857142857135 / 11  (61.0):  37%|▎| 11/30 [00:13<00:21,  1.12s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.047619047619047 / 12  (58.7):  37%|▎| 11/30 [00:13<00:21,  1.12s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.047619047619047 / 13  (54.2):  40%|▍| 12/30 [00:15<00:20,  1.12s/i\u001b[A\n",
      "Average Metric: 7.047619047619047 / 13  (54.2):  43%|▍| 13/30 [00:15<00:17,  1.03s/i\u001b[A\n",
      "Average Metric: 7.38095238095238 / 14  (52.7):  43%|▍| 13/30 [00:15<00:17,  1.03s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.38095238095238 / 15  (49.2):  47%|▍| 14/30 [00:16<00:16,  1.03s/it\u001b[A\n",
      "Average Metric: 7.38095238095238 / 15  (49.2):  50%|▌| 15/30 [00:16<00:11,  1.35it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.88095238095238 / 16  (49.3):  50%|▌| 15/30 [00:19<00:11,  1.35it/s\u001b[A\n",
      "Average Metric: 7.88095238095238 / 16  (49.3):  53%|▌| 16/30 [00:19<00:16,  1.20s/it\u001b[A\n",
      "Average Metric: 8.738095238095237 / 17  (51.4):  53%|▌| 16/30 [00:19<00:16,  1.20s/i\u001b[A\n",
      "Average Metric: 8.738095238095237 / 17  (51.4):  57%|▌| 17/30 [00:19<00:13,  1.05s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.738095238095237 / 18  (48.5):  57%|▌| 17/30 [00:20<00:13,  1.05s/i\u001b[A\n",
      "Average Metric: 8.738095238095237 / 18  (48.5):  60%|▌| 18/30 [00:20<00:12,  1.06s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.738095238095237 / 19  (51.3):  60%|▌| 18/30 [00:21<00:12,  1.06s/i\u001b[A\n",
      "Average Metric: 9.738095238095237 / 19  (51.3):  63%|▋| 19/30 [00:21<00:11,  1.01s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 15.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.738095238095237 / 20  (48.7):  63%|▋| 19/30 [00:23<00:11,  1.01s/i\u001b[A\n",
      "Average Metric: 9.738095238095237 / 20  (48.7):  67%|▋| 20/30 [00:23<00:12,  1.27s/i\u001b[A\n",
      "Average Metric: 9.738095238095237 / 21  (46.4):  67%|▋| 20/30 [00:24<00:12,  1.27s/i\u001b[A\n",
      "Average Metric: 9.738095238095237 / 21  (46.4):  70%|▋| 21/30 [00:24<00:11,  1.28s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 28.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.738095238095237 / 22  (44.3):  70%|▋| 21/30 [00:25<00:11,  1.28s/i\u001b[A\n",
      "Average Metric: 9.738095238095237 / 22  (44.3):  73%|▋| 22/30 [00:25<00:09,  1.23s/i\u001b[A\n",
      "Average Metric: 10.538095238095238 / 23  (45.8):  73%|▋| 22/30 [00:26<00:09,  1.23s/\u001b[A\n",
      "Average Metric: 10.538095238095238 / 23  (45.8):  77%|▊| 23/30 [00:26<00:06,  1.07it\u001b[A\n",
      "Average Metric: 11.395238095238096 / 24  (47.5):  77%|▊| 23/30 [00:26<00:06,  1.07it\u001b[A\n",
      "Average Metric: 11.395238095238096 / 24  (47.5):  80%|▊| 24/30 [00:26<00:05,  1.14it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.395238095238096 / 25  (49.6):  80%|▊| 24/30 [00:27<00:05,  1.14it\u001b[A\n",
      "Average Metric: 12.395238095238096 / 25  (49.6):  83%|▊| 25/30 [00:27<00:03,  1.38it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.061904761904762 / 26  (50.2):  83%|▊| 25/30 [00:28<00:03,  1.38it\u001b[A\n",
      "Average Metric: 13.061904761904762 / 26  (50.2):  87%|▊| 26/30 [00:28<00:03,  1.17it\u001b[A\n",
      "Average Metric: 13.347619047619048 / 27  (49.4):  87%|▊| 26/30 [00:28<00:03,  1.17it\u001b[A\n",
      "Average Metric: 13.347619047619048 / 27  (49.4):  90%|▉| 27/30 [00:28<00:02,  1.49it\u001b[A\n",
      "Average Metric: 14.347619047619048 / 28  (51.2):  90%|▉| 27/30 [00:29<00:02,  1.49it\u001b[A\n",
      "Average Metric: 14.347619047619048 / 28  (51.2):  93%|▉| 28/30 [00:29<00:01,  1.22it\u001b[A\n",
      "Average Metric: 14.792063492063493 / 29  (51.0):  93%|▉| 28/30 [00:38<00:01,  1.22it\u001b[A\n",
      "Average Metric: 14.792063492063493 / 29  (51.0):  97%|▉| 29/30 [00:38<00:03,  3.32s/\u001b[A\n",
      "Average Metric: 15.253601953601954 / 30  (50.8):  97%|▉| 29/30 [00:54<00:03,  3.32s/\u001b[A\n",
      "Average Metric: 15.253601953601954 / 30  (50.8): 100%|█| 30/30 [00:54<00:00,  1.83s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:50:31,080] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.253601953601954 / 30  (50.8%)\n",
      "Trial pruned.\n",
      "Starting trial #45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:24,  2.91s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:03<01:24,  2.91s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:03<00:37,  1.34s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):   7%|█               | 2/30 [00:03<00:37,  1.34s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):  10%|█▌              | 3/30 [00:03<00:22,  1.21it/s]\u001b[A\n",
      "Average Metric: 0.4 / 4  (10.0):  10%|█▌             | 3/30 [00:03<00:22,  1.21it/s]\u001b[A\n",
      "Average Metric: 1.2888888888888888 / 5  (25.8):  13%|▏| 4/30 [00:03<00:21,  1.21it/s\u001b[A\n",
      "Average Metric: 1.2888888888888888 / 5  (25.8):  17%|▏| 5/30 [00:03<00:10,  2.50it/s\u001b[A\n",
      "Average Metric: 1.7888888888888888 / 6  (29.8):  17%|▏| 5/30 [00:03<00:10,  2.50it/s\u001b[A\n",
      "Average Metric: 1.7888888888888888 / 6  (29.8):  20%|▏| 6/30 [00:03<00:09,  2.65it/s\u001b[A\n",
      "Average Metric: 2.4555555555555553 / 7  (35.1):  20%|▏| 6/30 [00:04<00:09,  2.65it/s\u001b[A\n",
      "Average Metric: 2.4555555555555553 / 7  (35.1):  23%|▏| 7/30 [00:04<00:07,  3.00it/s\u001b[A\n",
      "Average Metric: 2.9555555555555553 / 8  (36.9):  23%|▏| 7/30 [00:04<00:07,  3.00it/s\u001b[A\n",
      "Average Metric: 2.9555555555555553 / 8  (36.9):  27%|▎| 8/30 [00:04<00:08,  2.60it/s\u001b[A\n",
      "Average Metric: 3.622222222222222 / 9  (40.2):  27%|▎| 8/30 [00:05<00:08,  2.60it/s]\u001b[A\n",
      "Average Metric: 3.622222222222222 / 9  (40.2):  30%|▎| 9/30 [00:05<00:10,  1.95it/s]\u001b[A\n",
      "Average Metric: 4.0837606837606835 / 10  (40.8):  30%|▎| 9/30 [00:05<00:10,  1.95it/\u001b[A\n",
      "Average Metric: 4.0837606837606835 / 10  (40.8):  33%|▎| 10/30 [00:05<00:09,  2.20it\u001b[A\n",
      "Average Metric: 5.0837606837606835 / 11  (46.2):  33%|▎| 10/30 [00:06<00:09,  2.20it\u001b[A\n",
      "Average Metric: 5.0837606837606835 / 11  (46.2):  37%|▎| 11/30 [00:06<00:09,  2.04it\u001b[A\n",
      "Average Metric: 5.0837606837606835 / 12  (42.4):  37%|▎| 11/30 [00:06<00:09,  2.04it\u001b[A\n",
      "Average Metric: 5.94090354090354 / 13  (45.7):  40%|▍| 12/30 [00:06<00:08,  2.04it/s\u001b[A\n",
      "Average Metric: 5.94090354090354 / 13  (45.7):  43%|▍| 13/30 [00:06<00:05,  3.34it/s\u001b[A\n",
      "Average Metric: 6.340903540903541 / 14  (45.3):  43%|▍| 13/30 [00:06<00:05,  3.34it/\u001b[A\n",
      "Average Metric: 7.229792429792429 / 15  (48.2):  47%|▍| 14/30 [00:06<00:04,  3.34it/\u001b[A\n",
      "Average Metric: 7.729792429792429 / 16  (48.3):  50%|▌| 15/30 [00:07<00:04,  3.34it/\u001b[A\n",
      "Average Metric: 7.729792429792429 / 16  (48.3):  53%|▌| 16/30 [00:07<00:03,  3.92it/\u001b[A\n",
      "Average Metric: 8.12979242979243 / 17  (47.8):  53%|▌| 16/30 [00:07<00:03,  3.92it/s\u001b[A\n",
      "Average Metric: 8.12979242979243 / 17  (47.8):  57%|▌| 17/30 [00:07<00:03,  4.01it/s\u001b[A\n",
      "Average Metric: 8.415506715506716 / 18  (46.8):  57%|▌| 17/30 [00:07<00:03,  4.01it/\u001b[A\n",
      "Average Metric: 8.415506715506716 / 18  (46.8):  60%|▌| 18/30 [00:07<00:04,  2.90it/\u001b[A\n",
      "Average Metric: 8.415506715506716 / 19  (44.3):  60%|▌| 18/30 [00:08<00:04,  2.90it/\u001b[A\n",
      "Average Metric: 8.415506715506716 / 19  (44.3):  63%|▋| 19/30 [00:08<00:03,  3.22it/\u001b[A\n",
      "Average Metric: 8.415506715506716 / 20  (42.1):  63%|▋| 19/30 [00:08<00:03,  3.22it/\u001b[A\n",
      "Average Metric: 8.415506715506716 / 20  (42.1):  67%|▋| 20/30 [00:08<00:03,  2.71it/\u001b[A\n",
      "Average Metric: 8.915506715506716 / 21  (42.5):  67%|▋| 20/30 [00:09<00:03,  2.71it/\u001b[A\n",
      "Average Metric: 8.915506715506716 / 21  (42.5):  70%|▋| 21/30 [00:09<00:03,  2.41it/\u001b[A\n",
      "Average Metric: 8.915506715506716 / 22  (40.5):  70%|▋| 21/30 [00:09<00:03,  2.41it/\u001b[A\n",
      "Average Metric: 9.582173382173382 / 23  (41.7):  73%|▋| 22/30 [00:09<00:03,  2.41it/\u001b[A\n",
      "Average Metric: 9.582173382173382 / 23  (41.7):  77%|▊| 23/30 [00:09<00:01,  3.56it/\u001b[A\n",
      "Average Metric: 10.582173382173382 / 24  (44.1):  77%|▊| 23/30 [00:09<00:01,  3.56it\u001b[A\n",
      "Average Metric: 10.582173382173382 / 24  (44.1):  80%|▊| 24/30 [00:09<00:01,  3.25it\u001b[A\n",
      "Average Metric: 10.582173382173382 / 25  (42.3):  80%|▊| 24/30 [00:10<00:01,  3.25it\u001b[A\n",
      "Average Metric: 10.582173382173382 / 25  (42.3):  83%|▊| 25/30 [00:10<00:01,  3.37it\u001b[A\n",
      "Average Metric: 10.582173382173382 / 26  (40.7):  83%|▊| 25/30 [00:10<00:01,  3.37it\u001b[A\n",
      "Average Metric: 10.582173382173382 / 26  (40.7):  87%|▊| 26/30 [00:10<00:01,  2.83it\u001b[A\n",
      "Average Metric: 10.582173382173382 / 27  (39.2):  87%|▊| 26/30 [00:10<00:01,  2.83it\u001b[A\n",
      "Average Metric: 10.867887667887668 / 28  (38.8):  90%|▉| 27/30 [00:10<00:01,  2.83it\u001b[A\n",
      "Average Metric: 10.867887667887668 / 28  (38.8):  93%|▉| 28/30 [00:10<00:00,  4.05it\u001b[A\n",
      "Average Metric: 11.725030525030526 / 29  (40.4):  93%|▉| 28/30 [00:12<00:00,  4.05it\u001b[A\n",
      "Average Metric: 11.725030525030526 / 29  (40.4):  97%|▉| 29/30 [00:12<00:00,  1.74it\u001b[A\n",
      "Average Metric: 12.582173382173384 / 30  (41.9):  97%|▉| 29/30 [00:14<00:00,  1.74it\u001b[A\n",
      "Average Metric: 12.582173382173384 / 30  (41.9): 100%|█| 30/30 [00:14<00:00,  2.10it\u001b[A\n",
      "[I 2024-04-28 22:50:45,417] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.582173382173384 / 30  (41.9%)\n",
      "Trial pruned.\n",
      "Starting trial #46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:09,  2.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:03<01:09,  2.41s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:03<00:44,  1.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.3 / 3  (43.3):   7%|█              | 2/30 [00:04<00:44,  1.57s/it]\u001b[A\n",
      "Average Metric: 1.3 / 3  (43.3):  10%|█▌             | 3/30 [00:04<00:32,  1.22s/it]\u001b[A\n",
      "Average Metric: 1.3 / 4  (32.5):  10%|█▌             | 3/30 [00:04<00:32,  1.22s/it]\u001b[A\n",
      "Average Metric: 1.3 / 4  (32.5):  13%|██             | 4/30 [00:04<00:20,  1.27it/s]\u001b[A\n",
      "Average Metric: 1.3 / 5  (26.0):  13%|██             | 4/30 [00:04<00:20,  1.27it/s]\u001b[A\n",
      "Average Metric: 1.3 / 5  (26.0):  17%|██▌            | 5/30 [00:04<00:18,  1.36it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.3 / 6  (38.3):  17%|██▌            | 5/30 [00:05<00:18,  1.36it/s]\u001b[A\n",
      "Average Metric: 2.3 / 6  (38.3):  20%|███            | 6/30 [00:05<00:18,  1.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.3 / 7  (47.1):  20%|███            | 6/30 [00:06<00:18,  1.27it/s]\u001b[A\n",
      "Average Metric: 3.3 / 7  (47.1):  23%|███▌           | 7/30 [00:06<00:20,  1.13it/s]\u001b[A\n",
      "Average Metric: 3.6333333333333333 / 8  (45.4):  23%|▏| 7/30 [00:07<00:20,  1.13it/s\u001b[A\n",
      "Average Metric: 3.6333333333333333 / 8  (45.4):  27%|▎| 8/30 [00:07<00:18,  1.17it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.6333333333333333 / 9  (40.4):  27%|▎| 8/30 [00:08<00:18,  1.17it/s\u001b[A\n",
      "Average Metric: 3.6333333333333333 / 9  (40.4):  30%|▎| 9/30 [00:08<00:20,  1.03it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.133333333333333 / 10  (41.3):  30%|▎| 9/30 [00:11<00:20,  1.03it/s\u001b[A\n",
      "Average Metric: 4.133333333333333 / 10  (41.3):  33%|▎| 10/30 [00:11<00:26,  1.31s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.133333333333333 / 11  (46.7):  33%|▎| 10/30 [00:12<00:26,  1.31s/i\u001b[A\n",
      "Average Metric: 5.133333333333333 / 11  (46.7):  37%|▎| 11/30 [00:12<00:27,  1.44s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.5777777777777775 / 12  (46.5):  37%|▎| 11/30 [00:14<00:27,  1.44s/\u001b[A\n",
      "Average Metric: 5.5777777777777775 / 12  (46.5):  40%|▍| 12/30 [00:14<00:26,  1.47s/\u001b[A\n",
      "Average Metric: 6.5777777777777775 / 13  (50.6):  40%|▍| 12/30 [00:14<00:26,  1.47s/\u001b[A\n",
      "Average Metric: 6.5777777777777775 / 14  (47.0):  43%|▍| 13/30 [00:14<00:25,  1.47s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.377777777777777 / 15  (49.2):  47%|▍| 14/30 [00:15<00:23,  1.47s/i\u001b[A\n",
      "Average Metric: 7.377777777777777 / 15  (49.2):  50%|▌| 15/30 [00:15<00:13,  1.13it/\u001b[A\n",
      "Average Metric: 7.377777777777777 / 16  (46.1):  50%|▌| 15/30 [00:15<00:13,  1.13it/\u001b[A\n",
      "Average Metric: 7.377777777777777 / 16  (46.1):  53%|▌| 16/30 [00:15<00:10,  1.35it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.044444444444444 / 17  (47.3):  53%|▌| 16/30 [00:16<00:10,  1.35it/\u001b[A\n",
      "Average Metric: 8.044444444444444 / 17  (47.3):  57%|▌| 17/30 [00:16<00:10,  1.25it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.901587301587302 / 18  (49.5):  57%|▌| 17/30 [00:18<00:10,  1.25it/\u001b[A\n",
      "Average Metric: 8.901587301587302 / 18  (49.5):  60%|▌| 18/30 [00:18<00:11,  1.01it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.568253968253968 / 19  (50.4):  60%|▌| 18/30 [00:18<00:11,  1.01it/\u001b[A\n",
      "Average Metric: 9.568253968253968 / 19  (50.4):  63%|▋| 19/30 [00:18<00:08,  1.26it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.568253968253968 / 20  (52.8):  63%|▋| 19/30 [00:20<00:08,  1.26it\u001b[A\n",
      "Average Metric: 10.568253968253968 / 20  (52.8):  67%|▋| 20/30 [00:20<00:10,  1.06s/\u001b[A\n",
      "Average Metric: 10.568253968253968 / 21  (50.3):  67%|▋| 20/30 [00:20<00:10,  1.06s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.568253968253968 / 22  (52.6):  70%|▋| 21/30 [00:21<00:09,  1.06s/\u001b[A\n",
      "Average Metric: 11.568253968253968 / 22  (52.6):  73%|▋| 22/30 [00:21<00:06,  1.33it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.568253968253968 / 23  (54.6):  73%|▋| 22/30 [00:22<00:06,  1.33it\u001b[A\n",
      "Average Metric: 12.568253968253968 / 23  (54.6):  77%|▊| 23/30 [00:22<00:05,  1.21it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.234920634920634 / 24  (55.1):  77%|▊| 23/30 [00:23<00:05,  1.21it\u001b[A\n",
      "Average Metric: 13.234920634920634 / 24  (55.1):  80%|▊| 24/30 [00:23<00:06,  1.01s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 6.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.234920634920634 / 25  (52.9):  80%|▊| 24/30 [00:24<00:06,  1.01s/\u001b[A\n",
      "Average Metric: 13.234920634920634 / 25  (52.9):  83%|▊| 25/30 [00:24<00:05,  1.01s/\u001b[A\n",
      "Average Metric: 14.234920634920634 / 26  (54.7):  83%|▊| 25/30 [00:26<00:05,  1.01s/\u001b[A\n",
      "Average Metric: 14.234920634920634 / 26  (54.7):  87%|▊| 26/30 [00:26<00:04,  1.13s/\u001b[A\n",
      "Average Metric: 14.52063492063492 / 27  (53.8):  87%|▊| 26/30 [00:28<00:04,  1.13s/i\u001b[A\n",
      "Average Metric: 14.52063492063492 / 27  (53.8):  90%|▉| 27/30 [00:28<00:04,  1.60s/i\u001b[A\n",
      "Average Metric: 14.52063492063492 / 28  (51.9):  90%|▉| 27/30 [00:29<00:04,  1.60s/i\u001b[A\n",
      "Average Metric: 14.52063492063492 / 28  (51.9):  93%|▉| 28/30 [00:29<00:02,  1.23s/i\u001b[A\n",
      "Average Metric: 14.806349206349207 / 29  (51.1):  93%|▉| 28/30 [00:31<00:02,  1.23s/\u001b[A\n",
      "Average Metric: 14.806349206349207 / 29  (51.1):  97%|▉| 29/30 [00:31<00:01,  1.54s/\u001b[A\n",
      "Average Metric: 15.139682539682541 / 30  (50.5):  97%|▉| 29/30 [00:34<00:01,  1.54s/\u001b[A\n",
      "Average Metric: 15.139682539682541 / 30  (50.5): 100%|█| 30/30 [00:34<00:00,  1.14s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:51:19,520] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.139682539682541 / 30  (50.5%)\n",
      "Trial pruned.\n",
      "Starting trial #47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:04<02:20,  4.83s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:04<02:20,  4.83s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:04<00:58,  2.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.5 / 3  (16.7):   7%|█              | 2/30 [00:06<00:58,  2.07s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):  10%|█▌             | 3/30 [00:06<00:48,  1.78s/it]\u001b[A\n",
      "Average Metric: 0.5 / 4  (12.5):  10%|█▌             | 3/30 [00:06<00:48,  1.78s/it]\u001b[A\n",
      "Average Metric: 1.5 / 5  (30.0):  13%|██             | 4/30 [00:06<00:46,  1.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.357142857142857 / 6  (39.3):  17%|▏| 5/30 [00:07<00:44,  1.78s/it]\u001b[A\n",
      "Average Metric: 2.357142857142857 / 6  (39.3):  20%|▏| 6/30 [00:07<00:21,  1.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.357142857142857 / 7  (33.7):  20%|▏| 6/30 [00:09<00:21,  1.10it/s]\u001b[A\n",
      "Average Metric: 2.357142857142857 / 7  (33.7):  23%|▏| 7/30 [00:09<00:26,  1.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.757142857142857 / 8  (34.5):  23%|▏| 7/30 [00:10<00:26,  1.15s/it]\u001b[A\n",
      "Average Metric: 2.757142857142857 / 8  (34.5):  27%|▎| 8/30 [00:10<00:25,  1.17s/it]\u001b[A\n",
      "Average Metric: 3.0904761904761906 / 9  (34.3):  27%|▎| 8/30 [00:11<00:25,  1.17s/it\u001b[A\n",
      "Average Metric: 3.0904761904761906 / 9  (34.3):  30%|▎| 9/30 [00:11<00:22,  1.08s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.4904761904761905 / 10  (34.9):  30%|▎| 9/30 [00:12<00:22,  1.08s/i\u001b[A\n",
      "Average Metric: 3.4904761904761905 / 10  (34.9):  33%|▎| 10/30 [00:12<00:20,  1.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.4904761904761905 / 11  (31.7):  33%|▎| 10/30 [00:13<00:20,  1.02s/\u001b[A\n",
      "Average Metric: 3.4904761904761905 / 11  (31.7):  37%|▎| 11/30 [00:13<00:19,  1.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.4904761904761905 / 12  (29.1):  37%|▎| 11/30 [00:14<00:19,  1.02s/\u001b[A\n",
      "Average Metric: 3.4904761904761905 / 12  (29.1):  40%|▍| 12/30 [00:14<00:20,  1.11s/\u001b[A\n",
      "Average Metric: 3.4904761904761905 / 13  (26.8):  40%|▍| 12/30 [00:15<00:20,  1.11s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.9904761904761905 / 14  (28.5):  43%|▍| 13/30 [00:16<00:18,  1.11s/\u001b[A\n",
      "Average Metric: 3.9904761904761905 / 14  (28.5):  47%|▍| 14/30 [00:16<00:15,  1.04it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.390476190476191 / 15  (29.3):  47%|▍| 14/30 [00:17<00:15,  1.04it/\u001b[A\n",
      "Average Metric: 4.390476190476191 / 15  (29.3):  50%|▌| 15/30 [00:17<00:15,  1.00s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.390476190476191 / 16  (27.4):  50%|▌| 15/30 [00:20<00:15,  1.00s/i\u001b[A\n",
      "Average Metric: 4.390476190476191 / 16  (27.4):  53%|▌| 16/30 [00:20<00:20,  1.45s/i\u001b[A\n",
      "Average Metric: 4.390476190476191 / 17  (25.8):  53%|▌| 16/30 [00:20<00:20,  1.45s/i\u001b[A\n",
      "Average Metric: 4.723809523809524 / 18  (26.2):  57%|▌| 17/30 [00:20<00:18,  1.45s/i\u001b[A\n",
      "Average Metric: 4.723809523809524 / 18  (26.2):  60%|▌| 18/30 [00:20<00:11,  1.04it/\u001b[A\n",
      "Average Metric: 4.723809523809524 / 19  (24.9):  60%|▌| 18/30 [00:21<00:11,  1.04it/\u001b[A\n",
      "Average Metric: 4.723809523809524 / 19  (24.9):  63%|▋| 19/30 [00:21<00:09,  1.16it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.223809523809524 / 20  (26.1):  63%|▋| 19/30 [00:22<00:09,  1.16it/\u001b[A\n",
      "Average Metric: 5.223809523809524 / 20  (26.1):  67%|▋| 20/30 [00:22<00:08,  1.14it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.223809523809524 / 21  (24.9):  67%|▋| 20/30 [00:23<00:08,  1.14it/\u001b[A\n",
      "Average Metric: 5.223809523809524 / 21  (24.9):  70%|▋| 21/30 [00:23<00:07,  1.22it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.405627705627706 / 22  (24.6):  70%|▋| 21/30 [00:25<00:07,  1.22it/\u001b[A\n",
      "Average Metric: 5.405627705627706 / 22  (24.6):  73%|▋| 22/30 [00:25<00:10,  1.32s/i\u001b[A\n",
      "Average Metric: 6.405627705627706 / 23  (27.9):  73%|▋| 22/30 [00:25<00:10,  1.32s/i\u001b[A\n",
      "Average Metric: 6.405627705627706 / 23  (27.9):  77%|▊| 23/30 [00:25<00:06,  1.02it/\u001b[A\n",
      "Average Metric: 7.262770562770562 / 24  (30.3):  77%|▊| 23/30 [00:26<00:06,  1.02it/\u001b[A\n",
      "Average Metric: 7.262770562770562 / 24  (30.3):  80%|▊| 24/30 [00:26<00:05,  1.20it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.262770562770562 / 25  (33.1):  80%|▊| 24/30 [00:27<00:05,  1.20it/\u001b[A\n",
      "Average Metric: 8.262770562770562 / 25  (33.1):  83%|▊| 25/30 [00:27<00:04,  1.17it/\u001b[A\n",
      "Average Metric: 8.262770562770562 / 26  (31.8):  83%|▊| 25/30 [00:28<00:04,  1.17it/\u001b[A\n",
      "Average Metric: 8.262770562770562 / 26  (31.8):  87%|▊| 26/30 [00:28<00:03,  1.18it/\u001b[A\n",
      "Average Metric: 8.262770562770562 / 27  (30.6):  87%|▊| 26/30 [00:28<00:03,  1.18it/\u001b[A\n",
      "Average Metric: 8.262770562770562 / 27  (30.6):  90%|▉| 27/30 [00:28<00:02,  1.23it/\u001b[A\n",
      "Average Metric: 8.929437229437228 / 28  (31.9):  90%|▉| 27/30 [00:28<00:02,  1.23it/\u001b[A\n",
      "Average Metric: 9.596103896103894 / 29  (33.1):  93%|▉| 28/30 [00:32<00:01,  1.23it/\u001b[A\n",
      "Average Metric: 9.596103896103894 / 29  (33.1):  97%|▉| 29/30 [00:32<00:01,  1.28s/i\u001b[A\n",
      "Average Metric: 9.596103896103894 / 30  (32.0):  97%|▉| 29/30 [00:36<00:01,  1.28s/i\u001b[A\n",
      "Average Metric: 9.596103896103894 / 30  (32.0): 100%|█| 30/30 [00:36<00:00,  1.20s/i\u001b[A\n",
      "[I 2024-04-28 22:51:55,664] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 9.596103896103894 / 30  (32.0%)\n",
      "Trial pruned.\n",
      "Starting trial #48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:02<01:15,  2.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:02<01:15,  2.61s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:02<00:36,  1.29s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:03<00:36,  1.29s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):  10%|█▌             | 3/30 [00:03<00:22,  1.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.357142857142857 / 4  (58.9):  10%| | 3/30 [00:04<00:22,  1.22it/s]\u001b[A\n",
      "Average Metric: 2.357142857142857 / 4  (58.9):  13%|▏| 4/30 [00:04<00:23,  1.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.357142857142857 / 5  (47.1):  13%|▏| 4/30 [00:04<00:23,  1.13it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.2142857142857144 / 6  (53.6):  17%|▏| 5/30 [00:08<00:22,  1.13it/s\u001b[A\n",
      "Average Metric: 3.2142857142857144 / 6  (53.6):  20%|▏| 6/30 [00:08<00:35,  1.49s/it\u001b[A\n",
      "Average Metric: 4.214285714285714 / 7  (60.2):  20%|▏| 6/30 [00:08<00:35,  1.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.614285714285715 / 8  (57.7):  23%|▏| 7/30 [00:08<00:34,  1.49s/it]\u001b[A\n",
      "Average Metric: 4.614285714285715 / 8  (57.7):  27%|▎| 8/30 [00:09<00:22,  1.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.114285714285715 / 9  (56.8):  27%|▎| 8/30 [00:11<00:22,  1.00s/it]\u001b[A\n",
      "Average Metric: 5.114285714285715 / 9  (56.8):  30%|▎| 9/30 [00:11<00:29,  1.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.114285714285715 / 10  (61.1):  30%|▎| 9/30 [00:12<00:29,  1.41s/it\u001b[A\n",
      "Average Metric: 6.114285714285715 / 10  (61.1):  33%|▎| 10/30 [00:12<00:25,  1.27s/i\u001b[A\n",
      "Average Metric: 6.114285714285715 / 11  (55.6):  33%|▎| 10/30 [00:12<00:25,  1.27s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.447619047619048 / 12  (53.7):  37%|▎| 11/30 [00:12<00:24,  1.27s/i\u001b[A\n",
      "Average Metric: 6.447619047619048 / 12  (53.7):  40%|▍| 12/30 [00:12<00:14,  1.22it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.947619047619048 / 13  (53.4):  40%|▍| 12/30 [00:15<00:14,  1.22it/\u001b[A\n",
      "Average Metric: 6.947619047619048 / 13  (53.4):  43%|▍| 13/30 [00:15<00:19,  1.16s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.947619047619048 / 14  (56.8):  43%|▍| 13/30 [00:16<00:19,  1.16s/i\u001b[A\n",
      "Average Metric: 7.947619047619048 / 14  (56.8):  47%|▍| 14/30 [00:16<00:20,  1.29s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.614285714285714 / 15  (57.4):  47%|▍| 14/30 [00:17<00:20,  1.29s/i\u001b[A\n",
      "Average Metric: 8.614285714285714 / 15  (57.4):  50%|▌| 15/30 [00:17<00:17,  1.17s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.614285714285714 / 16  (53.8):  50%|▌| 15/30 [00:18<00:17,  1.17s/i\u001b[A\n",
      "Average Metric: 8.614285714285714 / 16  (53.8):  53%|▌| 16/30 [00:18<00:15,  1.11s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.471428571428572 / 17  (55.7):  53%|▌| 16/30 [00:20<00:15,  1.11s/i\u001b[A\n",
      "Average Metric: 9.471428571428572 / 17  (55.7):  57%|▌| 17/30 [00:20<00:17,  1.38s/i\u001b[A\n",
      "Average Metric: 9.471428571428572 / 18  (52.6):  57%|▌| 17/30 [00:21<00:17,  1.38s/i\u001b[A\n",
      "Average Metric: 9.471428571428572 / 18  (52.6):  60%|▌| 18/30 [00:21<00:12,  1.05s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.138095238095238 / 19  (53.4):  60%|▌| 18/30 [00:21<00:12,  1.05s/\u001b[A\n",
      "Average Metric: 10.138095238095238 / 19  (53.4):  63%|▋| 19/30 [00:21<00:11,  1.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 21.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.138095238095238 / 20  (55.7):  63%|▋| 19/30 [00:26<00:11,  1.02s/\u001b[A\n",
      "Average Metric: 11.138095238095238 / 20  (55.7):  67%|▋| 20/30 [00:26<00:19,  1.95s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.566666666666666 / 21  (55.1):  67%|▋| 20/30 [00:27<00:19,  1.95s/\u001b[A\n",
      "Average Metric: 11.566666666666666 / 21  (55.1):  70%|▋| 21/30 [00:27<00:16,  1.86s/\u001b[A\n",
      "Average Metric: 11.566666666666666 / 22  (52.6):  70%|▋| 21/30 [00:28<00:16,  1.86s/\u001b[A\n",
      "Average Metric: 11.566666666666666 / 22  (52.6):  73%|▋| 22/30 [00:28<00:11,  1.38s/\u001b[A\n",
      "Average Metric: 12.566666666666666 / 23  (54.6):  73%|▋| 22/30 [00:28<00:11,  1.38s/\u001b[A\n",
      "Average Metric: 12.566666666666666 / 23  (54.6):  77%|▊| 23/30 [00:28<00:08,  1.16s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 8.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.566666666666666 / 24  (56.5):  77%|▊| 23/30 [00:29<00:08,  1.16s/\u001b[A\n",
      "Average Metric: 13.566666666666666 / 24  (56.5):  80%|▊| 24/30 [00:29<00:06,  1.00s/\u001b[A\n",
      "Average Metric: 13.566666666666666 / 25  (54.3):  80%|▊| 24/30 [00:29<00:06,  1.00s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 26  (52.9):  83%|▊| 25/30 [00:31<00:05,  1.00s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 26  (52.9):  87%|▊| 26/30 [00:31<00:03,  1.07it\u001b[A\n",
      "Average Metric: 13.748484848484848 / 27  (50.9):  87%|▊| 26/30 [00:35<00:03,  1.07it\u001b[A\n",
      "Average Metric: 13.748484848484848 / 27  (50.9):  90%|▉| 27/30 [00:35<00:05,  1.79s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 28  (49.1):  90%|▉| 27/30 [00:35<00:05,  1.79s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 28  (49.1):  93%|▉| 28/30 [00:35<00:02,  1.44s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 29  (47.4):  93%|▉| 28/30 [00:38<00:02,  1.44s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 29  (47.4):  97%|▉| 29/30 [00:38<00:01,  1.78s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 30  (45.8):  97%|▉| 29/30 [00:47<00:01,  1.78s/\u001b[A\n",
      "Average Metric: 13.748484848484848 / 30  (45.8): 100%|█| 30/30 [00:47<00:00,  1.57s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:52:42,776] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.748484848484848 / 30  (45.8%)\n",
      "Trial pruned.\n",
      "Starting trial #49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:02<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:02<01:11,  2.47s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:02<01:11,  2.47s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):   7%|█              | 2/30 [00:02<01:09,  2.47s/it]\u001b[A\n",
      "Average Metric: 0.4 / 3  (13.3):  10%|█▌             | 3/30 [00:02<00:21,  1.27it/s]\u001b[A\n",
      "Average Metric: 0.8 / 4  (20.0):  10%|█▌             | 3/30 [00:02<00:21,  1.27it/s]\u001b[A\n",
      "Average Metric: 1.6 / 5  (32.0):  13%|██             | 4/30 [00:03<00:20,  1.27it/s]\u001b[A\n",
      "Average Metric: 1.6 / 5  (32.0):  17%|██▌            | 5/30 [00:03<00:10,  2.30it/s]\u001b[A\n",
      "Average Metric: 1.6 / 6  (26.7):  17%|██▌            | 5/30 [00:03<00:10,  2.30it/s]\u001b[A\n",
      "Average Metric: 1.6 / 6  (26.7):  20%|███            | 6/30 [00:03<00:11,  2.18it/s]\u001b[A\n",
      "Average Metric: 1.9636363636363638 / 7  (28.1):  20%|▏| 6/30 [00:04<00:11,  2.18it/s\u001b[A\n",
      "Average Metric: 1.9636363636363638 / 7  (28.1):  23%|▏| 7/30 [00:04<00:14,  1.62it/s\u001b[A\n",
      "Average Metric: 2.3922077922077922 / 8  (29.9):  23%|▏| 7/30 [00:04<00:14,  1.62it/s\u001b[A\n",
      "Average Metric: 2.3922077922077922 / 8  (29.9):  27%|▎| 8/30 [00:04<00:11,  2.00it/s\u001b[A\n",
      "Average Metric: 2.3922077922077922 / 9  (26.6):  27%|▎| 8/30 [00:04<00:11,  2.00it/s\u001b[A\n",
      "Average Metric: 3.1922077922077925 / 10  (31.9):  30%|▎| 9/30 [00:05<00:10,  2.00it/\u001b[A\n",
      "Average Metric: 3.1922077922077925 / 10  (31.9):  33%|▎| 10/30 [00:05<00:08,  2.40it\u001b[A\n",
      "Average Metric: 4.1922077922077925 / 11  (38.1):  33%|▎| 10/30 [00:05<00:08,  2.40it\u001b[A\n",
      "Average Metric: 4.1922077922077925 / 11  (38.1):  37%|▎| 11/30 [00:05<00:06,  2.87it\u001b[A\n",
      "Average Metric: 4.1922077922077925 / 12  (34.9):  37%|▎| 11/30 [00:05<00:06,  2.87it\u001b[A\n",
      "Average Metric: 4.1922077922077925 / 12  (34.9):  40%|▍| 12/30 [00:05<00:05,  3.36it\u001b[A\n",
      "Average Metric: 4.66279602750191 / 13  (35.9):  40%|▍| 12/30 [00:05<00:05,  3.36it/s\u001b[A\n",
      "Average Metric: 4.66279602750191 / 13  (35.9):  43%|▍| 13/30 [00:05<00:04,  3.84it/s\u001b[A\n",
      "Average Metric: 5.66279602750191 / 14  (40.4):  43%|▍| 13/30 [00:06<00:04,  3.84it/s\u001b[A\n",
      "Average Metric: 5.66279602750191 / 14  (40.4):  47%|▍| 14/30 [00:06<00:06,  2.38it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.66279602750191 / 15  (44.4):  47%|▍| 14/30 [00:08<00:06,  2.38it/s\u001b[A\n",
      "Average Metric: 6.66279602750191 / 15  (44.4):  50%|▌| 15/30 [00:08<00:11,  1.33it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.948510313216196 / 16  (43.4):  50%|▌| 15/30 [00:09<00:11,  1.33it/\u001b[A\n",
      "Average Metric: 6.948510313216196 / 16  (43.4):  53%|▌| 16/30 [00:09<00:11,  1.19it/\u001b[A\n",
      "Average Metric: 6.948510313216196 / 17  (40.9):  53%|▌| 16/30 [00:09<00:11,  1.19it/\u001b[A\n",
      "Average Metric: 6.948510313216196 / 17  (40.9):  57%|▌| 17/30 [00:09<00:09,  1.37it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.948510313216196 / 18  (38.6):  57%|▌| 17/30 [00:11<00:09,  1.37it/\u001b[A\n",
      "Average Metric: 6.948510313216196 / 18  (38.6):  60%|▌| 18/30 [00:11<00:12,  1.05s/i\u001b[A\n",
      "Average Metric: 7.805653170359053 / 19  (41.1):  60%|▌| 18/30 [00:11<00:12,  1.05s/i\u001b[A\n",
      "Average Metric: 8.305653170359053 / 20  (41.5):  63%|▋| 19/30 [00:12<00:11,  1.05s/i\u001b[A\n",
      "Average Metric: 8.305653170359053 / 20  (41.5):  67%|▋| 20/30 [00:12<00:07,  1.39it/\u001b[A\n",
      "Average Metric: 8.972319837025719 / 21  (42.7):  67%|▋| 20/30 [00:12<00:07,  1.39it/\u001b[A\n",
      "Average Metric: 8.972319837025719 / 21  (42.7):  70%|▋| 21/30 [00:12<00:05,  1.66it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.972319837025719 / 22  (45.3):  70%|▋| 21/30 [00:13<00:05,  1.66it/\u001b[A\n",
      "Average Metric: 9.972319837025719 / 22  (45.3):  73%|▋| 22/30 [00:13<00:04,  1.64it/\u001b[A\n",
      "Average Metric: 9.972319837025719 / 23  (43.4):  73%|▋| 22/30 [00:13<00:04,  1.64it/\u001b[A\n",
      "Average Metric: 9.972319837025719 / 23  (43.4):  77%|▊| 23/30 [00:13<00:04,  1.55it/\u001b[A\n",
      "Average Metric: 10.972319837025719 / 24  (45.7):  77%|▊| 23/30 [00:15<00:04,  1.55it\u001b[A\n",
      "Average Metric: 10.972319837025719 / 24  (45.7):  80%|▊| 24/30 [00:15<00:04,  1.27it\u001b[A\n",
      "Average Metric: 11.972319837025719 / 25  (47.9):  80%|▊| 24/30 [00:15<00:04,  1.27it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.258034122740005 / 26  (47.1):  83%|▊| 25/30 [00:16<00:03,  1.27it\u001b[A\n",
      "Average Metric: 12.258034122740005 / 26  (47.1):  87%|▊| 26/30 [00:16<00:03,  1.27it\u001b[A\n",
      "Average Metric: 13.115176979882863 / 27  (48.6):  87%|▊| 26/30 [00:17<00:03,  1.27it\u001b[A\n",
      "Average Metric: 13.115176979882863 / 27  (48.6):  90%|▉| 27/30 [00:17<00:02,  1.33it\u001b[A\n",
      "Average Metric: 13.615176979882863 / 28  (48.6):  90%|▉| 27/30 [00:19<00:02,  1.33it\u001b[A\n",
      "Average Metric: 13.615176979882863 / 28  (48.6):  93%|▉| 28/30 [00:19<00:02,  1.06s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.415176979882864 / 29  (49.7):  93%|▉| 28/30 [00:19<00:02,  1.06s/\u001b[A\n",
      "Average Metric: 14.415176979882864 / 29  (49.7):  97%|▉| 29/30 [00:19<00:00,  1.07it\u001b[A\n",
      "Average Metric: 14.415176979882864 / 30  (48.1):  97%|▉| 29/30 [00:22<00:00,  1.07it\u001b[A\n",
      "Average Metric: 14.415176979882864 / 30  (48.1): 100%|█| 30/30 [00:22<00:00,  1.31it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "[I 2024-04-28 22:53:05,701] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.415176979882864 / 30  (48.1%)\n",
      "Trial pruned.\n",
      "Returning generate_aspects.predictor = Predict(StringSignature(review -> reasoning, aspects_list\n",
      "    instructions='Identify specific aspects mentioned in a customer review related to restaurants. The aspects should be focused on food quality, service, atmosphere, and pricing, and can include items like sushi, dosa, jalapeno. Ensure the aspects are relevant to the dining experience and reflect both positive and negative feedback accurately.'\n",
      "    review = Field(annotation=str required=True json_schema_extra={'desc': 'a customer review', '__dspy_field_type': 'input', 'prefix': 'Review:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the aspects_list}. We ...', '__dspy_field_type': 'output'})\n",
      "    aspects_list = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review. Must be a valid Python list.\\n', '__dspy_field_type': 'output', 'prefix': 'Aspects List:'})\n",
      "))\n",
      "generate_reasons = ChainOfThought(Aspects2Reasons(review, aspects_list -> reasons\n",
      "    instructions='\\n    Using the customer review and list of aspects, reason about whether each aspect is positive, neutral, or negative.\\n    Think deeply about each aspect in the context of the entire review.\\n    '\n",
      "    review = Field(annotation=str required=True json_schema_extra={'desc': 'a customer review', '__dspy_field_type': 'input', 'prefix': 'Review:'})\n",
      "    aspects_list = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review\\n', '__dspy_field_type': 'input', 'prefix': 'Aspects List:'})\n",
      "    reasons = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review. Under each aspect, there are some thoughts or reasons\\nabout whether the aspect is positive, neutral, or negative.\\n', '__dspy_field_type': 'output', 'prefix': 'Reasons:'})\n",
      "))\n",
      "generate_labels.predictor = Predict(StringSignature(aspects_list, reasons -> reasoning, aspects_with_label\n",
      "    instructions='Given the detailed dataset, consider assigning a positive label (1) to aspects mentioned favorably, a neutral label (0) to aspects not commented on, and a negative label (-1) to aspects mentioned negatively. Generate a structured output response reflecting the sentiment towards each aspect.'\n",
      "    aspects_list = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review\\n', '__dspy_field_type': 'input', 'prefix': 'Aspects List:'})\n",
      "    reasons = Field(annotation=str required=True json_schema_extra={'desc': '\\nA list of all the aspects in the customer review. Under each aspect, there are some thoughts or reasons\\nabout whether the aspect is positive, neutral, or negative.\\n', '__dspy_field_type': 'input', 'prefix': 'Reasons:'})\n",
      "    reasoning = Field(annotation=str required=True json_schema_extra={'prefix': \"Reasoning: Let's think step by step in order to\", 'desc': '${produce the aspects_with_label}. We ...', '__dspy_field_type': 'output'})\n",
      "    aspects_with_label = Field(annotation=dict required=True json_schema_extra={'format': <class 'dict'>, 'desc': '\\na single Python dictionary, where each key is an aspect and the value is the label,\\nwith label 1 indicating positive sentiment, 0 indicating neutral sentiment, and -1\\nindicating negative sentiment.\\n', '__dspy_field_type': 'output', 'prefix': 'Sentiment Analysis:'})\n",
      ")) from continue_program\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:07<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:07<11:46,  7.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|▏              | 1/100 [00:11<11:46,  7.14s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   2%|▎              | 2/100 [00:11<08:31,  5.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 5.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 3  (0.0):   2%|▎              | 2/100 [00:13<08:31,  5.22s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):   3%|▍              | 3/100 [00:13<06:42,  4.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 4  (0.0):   3%|▍              | 3/100 [00:14<06:42,  4.14s/it]\u001b[A\n",
      "Average Metric: 0.0 / 4  (0.0):   4%|▌              | 4/100 [00:14<04:10,  2.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 5  (0.0):   4%|▌              | 4/100 [00:16<04:10,  2.61s/it]\u001b[A\n",
      "Average Metric: 0.0 / 5  (0.0):   5%|▊              | 5/100 [00:16<03:47,  2.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 9.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 6  (0.0):   5%|▊              | 5/100 [00:16<03:47,  2.39s/it]\u001b[A\n",
      "Average Metric: 0.0 / 6  (0.0):   6%|▉              | 6/100 [00:16<02:48,  1.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 7  (0.0):   6%|▉              | 6/100 [00:19<02:48,  1.79s/it]\u001b[A\n",
      "Average Metric: 0.0 / 7  (0.0):   7%|█              | 7/100 [00:19<03:20,  2.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 8  (0.0):   7%|█              | 7/100 [00:21<03:20,  2.16s/it]\u001b[A\n",
      "Average Metric: 0.0 / 8  (0.0):   8%|█▏             | 8/100 [00:21<02:59,  1.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 9  (0.0):   8%|█▏             | 8/100 [00:22<02:59,  1.96s/it]\u001b[A\n",
      "Average Metric: 0.0 / 9  (0.0):   9%|█▎             | 9/100 [00:22<02:52,  1.89s/it]\u001b[A\n",
      "Average Metric: 0.0 / 10  (0.0):   9%|█▎            | 9/100 [00:22<02:52,  1.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 11  (0.0):  10%|█▎           | 10/100 [00:25<02:50,  1.89s/it]\u001b[A\n",
      "Average Metric: 0.0 / 11  (0.0):  11%|█▍           | 11/100 [00:25<02:18,  1.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 19.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 23.0 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 12  (0.0):  11%|█▍           | 11/100 [00:30<02:18,  1.56s/it]\u001b[A\n",
      "Average Metric: 0.0 / 12  (0.0):  12%|█▌           | 12/100 [00:30<03:30,  2.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 13  (0.0):  12%|█▌           | 12/100 [00:30<03:30,  2.39s/it]\u001b[A\n",
      "Average Metric: 0.0 / 13  (0.0):  13%|█▋           | 13/100 [00:30<02:44,  1.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 14  (0.0):  13%|█▋           | 13/100 [00:32<02:44,  1.89s/it]\u001b[A\n",
      "Average Metric: 0.0 / 14  (0.0):  14%|█▊           | 14/100 [00:32<02:35,  1.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 5.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 18.0 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 15  (0.0):  14%|█▊           | 14/100 [00:35<02:35,  1.81s/it]\u001b[A\n",
      "Average Metric: 0.0 / 15  (0.0):  15%|█▉           | 15/100 [00:35<02:57,  2.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 16  (0.0):  15%|█▉           | 15/100 [00:35<02:57,  2.09s/it]\u001b[A\n",
      "Average Metric: 0.0 / 16  (0.0):  16%|██           | 16/100 [00:35<02:25,  1.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 17  (0.0):  16%|██           | 16/100 [00:36<02:25,  1.73s/it]\u001b[A\n",
      "Average Metric: 0.0 / 17  (0.0):  17%|██▏          | 17/100 [00:36<02:05,  1.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 18  (0.0):  17%|██▏          | 17/100 [00:40<02:05,  1.51s/it]\u001b[A\n",
      "Average Metric: 0.0 / 18  (0.0):  18%|██▎          | 18/100 [00:40<02:45,  2.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 3.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 19  (0.0):  18%|██▎          | 18/100 [00:41<02:45,  2.02s/it]\u001b[A\n",
      "Average Metric: 0.0 / 19  (0.0):  19%|██▍          | 19/100 [00:41<02:24,  1.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 20  (0.0):  19%|██▍          | 19/100 [00:43<02:24,  1.78s/it]\u001b[A\n",
      "Average Metric: 0.0 / 20  (0.0):  20%|██▌          | 20/100 [00:43<02:40,  2.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 21  (0.0):  20%|██▌          | 20/100 [00:47<02:40,  2.01s/it]\u001b[A\n",
      "Average Metric: 0.0 / 21  (0.0):  21%|██▋          | 21/100 [00:47<03:10,  2.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 22  (0.0):  21%|██▋          | 21/100 [00:48<03:10,  2.42s/it]\u001b[A\n",
      "Average Metric: 0.0 / 22  (0.0):  22%|██▊          | 22/100 [00:48<02:31,  1.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 21.8 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 23  (0.0):  22%|██▊          | 22/100 [00:49<02:31,  1.94s/it]\u001b[A\n",
      "Average Metric: 0.0 / 23  (0.0):  23%|██▉          | 23/100 [00:49<02:25,  1.89s/it]\u001b[A\n",
      "Average Metric: 0.0 / 24  (0.0):  23%|██▉          | 23/100 [00:50<02:25,  1.89s/it]\u001b[A\n",
      "Average Metric: 0.0 / 24  (0.0):  24%|███          | 24/100 [00:50<01:43,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 83.7 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 52.0 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 30.2 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.0 / 25  (0.0):  24%|███          | 24/100 [00:55<01:43,  1.37s/it]\u001b[A\n",
      "Average Metric: 0.0 / 25  (0.0):  25%|███▎         | 25/100 [00:55<03:07,  2.50s/it]\u001b[A\n",
      "Average Metric: 0.0 / 26  (0.0):  25%|███▎         | 25/100 [00:56<03:07,  2.50s/it]\u001b[A\n",
      "Average Metric: 0.0 / 26  (0.0):  26%|███▍         | 26/100 [00:56<02:32,  2.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 27  (0.0):  26%|███▍         | 26/100 [00:57<02:32,  2.06s/it]\u001b[A\n",
      "Average Metric: 0.0 / 27  (0.0):  27%|███▌         | 27/100 [00:57<02:24,  1.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 28  (0.0):  27%|███▌         | 27/100 [00:59<02:24,  1.97s/it]\u001b[A\n",
      "Average Metric: 0.0 / 28  (0.0):  28%|███▋         | 28/100 [00:59<02:06,  1.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 29  (0.0):  28%|███▋         | 28/100 [01:03<02:06,  1.76s/it]\u001b[A\n",
      "Average Metric: 0.0 / 29  (0.0):  29%|███▊         | 29/100 [01:03<02:53,  2.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 30  (0.0):  29%|███▊         | 29/100 [01:04<02:53,  2.44s/it]\u001b[A\n",
      "Average Metric: 0.0 / 30  (0.0):  30%|███▉         | 30/100 [01:04<02:27,  2.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 31  (0.0):  30%|███▉         | 30/100 [01:04<02:27,  2.11s/it]\u001b[A\n",
      "Average Metric: 0.0 / 31  (0.0):  31%|████         | 31/100 [01:04<01:47,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 32  (0.0):  31%|████         | 31/100 [01:06<01:47,  1.55s/it]\u001b[A\n",
      "Average Metric: 0.0 / 32  (0.0):  32%|████▏        | 32/100 [01:06<01:54,  1.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 33  (0.0):  32%|████▏        | 32/100 [01:11<01:54,  1.68s/it]\u001b[A\n",
      "Average Metric: 0.0 / 33  (0.0):  33%|████▎        | 33/100 [01:11<02:50,  2.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 56.9 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 34  (0.0):  33%|████▎        | 33/100 [01:12<02:50,  2.54s/it]\u001b[A\n",
      "Average Metric: 0.0 / 34  (0.0):  34%|████▍        | 34/100 [01:12<02:12,  2.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 35  (0.0):  34%|████▍        | 34/100 [01:15<02:12,  2.01s/it]\u001b[A\n",
      "Average Metric: 0.0 / 35  (0.0):  35%|████▌        | 35/100 [01:15<02:30,  2.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 36  (0.0):  35%|████▌        | 35/100 [01:16<02:30,  2.31s/it]\u001b[A\n",
      "Average Metric: 0.0 / 36  (0.0):  36%|████▋        | 36/100 [01:16<02:07,  1.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 37  (0.0):  36%|████▋        | 36/100 [01:17<02:07,  1.99s/it]\u001b[A\n",
      "Average Metric: 0.0 / 37  (0.0):  37%|████▊        | 37/100 [01:17<01:39,  1.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.5 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 38  (0.0):  37%|████▊        | 37/100 [01:19<01:39,  1.58s/it]\u001b[A\n",
      "Average Metric: 0.0 / 38  (0.0):  38%|████▉        | 38/100 [01:19<01:58,  1.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 39  (0.0):  38%|████▉        | 38/100 [01:21<01:58,  1.91s/it]\u001b[A\n",
      "Average Metric: 0.0 / 39  (0.0):  39%|█████        | 39/100 [01:21<01:48,  1.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 40  (0.0):  39%|█████        | 39/100 [01:23<01:48,  1.77s/it]\u001b[A\n",
      "Average Metric: 0.0 / 40  (0.0):  40%|█████▏       | 40/100 [01:23<01:53,  1.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 2.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 41  (0.0):  40%|█████▏       | 40/100 [01:24<01:53,  1.89s/it]\u001b[A\n",
      "Average Metric: 0.0 / 41  (0.0):  41%|█████▎       | 41/100 [01:24<01:42,  1.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 2.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 63.0 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 42  (0.0):  41%|█████▎       | 41/100 [01:27<01:42,  1.74s/it]\u001b[A\n",
      "Average Metric: 0.0 / 42  (0.0):  42%|█████▍       | 42/100 [01:27<01:57,  2.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 9.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 43  (0.0):  42%|█████▍       | 42/100 [01:29<01:57,  2.03s/it]\u001b[A\n",
      "Average Metric: 0.0 / 43  (0.0):  43%|█████▌       | 43/100 [01:29<01:49,  1.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 44  (0.0):  43%|█████▌       | 43/100 [01:29<01:49,  1.93s/it]\u001b[A\n",
      "Average Metric: 0.0 / 44  (0.0):  44%|█████▋       | 44/100 [01:29<01:19,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 45  (0.0):  44%|█████▋       | 44/100 [01:31<01:19,  1.43s/it]\u001b[A\n",
      "Average Metric: 0.0 / 45  (0.0):  45%|█████▊       | 45/100 [01:31<01:25,  1.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 50.2 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 46  (0.0):  45%|█████▊       | 45/100 [01:34<01:25,  1.56s/it]\u001b[A\n",
      "Average Metric: 0.0 / 46  (0.0):  46%|█████▉       | 46/100 [01:34<01:58,  2.19s/it]\u001b[A\n",
      "Average Metric: 0.0 / 47  (0.0):  46%|█████▉       | 46/100 [01:35<01:58,  2.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 47  (0.0):  47%|██████       | 47/100 [01:35<01:24,  1.59s/it]\u001b[A\n",
      "Average Metric: 0.0 / 48  (0.0):  47%|██████       | 47/100 [01:35<01:24,  1.59s/it]\u001b[A\n",
      "Average Metric: 0.0 / 48  (0.0):  48%|██████▏      | 48/100 [01:35<01:07,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 49  (0.0):  48%|██████▏      | 48/100 [01:38<01:07,  1.30s/it]\u001b[A\n",
      "Average Metric: 0.0 / 49  (0.0):  49%|██████▎      | 49/100 [01:38<01:22,  1.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 19.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 50  (0.0):  49%|██████▎      | 49/100 [01:42<01:22,  1.61s/it]\u001b[A\n",
      "Average Metric: 0.0 / 50  (0.0):  50%|██████▌      | 50/100 [01:42<02:03,  2.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 51  (0.0):  50%|██████▌      | 50/100 [01:44<02:03,  2.48s/it]\u001b[A\n",
      "Average Metric: 0.0 / 51  (0.0):  51%|██████▋      | 51/100 [01:44<01:46,  2.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 52  (0.0):  51%|██████▋      | 51/100 [01:45<01:46,  2.17s/it]\u001b[A\n",
      "Average Metric: 0.0 / 52  (0.0):  52%|██████▊      | 52/100 [01:45<01:28,  1.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 53  (0.0):  52%|██████▊      | 52/100 [01:45<01:28,  1.84s/it]\u001b[A\n",
      "Average Metric: 0.0 / 53  (0.0):  53%|██████▉      | 53/100 [01:45<01:08,  1.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 54  (0.0):  53%|██████▉      | 53/100 [01:46<01:08,  1.46s/it]\u001b[A\n",
      "Average Metric: 0.0 / 54  (0.0):  54%|███████      | 54/100 [01:46<01:02,  1.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 55  (0.0):  54%|███████      | 54/100 [01:48<01:02,  1.36s/it]\u001b[A\n",
      "Average Metric: 0.0 / 55  (0.0):  55%|███████▏     | 55/100 [01:48<01:08,  1.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 56  (0.0):  55%|███████▏     | 55/100 [01:52<01:08,  1.51s/it]\u001b[A\n",
      "Average Metric: 0.0 / 56  (0.0):  56%|███████▎     | 56/100 [01:52<01:39,  2.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 57  (0.0):  56%|███████▎     | 56/100 [01:53<01:39,  2.27s/it]\u001b[A\n",
      "Average Metric: 0.0 / 57  (0.0):  57%|███████▍     | 57/100 [01:53<01:18,  1.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 58  (0.0):  57%|███████▍     | 57/100 [01:55<01:18,  1.83s/it]\u001b[A\n",
      "Average Metric: 0.0 / 58  (0.0):  58%|███████▌     | 58/100 [01:55<01:23,  1.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 59  (0.0):  58%|███████▌     | 58/100 [01:58<01:23,  1.99s/it]\u001b[A\n",
      "Average Metric: 0.0 / 59  (0.0):  59%|███████▋     | 59/100 [01:58<01:28,  2.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 60  (0.0):  59%|███████▋     | 59/100 [02:00<01:28,  2.16s/it]\u001b[A\n",
      "Average Metric: 0.0 / 60  (0.0):  60%|███████▊     | 60/100 [02:00<01:24,  2.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 26.0 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 61  (0.0):  60%|███████▊     | 60/100 [02:01<01:24,  2.11s/it]\u001b[A\n",
      "Average Metric: 0.0 / 61  (0.0):  61%|███████▉     | 61/100 [02:01<01:10,  1.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 62  (0.0):  61%|███████▉     | 61/100 [02:04<01:10,  1.81s/it]\u001b[A\n",
      "Average Metric: 0.0 / 62  (0.0):  62%|████████     | 62/100 [02:04<01:21,  2.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 63  (0.0):  62%|████████     | 62/100 [02:05<01:21,  2.15s/it]\u001b[A\n",
      "Average Metric: 0.0 / 63  (0.0):  63%|████████▏    | 63/100 [02:05<01:06,  1.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 8.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 64  (0.0):  63%|████████▏    | 63/100 [02:10<01:06,  1.79s/it]\u001b[A\n",
      "Average Metric: 0.0 / 64  (0.0):  64%|████████▎    | 64/100 [02:10<01:36,  2.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 65  (0.0):  64%|████████▎    | 64/100 [02:11<01:36,  2.67s/it]\u001b[A\n",
      "Average Metric: 0.0 / 65  (0.0):  65%|████████▍    | 65/100 [02:11<01:17,  2.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 66  (0.0):  65%|████████▍    | 65/100 [02:12<01:17,  2.21s/it]\u001b[A\n",
      "Average Metric: 0.0 / 66  (0.0):  66%|████████▌    | 66/100 [02:12<01:09,  2.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 67  (0.0):  66%|████████▌    | 66/100 [02:14<01:09,  2.05s/it]\u001b[A\n",
      "Average Metric: 0.0 / 67  (0.0):  67%|████████▋    | 67/100 [02:14<01:06,  2.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.7 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 68  (0.0):  67%|████████▋    | 67/100 [02:16<01:06,  2.01s/it]\u001b[A\n",
      "Average Metric: 0.0 / 68  (0.0):  68%|████████▊    | 68/100 [02:16<00:58,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 69  (0.0):  68%|████████▊    | 68/100 [02:18<00:58,  1.82s/it]\u001b[A\n",
      "Average Metric: 0.0 / 69  (0.0):  69%|████████▉    | 69/100 [02:18<01:01,  1.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 70  (0.0):  69%|████████▉    | 69/100 [02:19<01:01,  1.97s/it]\u001b[A\n",
      "Average Metric: 0.0 / 70  (0.0):  70%|█████████    | 70/100 [02:19<00:45,  1.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 71  (0.0):  70%|█████████    | 70/100 [02:19<00:45,  1.53s/it]\u001b[A\n",
      "Average Metric: 0.0 / 71  (0.0):  71%|█████████▏   | 71/100 [02:19<00:34,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 72  (0.0):  71%|█████████▏   | 71/100 [02:23<00:34,  1.19s/it]\u001b[A\n",
      "Average Metric: 0.0 / 72  (0.0):  72%|█████████▎   | 72/100 [02:23<01:00,  2.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 73  (0.0):  72%|█████████▎   | 72/100 [02:24<01:00,  2.18s/it]\u001b[A\n",
      "Average Metric: 0.0 / 73  (0.0):  73%|█████████▍   | 73/100 [02:24<00:49,  1.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 44.3 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 60.1 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 74  (0.0):  73%|█████████▍   | 73/100 [02:26<00:49,  1.82s/it]\u001b[A\n",
      "Average Metric: 0.0 / 74  (0.0):  74%|█████████▌   | 74/100 [02:26<00:49,  1.90s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 78.7 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 75  (0.0):  74%|█████████▌   | 74/100 [02:29<00:49,  1.90s/it]\u001b[A\n",
      "Average Metric: 0.0 / 75  (0.0):  75%|█████████▊   | 75/100 [02:29<00:53,  2.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 13.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 76  (0.0):  75%|█████████▊   | 75/100 [02:32<00:53,  2.12s/it]\u001b[A\n",
      "Average Metric: 0.0 / 76  (0.0):  76%|█████████▉   | 76/100 [02:32<00:56,  2.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 77  (0.0):  76%|█████████▉   | 76/100 [02:33<00:56,  2.34s/it]\u001b[A\n",
      "Average Metric: 0.0 / 77  (0.0):  77%|██████████   | 77/100 [02:33<00:47,  2.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 78  (0.0):  77%|██████████   | 77/100 [02:35<00:47,  2.05s/it]\u001b[A\n",
      "Average Metric: 0.0 / 78  (0.0):  78%|██████████▏  | 78/100 [02:35<00:39,  1.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 79  (0.0):  78%|██████████▏  | 78/100 [02:39<00:39,  1.78s/it]\u001b[A\n",
      "Average Metric: 0.0 / 79  (0.0):  79%|██████████▎  | 79/100 [02:39<00:52,  2.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 80  (0.0):  79%|██████████▎  | 79/100 [02:40<00:52,  2.52s/it]\u001b[A\n",
      "Average Metric: 0.0 / 80  (0.0):  80%|██████████▍  | 80/100 [02:40<00:40,  2.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 81  (0.0):  80%|██████████▍  | 80/100 [02:41<00:40,  2.02s/it]\u001b[A\n",
      "Average Metric: 0.0 / 81  (0.0):  81%|██████████▌  | 81/100 [02:41<00:34,  1.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 82  (0.0):  81%|██████████▌  | 81/100 [02:44<00:34,  1.80s/it]\u001b[A\n",
      "Average Metric: 0.0 / 82  (0.0):  82%|██████████▋  | 82/100 [02:44<00:36,  2.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 83  (0.0):  82%|██████████▋  | 82/100 [02:44<00:36,  2.05s/it]\u001b[A\n",
      "Average Metric: 0.0 / 83  (0.0):  83%|██████████▊  | 83/100 [02:44<00:27,  1.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 84  (0.0):  83%|██████████▊  | 83/100 [02:48<00:27,  1.60s/it]\u001b[A\n",
      "Average Metric: 0.0 / 84  (0.0):  84%|██████████▉  | 84/100 [02:48<00:38,  2.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 85  (0.0):  84%|██████████▉  | 84/100 [02:49<00:38,  2.39s/it]\u001b[A\n",
      "Average Metric: 0.0 / 85  (0.0):  85%|███████████  | 85/100 [02:49<00:26,  1.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 86  (0.0):  85%|███████████  | 85/100 [02:50<00:26,  1.80s/it]\u001b[A\n",
      "Average Metric: 0.0 / 86  (0.0):  86%|███████████▏ | 86/100 [02:50<00:22,  1.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.3 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 87  (0.0):  86%|███████████▏ | 86/100 [02:53<00:22,  1.60s/it]\u001b[A\n",
      "Average Metric: 0.0 / 87  (0.0):  87%|███████████▎ | 87/100 [02:53<00:25,  1.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 88  (0.0):  87%|███████████▎ | 87/100 [02:54<00:25,  1.97s/it]\u001b[A\n",
      "Average Metric: 0.0 / 88  (0.0):  88%|███████████▍ | 88/100 [02:54<00:20,  1.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 89  (0.0):  88%|███████████▍ | 88/100 [02:55<00:20,  1.72s/it]\u001b[A\n",
      "Average Metric: 0.0 / 89  (0.0):  89%|███████████▌ | 89/100 [02:55<00:15,  1.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 90  (0.0):  89%|███████████▌ | 89/100 [02:55<00:15,  1.43s/it]\u001b[A\n",
      "Average Metric: 0.0 / 90  (0.0):  90%|███████████▋ | 90/100 [02:55<00:11,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 91  (0.0):  90%|███████████▋ | 90/100 [02:57<00:11,  1.16s/it]\u001b[A\n",
      "Average Metric: 0.0 / 91  (0.0):  91%|███████████▊ | 91/100 [02:57<00:13,  1.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 92  (0.0):  91%|███████████▊ | 91/100 [03:01<00:13,  1.48s/it]\u001b[A\n",
      "Average Metric: 0.0 / 92  (0.0):  92%|███████████▉ | 92/100 [03:01<00:17,  2.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 55.5 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 93  (0.0):  92%|███████████▉ | 92/100 [03:02<00:17,  2.14s/it]\u001b[A\n",
      "Average Metric: 0.0 / 93  (0.0):  93%|████████████ | 93/100 [03:02<00:12,  1.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 94  (0.0):  93%|████████████ | 93/100 [03:03<00:12,  1.76s/it]\u001b[A\n",
      "Average Metric: 0.0 / 94  (0.0):  94%|████████████▏| 94/100 [03:03<00:10,  1.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 95  (0.0):  94%|████████████▏| 94/100 [03:04<00:10,  1.70s/it]\u001b[A\n",
      "Average Metric: 0.0 / 95  (0.0):  95%|████████████▎| 95/100 [03:04<00:06,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 96  (0.0):  95%|████████████▎| 95/100 [03:05<00:06,  1.37s/it]\u001b[A\n",
      "Average Metric: 0.0 / 96  (0.0):  96%|████████████▍| 96/100 [03:05<00:04,  1.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 97  (0.0):  96%|████████████▍| 96/100 [03:10<00:04,  1.11s/it]\u001b[A\n",
      "Average Metric: 0.0 / 97  (0.0):  97%|████████████▌| 97/100 [03:10<00:07,  2.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 98  (0.0):  97%|████████████▌| 97/100 [03:26<00:07,  2.41s/it]\u001b[A\n",
      "Average Metric: 0.0 / 98  (0.0):  98%|████████████▋| 98/100 [03:26<00:12,  6.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 99  (0.0):  98%|████████████▋| 98/100 [03:48<00:12,  6.47s/it]\u001b[A\n",
      "Average Metric: 0.0 / 99  (0.0):  99%|████████████▊| 99/100 [03:48<00:11, 11.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 100  (0.0):  99%|███████████▉| 99/100 [03:58<00:11, 11.08s/it]\u001b[A\n",
      "Average Metric: 0.0 / 100  (0.0): 100%|███████████| 100/100 [03:58<00:00,  2.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t 'NoneType' object is not callable\n",
      "Average Metric: 0.0 / 100  (0.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(num_threads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, display_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, display_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      5\u001b[0m compiled_mipro \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mcompile(ABSAPipelineV2(), trainset\u001b[38;5;241m=\u001b[39mdspy_train[:\u001b[38;5;241m30\u001b[39m], num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, max_bootstrapped_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, max_labeled_demos\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, eval_kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m----> 6\u001b[0m eval_score \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiled_mipro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdspy_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:190\u001b[0m, in \u001b[0;36mEvaluate.__call__\u001b[0;34m(self, program, metric, devset, num_threads, display_progress, display_table, display, return_all_scores, return_outputs)\u001b[0m\n\u001b[1;32m    187\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapplymap(truncate_cell)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Rename the 'correct' column to the name of the metric object\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(metric)\n\u001b[1;32m    191\u001b[0m metric_name \u001b[38;5;241m=\u001b[39m metric\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    192\u001b[0m     metric, types\u001b[38;5;241m.\u001b[39mFunctionType) \u001b[38;5;28;01melse\u001b[39;00m metric\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m    193\u001b[0m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m\"\u001b[39m: metric_name}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import MIPRO\n",
    "\n",
    "optimizer = MIPRO(metric=validate_f1)\n",
    "kwargs = dict(num_threads=10, display_progress=True, display_table=5)\n",
    "compiled_mipro = optimizer.compile(ABSAPipelineV2(), trainset=dspy_train[:30], num_trials=50, max_bootstrapped_demos=3, max_labeled_demos=5, eval_kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9f7e9dfb-7f7b-439a-9f17-5df92e1da4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSAPipelineV2.load(compiled_mipro, \"./ABSAPipelineV2MIPRO.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a471ac73-e814-4504-8971-40b9242bcd50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                     | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   1%|▏            | 1/100 [00:00<00:15,  6.30it/s]\u001b[A\n",
      "Average Metric: 1.4 / 2  (70.0):   1%|▏             | 1/100 [00:00<00:15,  6.30it/s]\u001b[A\n",
      "Average Metric: 2.15 / 3  (71.7):   2%|▎            | 2/100 [00:00<00:15,  6.30it/s]\u001b[A\n",
      "Average Metric: 3.15 / 4  (78.8):   3%|▍            | 3/100 [00:00<00:15,  6.30it/s]\u001b[A\n",
      "Average Metric: 3.877272727272727 / 5  (77.5):   4%| | 4/100 [00:00<00:15,  6.30it/s\u001b[A\n",
      "Average Metric: 4.099494949494949 / 6  (68.3):   5%| | 5/100 [00:00<00:15,  6.30it/s\u001b[A\n",
      "Average Metric: 5.099494949494949 / 7  (72.8):   6%| | 6/100 [00:00<00:14,  6.30it/s\u001b[A\n",
      "Average Metric: 5.099494949494949 / 7  (72.8):   7%| | 7/100 [00:00<00:03, 27.78it/s\u001b[A\n",
      "Average Metric: 5.432828282828282 / 8  (67.9):   7%| | 7/100 [00:00<00:03, 27.78it/s\u001b[A\n",
      "Average Metric: 5.432828282828282 / 9  (60.4):   8%| | 8/100 [00:00<00:03, 27.78it/s\u001b[A\n",
      "Average Metric: 5.432828282828282 / 10  (54.3):   9%| | 9/100 [00:00<00:03, 27.78it/\u001b[A\n",
      "Average Metric: 6.099494949494949 / 11  (55.4):  10%| | 10/100 [00:00<00:03, 27.78it\u001b[A\n",
      "Average Metric: 6.899494949494949 / 12  (57.5):  11%| | 11/100 [00:00<00:03, 27.78it\u001b[A\n",
      "Average Metric: 7.399494949494949 / 13  (56.9):  12%| | 12/100 [00:00<00:03, 27.78it\u001b[A\n",
      "Average Metric: 8.066161616161615 / 14  (57.6):  13%|▏| 13/100 [00:00<00:03, 27.78it\u001b[A\n",
      "Average Metric: 8.066161616161615 / 14  (57.6):  14%|▏| 14/100 [00:00<00:02, 40.88it\u001b[A\n",
      "Average Metric: 8.066161616161615 / 15  (53.8):  14%|▏| 14/100 [00:00<00:02, 40.88it\u001b[A\n",
      "Average Metric: 9.066161616161615 / 16  (56.7):  15%|▏| 15/100 [00:00<00:02, 40.88it\u001b[A\n",
      "Average Metric: 9.666161616161615 / 17  (56.9):  16%|▏| 16/100 [00:00<00:02, 40.88it\u001b[A\n",
      "Average Metric: 10.166161616161615 / 18  (56.5):  17%|▏| 17/100 [00:00<00:02, 40.88i\u001b[A\n",
      "Average Metric: 11.166161616161615 / 19  (58.8):  18%|▏| 18/100 [00:00<00:02, 40.88i\u001b[A\n",
      "Average Metric: 11.166161616161615 / 19  (58.8):  19%|▏| 19/100 [00:00<00:01, 40.97i\u001b[A\n",
      "Average Metric: 12.166161616161615 / 20  (60.8):  19%|▏| 19/100 [00:00<00:01, 40.97i\u001b[A\n",
      "Average Metric: 13.023304473304472 / 21  (62.0):  20%|▏| 20/100 [00:00<00:01, 40.97i\u001b[A\n",
      "Average Metric: 14.023304473304472 / 22  (63.7):  21%|▏| 21/100 [00:00<00:01, 40.97i\u001b[A\n",
      "Average Metric: 15.023304473304472 / 23  (65.3):  22%|▏| 22/100 [00:00<00:01, 40.97i\u001b[A\n",
      "Average Metric: 15.689971139971139 / 24  (65.4):  23%|▏| 23/100 [00:00<00:01, 40.97i\u001b[A\n",
      "Average Metric: 16.68997113997114 / 25  (66.8):  24%|▏| 24/100 [00:00<00:01, 40.97it\u001b[A\n",
      "Average Metric: 16.68997113997114 / 26  (64.2):  25%|▎| 25/100 [00:00<00:01, 40.97it\u001b[A\n",
      "Average Metric: 16.68997113997114 / 26  (64.2):  26%|▎| 26/100 [00:00<00:01, 47.60it\u001b[A\n",
      "Average Metric: 17.68997113997114 / 27  (65.5):  26%|▎| 26/100 [00:00<00:01, 47.60it\u001b[A\n",
      "Average Metric: 18.68997113997114 / 28  (66.7):  27%|▎| 27/100 [00:00<00:01, 47.60it\u001b[A\n",
      "Average Metric: 18.68997113997114 / 29  (64.4):  28%|▎| 28/100 [00:00<00:01, 47.60it\u001b[A\n",
      "Average Metric: 19.43997113997114 / 30  (64.8):  29%|▎| 29/100 [00:00<00:01, 47.60it\u001b[A\n",
      "Average Metric: 19.43997113997114 / 31  (62.7):  30%|▎| 30/100 [00:00<00:01, 47.60it\u001b[A\n",
      "Average Metric: 19.43997113997114 / 31  (62.7):  31%|▎| 31/100 [00:00<00:01, 47.25it\u001b[A\n",
      "Average Metric: 20.43997113997114 / 32  (63.9):  31%|▎| 31/100 [00:00<00:01, 47.25it\u001b[A\n",
      "Average Metric: 20.43997113997114 / 33  (61.9):  32%|▎| 32/100 [00:00<00:01, 47.25it\u001b[A\n",
      "Average Metric: 20.43997113997114 / 34  (60.1):  33%|▎| 33/100 [00:00<00:01, 47.25it\u001b[A\n",
      "Average Metric: 21.43997113997114 / 35  (61.3):  34%|▎| 34/100 [00:00<00:01, 47.25it\u001b[A\n",
      "Average Metric: 21.93997113997114 / 36  (60.9):  35%|▎| 35/100 [00:00<00:01, 47.25it\u001b[A\n",
      "Average Metric: 21.93997113997114 / 36  (60.9):  36%|▎| 36/100 [00:00<00:01, 47.30it\u001b[A\n",
      "Average Metric: 22.93997113997114 / 37  (62.0):  36%|▎| 36/100 [00:00<00:01, 47.30it\u001b[A\n",
      "Average Metric: 23.93997113997114 / 38  (63.0):  37%|▎| 37/100 [00:00<00:01, 47.30it\u001b[A\n",
      "Average Metric: 24.93997113997114 / 39  (63.9):  38%|▍| 38/100 [00:00<00:01, 47.30it\u001b[A\n",
      "Average Metric: 25.93997113997114 / 40  (64.8):  39%|▍| 39/100 [00:00<00:01, 47.30it\u001b[A\n",
      "Average Metric: 26.68997113997114 / 41  (65.1):  40%|▍| 40/100 [00:00<00:01, 47.30it\u001b[A\n",
      "Average Metric: 26.68997113997114 / 41  (65.1):  41%|▍| 41/100 [00:00<00:01, 47.65it\u001b[A\n",
      "Average Metric: 27.089971139971137 / 42  (64.5):  41%|▍| 41/100 [00:01<00:01, 47.65i\u001b[A\n",
      "Average Metric: 27.889971139971138 / 43  (64.9):  42%|▍| 42/100 [00:01<00:01, 47.65i\u001b[A\n",
      "Average Metric: 28.556637806637806 / 44  (64.9):  43%|▍| 43/100 [00:01<00:01, 47.65i\u001b[A\n",
      "Average Metric: 29.556637806637806 / 45  (65.7):  44%|▍| 44/100 [00:01<00:01, 47.65i\u001b[A\n",
      "Average Metric: 30.556637806637806 / 46  (66.4):  45%|▍| 45/100 [00:01<00:01, 47.65i\u001b[A\n",
      "Average Metric: 30.556637806637806 / 46  (66.4):  46%|▍| 46/100 [00:01<00:01, 36.71i\u001b[A\n",
      "Average Metric: 31.556637806637806 / 47  (67.1):  46%|▍| 46/100 [00:01<00:01, 36.71i\u001b[A\n",
      "Average Metric: 32.55663780663781 / 48  (67.8):  47%|▍| 47/100 [00:01<00:01, 36.71it\u001b[A\n",
      "Average Metric: 33.55663780663781 / 49  (68.5):  48%|▍| 48/100 [00:01<00:01, 36.71it\u001b[A\n",
      "Average Metric: 33.55663780663781 / 50  (67.1):  49%|▍| 49/100 [00:01<00:01, 36.71it\u001b[A\n",
      "Average Metric: 33.55663780663781 / 51  (65.8):  50%|▌| 50/100 [00:01<00:01, 36.71it\u001b[A\n",
      "Average Metric: 33.95663780663781 / 52  (65.3):  51%|▌| 51/100 [00:01<00:01, 36.71it\u001b[A\n",
      "Average Metric: 34.62330447330447 / 53  (65.3):  52%|▌| 52/100 [00:01<00:01, 36.71it\u001b[A\n",
      "Average Metric: 34.62330447330447 / 53  (65.3):  53%|▌| 53/100 [00:01<00:01, 43.77it\u001b[A\n",
      "Average Metric: 35.289971139971136 / 54  (65.4):  53%|▌| 53/100 [00:01<00:01, 43.77i\u001b[A\n",
      "Average Metric: 36.289971139971136 / 55  (66.0):  54%|▌| 54/100 [00:01<00:01, 43.77i\u001b[A\n",
      "Average Metric: 37.289971139971136 / 56  (66.6):  55%|▌| 55/100 [00:01<00:01, 43.77i\u001b[A\n",
      "Average Metric: 37.289971139971136 / 57  (65.4):  56%|▌| 56/100 [00:01<00:01, 43.77i\u001b[A\n",
      "Average Metric: 38.089971139971134 / 58  (65.7):  57%|▌| 57/100 [00:01<00:00, 43.77i\u001b[A\n",
      "Average Metric: 38.089971139971134 / 58  (65.7):  58%|▌| 58/100 [00:01<00:00, 44.10i\u001b[A\n",
      "Average Metric: 38.089971139971134 / 59  (64.6):  58%|▌| 58/100 [00:01<00:00, 44.10i\u001b[A\n",
      "Average Metric: 38.089971139971134 / 60  (63.5):  59%|▌| 59/100 [00:01<00:00, 44.10i\u001b[A\n",
      "Average Metric: 38.089971139971134 / 61  (62.4):  60%|▌| 60/100 [00:01<00:00, 44.10i\u001b[A\n",
      "Average Metric: 39.089971139971134 / 62  (63.0):  61%|▌| 61/100 [00:01<00:00, 44.10i\u001b[A\n",
      "Average Metric: 40.089971139971134 / 63  (63.6):  62%|▌| 62/100 [00:01<00:00, 44.10i\u001b[A\n",
      "Average Metric: 40.53441558441558 / 64  (63.3):  63%|▋| 63/100 [00:01<00:00, 44.10it\u001b[A\n",
      "Average Metric: 40.53441558441558 / 65  (62.4):  64%|▋| 64/100 [00:01<00:00, 44.10it\u001b[A\n",
      "Average Metric: 41.53441558441558 / 66  (62.9):  65%|▋| 65/100 [00:01<00:00, 44.10it\u001b[A\n",
      "Average Metric: 41.53441558441558 / 66  (62.9):  66%|▋| 66/100 [00:01<00:00, 51.41it\u001b[A\n",
      "Average Metric: 41.89805194805194 / 67  (62.5):  66%|▋| 66/100 [00:01<00:00, 51.41it\u001b[A\n",
      "Average Metric: 42.89805194805194 / 68  (63.1):  67%|▋| 67/100 [00:01<00:00, 51.41it\u001b[A\n",
      "Average Metric: 43.29805194805194 / 69  (62.8):  68%|▋| 68/100 [00:01<00:00, 51.41it\u001b[A\n",
      "Average Metric: 43.29805194805194 / 70  (61.9):  69%|▋| 69/100 [00:01<00:00, 51.41it\u001b[A\n",
      "Average Metric: 44.29805194805194 / 71  (62.4):  70%|▋| 70/100 [00:01<00:00, 51.41it\u001b[A\n",
      "Average Metric: 45.29805194805194 / 72  (62.9):  71%|▋| 71/100 [00:01<00:00, 51.41it\u001b[A\n",
      "Average Metric: 45.29805194805194 / 72  (62.9):  72%|▋| 72/100 [00:01<00:00, 52.62it\u001b[A\n",
      "Average Metric: 46.09805194805194 / 73  (63.1):  72%|▋| 72/100 [00:01<00:00, 52.62it\u001b[A\n",
      "Average Metric: 47.09805194805194 / 74  (63.6):  73%|▋| 73/100 [00:01<00:00, 52.62it\u001b[A\n",
      "Average Metric: 47.09805194805194 / 75  (62.8):  74%|▋| 74/100 [00:01<00:00, 52.62it\u001b[A\n",
      "Average Metric: 47.09805194805194 / 76  (62.0):  75%|▊| 75/100 [00:01<00:00, 52.62it\u001b[A\n",
      "Average Metric: 47.461688311688306 / 77  (61.6):  76%|▊| 76/100 [00:01<00:00, 52.62i\u001b[A\n",
      "Average Metric: 47.461688311688306 / 78  (60.8):  77%|▊| 77/100 [00:01<00:00, 52.62i\u001b[A\n",
      "Average Metric: 47.461688311688306 / 78  (60.8):  78%|▊| 78/100 [00:01<00:00, 49.57i\u001b[A\n",
      "Average Metric: 48.461688311688306 / 79  (61.3):  78%|▊| 78/100 [00:01<00:00, 49.57i\u001b[A\n",
      "Average Metric: 49.31883116883116 / 80  (61.6):  79%|▊| 79/100 [00:01<00:00, 49.57it\u001b[A\n",
      "Average Metric: 49.31883116883116 / 81  (60.9):  80%|▊| 80/100 [00:01<00:00, 49.57it\u001b[A\n",
      "Average Metric: 49.31883116883116 / 82  (60.1):  81%|▊| 81/100 [00:01<00:00, 49.57it\u001b[A\n",
      "Average Metric: 49.81883116883116 / 83  (60.0):  82%|▊| 82/100 [00:01<00:00, 49.57it\u001b[A\n",
      "Average Metric: 50.81883116883116 / 84  (60.5):  83%|▊| 83/100 [00:01<00:00, 49.57it\u001b[A\n",
      "Average Metric: 50.81883116883116 / 84  (60.5):  84%|▊| 84/100 [00:01<00:00, 47.53it\u001b[A\n",
      "Average Metric: 51.485497835497824 / 85  (60.6):  84%|▊| 84/100 [00:01<00:00, 47.53i\u001b[A\n",
      "Average Metric: 52.28549783549782 / 86  (60.8):  85%|▊| 85/100 [00:01<00:00, 47.53it\u001b[A\n",
      "Average Metric: 53.28549783549782 / 87  (61.2):  86%|▊| 86/100 [00:01<00:00, 47.53it\u001b[A\n",
      "Average Metric: 53.28549783549782 / 88  (60.6):  87%|▊| 87/100 [00:01<00:00, 47.53it\u001b[A\n",
      "Average Metric: 54.28549783549782 / 89  (61.0):  88%|▉| 88/100 [00:01<00:00, 47.53it\u001b[A\n",
      "Average Metric: 54.952164502164486 / 90  (61.1):  89%|▉| 89/100 [00:01<00:00, 47.53i\u001b[A\n",
      "Average Metric: 54.952164502164486 / 90  (61.1):  90%|▉| 90/100 [00:01<00:00, 50.03i\u001b[A\n",
      "Average Metric: 55.452164502164486 / 91  (60.9):  90%|▉| 90/100 [00:01<00:00, 50.03i\u001b[A\n",
      "Average Metric: 56.11883116883115 / 92  (61.0):  91%|▉| 91/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 56.61883116883115 / 93  (60.9):  92%|▉| 92/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 56.61883116883115 / 94  (60.2):  93%|▉| 93/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 57.01883116883115 / 95  (60.0):  94%|▉| 94/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 57.76883116883115 / 96  (60.2):  95%|▉| 95/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 57.76883116883115 / 97  (59.6):  96%|▉| 96/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 57.76883116883115 / 98  (58.9):  97%|▉| 97/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 57.76883116883115 / 99  (58.4):  98%|▉| 98/100 [00:02<00:00, 50.03it\u001b[A\n",
      "Average Metric: 58.43549783549781 / 100  (58.4): 100%|█| 100/100 [00:02<00:00, 49.66\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.7272727272727273' '1.0' '0.4' '0.0' '1.0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 58.43549783549781 / 100  (58.4%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6fc65 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6fc65 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6fc65_row0_col0, #T_6fc65_row0_col1, #T_6fc65_row0_col2, #T_6fc65_row0_col3, #T_6fc65_row0_col4, #T_6fc65_row1_col0, #T_6fc65_row1_col1, #T_6fc65_row1_col2, #T_6fc65_row1_col3, #T_6fc65_row1_col4, #T_6fc65_row2_col0, #T_6fc65_row2_col1, #T_6fc65_row2_col2, #T_6fc65_row2_col3, #T_6fc65_row2_col4, #T_6fc65_row3_col0, #T_6fc65_row3_col1, #T_6fc65_row3_col2, #T_6fc65_row3_col3, #T_6fc65_row3_col4, #T_6fc65_row4_col0, #T_6fc65_row4_col1, #T_6fc65_row4_col2, #T_6fc65_row4_col3, #T_6fc65_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6fc65\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6fc65_level0_col0\" class=\"col_heading level0 col0\" >review</th>\n",
       "      <th id=\"T_6fc65_level0_col1\" class=\"col_heading level0 col1\" >example_aspects_with_label</th>\n",
       "      <th id=\"T_6fc65_level0_col2\" class=\"col_heading level0 col2\" >aspects_list</th>\n",
       "      <th id=\"T_6fc65_level0_col3\" class=\"col_heading level0 col3\" >pred_aspects_with_label</th>\n",
       "      <th id=\"T_6fc65_level0_col4\" class=\"col_heading level0 col4\" >validate_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6fc65_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6fc65_row0_col0\" class=\"data row0 col0\" >\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.</td>\n",
       "      <td id=\"T_6fc65_row0_col1\" class=\"data row0 col1\" >{'menu': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'pub fare': 0}</td>\n",
       "      <td id=\"T_6fc65_row0_col2\" class=\"data row0 col2\" >dict_keys(['menu', 'burgers', 'steaks', 'shepherds pie', 'portabella lasagna', 'pub fare'])</td>\n",
       "      <td id=\"T_6fc65_row0_col3\" class=\"data row0 col3\" >{'menu': 1, 'pub fare': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 1, 'vegetarians': 1}</td>\n",
       "      <td id=\"T_6fc65_row0_col4\" class=\"data row0 col4\" >0.7272727272727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6fc65_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6fc65_row1_col0\" class=\"data row1 col0\" >(The sashimi is cut a little thinly.</td>\n",
       "      <td id=\"T_6fc65_row1_col1\" class=\"data row1 col1\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_6fc65_row1_col2\" class=\"data row1 col2\" >dict_keys(['sashimi'])</td>\n",
       "      <td id=\"T_6fc65_row1_col3\" class=\"data row1 col3\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_6fc65_row1_col4\" class=\"data row1 col4\" >1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6fc65_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6fc65_row2_col0\" class=\"data row2 col0\" >) It's not the best Japanese restaurant in the East Village, but it's a pretty solid one for its modest prices, and worth repeat visits.</td>\n",
       "      <td id=\"T_6fc65_row2_col1\" class=\"data row2 col1\" >{'prices': 1}</td>\n",
       "      <td id=\"T_6fc65_row2_col2\" class=\"data row2 col2\" >dict_keys(['prices'])</td>\n",
       "      <td id=\"T_6fc65_row2_col3\" class=\"data row2 col3\" >{'Japanese restaurant': 0, 'East Village': 0, 'prices': 1, 'repeat visits': 1}</td>\n",
       "      <td id=\"T_6fc65_row2_col4\" class=\"data row2 col4\" >0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6fc65_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6fc65_row3_col0\" class=\"data row3 col0\" >15% gratuity automatically added to the bill.</td>\n",
       "      <td id=\"T_6fc65_row3_col1\" class=\"data row3 col1\" >{'bill': -1, 'gratuity': -1}</td>\n",
       "      <td id=\"T_6fc65_row3_col2\" class=\"data row3 col2\" >dict_keys(['bill', 'gratuity'])</td>\n",
       "      <td id=\"T_6fc65_row3_col3\" class=\"data row3 col3\" >{'gratuity': 0, 'bill': 0}</td>\n",
       "      <td id=\"T_6fc65_row3_col4\" class=\"data row3 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6fc65_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6fc65_row4_col0\" class=\"data row4 col0\" >A beautiful atmosphere, perfect for drinks and/or appetizers.</td>\n",
       "      <td id=\"T_6fc65_row4_col1\" class=\"data row4 col1\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_6fc65_row4_col2\" class=\"data row4 col2\" >dict_keys(['atmosphere', 'drinks', 'appetizers'])</td>\n",
       "      <td id=\"T_6fc65_row4_col3\" class=\"data row4 col3\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_6fc65_row4_col4\" class=\"data row4 col4\" >1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x35b6d2050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_score = evaluate_test(compiled_mipro, metric=validate_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c31bce7c-b99c-481a-8a88-dffe5f3ff7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58.44, 56.71)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_score, eval_score_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f531db3-0b69-4766-a95f-ffccdc1e7692",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dc4025d2-7554-443a-b0fb-9999055d3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review2AspectsList(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Identify aspects from a customer review. The aspects must be words or phrases in the review. The aspect\n",
    "    is typically a noun, and it must be the narrowest word or phrase possible. The response must be a valid Python list.\n",
    "    \"\"\"\n",
    "\n",
    "    review: str = dspy.InputField(desc=\"a customer review\")\n",
    "    aspects_list: str = dspy.OutputField(desc=dedent(\"\"\"\n",
    "        The value should be a valid Python list that contains all the aspects.\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6449db25-564c-49dc-856f-3a9706acf8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aspect2Reason(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Using the customer review and given aspect, reason about whether the aspect is positive, neutral, or negative.\n",
    "    Think deeply about the aspect in the context of the entire review.\n",
    "    \"\"\"\n",
    "\n",
    "    review: str = dspy.InputField(desc=\"a customer review\")\n",
    "    aspect: str = dspy.InputField(desc=dedent(\"\"\"\n",
    "        An aspect that is mentioned in the customer review\n",
    "        \"\"\"))\n",
    "    reason: str = dspy.OutputField(desc=dedent(\"\"\"\n",
    "        Reasons why the given aspect is positively described, neutrally described, or negatively described in the customer review.\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6481cd9c-e03c-4dc9-b1fa-238dab1f8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reason2Label(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Looks at the reason for whether the given aspect is positive, neutral, or negative, and labels it with a\n",
    "    \"\"\"\n",
    "\n",
    "    aspect: str = dspy.InputField(desc=dedent(\"\"\"\n",
    "        An aspect that is mentioned in the customer review\n",
    "        \"\"\"))\n",
    "    reason: str = dspy.InputField(desc=dedent(\"\"\"\n",
    "        Reasons why the given aspect is positively described, neutrally described, or negatively described in a customer review.\n",
    "        \"\"\"))\n",
    "    label: int = dspy.OutputField(format=int, desc=dedent(\"\"\"\n",
    "        an integer. 1 indicates positive sentiment. 0 indicates neutral sentiment. -1 indicates negative sentiment.\n",
    "        \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c569a933-8445-4e13-b022-c473ce66717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class ABSAPipelineV3(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_aspects = dspy.ChainOfThought(Review2AspectsList)\n",
    "        self.generate_reasons = dspy.ChainOfThought(Aspect2Reason)\n",
    "        self.generate_label = dspy.TypedChainOfThought(Reason2Label)\n",
    "\n",
    "    def forward(self, review):\n",
    "        aspects = self.generate_aspects(review=review)\n",
    "        aspects_with_label = {}\n",
    "        for aspect in ast.literal_eval(aspects.aspects_list):\n",
    "            if len(aspect) == 1:\n",
    "                print(\"invalid aspect\")\n",
    "                continue\n",
    "            reason = self.generate_reasons(review=review, aspect=aspect)\n",
    "            label = self.generate_label(aspect=aspect, reason=reason.reason)\n",
    "            aspects_with_label[aspect] = int(label.label)\n",
    "        return dspy.Prediction(aspects_with_label=aspects_with_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4fe507f9-68ac-4bf1-b16a-e23a92db1e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'menu': 1,\n",
       " 'pub fare': 0,\n",
       " 'burgers': 1,\n",
       " 'steaks': 1,\n",
       " 'shepherds pie': 1,\n",
       " 'portabella lasagna': 1,\n",
       " 'vegetarians': 0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncompiled_pipeline_v3 = ABSAPipelineV3()\n",
    "pred = uncompiled_pipeline_v3(dspy_test[0].review)\n",
    "pred.aspects_with_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e0f6a91-93b6-4d3c-9962-abef34a98853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                       | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   1%|▏              | 1/100 [00:00<00:11,  8.98it/s]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|▏              | 1/100 [00:02<00:11,  8.98it/s]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   2%|▎              | 2/100 [00:02<02:02,  1.25s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):   2%|▎              | 2/100 [00:02<02:02,  1.25s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):   3%|▍              | 3/100 [00:02<01:10,  1.38it/s]\u001b[A\n",
      "Average Metric: 0.0 / 4  (0.0):   3%|▍              | 3/100 [00:03<01:10,  1.38it/s]\u001b[A\n",
      "Average Metric: 0.0 / 4  (0.0):   4%|▌              | 4/100 [00:03<01:29,  1.07it/s]\u001b[A\n",
      "Average Metric: 0.0 / 5  (0.0):   4%|▌              | 4/100 [00:03<01:29,  1.07it/s]\u001b[A\n",
      "Average Metric: 0.5 / 6  (8.3):   5%|▊              | 5/100 [00:03<01:28,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.8333333333333333 / 7  (11.9):   6%| | 6/100 [00:04<01:27,  1.07it/\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 7  (11.9):   7%| | 7/100 [00:04<00:51,  1.82it/\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 8  (10.4):   7%| | 7/100 [00:04<00:51,  1.82it/\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 8  (10.4):   8%| | 8/100 [00:04<00:41,  2.19it/\u001b[A\n",
      "Average Metric: 1.6904761904761902 / 9  (18.8):   8%| | 8/100 [00:04<00:41,  2.19it/\u001b[A\n",
      "Average Metric: 1.6904761904761902 / 9  (18.8):   9%| | 9/100 [00:04<00:38,  2.36it/\u001b[A\n",
      "Average Metric: 1.6904761904761902 / 10  (16.9):   9%| | 9/100 [00:05<00:38,  2.36it\u001b[A\n",
      "Average Metric: 1.6904761904761902 / 10  (16.9):  10%| | 10/100 [00:05<00:41,  2.15i\u001b[A\n",
      "Average Metric: 2.6904761904761902 / 11  (24.5):  10%| | 10/100 [00:05<00:41,  2.15i\u001b[A\n",
      "Average Metric: 2.6904761904761902 / 11  (24.5):  11%| | 11/100 [00:05<00:33,  2.65i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.6904761904761902 / 12  (22.4):  11%| | 11/100 [00:05<00:33,  2.65i\u001b[A\n",
      "Average Metric: 2.6904761904761902 / 12  (22.4):  12%| | 12/100 [00:05<00:28,  3.04i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 13  (28.4):  12%| | 12/100 [00:06<00:28,  3.04i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 13  (28.4):  13%|▏| 13/100 [00:06<00:25,  3.43i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 14  (26.4):  13%|▏| 13/100 [00:06<00:25,  3.43i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 14  (26.4):  14%|▏| 14/100 [00:06<00:26,  3.26i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 15  (24.6):  14%|▏| 14/100 [00:06<00:26,  3.26i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 15  (24.6):  15%|▏| 15/100 [00:06<00:27,  3.14i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 16  (23.1):  15%|▏| 15/100 [00:07<00:27,  3.14i\u001b[A\n",
      "Average Metric: 3.6904761904761902 / 16  (23.1):  16%|▏| 16/100 [00:07<00:27,  3.08i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.19047619047619 / 17  (24.6):  16%|▏| 16/100 [00:07<00:27,  3.08it/\u001b[A\n",
      "Average Metric: 4.19047619047619 / 17  (24.6):  17%|▏| 17/100 [00:07<00:35,  2.36it/\u001b[A\n",
      "Average Metric: 5.079365079365079 / 18  (28.2):  17%|▏| 17/100 [00:07<00:35,  2.36it\u001b[A\n",
      "Average Metric: 5.079365079365079 / 19  (26.7):  18%|▏| 18/100 [00:08<00:34,  2.36it\u001b[A\n",
      "Average Metric: 5.079365079365079 / 19  (26.7):  19%|▏| 19/100 [00:08<00:26,  3.01it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.079365079365079 / 20  (25.4):  19%|▏| 19/100 [00:08<00:26,  3.01it\u001b[A\n",
      "Average Metric: 5.079365079365079 / 20  (25.4):  20%|▏| 20/100 [00:08<00:28,  2.83it\u001b[A\n",
      "Average Metric: 5.079365079365079 / 21  (24.2):  20%|▏| 20/100 [00:08<00:28,  2.83it\u001b[A\n",
      "Average Metric: 5.079365079365079 / 21  (24.2):  21%|▏| 21/100 [00:08<00:23,  3.37it\u001b[A\n",
      "Average Metric: 5.079365079365079 / 22  (23.1):  21%|▏| 21/100 [00:08<00:23,  3.37it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.079365079365079 / 23  (26.4):  22%|▏| 22/100 [00:09<00:23,  3.37it\u001b[A\n",
      "Average Metric: 6.079365079365079 / 23  (26.4):  23%|▏| 23/100 [00:09<00:22,  3.44it\u001b[A\n",
      "Average Metric: 6.079365079365079 / 24  (25.3):  23%|▏| 23/100 [00:09<00:22,  3.44it\u001b[A\n",
      "Average Metric: 6.079365079365079 / 24  (25.3):  24%|▏| 24/100 [00:09<00:19,  3.96it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.079365079365079 / 25  (28.3):  24%|▏| 24/100 [00:09<00:19,  3.96it\u001b[A\n",
      "Average Metric: 7.079365079365079 / 25  (28.3):  25%|▎| 25/100 [00:09<00:22,  3.28it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 26  (31.1):  25%|▎| 25/100 [00:10<00:22,  3.28it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 26  (31.1):  26%|▎| 26/100 [00:10<00:19,  3.80it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 27  (29.9):  26%|▎| 26/100 [00:10<00:19,  3.80it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 27  (29.9):  27%|▎| 27/100 [00:10<00:22,  3.20it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 28  (28.9):  27%|▎| 27/100 [00:11<00:22,  3.20it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 28  (28.9):  28%|▎| 28/100 [00:11<00:31,  2.31it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 29  (27.9):  28%|▎| 28/100 [00:11<00:31,  2.31it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 29  (27.9):  29%|▎| 29/100 [00:11<00:36,  1.92it\u001b[A\n",
      "Average Metric: 8.079365079365079 / 30  (26.9):  29%|▎| 29/100 [00:12<00:36,  1.92it\u001b[A\n",
      "Average Metric: 8.746031746031745 / 31  (28.2):  30%|▎| 30/100 [00:12<00:36,  1.92it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.746031746031745 / 32  (27.3):  31%|▎| 31/100 [00:12<00:35,  1.92it\u001b[A\n",
      "Average Metric: 8.746031746031745 / 32  (27.3):  32%|▎| 32/100 [00:12<00:26,  2.52it\u001b[A\n",
      "Average Metric: 9.546031746031746 / 33  (28.9):  32%|▎| 32/100 [00:12<00:26,  2.52it\u001b[A\n",
      "Average Metric: 9.546031746031746 / 34  (28.1):  33%|▎| 33/100 [00:12<00:26,  2.52it\u001b[A\n",
      "Average Metric: 9.546031746031746 / 34  (28.1):  34%|▎| 34/100 [00:12<00:18,  3.57it\u001b[A\n",
      "Average Metric: 9.546031746031746 / 35  (27.3):  34%|▎| 34/100 [00:13<00:18,  3.57it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.546031746031746 / 36  (29.3):  35%|▎| 35/100 [00:13<00:18,  3.57i\u001b[A\n",
      "Average Metric: 10.546031746031746 / 36  (29.3):  36%|▎| 36/100 [00:13<00:19,  3.23i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 37  (31.2):  36%|▎| 36/100 [00:14<00:19,  3.23i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 37  (31.2):  37%|▎| 37/100 [00:14<00:25,  2.44i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 38  (30.4):  37%|▎| 37/100 [00:15<00:25,  2.44i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 38  (30.4):  38%|▍| 38/100 [00:15<00:35,  1.73i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 39  (29.6):  38%|▍| 38/100 [00:15<00:35,  1.73i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 39  (29.6):  39%|▍| 39/100 [00:15<00:29,  2.04i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 40  (28.9):  39%|▍| 39/100 [00:16<00:29,  2.04i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 41  (28.2):  40%|▍| 40/100 [00:16<00:29,  2.04i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.546031746031746 / 42  (27.5):  41%|▍| 41/100 [00:16<00:28,  2.04i\u001b[A\n",
      "Average Metric: 11.546031746031746 / 42  (27.5):  42%|▍| 42/100 [00:16<00:16,  3.52i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.946031746031746 / 43  (27.8):  42%|▍| 42/100 [00:16<00:16,  3.52i\u001b[A\n",
      "Average Metric: 11.946031746031746 / 43  (27.8):  43%|▍| 43/100 [00:16<00:16,  3.38i\u001b[A\n",
      "Average Metric: 12.946031746031746 / 44  (29.4):  43%|▍| 43/100 [00:16<00:16,  3.38i\u001b[A\n",
      "Average Metric: 12.946031746031746 / 44  (29.4):  44%|▍| 44/100 [00:16<00:16,  3.39i\u001b[A\n",
      "Average Metric: 13.946031746031746 / 45  (31.0):  44%|▍| 44/100 [00:16<00:16,  3.39i\u001b[A\n",
      "Average Metric: 13.946031746031746 / 46  (30.3):  45%|▍| 45/100 [00:16<00:16,  3.39i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.946031746031746 / 47  (31.8):  46%|▍| 46/100 [00:17<00:15,  3.39i\u001b[A\n",
      "Average Metric: 14.946031746031746 / 47  (31.8):  47%|▍| 47/100 [00:17<00:11,  4.76i\u001b[A\n",
      "Average Metric: 15.612698412698412 / 48  (32.5):  47%|▍| 47/100 [00:17<00:11,  4.76i\u001b[A\n",
      "Average Metric: 15.612698412698412 / 48  (32.5):  48%|▍| 48/100 [00:17<00:15,  3.40i\u001b[A\n",
      "Average Metric: 16.612698412698414 / 49  (33.9):  48%|▍| 48/100 [00:18<00:15,  3.40i\u001b[A\n",
      "Average Metric: 16.612698412698414 / 49  (33.9):  49%|▍| 49/100 [00:18<00:22,  2.22i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 50  (34.2):  49%|▍| 49/100 [00:19<00:22,  2.22i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 50  (34.2):  50%|▌| 50/100 [00:19<00:19,  2.52i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 51  (33.6):  50%|▌| 50/100 [00:19<00:19,  2.52i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 17.112698412698414 / 52  (32.9):  51%|▌| 51/100 [00:19<00:19,  2.52i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 52  (32.9):  52%|▌| 52/100 [00:19<00:14,  3.23i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 53  (32.3):  52%|▌| 52/100 [00:19<00:14,  3.23i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 53  (32.3):  53%|▌| 53/100 [00:19<00:12,  3.77i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 54  (31.7):  53%|▌| 53/100 [00:19<00:12,  3.77i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 54  (31.7):  54%|▌| 54/100 [00:19<00:11,  3.93i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 55  (31.1):  54%|▌| 54/100 [00:19<00:11,  3.93i\u001b[A\n",
      "Average Metric: 17.112698412698414 / 56  (30.6):  55%|▌| 55/100 [00:19<00:11,  3.93i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.112698412698414 / 57  (31.8):  56%|▌| 56/100 [00:20<00:11,  3.93i\u001b[A\n",
      "Average Metric: 18.112698412698414 / 57  (31.8):  57%|▌| 57/100 [00:20<00:08,  5.19i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 58  (33.0):  57%|▌| 57/100 [00:22<00:08,  5.19i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 58  (33.0):  58%|▌| 58/100 [00:22<00:23,  1.82i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 59  (32.4):  58%|▌| 58/100 [00:22<00:23,  1.82i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 59  (32.4):  59%|▌| 59/100 [00:22<00:18,  2.18i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 60  (31.9):  59%|▌| 59/100 [00:22<00:18,  2.18i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 60  (31.9):  60%|▌| 60/100 [00:22<00:15,  2.50i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 61  (31.3):  60%|▌| 60/100 [00:23<00:15,  2.50i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 61  (31.3):  61%|▌| 61/100 [00:23<00:17,  2.28i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 62  (30.8):  61%|▌| 61/100 [00:23<00:17,  2.28i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 63  (30.3):  62%|▌| 62/100 [00:23<00:16,  2.28i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 63  (30.3):  63%|▋| 63/100 [00:23<00:10,  3.45i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n",
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.112698412698414 / 64  (29.9):  63%|▋| 63/100 [00:24<00:10,  3.45i\u001b[A\n",
      "Average Metric: 19.112698412698414 / 64  (29.9):  64%|▋| 64/100 [00:24<00:16,  2.19i\u001b[A\n",
      "Average Metric: 19.779365079365082 / 65  (30.4):  64%|▋| 64/100 [00:24<00:16,  2.19i\u001b[A\n",
      "Average Metric: 19.779365079365082 / 65  (30.4):  65%|▋| 65/100 [00:24<00:17,  1.97i\u001b[A\n",
      "Average Metric: 19.779365079365082 / 66  (30.0):  65%|▋| 65/100 [00:24<00:17,  1.97i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 67  (31.0):  66%|▋| 66/100 [00:25<00:17,  1.97i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 67  (31.0):  67%|▋| 67/100 [00:25<00:11,  2.85i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 68  (30.6):  67%|▋| 67/100 [00:25<00:11,  2.85i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 69  (30.1):  68%|▋| 68/100 [00:25<00:11,  2.85i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 69  (30.1):  69%|▋| 69/100 [00:25<00:07,  3.93i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 70  (29.7):  69%|▋| 69/100 [00:26<00:07,  3.93i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 70  (29.7):  70%|▋| 70/100 [00:26<00:10,  2.73i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 71  (29.3):  70%|▋| 70/100 [00:26<00:10,  2.73i\u001b[A\n",
      "Average Metric: 20.779365079365082 / 71  (29.3):  71%|▋| 71/100 [00:26<00:10,  2.65i\u001b[A\n",
      "Average Metric: 21.779365079365082 / 72  (30.2):  71%|▋| 71/100 [00:26<00:10,  2.65i\u001b[A\n",
      "Average Metric: 22.779365079365082 / 73  (31.2):  72%|▋| 72/100 [00:26<00:10,  2.65i\u001b[A\n",
      "Average Metric: 22.779365079365082 / 73  (31.2):  73%|▋| 73/100 [00:26<00:07,  3.55i\u001b[A\n",
      "Average Metric: 22.779365079365082 / 74  (30.8):  73%|▋| 73/100 [00:26<00:07,  3.55i\u001b[A\n",
      "Average Metric: 23.779365079365082 / 75  (31.7):  74%|▋| 74/100 [00:27<00:07,  3.55i\u001b[A\n",
      "Average Metric: 23.779365079365082 / 75  (31.7):  75%|▊| 75/100 [00:27<00:05,  4.42i\u001b[A\n",
      "Average Metric: 23.779365079365082 / 76  (31.3):  75%|▊| 75/100 [00:27<00:05,  4.42i\u001b[A\n",
      "Average Metric: 23.779365079365082 / 76  (31.3):  76%|▊| 76/100 [00:27<00:06,  3.97i\u001b[A\n",
      "Average Metric: 24.779365079365082 / 77  (32.2):  76%|▊| 76/100 [00:28<00:06,  3.97i\u001b[A\n",
      "Average Metric: 24.779365079365082 / 77  (32.2):  77%|▊| 77/100 [00:28<00:11,  1.93i\u001b[A\n",
      "Average Metric: 25.779365079365082 / 78  (33.1):  77%|▊| 77/100 [00:29<00:11,  1.93i\u001b[A\n",
      "Average Metric: 25.779365079365082 / 78  (33.1):  78%|▊| 78/100 [00:29<00:11,  1.93i\u001b[A\n",
      "Average Metric: 25.779365079365082 / 79  (32.6):  78%|▊| 78/100 [00:29<00:11,  1.93i\u001b[A\n",
      "Average Metric: 25.779365079365082 / 79  (32.6):  79%|▊| 79/100 [00:29<00:09,  2.23i\u001b[A\n",
      "Average Metric: 26.779365079365082 / 80  (33.5):  79%|▊| 79/100 [00:30<00:09,  2.23i\u001b[A\n",
      "Average Metric: 26.779365079365082 / 80  (33.5):  80%|▊| 80/100 [00:30<00:08,  2.36i\u001b[A\n",
      "Average Metric: 27.44603174603175 / 81  (33.9):  80%|▊| 80/100 [00:30<00:08,  2.36it\u001b[A\n",
      "Average Metric: 27.44603174603175 / 81  (33.9):  81%|▊| 81/100 [00:30<00:08,  2.27it\u001b[A\n",
      "Average Metric: 27.44603174603175 / 82  (33.5):  81%|▊| 81/100 [00:31<00:08,  2.27it\u001b[A\n",
      "Average Metric: 27.44603174603175 / 82  (33.5):  82%|▊| 82/100 [00:31<00:08,  2.17it\u001b[A\n",
      "Average Metric: 27.44603174603175 / 83  (33.1):  82%|▊| 82/100 [00:31<00:08,  2.17it\u001b[A\n",
      "Average Metric: 27.44603174603175 / 83  (33.1):  83%|▊| 83/100 [00:31<00:08,  2.07it\u001b[A\n",
      "Average Metric: 28.44603174603175 / 84  (33.9):  83%|▊| 83/100 [00:31<00:08,  2.07it\u001b[A\n",
      "Average Metric: 28.84603174603175 / 85  (33.9):  84%|▊| 84/100 [00:32<00:07,  2.07it\u001b[A\n",
      "Average Metric: 28.84603174603175 / 85  (33.9):  85%|▊| 85/100 [00:32<00:06,  2.47it\u001b[A\n",
      "Average Metric: 29.34603174603175 / 86  (34.1):  85%|▊| 85/100 [00:32<00:06,  2.47it\u001b[A\n",
      "Average Metric: 29.34603174603175 / 86  (34.1):  86%|▊| 86/100 [00:32<00:06,  2.08it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 87  (34.9):  86%|▊| 86/100 [00:33<00:06,  2.08it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 87  (34.9):  87%|▊| 87/100 [00:33<00:05,  2.57it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 88  (34.5):  87%|▊| 87/100 [00:33<00:05,  2.57it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 88  (34.5):  88%|▉| 88/100 [00:33<00:04,  2.92it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.34603174603175 / 89  (34.1):  88%|▉| 88/100 [00:33<00:04,  2.92it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 89  (34.1):  89%|▉| 89/100 [00:33<00:04,  2.25it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 90  (33.7):  89%|▉| 89/100 [00:34<00:04,  2.25it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 91  (33.3):  90%|▉| 90/100 [00:34<00:04,  2.25it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 91  (33.3):  91%|▉| 91/100 [00:34<00:02,  3.70it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 92  (33.0):  91%|▉| 91/100 [00:34<00:02,  3.70it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.34603174603175 / 93  (32.6):  92%|▉| 92/100 [00:35<00:02,  3.70it\u001b[A\n",
      "Average Metric: 30.34603174603175 / 93  (32.6):  93%|▉| 93/100 [00:35<00:03,  2.06it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.012698412698416 / 94  (33.0):  93%|▉| 93/100 [00:36<00:03,  2.06i\u001b[A\n",
      "Average Metric: 31.012698412698416 / 94  (33.0):  94%|▉| 94/100 [00:36<00:02,  2.00i\u001b[A\n",
      "Average Metric: 31.012698412698416 / 95  (32.6):  94%|▉| 94/100 [00:37<00:02,  2.00i\u001b[A\n",
      "Average Metric: 31.012698412698416 / 95  (32.6):  95%|▉| 95/100 [00:37<00:03,  1.50i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for example in dev set: \t\t ('Too many retries trying to get the correct output format. Try simplifying the requirements.', {'aspects': 'Field required: value (error type: missing)'})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 31.012698412698416 / 96  (32.3):  95%|▉| 95/100 [00:37<00:03,  1.50i\u001b[A\n",
      "Average Metric: 31.012698412698416 / 96  (32.3):  96%|▉| 96/100 [00:37<00:02,  1.67i\u001b[A\n",
      "Average Metric: 31.012698412698416 / 97  (32.0):  96%|▉| 96/100 [00:38<00:02,  1.67i\u001b[A\n",
      "Average Metric: 31.012698412698416 / 97  (32.0):  97%|▉| 97/100 [00:38<00:01,  1.80i\u001b[A\n",
      "Average Metric: 31.012698412698416 / 98  (31.6):  97%|▉| 97/100 [00:38<00:01,  1.80i\u001b[A\n",
      "Average Metric: 31.262698412698416 / 99  (31.6):  98%|▉| 98/100 [00:39<00:01,  1.80i\u001b[A\n",
      "Average Metric: 31.262698412698416 / 99  (31.6):  99%|▉| 99/100 [00:39<00:00,  1.95i\u001b[A\n",
      "Average Metric: 31.929365079365084 / 100  (31.9):  99%|▉| 99/100 [00:40<00:00,  1.95\u001b[A\n",
      "Average Metric: 31.929365079365084 / 100  (31.9): 100%|█| 100/100 [00:40<00:00,  2.4\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 31.929365079365084 / 100  (31.9%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.0' '0.0' '0.0' '0.0' '0.5']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aa66e th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aa66e td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aa66e_row0_col0, #T_aa66e_row0_col1, #T_aa66e_row0_col2, #T_aa66e_row0_col3, #T_aa66e_row0_col4, #T_aa66e_row1_col0, #T_aa66e_row1_col1, #T_aa66e_row1_col2, #T_aa66e_row1_col3, #T_aa66e_row1_col4, #T_aa66e_row2_col0, #T_aa66e_row2_col1, #T_aa66e_row2_col2, #T_aa66e_row2_col3, #T_aa66e_row2_col4, #T_aa66e_row3_col0, #T_aa66e_row3_col1, #T_aa66e_row3_col2, #T_aa66e_row3_col3, #T_aa66e_row3_col4, #T_aa66e_row4_col0, #T_aa66e_row4_col1, #T_aa66e_row4_col2, #T_aa66e_row4_col3, #T_aa66e_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aa66e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aa66e_level0_col0\" class=\"col_heading level0 col0\" >review</th>\n",
       "      <th id=\"T_aa66e_level0_col1\" class=\"col_heading level0 col1\" >example_aspects</th>\n",
       "      <th id=\"T_aa66e_level0_col2\" class=\"col_heading level0 col2\" >pred_aspects</th>\n",
       "      <th id=\"T_aa66e_level0_col3\" class=\"col_heading level0 col3\" >validate_f1</th>\n",
       "      <th id=\"T_aa66e_level0_col4\" class=\"col_heading level0 col4\" >aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aa66e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_aa66e_row0_col0\" class=\"data row0 col0\" >\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.</td>\n",
       "      <td id=\"T_aa66e_row0_col1\" class=\"data row0 col1\" >{'menu': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'pub fare': 0}</td>\n",
       "      <td id=\"T_aa66e_row0_col2\" class=\"data row0 col2\" >{'menu': 1, 'pub fare': 1, 'burgers': 1, 'steaks': 0, 'shepherds pie': 1, 'portabella lasagna': 1, 'vegetarians': 0}</td>\n",
       "      <td id=\"T_aa66e_row0_col3\" class=\"data row0 col3\" >0.0</td>\n",
       "      <td id=\"T_aa66e_row0_col4\" class=\"data row0 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa66e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_aa66e_row1_col0\" class=\"data row1 col0\" >(The sashimi is cut a little thinly.</td>\n",
       "      <td id=\"T_aa66e_row1_col1\" class=\"data row1 col1\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_aa66e_row1_col2\" class=\"data row1 col2\" >{'sashimi': -1, 'cut': -1, 'thinly': -1}</td>\n",
       "      <td id=\"T_aa66e_row1_col3\" class=\"data row1 col3\" >0.0</td>\n",
       "      <td id=\"T_aa66e_row1_col4\" class=\"data row1 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa66e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_aa66e_row2_col0\" class=\"data row2 col0\" >) It's not the best Japanese restaurant in the East Village, but it's a pretty solid one for its modest prices, and worth repeat visits.</td>\n",
       "      <td id=\"T_aa66e_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_aa66e_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_aa66e_row2_col3\" class=\"data row2 col3\" >0.0</td>\n",
       "      <td id=\"T_aa66e_row2_col4\" class=\"data row2 col4\" >{'prices': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa66e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_aa66e_row3_col0\" class=\"data row3 col0\" >15% gratuity automatically added to the bill.</td>\n",
       "      <td id=\"T_aa66e_row3_col1\" class=\"data row3 col1\" >{'bill': -1, 'gratuity': -1}</td>\n",
       "      <td id=\"T_aa66e_row3_col2\" class=\"data row3 col2\" >{'gratuity': -1, 'bill': 0}</td>\n",
       "      <td id=\"T_aa66e_row3_col3\" class=\"data row3 col3\" >0.0</td>\n",
       "      <td id=\"T_aa66e_row3_col4\" class=\"data row3 col4\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aa66e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_aa66e_row4_col0\" class=\"data row4 col0\" >A beautiful atmosphere, perfect for drinks and/or appetizers.</td>\n",
       "      <td id=\"T_aa66e_row4_col1\" class=\"data row4 col1\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_aa66e_row4_col2\" class=\"data row4 col2\" >{'atmosphere': 1, 'drinks': 1, 'appetizers': 1}</td>\n",
       "      <td id=\"T_aa66e_row4_col3\" class=\"data row4 col3\" >0.5</td>\n",
       "      <td id=\"T_aa66e_row4_col4\" class=\"data row4 col4\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x31af9fad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31.93"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " evaluate_test(uncompiled_pipeline_v3, metric=validate_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "99027031-0560-4adc-9fef-3988367fef01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to sample between 1 and 4 traces per predictor.\n",
      "Will attempt to train 16 candidate sets.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:00<00:05,  5.67it/s]\u001b[A\n",
      "Average Metric: 1.5 / 2  (75.0):   3%|▌              | 1/30 [00:00<00:05,  5.67it/s]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:00<00:04,  5.67it/s]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):  10%|█▌             | 3/30 [00:00<00:04,  5.67it/s]\u001b[A\n",
      "Average Metric: 1.5 / 5  (30.0):  13%|██             | 4/30 [00:00<00:04,  5.67it/s]\u001b[A\n",
      "Average Metric: 1.5 / 5  (30.0):  17%|██▌            | 5/30 [00:00<00:01, 19.91it/s]\u001b[A\n",
      "Average Metric: 1.5 / 6  (25.0):  17%|██▌            | 5/30 [00:00<00:01, 19.91it/s]\u001b[A\n",
      "Average Metric: 2.0 / 7  (28.6):  20%|███            | 6/30 [00:00<00:01, 19.91it/s]\u001b[A\n",
      "Average Metric: 2.0 / 8  (25.0):  23%|███▌           | 7/30 [00:00<00:01, 19.91it/s]\u001b[A\n",
      "Average Metric: 2.0 / 8  (25.0):  27%|████           | 8/30 [00:00<00:02,  7.40it/s]\u001b[A\n",
      "Average Metric: 2.25 / 9  (25.0):  27%|███▋          | 8/30 [00:00<00:02,  7.40it/s]\u001b[A\n",
      "Average Metric: 2.25 / 10  (22.5):  30%|███▉         | 9/30 [00:00<00:02,  7.40it/s]\u001b[A\n",
      "Average Metric: 2.75 / 11  (25.0):  33%|████        | 10/30 [00:01<00:02,  7.40it/s]\u001b[A\n",
      "Average Metric: 3.0833333333333335 / 12  (25.7):  37%|▎| 11/30 [00:01<00:02,  7.40it\u001b[A\n",
      "Average Metric: 4.083333333333334 / 13  (31.4):  40%|▍| 12/30 [00:01<00:02,  7.40it/\u001b[A\n",
      "Average Metric: 4.083333333333334 / 13  (31.4):  43%|▍| 13/30 [00:01<00:01, 11.86it/\u001b[A\n",
      "Average Metric: 5.083333333333334 / 14  (36.3):  43%|▍| 13/30 [00:01<00:01, 11.86it/\u001b[A\n",
      "Average Metric: 5.183333333333334 / 15  (34.6):  47%|▍| 14/30 [00:01<00:01, 11.86it/\u001b[A\n",
      "Average Metric: 5.933333333333334 / 16  (37.1):  50%|▌| 15/30 [00:01<00:01, 11.86it/\u001b[A\n",
      "Average Metric: 6.266666666666667 / 17  (36.9):  53%|▌| 16/30 [00:01<00:01, 11.86it/\u001b[A\n",
      "Average Metric: 6.266666666666667 / 17  (36.9):  57%|▌| 17/30 [00:01<00:00, 15.18it/\u001b[A\n",
      "Average Metric: 6.6 / 18  (36.7):  57%|███████▎     | 17/30 [00:01<00:00, 15.18it/s]\u001b[A\n",
      "Average Metric: 6.6 / 19  (34.7):  60%|███████▊     | 18/30 [00:01<00:00, 15.18it/s]\u001b[A\n",
      "Average Metric: 6.933333333333333 / 20  (34.7):  63%|▋| 19/30 [00:01<00:00, 15.18it/\u001b[A\n",
      "Average Metric: 7.266666666666666 / 21  (34.6):  67%|▋| 20/30 [00:01<00:00, 15.18it/\u001b[A\n",
      "Average Metric: 7.266666666666666 / 21  (34.6):  70%|▋| 21/30 [00:01<00:00, 19.04it/\u001b[A\n",
      "Average Metric: 7.266666666666666 / 22  (33.0):  70%|▋| 21/30 [00:01<00:00, 19.04it/\u001b[A\n",
      "Average Metric: 8.266666666666666 / 23  (35.9):  73%|▋| 22/30 [00:01<00:00, 19.04it/\u001b[A\n",
      "Average Metric: 8.766666666666666 / 24  (36.5):  77%|▊| 23/30 [00:01<00:00, 19.04it/\u001b[A\n",
      "Average Metric: 8.766666666666666 / 25  (35.1):  80%|▊| 24/30 [00:01<00:00, 19.04it/\u001b[A\n",
      "Average Metric: 8.766666666666666 / 25  (35.1):  83%|▊| 25/30 [00:01<00:00, 22.63it/\u001b[A\n",
      "Average Metric: 8.766666666666666 / 26  (33.7):  83%|▊| 25/30 [00:01<00:00, 22.63it/\u001b[A\n",
      "Average Metric: 9.766666666666666 / 27  (36.2):  87%|▊| 26/30 [00:01<00:00, 22.63it/\u001b[A\n",
      "Average Metric: 10.766666666666666 / 28  (38.5):  90%|▉| 27/30 [00:01<00:00, 22.63it\u001b[A\n",
      "Average Metric: 11.266666666666666 / 29  (38.9):  93%|▉| 28/30 [00:01<00:00, 22.63it\u001b[A\n",
      "Average Metric: 11.266666666666666 / 30  (37.6): 100%|█| 30/30 [00:01<00:00, 18.37it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.266666666666666 / 30  (37.6%)\n",
      "Score: 37.56 for set: [0, 0, 0]\n",
      "New best score: 37.56 for seed -3\n",
      "Scores so far: [37.56]\n",
      "Best score: 37.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:00<00:28,  1.01it/s]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:01<00:28,  1.01it/s]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:01<00:13,  2.09it/s]\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   7%| | 2/30 [00:01<00:13,  2.09it/s\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):  10%| | 3/30 [00:01<00:12,  2.09it/s\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):  13%|▏| 4/30 [00:01<00:06,  4.10it/s\u001b[A\n",
      "Average Metric: 2.333333333333333 / 5  (46.7):  13%|▏| 4/30 [00:01<00:06,  4.10it/s]\u001b[A\n",
      "Average Metric: 2.733333333333333 / 6  (45.6):  17%|▏| 5/30 [00:01<00:06,  4.10it/s]\u001b[A\n",
      "Average Metric: 2.733333333333333 / 6  (45.6):  20%|▏| 6/30 [00:01<00:03,  6.29it/s]\u001b[A\n",
      "Average Metric: 3.3999999999999995 / 7  (48.6):  20%|▏| 6/30 [00:02<00:03,  6.29it/s\u001b[A\n",
      "Average Metric: 3.8999999999999995 / 8  (48.7):  23%|▏| 7/30 [00:02<00:03,  6.29it/s\u001b[A\n",
      "Average Metric: 3.8999999999999995 / 8  (48.7):  27%|▎| 8/30 [00:02<00:06,  3.18it/s\u001b[A\n",
      "Average Metric: 4.1 / 9  (45.6):  27%|████           | 8/30 [00:03<00:06,  3.18it/s]\u001b[A\n",
      "Average Metric: 4.1 / 9  (45.6):  30%|████▌          | 9/30 [00:03<00:07,  2.80it/s]\u001b[A\n",
      "Average Metric: 4.5 / 10  (45.0):  30%|████▏         | 9/30 [00:03<00:07,  2.80it/s]\u001b[A\n",
      "Average Metric: 5.5 / 11  (50.0):  33%|████▎        | 10/30 [00:03<00:07,  2.80it/s]\u001b[A\n",
      "Average Metric: 5.5 / 11  (50.0):  37%|████▊        | 11/30 [00:03<00:05,  3.34it/s]\u001b[A\n",
      "Average Metric: 5.5 / 12  (45.8):  37%|████▊        | 11/30 [00:03<00:05,  3.34it/s]\u001b[A\n",
      "Average Metric: 5.5 / 12  (45.8):  40%|█████▏       | 12/30 [00:03<00:06,  2.95it/s]\u001b[A\n",
      "Average Metric: 5.833333333333333 / 13  (44.9):  40%|▍| 12/30 [00:04<00:06,  2.95it/\u001b[A\n",
      "Average Metric: 5.833333333333333 / 13  (44.9):  43%|▍| 13/30 [00:04<00:05,  3.31it/\u001b[A\n",
      "Average Metric: 6.583333333333333 / 14  (47.0):  43%|▍| 13/30 [00:04<00:05,  3.31it/\u001b[A\n",
      "Average Metric: 7.583333333333333 / 15  (50.6):  47%|▍| 14/30 [00:04<00:04,  3.31it/\u001b[A\n",
      "Average Metric: 7.583333333333333 / 15  (50.6):  50%|▌| 15/30 [00:04<00:03,  3.97it/\u001b[A\n",
      "Average Metric: 7.583333333333333 / 16  (47.4):  50%|▌| 15/30 [00:04<00:03,  3.97it/\u001b[A\n",
      "Average Metric: 7.583333333333333 / 16  (47.4):  53%|▌| 16/30 [00:04<00:04,  3.44it/\u001b[A\n",
      "Average Metric: 8.25 / 17  (48.5):  53%|██████▍     | 16/30 [00:04<00:04,  3.44it/s]\u001b[A\n",
      "Average Metric: 8.25 / 17  (48.5):  57%|██████▊     | 17/30 [00:05<00:03,  4.08it/s]\u001b[A\n",
      "Average Metric: 8.25 / 18  (45.8):  57%|██████▊     | 17/30 [00:05<00:03,  4.08it/s]\u001b[A\n",
      "Average Metric: 9.25 / 19  (48.7):  60%|███████▏    | 18/30 [00:05<00:02,  4.08it/s]\u001b[A\n",
      "Average Metric: 9.25 / 19  (48.7):  63%|███████▌    | 19/30 [00:05<00:02,  4.12it/s]\u001b[A\n",
      "Average Metric: 9.75 / 20  (48.8):  63%|███████▌    | 19/30 [00:05<00:02,  4.12it/s]\u001b[A\n",
      "Average Metric: 10.75 / 21  (51.2):  67%|███████▎   | 20/30 [00:06<00:02,  4.12it/s]\u001b[A\n",
      "Average Metric: 10.75 / 21  (51.2):  70%|███████▋   | 21/30 [00:06<00:02,  3.87it/s]\u001b[A\n",
      "Average Metric: 11.75 / 22  (53.4):  70%|███████▋   | 21/30 [00:06<00:02,  3.87it/s]\u001b[A\n",
      "Average Metric: 12.25 / 23  (53.3):  73%|████████   | 22/30 [00:06<00:02,  3.87it/s]\u001b[A\n",
      "Average Metric: 12.25 / 23  (53.3):  77%|████████▍  | 23/30 [00:06<00:01,  4.23it/s]\u001b[A\n",
      "Average Metric: 12.25 / 24  (51.0):  77%|████████▍  | 23/30 [00:06<00:01,  4.23it/s]\u001b[A\n",
      "Average Metric: 12.25 / 24  (51.0):  80%|████████▊  | 24/30 [00:06<00:01,  4.74it/s]\u001b[A\n",
      "Average Metric: 13.25 / 25  (53.0):  80%|████████▊  | 24/30 [00:06<00:01,  4.74it/s]\u001b[A\n",
      "Average Metric: 13.25 / 25  (53.0):  83%|█████████▏ | 25/30 [00:06<00:01,  4.21it/s]\u001b[A\n",
      "Average Metric: 14.25 / 26  (54.8):  83%|█████████▏ | 25/30 [00:07<00:01,  4.21it/s]\u001b[A\n",
      "Average Metric: 14.25 / 26  (54.8):  87%|█████████▌ | 26/30 [00:07<00:00,  4.77it/s]\u001b[A\n",
      "Average Metric: 15.25 / 27  (56.5):  87%|█████████▌ | 26/30 [00:07<00:00,  4.77it/s]\u001b[A\n",
      "Average Metric: 15.25 / 27  (56.5):  90%|█████████▉ | 27/30 [00:07<00:00,  4.54it/s]\u001b[A\n",
      "Average Metric: 16.0 / 28  (57.1):  90%|██████████▊ | 27/30 [00:07<00:00,  4.54it/s]\u001b[A\n",
      "Average Metric: 16.0 / 28  (57.1):  93%|███████████▏| 28/30 [00:07<00:00,  3.60it/s]\u001b[A\n",
      "Average Metric: 17.0 / 29  (58.6):  93%|███████████▏| 28/30 [00:08<00:00,  3.60it/s]\u001b[A\n",
      "Average Metric: 17.0 / 29  (58.6):  97%|███████████▌| 29/30 [00:08<00:00,  3.47it/s]\u001b[A\n",
      "Average Metric: 17.0 / 30  (56.7): 100%|████████████| 30/30 [00:08<00:00,  3.75it/s]\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 17.0 / 30  (56.7%)\n",
      "Score: 56.67 for set: [16, 16, 16]\n",
      "New best score: 56.67 for seed -2\n",
      "Scores so far: [37.56, 56.67]\n",
      "Best score: 56.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:01<00:16,  1.74it/s]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:01<00:07,  3.67it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid aspect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|█████████▌                                      | 6/30 [00:02<00:12,  1.87it/s]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:04<00:15,  1.47it/s]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:05<00:16,  1.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run or to evaluate example Example({'review': \"- the bread at the beginning is super tasty and makes you want more - the pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\", 'aspects_with_label': {'bread': 1, 'pizza': 1, 'margarite pizza with cold prosciutto and baby arugula on top': 0, 'salad': 0, \"Peter's Favourite pizza with prosciutto and baby arugula\": 0}, 'aspects_list': 'dict_keys([\\'bread\\', \\'pizza\\', \\'margarite pizza with cold prosciutto and baby arugula on top\\', \\'salad\\', \"Peter\\'s Favourite pizza with prosciutto and baby arugula\"])'}) (input_keys={'review'}) with <function validate_venn at 0x1606cfa60> due to unterminated string literal (detected at line 1) (<unknown>, line 1).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███████████████▋                               | 10/30 [00:07<00:16,  1.18it/s]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:08<00:17,  1.09it/s]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:09<00:18,  1.04s/it]\u001b[A\n",
      " 43%|████████████████████▎                          | 13/30 [00:10<00:19,  1.13s/it]\u001b[A\n",
      " 47%|█████████████████████▉                         | 14/30 [00:12<00:17,  1.12s/it]\u001b[A\n",
      " 50%|███████████████████████▌                       | 15/30 [00:13<00:18,  1.24s/it]\u001b[A\n",
      " 53%|█████████████████████████                      | 16/30 [00:15<00:18,  1.32s/it]\u001b[A\n",
      " 57%|██████████████████████████▋                    | 17/30 [00:16<00:17,  1.37s/it]\u001b[A\n",
      " 60%|████████████████████████████▏                  | 18/30 [00:17<00:16,  1.35s/it]\u001b[A\n",
      " 63%|█████████████████████████████▊                 | 19/30 [00:18<00:13,  1.26s/it]\u001b[A\n",
      " 67%|███████████████████████████████▎               | 20/30 [00:20<00:12,  1.22s/it]\u001b[A\n",
      " 70%|████████████████████████████████▉              | 21/30 [00:20<00:10,  1.14s/it]\u001b[A\n",
      " 73%|██████████████████████████████████▍            | 22/30 [00:22<00:09,  1.20s/it]\u001b[A\n",
      " 77%|████████████████████████████████████           | 23/30 [00:24<00:10,  1.45s/it]\u001b[A\n",
      " 80%|█████████████████████████████████████▌         | 24/30 [00:26<00:09,  1.56s/it]\u001b[A\n",
      " 83%|███████████████████████████████████████▏       | 25/30 [00:27<00:07,  1.45s/it]\u001b[A\n",
      " 87%|████████████████████████████████████████▋      | 26/30 [00:28<00:05,  1.29s/it]\u001b[A\n",
      " 90%|██████████████████████████████████████████▎    | 27/30 [00:29<00:03,  1.09s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 28 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:37,  3.36s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:04<01:37,  3.36s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:04<00:52,  1.89s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:07<00:52,  1.89s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:07<01:04,  2.40s/it]\u001b[A\n",
      "Average Metric: 1.25 / 4  (31.2):  10%|█▍            | 3/30 [00:09<01:04,  2.40s/it]\u001b[A\n",
      "Average Metric: 1.25 / 4  (31.2):  13%|█▊            | 4/30 [00:09<00:58,  2.24s/it]\u001b[A\n",
      "Average Metric: 1.9166666666666665 / 5  (38.3):  13%|▏| 4/30 [00:10<00:58,  2.24s/it\u001b[A\n",
      "Average Metric: 1.9166666666666665 / 5  (38.3):  17%|▏| 5/30 [00:10<00:50,  2.02s/it\u001b[A\n",
      "Average Metric: 2.9166666666666665 / 6  (48.6):  17%|▏| 5/30 [00:13<00:50,  2.02s/it\u001b[A\n",
      "Average Metric: 2.9166666666666665 / 6  (48.6):  20%|▏| 6/30 [00:13<00:51,  2.16s/it\u001b[A\n",
      "Average Metric: 2.9166666666666665 / 7  (41.7):  20%|▏| 6/30 [00:17<00:51,  2.16s/it\u001b[A\n",
      "Average Metric: 2.9166666666666665 / 7  (41.7):  23%|▏| 7/30 [00:17<01:07,  2.92s/it\u001b[A\n",
      "Average Metric: 3.4166666666666665 / 8  (42.7):  23%|▏| 7/30 [00:19<01:07,  2.92s/it\u001b[A\n",
      "Average Metric: 3.4166666666666665 / 8  (42.7):  27%|▎| 8/30 [00:19<00:57,  2.62s/it\u001b[A\n",
      "Average Metric: 3.75 / 9  (41.7):  27%|███▋          | 8/30 [00:20<00:57,  2.62s/it]\u001b[A\n",
      "Average Metric: 3.75 / 9  (41.7):  30%|████▏         | 9/30 [00:20<00:44,  2.12s/it]\u001b[A\n",
      "Average Metric: 3.75 / 10  (37.5):  30%|███▉         | 9/30 [00:23<00:44,  2.12s/it]\u001b[A\n",
      "Average Metric: 3.75 / 10  (37.5):  33%|████        | 10/30 [00:23<00:44,  2.22s/it]\u001b[A\n",
      "Average Metric: 3.75 / 11  (34.1):  33%|████        | 10/30 [00:25<00:44,  2.22s/it]\u001b[A\n",
      "Average Metric: 3.75 / 11  (34.1):  37%|████▍       | 11/30 [00:25<00:40,  2.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.113636363636363 / 12  (34.3):  37%|▎| 11/30 [00:30<00:40,  2.11s/i\u001b[A\n",
      "Average Metric: 4.113636363636363 / 12  (34.3):  40%|▍| 12/30 [00:30<00:56,  3.12s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.363636363636363 / 13  (33.6):  40%|▍| 12/30 [00:34<00:56,  3.12s/i\u001b[A\n",
      "Average Metric: 4.363636363636363 / 13  (33.6):  43%|▍| 13/30 [00:34<00:59,  3.51s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.5636363636363635 / 14  (32.6):  43%|▍| 13/30 [00:42<00:59,  3.51s/\u001b[A\n",
      "Average Metric: 4.5636363636363635 / 14  (32.6):  47%|▍| 14/30 [00:42<01:17,  4.86s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 9.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.8969696969696965 / 15  (32.6):  47%|▍| 14/30 [00:51<01:17,  4.86s/\u001b[A\n",
      "Average Metric: 4.8969696969696965 / 15  (32.6):  50%|▌| 15/30 [00:51<01:28,  5.91s/\u001b[A\n",
      "Average Metric: 5.6469696969696965 / 16  (35.3):  50%|▌| 15/30 [00:51<01:28,  5.91s/\u001b[A\n",
      "Average Metric: 5.6469696969696965 / 16  (35.3):  53%|▌| 16/30 [00:51<01:01,  4.36s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.746969696969696 / 17  (33.8):  53%|▌| 16/30 [00:53<01:01,  4.36s/i\u001b[A\n",
      "Average Metric: 5.746969696969696 / 17  (33.8):  57%|▌| 17/30 [00:53<00:45,  3.47s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.746969696969696 / 18  (37.5):  57%|▌| 17/30 [00:59<00:45,  3.47s/i\u001b[A\n",
      "Average Metric: 6.746969696969696 / 18  (37.5):  60%|▌| 18/30 [00:59<00:49,  4.12s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 14.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.746969696969696 / 19  (40.8):  60%|▌| 18/30 [01:12<00:49,  4.12s/i\u001b[A\n",
      "Average Metric: 7.746969696969696 / 19  (40.8):  63%|▋| 19/30 [01:12<01:16,  6.95s/i\u001b[A\n",
      "Average Metric: 8.246969696969696 / 20  (41.2):  63%|▋| 19/30 [01:15<01:16,  6.95s/i\u001b[A\n",
      "Average Metric: 8.246969696969696 / 20  (41.2):  67%|▋| 20/30 [01:15<00:55,  5.60s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.246969696969696 / 21  (44.0):  67%|▋| 20/30 [01:17<00:55,  5.60s/i\u001b[A\n",
      "Average Metric: 9.246969696969696 / 21  (44.0):  70%|▋| 21/30 [01:17<00:42,  4.76s/i\u001b[A\n",
      "Average Metric: 9.496969696969696 / 22  (43.2):  70%|▋| 21/30 [01:18<00:42,  4.76s/i\u001b[A\n",
      "Average Metric: 9.496969696969696 / 22  (43.2):  73%|▋| 22/30 [01:18<00:28,  3.61s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.496969696969696 / 23  (45.6):  73%|▋| 22/30 [01:25<00:28,  3.61s/\u001b[A\n",
      "Average Metric: 10.496969696969696 / 23  (45.6):  77%|▊| 23/30 [01:25<00:31,  4.53s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.996969696969696 / 24  (45.8):  77%|▊| 23/30 [01:26<00:31,  4.53s/\u001b[A\n",
      "Average Metric: 10.996969696969696 / 24  (45.8):  80%|▊| 24/30 [01:26<00:21,  3.57s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.996969696969696 / 25  (48.0):  80%|▊| 24/30 [01:27<00:21,  3.57s/\u001b[A\n",
      "Average Metric: 11.996969696969696 / 25  (48.0):  83%|▊| 25/30 [01:27<00:13,  2.75s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.996969696969696 / 26  (50.0):  83%|▊| 25/30 [01:29<00:13,  2.75s/\u001b[A\n",
      "Average Metric: 12.996969696969696 / 26  (50.0):  87%|▊| 26/30 [01:29<00:10,  2.54s/\u001b[A\n",
      "Average Metric: 12.996969696969696 / 27  (48.1):  87%|▊| 26/30 [01:31<00:10,  2.54s/\u001b[A\n",
      "Average Metric: 12.996969696969696 / 27  (48.1):  90%|▉| 27/30 [01:31<00:07,  2.48s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.996969696969696 / 28  (46.4):  90%|▉| 27/30 [01:35<00:07,  2.48s/\u001b[A\n",
      "Average Metric: 12.996969696969696 / 28  (46.4):  93%|▉| 28/30 [01:35<00:05,  2.68s/\u001b[A\n",
      "Average Metric: 13.496969696969696 / 29  (46.5):  93%|▉| 28/30 [01:39<00:05,  2.68s/\u001b[A\n",
      "Average Metric: 13.496969696969696 / 29  (46.5):  97%|▉| 29/30 [01:39<00:03,  3.09s/\u001b[A\n",
      "Average Metric: 14.246969696969696 / 30  (47.5):  97%|▉| 29/30 [01:44<00:03,  3.09s/\u001b[A\n",
      "Average Metric: 14.246969696969696 / 30  (47.5): 100%|█| 30/30 [01:44<00:00,  3.49s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.246969696969696 / 30  (47.5%)\n",
      "Score: 47.49 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7587878787878789\n",
      "Average of max per entry across top 3 scores: 0.7976767676767677\n",
      "Average of max per entry across top 5 scores: 0.7976767676767677\n",
      "Average of max per entry across top 8 scores: 0.7976767676767677\n",
      "Average of max per entry across top 9999 scores: 0.7976767676767677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:39,  1.37s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:34,  1.22s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:04<00:42,  1.56s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:05<00:35,  1.36s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:06<00:32,  1.30s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:08<00:31,  1.31s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:10<00:36,  1.58s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:11<00:31,  1.42s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:12<00:28,  1.34s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:13<00:26,  1.34s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:14<00:23,  1.22s/it]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:15<00:19,  1.07s/it]\u001b[A\n",
      " 43%|████████████████████▎                          | 13/30 [00:16<00:19,  1.13s/it]\u001b[A\n",
      " 47%|█████████████████████▉                         | 14/30 [00:17<00:16,  1.05s/it]\u001b[A\n",
      " 50%|███████████████████████▌                       | 15/30 [00:18<00:15,  1.01s/it]\u001b[A\n",
      " 53%|█████████████████████████                      | 16/30 [00:19<00:15,  1.08s/it]\u001b[A\n",
      " 57%|██████████████████████████▋                    | 17/30 [00:21<00:14,  1.15s/it]\u001b[A\n",
      " 60%|████████████████████████████▏                  | 18/30 [00:22<00:14,  1.21s/it]\u001b[A\n",
      " 63%|█████████████████████████████▊                 | 19/30 [00:23<00:12,  1.18s/it]\u001b[A\n",
      " 67%|███████████████████████████████▎               | 20/30 [00:25<00:14,  1.41s/it]\u001b[A\n",
      " 70%|████████████████████████████████▉              | 21/30 [00:26<00:12,  1.42s/it]\u001b[A\n",
      " 73%|██████████████████████████████████▍            | 22/30 [00:27<00:10,  1.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 23 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:03<01:38,  3.39s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:03<01:38,  3.39s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:03<00:47,  1.68s/it]\u001b[A\n",
      "Average Metric: 1.5 / 3  (50.0):   7%|█              | 2/30 [00:03<00:47,  1.68s/it]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):  10%|█▌             | 3/30 [00:07<00:45,  1.68s/it]\u001b[A\n",
      "Average Metric: 1.5 / 4  (37.5):  13%|██             | 4/30 [00:07<00:44,  1.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5 / 5  (50.0):  13%|██             | 4/30 [00:12<00:44,  1.69s/it]\u001b[A\n",
      "Average Metric: 2.5 / 5  (50.0):  17%|██▌            | 5/30 [00:12<01:12,  2.91s/it]\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 6  (52.8):  17%|▏| 5/30 [00:13<01:12,  2.91s/it\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 6  (52.8):  20%|▏| 6/30 [00:13<00:51,  2.13s/it\u001b[A\n",
      "Average Metric: 4.166666666666666 / 7  (59.5):  20%|▏| 6/30 [00:13<00:51,  2.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.166666666666666 / 8  (52.1):  23%|▏| 7/30 [00:23<00:48,  2.13s/it]\u001b[A\n",
      "Average Metric: 4.166666666666666 / 8  (52.1):  27%|▎| 8/30 [00:23<01:18,  3.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.166666666666666 / 9  (46.3):  27%|▎| 8/30 [00:27<01:18,  3.57s/it]\u001b[A\n",
      "Average Metric: 4.166666666666666 / 9  (46.3):  30%|▎| 9/30 [00:27<01:14,  3.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.166666666666666 / 10  (51.7):  30%|▎| 9/30 [00:30<01:14,  3.53s/it\u001b[A\n",
      "Average Metric: 5.166666666666666 / 10  (51.7):  33%|▎| 10/30 [00:30<01:09,  3.46s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.416666666666666 / 11  (49.2):  33%|▎| 10/30 [00:31<01:09,  3.46s/i\u001b[A\n",
      "Average Metric: 5.416666666666666 / 11  (49.2):  37%|▎| 11/30 [00:31<00:55,  2.94s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.816666666666666 / 12  (48.5):  37%|▎| 11/30 [00:33<00:55,  2.94s/i\u001b[A\n",
      "Average Metric: 5.816666666666666 / 12  (48.5):  40%|▍| 12/30 [00:33<00:47,  2.65s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.95952380952381 / 13  (45.8):  40%|▍| 12/30 [00:46<00:47,  2.65s/it\u001b[A\n",
      "Average Metric: 5.95952380952381 / 13  (45.8):  43%|▍| 13/30 [00:46<01:35,  5.63s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.45952380952381 / 14  (46.1):  43%|▍| 13/30 [00:50<01:35,  5.63s/it\u001b[A\n",
      "Average Metric: 6.45952380952381 / 14  (46.1):  47%|▍| 14/30 [00:50<01:22,  5.16s/it\u001b[A\n",
      "Average Metric: 7.45952380952381 / 15  (49.7):  47%|▍| 14/30 [00:51<01:22,  5.16s/it\u001b[A\n",
      "Average Metric: 7.45952380952381 / 15  (49.7):  50%|▌| 15/30 [00:51<00:58,  3.90s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.792857142857143 / 16  (48.7):  50%|▌| 15/30 [00:54<00:58,  3.90s/i\u001b[A\n",
      "Average Metric: 7.792857142857143 / 16  (48.7):  53%|▌| 16/30 [00:54<00:47,  3.42s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 14.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.459523809523809 / 17  (49.8):  53%|▌| 16/30 [00:58<00:47,  3.42s/i\u001b[A\n",
      "Average Metric: 8.459523809523809 / 17  (49.8):  57%|▌| 17/30 [00:58<00:50,  3.86s/i\u001b[A\n",
      "Average Metric: 8.459523809523809 / 18  (47.0):  57%|▌| 17/30 [00:59<00:50,  3.86s/i\u001b[A\n",
      "Average Metric: 8.459523809523809 / 18  (47.0):  60%|▌| 18/30 [00:59<00:33,  2.80s/i\u001b[A\n",
      "Average Metric: 8.459523809523809 / 19  (44.5):  60%|▌| 18/30 [00:59<00:33,  2.80s/i\u001b[A\n",
      "Average Metric: 8.459523809523809 / 19  (44.5):  63%|▋| 19/30 [00:59<00:22,  2.01s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.959523809523809 / 20  (44.8):  63%|▋| 19/30 [01:10<00:22,  2.01s/i\u001b[A\n",
      "Average Metric: 8.959523809523809 / 20  (44.8):  67%|▋| 20/30 [01:10<00:46,  4.65s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.959523809523809 / 21  (47.4):  67%|▋| 20/30 [01:11<00:46,  4.65s/i\u001b[A\n",
      "Average Metric: 9.959523809523809 / 21  (47.4):  70%|▋| 21/30 [01:11<00:33,  3.78s/i\u001b[A\n",
      "Average Metric: 10.959523809523809 / 22  (49.8):  70%|▋| 21/30 [01:11<00:33,  3.78s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 34.2 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.626190476190475 / 23  (50.5):  73%|▋| 22/30 [01:18<00:30,  3.78s/\u001b[A\n",
      "Average Metric: 11.626190476190475 / 23  (50.5):  77%|▊| 23/30 [01:18<00:24,  3.48s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.626190476190475 / 24  (52.6):  77%|▊| 23/30 [01:21<00:24,  3.48s/\u001b[A\n",
      "Average Metric: 12.626190476190475 / 24  (52.6):  80%|▊| 24/30 [01:21<00:20,  3.40s/\u001b[A\n",
      "Average Metric: 13.626190476190475 / 25  (54.5):  80%|▊| 24/30 [01:21<00:20,  3.40s/\u001b[A\n",
      "Average Metric: 13.626190476190475 / 25  (54.5):  83%|▊| 25/30 [01:21<00:12,  2.54s/\u001b[A\n",
      "Average Metric: 14.126190476190475 / 26  (54.3):  83%|▊| 25/30 [01:22<00:12,  2.54s/\u001b[A\n",
      "Average Metric: 14.126190476190475 / 26  (54.3):  87%|▊| 26/30 [01:22<00:08,  2.04s/\u001b[A\n",
      "Average Metric: 14.126190476190475 / 27  (52.3):  87%|▊| 26/30 [01:25<00:08,  2.04s/\u001b[A\n",
      "Average Metric: 14.126190476190475 / 27  (52.3):  90%|▉| 27/30 [01:25<00:06,  2.30s/\u001b[A\n",
      "Average Metric: 14.126190476190475 / 28  (50.5):  90%|▉| 27/30 [01:29<00:06,  2.30s/\u001b[A\n",
      "Average Metric: 14.126190476190475 / 28  (50.5):  93%|▉| 28/30 [01:29<00:05,  2.78s/\u001b[A\n",
      "Average Metric: 14.792857142857141 / 29  (51.0):  93%|▉| 28/30 [01:32<00:05,  2.78s/\u001b[A\n",
      "Average Metric: 14.792857142857141 / 29  (51.0):  97%|▉| 29/30 [01:32<00:03,  3.08s/\u001b[A\n",
      "Average Metric: 15.459523809523807 / 30  (51.5):  97%|▉| 29/30 [01:56<00:03,  3.08s/\u001b[A\n",
      "Average Metric: 15.459523809523807 / 30  (51.5): 100%|█| 30/30 [01:56<00:00,  3.87s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.459523809523807 / 30  (51.5%)\n",
      "Score: 51.53 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7311111111111112\n",
      "Average of max per entry across top 3 scores: 0.8411111111111111\n",
      "Average of max per entry across top 5 scores: 0.88\n",
      "Average of max per entry across top 8 scores: 0.88\n",
      "Average of max per entry across top 9999 scores: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:00<00:26,  1.09it/s]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:01<00:27,  1.02it/s]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:02<00:26,  1.03it/s]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:05<00:44,  1.71s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:06<00:37,  1.50s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:07<00:32,  1.37s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:08<00:28,  1.22s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:10<00:26,  1.20s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:11<00:28,  1.35s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:12<00:24,  1.23s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:16<00:37,  1.98s/it]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:17<00:25,  1.44s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:00<00:28,  1.00it/s]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:01<00:28,  1.00it/s]\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   7%| | 2/30 [00:01<00:27,  1.00it/s\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):  10%| | 3/30 [00:01<00:09,  3.00it/s\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 4  (20.8):  10%| | 3/30 [00:01<00:09,  3.00it/s\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 4  (20.8):  13%|▏| 4/30 [00:01<00:07,  3.36it/s\u001b[A\n",
      "Average Metric: 0.9333333333333332 / 5  (18.7):  13%|▏| 4/30 [00:02<00:07,  3.36it/s\u001b[A\n",
      "Average Metric: 0.9333333333333332 / 5  (18.7):  17%|▏| 5/30 [00:02<00:17,  1.42it/s\u001b[A\n",
      "Average Metric: 0.9333333333333332 / 6  (15.6):  17%|▏| 5/30 [00:04<00:17,  1.42it/s\u001b[A\n",
      "Average Metric: 0.9333333333333332 / 6  (15.6):  20%|▏| 6/30 [00:04<00:20,  1.17it/s\u001b[A\n",
      "Average Metric: 1.4333333333333331 / 7  (20.5):  20%|▏| 6/30 [00:04<00:20,  1.17it/s\u001b[A\n",
      "Average Metric: 1.4333333333333331 / 8  (17.9):  23%|▏| 7/30 [00:04<00:19,  1.17it/s\u001b[A\n",
      "Average Metric: 1.4333333333333331 / 8  (17.9):  27%|▎| 8/30 [00:04<00:12,  1.70it/s\u001b[A\n",
      "Average Metric: 1.7666666666666664 / 9  (19.6):  27%|▎| 8/30 [00:05<00:12,  1.70it/s\u001b[A\n",
      "Average Metric: 1.7666666666666664 / 9  (19.6):  30%|▎| 9/30 [00:05<00:12,  1.72it/s\u001b[A\n",
      "Average Metric: 2.7666666666666666 / 10  (27.7):  30%|▎| 9/30 [00:05<00:12,  1.72it/\u001b[A\n",
      "Average Metric: 2.7666666666666666 / 10  (27.7):  33%|▎| 10/30 [00:05<00:10,  1.83it\u001b[A\n",
      "Average Metric: 3.2666666666666666 / 11  (29.7):  33%|▎| 10/30 [00:05<00:10,  1.83it\u001b[A\n",
      "Average Metric: 3.2666666666666666 / 11  (29.7):  37%|▎| 11/30 [00:05<00:08,  2.36it\u001b[A\n",
      "Average Metric: 4.016666666666667 / 12  (33.5):  37%|▎| 11/30 [00:06<00:08,  2.36it/\u001b[A\n",
      "Average Metric: 4.016666666666667 / 12  (33.5):  40%|▍| 12/30 [00:06<00:10,  1.77it/\u001b[A\n",
      "Average Metric: 5.016666666666667 / 13  (38.6):  40%|▍| 12/30 [00:06<00:10,  1.77it/\u001b[A\n",
      "Average Metric: 6.016666666666667 / 14  (43.0):  43%|▍| 13/30 [00:07<00:09,  1.77it/\u001b[A\n",
      "Average Metric: 6.016666666666667 / 14  (43.0):  47%|▍| 14/30 [00:07<00:06,  2.51it/\u001b[A\n",
      "Average Metric: 6.35 / 15  (42.3):  47%|█████▌      | 14/30 [00:07<00:06,  2.51it/s]\u001b[A\n",
      "Average Metric: 6.35 / 15  (42.3):  50%|██████      | 15/30 [00:07<00:05,  2.54it/s]\u001b[A\n",
      "Average Metric: 6.55 / 16  (40.9):  50%|██████      | 15/30 [00:08<00:05,  2.54it/s]\u001b[A\n",
      "Average Metric: 6.55 / 16  (40.9):  53%|██████▍     | 16/30 [00:08<00:06,  2.27it/s]\u001b[A\n",
      "Average Metric: 7.05 / 17  (41.5):  53%|██████▍     | 16/30 [00:08<00:06,  2.27it/s]\u001b[A\n",
      "Average Metric: 7.05 / 17  (41.5):  57%|██████▊     | 17/30 [00:08<00:06,  2.02it/s]\u001b[A\n",
      "Average Metric: 7.05 / 18  (39.2):  57%|██████▊     | 17/30 [00:09<00:06,  2.02it/s]\u001b[A\n",
      "Average Metric: 7.05 / 18  (39.2):  60%|███████▏    | 18/30 [00:09<00:05,  2.09it/s]\u001b[A\n",
      "Average Metric: 7.383333333333333 / 19  (38.9):  60%|▌| 18/30 [00:09<00:05,  2.09it/\u001b[A\n",
      "Average Metric: 7.716666666666666 / 20  (38.6):  63%|▋| 19/30 [00:09<00:05,  2.09it/\u001b[A\n",
      "Average Metric: 7.716666666666666 / 20  (38.6):  67%|▋| 20/30 [00:09<00:02,  3.37it/\u001b[A\n",
      "Average Metric: 8.383333333333333 / 21  (39.9):  67%|▋| 20/30 [00:10<00:02,  3.37it/\u001b[A\n",
      "Average Metric: 8.383333333333333 / 21  (39.9):  70%|▋| 21/30 [00:10<00:03,  2.46it/\u001b[A\n",
      "Average Metric: 9.383333333333333 / 22  (42.7):  70%|▋| 21/30 [00:10<00:03,  2.46it/\u001b[A\n",
      "Average Metric: 9.383333333333333 / 22  (42.7):  73%|▋| 22/30 [00:10<00:02,  3.01it/\u001b[A\n",
      "Average Metric: 9.883333333333333 / 23  (43.0):  73%|▋| 22/30 [00:10<00:02,  3.01it/\u001b[A\n",
      "Average Metric: 9.883333333333333 / 24  (41.2):  77%|▊| 23/30 [00:10<00:02,  3.01it/\u001b[A\n",
      "Average Metric: 10.883333333333333 / 25  (43.5):  80%|▊| 24/30 [00:10<00:01,  3.01it\u001b[A\n",
      "Average Metric: 10.883333333333333 / 25  (43.5):  83%|▊| 25/30 [00:10<00:01,  3.60it\u001b[A\n",
      "Average Metric: 10.883333333333333 / 26  (41.9):  83%|▊| 25/30 [00:10<00:01,  3.60it\u001b[A\n",
      "Average Metric: 10.883333333333333 / 26  (41.9):  87%|▊| 26/30 [00:10<00:00,  4.04it\u001b[A\n",
      "Average Metric: 11.883333333333333 / 27  (44.0):  87%|▊| 26/30 [00:11<00:00,  4.04it\u001b[A\n",
      "Average Metric: 12.883333333333333 / 28  (46.0):  90%|▉| 27/30 [00:11<00:00,  4.04it\u001b[A\n",
      "Average Metric: 12.883333333333333 / 28  (46.0):  93%|▉| 28/30 [00:11<00:00,  4.96it\u001b[A\n",
      "Average Metric: 13.883333333333333 / 29  (47.9):  93%|▉| 28/30 [00:11<00:00,  4.96it\u001b[A\n",
      "Average Metric: 13.883333333333333 / 29  (47.9):  97%|▉| 29/30 [00:11<00:00,  4.54it\u001b[A\n",
      "Average Metric: 13.883333333333333 / 30  (46.3):  97%|▉| 29/30 [00:12<00:00,  4.54it\u001b[A\n",
      "Average Metric: 13.883333333333333 / 30  (46.3): 100%|█| 30/30 [00:12<00:00,  2.36it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.883333333333333 / 30  (46.3%)\n",
      "Score: 46.28 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7311111111111112\n",
      "Average of max per entry across top 3 scores: 0.8411111111111111\n",
      "Average of max per entry across top 5 scores: 0.8916666666666667\n",
      "Average of max per entry across top 8 scores: 0.8916666666666667\n",
      "Average of max per entry across top 9999 scores: 0.8916666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:31,  1.08s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:03<00:51,  1.84s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:04<00:42,  1.58s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:06<00:40,  1.58s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:31,  3.15s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   3%|▌               | 1/30 [00:03<01:31,  3.15s/it]\u001b[A\n",
      "Average Metric: 0.0 / 2  (0.0):   7%|█               | 2/30 [00:03<00:44,  1.58s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):   7%|█               | 2/30 [00:06<00:44,  1.58s/it]\u001b[A\n",
      "Average Metric: 0.0 / 3  (0.0):  10%|█▌              | 3/30 [00:06<00:54,  2.00s/it]\u001b[A\n",
      "Average Metric: 0.6666666666666666 / 4  (16.7):  10%| | 3/30 [00:08<00:54,  2.00s/it\u001b[A\n",
      "Average Metric: 0.6666666666666666 / 4  (16.7):  13%|▏| 4/30 [00:08<00:55,  2.15s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.6666666666666665 / 5  (33.3):  13%|▏| 4/30 [00:13<00:55,  2.15s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 5  (33.3):  17%|▏| 5/30 [00:13<01:17,  3.08s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 6  (27.8):  17%|▏| 5/30 [00:13<01:17,  3.08s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 6  (27.8):  20%|▏| 6/30 [00:13<00:54,  2.26s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0666666666666664 / 7  (29.5):  20%|▏| 6/30 [00:15<00:54,  2.26s/it\u001b[A\n",
      "Average Metric: 2.0666666666666664 / 7  (29.5):  23%|▏| 7/30 [00:15<00:45,  1.97s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  23%|▏| 7/30 [00:18<00:45,  1.97s/it\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):  27%|▎| 8/30 [00:18<00:52,  2.39s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  27%|▎| 8/30 [00:22<00:52,  2.39s/it\u001b[A\n",
      "Average Metric: 2.5666666666666664 / 9  (28.5):  30%|▎| 9/30 [00:22<00:58,  2.78s/it\u001b[A\n",
      "Average Metric: 3.0666666666666664 / 10  (30.7):  30%|▎| 9/30 [00:23<00:58,  2.78s/i\u001b[A\n",
      "Average Metric: 3.0666666666666664 / 10  (30.7):  33%|▎| 10/30 [00:23<00:45,  2.26s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0666666666666664 / 11  (27.9):  33%|▎| 10/30 [00:24<00:45,  2.26s/\u001b[A\n",
      "Average Metric: 3.0666666666666664 / 11  (27.9):  37%|▎| 11/30 [00:24<00:35,  1.88s/\u001b[A\n",
      "Average Metric: 3.6916666666666664 / 12  (30.8):  37%|▎| 11/30 [00:25<00:35,  1.88s/\u001b[A\n",
      "Average Metric: 3.6916666666666664 / 12  (30.8):  40%|▍| 12/30 [00:25<00:30,  1.70s/\u001b[A\n",
      "Average Metric: 4.691666666666666 / 13  (36.1):  40%|▍| 12/30 [00:25<00:30,  1.70s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.941666666666666 / 14  (35.3):  43%|▍| 13/30 [00:26<00:28,  1.70s/i\u001b[A\n",
      "Average Metric: 4.941666666666666 / 14  (35.3):  47%|▍| 14/30 [00:26<00:16,  1.02s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.941666666666666 / 15  (39.6):  47%|▍| 14/30 [00:29<00:16,  1.02s/i\u001b[A\n",
      "Average Metric: 5.941666666666666 / 15  (39.6):  50%|▌| 15/30 [00:29<00:25,  1.68s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.191666666666666 / 16  (38.7):  50%|▌| 15/30 [00:30<00:25,  1.68s/i\u001b[A\n",
      "Average Metric: 6.191666666666666 / 16  (38.7):  53%|▌| 16/30 [00:30<00:21,  1.55s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.691666666666666 / 17  (39.4):  53%|▌| 16/30 [00:34<00:21,  1.55s/i\u001b[A\n",
      "Average Metric: 6.691666666666666 / 17  (39.4):  57%|▌| 17/30 [00:34<00:27,  2.10s/i\u001b[A\n",
      "Average Metric: 6.891666666666667 / 18  (38.3):  57%|▌| 17/30 [00:35<00:27,  2.10s/i\u001b[A\n",
      "Average Metric: 6.891666666666667 / 18  (38.3):  60%|▌| 18/30 [00:35<00:20,  1.73s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.391666666666667 / 19  (38.9):  60%|▌| 18/30 [00:36<00:20,  1.73s/i\u001b[A\n",
      "Average Metric: 7.391666666666667 / 19  (38.9):  63%|▋| 19/30 [00:36<00:17,  1.57s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.391666666666666 / 20  (42.0):  63%|▋| 19/30 [00:37<00:17,  1.57s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 20  (42.0):  67%|▋| 20/30 [00:37<00:13,  1.35s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.391666666666666 / 21  (40.0):  67%|▋| 20/30 [00:42<00:13,  1.35s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 21  (40.0):  70%|▋| 21/30 [00:42<00:21,  2.38s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 22  (38.1):  70%|▋| 21/30 [00:42<00:21,  2.38s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 22  (38.1):  73%|▋| 22/30 [00:42<00:15,  1.88s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 23  (36.5):  73%|▋| 22/30 [00:43<00:15,  1.88s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 23  (36.5):  77%|▊| 23/30 [00:43<00:09,  1.40s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 24  (35.0):  77%|▊| 23/30 [00:43<00:09,  1.40s/i\u001b[A\n",
      "Average Metric: 8.391666666666666 / 24  (35.0):  80%|▊| 24/30 [00:43<00:06,  1.15s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.891666666666666 / 25  (35.6):  80%|▊| 24/30 [00:44<00:06,  1.15s/i\u001b[A\n",
      "Average Metric: 8.891666666666666 / 25  (35.6):  83%|▊| 25/30 [00:44<00:05,  1.02s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.891666666666666 / 26  (34.2):  83%|▊| 25/30 [00:51<00:05,  1.02s/i\u001b[A\n",
      "Average Metric: 8.891666666666666 / 26  (34.2):  87%|▊| 26/30 [00:51<00:11,  2.90s/i\u001b[A\n",
      "Average Metric: 9.891666666666666 / 27  (36.6):  87%|▊| 26/30 [00:51<00:11,  2.90s/i\u001b[A\n",
      "Average Metric: 9.891666666666666 / 27  (36.6):  90%|▉| 27/30 [00:51<00:06,  2.07s/i\u001b[A\n",
      "Average Metric: 9.891666666666666 / 28  (35.3):  90%|▉| 27/30 [00:52<00:06,  2.07s/i\u001b[A\n",
      "Average Metric: 9.891666666666666 / 28  (35.3):  93%|▉| 28/30 [00:52<00:03,  1.71s/i\u001b[A\n",
      "Average Metric: 9.891666666666666 / 29  (34.1):  93%|▉| 28/30 [00:53<00:03,  1.71s/i\u001b[A\n",
      "Average Metric: 9.891666666666666 / 29  (34.1):  97%|▉| 29/30 [00:53<00:01,  1.54s/i\u001b[A\n",
      "Average Metric: 10.691666666666666 / 30  (35.6):  97%|▉| 29/30 [00:54<00:01,  1.54s/\u001b[A\n",
      "Average Metric: 10.691666666666666 / 30  (35.6): 100%|█| 30/30 [00:54<00:00,  1.83s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 10.691666666666666 / 30  (35.6%)\n",
      "Score: 35.64 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7311111111111112\n",
      "Average of max per entry across top 3 scores: 0.8411111111111111\n",
      "Average of max per entry across top 5 scores: 0.8916666666666667\n",
      "Average of max per entry across top 8 scores: 0.91\n",
      "Average of max per entry across top 9999 scores: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:35,  1.24s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:29,  1.06s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:30,  1.15s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:04<00:32,  1.26s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:05<00:29,  1.17s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:06<00:27,  1.14s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:07<00:23,  1.04s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:09<00:28,  1.29s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:10<00:24,  1.15s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:11<00:21,  1.06s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:12<00:21,  1.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:09<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:09<04:24,  9.11s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:10<04:24,  9.11s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:10<02:05,  4.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.6666666666666665 / 3  (55.6):   7%| | 2/30 [00:13<02:05,  4.48s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 3  (55.6):  10%| | 3/30 [00:13<01:46,  3.94s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.9166666666666665 / 4  (47.9):  10%| | 3/30 [00:16<01:46,  3.94s/it\u001b[A\n",
      "Average Metric: 1.9166666666666665 / 4  (47.9):  13%|▏| 4/30 [00:16<01:29,  3.43s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.4166666666666665 / 5  (48.3):  13%|▏| 4/30 [00:18<01:29,  3.43s/it\u001b[A\n",
      "Average Metric: 2.4166666666666665 / 5  (48.3):  17%|▏| 5/30 [00:18<01:14,  2.99s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.4166666666666665 / 6  (56.9):  17%|▏| 5/30 [00:19<01:14,  2.99s/it\u001b[A\n",
      "Average Metric: 3.4166666666666665 / 6  (56.9):  20%|▏| 6/30 [00:19<00:52,  2.19s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.016666666666667 / 7  (57.4):  20%|▏| 6/30 [00:26<00:52,  2.19s/it]\u001b[A\n",
      "Average Metric: 4.016666666666667 / 7  (57.4):  23%|▏| 7/30 [00:26<01:26,  3.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.016666666666667 / 8  (50.2):  23%|▏| 7/30 [00:33<01:26,  3.76s/it]\u001b[A\n",
      "Average Metric: 4.016666666666667 / 8  (50.2):  27%|▎| 8/30 [00:33<01:45,  4.80s/it]\u001b[A\n",
      "Average Metric: 4.516666666666667 / 9  (50.2):  27%|▎| 8/30 [00:35<01:45,  4.80s/it]\u001b[A\n",
      "Average Metric: 4.516666666666667 / 9  (50.2):  30%|▎| 9/30 [00:35<01:25,  4.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.516666666666667 / 10  (45.2):  30%|▎| 9/30 [00:42<01:25,  4.05s/it\u001b[A\n",
      "Average Metric: 4.516666666666667 / 10  (45.2):  33%|▎| 10/30 [00:42<01:38,  4.94s/i\u001b[A\n",
      "Average Metric: 4.85 / 11  (44.1):  33%|████        | 10/30 [00:45<01:38,  4.94s/it]\u001b[A\n",
      "Average Metric: 4.85 / 11  (44.1):  37%|████▍       | 11/30 [00:45<01:22,  4.36s/it]\u001b[A\n",
      "Average Metric: 5.225 / 12  (43.5):  37%|████       | 11/30 [00:53<01:22,  4.36s/it]\u001b[A\n",
      "Average Metric: 5.225 / 12  (43.5):  40%|████▍      | 12/30 [00:53<01:40,  5.57s/it]\u001b[A\n",
      "Average Metric: 5.975 / 13  (46.0):  40%|████▍      | 12/30 [00:57<01:40,  5.57s/it]\u001b[A\n",
      "Average Metric: 5.975 / 13  (46.0):  43%|████▊      | 13/30 [00:57<01:25,  5.01s/it]\u001b[A\n",
      "Average Metric: 6.975 / 14  (49.8):  43%|████▊      | 13/30 [01:00<01:25,  5.01s/it]\u001b[A\n",
      "Average Metric: 6.975 / 14  (49.8):  47%|█████▏     | 14/30 [01:00<01:09,  4.33s/it]\u001b[A\n",
      "Average Metric: 7.975 / 15  (53.2):  47%|█████▏     | 14/30 [01:01<01:09,  4.33s/it]\u001b[A\n",
      "Average Metric: 7.975 / 15  (53.2):  50%|█████▌     | 15/30 [01:01<00:49,  3.27s/it]\u001b[A\n",
      "Average Metric: 8.475 / 16  (53.0):  50%|█████▌     | 15/30 [01:08<00:49,  3.27s/it]\u001b[A\n",
      "Average Metric: 8.475 / 16  (53.0):  53%|█████▊     | 16/30 [01:08<01:01,  4.40s/it]\u001b[A\n",
      "Average Metric: 8.808333333333334 / 17  (51.8):  53%|▌| 16/30 [01:08<01:01,  4.40s/i\u001b[A\n",
      "Average Metric: 8.808333333333334 / 17  (51.8):  57%|▌| 17/30 [01:08<00:42,  3.24s/i\u001b[A\n",
      "Average Metric: 9.308333333333334 / 18  (51.7):  57%|▌| 17/30 [01:09<00:42,  3.24s/i\u001b[A\n",
      "Average Metric: 9.308333333333334 / 18  (51.7):  60%|▌| 18/30 [01:09<00:31,  2.60s/i\u001b[A\n",
      "Average Metric: 9.308333333333334 / 19  (49.0):  60%|▌| 18/30 [01:10<00:31,  2.60s/i\u001b[A\n",
      "Average Metric: 9.308333333333334 / 19  (49.0):  63%|▋| 19/30 [01:10<00:22,  2.01s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.308333333333334 / 20  (46.5):  63%|▋| 19/30 [01:13<00:22,  2.01s/i\u001b[A\n",
      "Average Metric: 9.308333333333334 / 20  (46.5):  67%|▋| 20/30 [01:13<00:24,  2.43s/i\u001b[A\n",
      "Average Metric: 9.558333333333334 / 21  (45.5):  67%|▋| 20/30 [01:15<00:24,  2.43s/i\u001b[A\n",
      "Average Metric: 9.558333333333334 / 21  (45.5):  70%|▋| 21/30 [01:15<00:18,  2.07s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.558333333333334 / 22  (43.4):  70%|▋| 21/30 [01:19<00:18,  2.07s/i\u001b[A\n",
      "Average Metric: 9.558333333333334 / 22  (43.4):  73%|▋| 22/30 [01:19<00:20,  2.62s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.558333333333334 / 23  (45.9):  73%|▋| 22/30 [01:19<00:20,  2.62s/\u001b[A\n",
      "Average Metric: 10.558333333333334 / 23  (45.9):  77%|▊| 23/30 [01:19<00:14,  2.02s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.558333333333334 / 24  (44.0):  77%|▊| 23/30 [01:23<00:14,  2.02s/\u001b[A\n",
      "Average Metric: 10.558333333333334 / 24  (44.0):  80%|▊| 24/30 [01:23<00:15,  2.66s/\u001b[A\n",
      "Average Metric: 11.558333333333334 / 25  (46.2):  80%|▊| 24/30 [01:24<00:15,  2.66s/\u001b[A\n",
      "Average Metric: 11.558333333333334 / 25  (46.2):  83%|▊| 25/30 [01:24<00:09,  1.97s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.058333333333334 / 26  (46.4):  83%|▊| 25/30 [01:29<00:09,  1.97s/\u001b[A\n",
      "Average Metric: 12.058333333333334 / 26  (46.4):  87%|▊| 26/30 [01:29<00:11,  2.91s/\u001b[A\n",
      "Average Metric: 12.683333333333334 / 27  (47.0):  87%|▊| 26/30 [01:32<00:11,  2.91s/\u001b[A\n",
      "Average Metric: 12.683333333333334 / 27  (47.0):  90%|▉| 27/30 [01:32<00:09,  3.09s/\u001b[A\n",
      "Average Metric: 13.683333333333334 / 28  (48.9):  90%|▉| 27/30 [01:33<00:09,  3.09s/\u001b[A\n",
      "Average Metric: 13.683333333333334 / 28  (48.9):  93%|▉| 28/30 [01:33<00:04,  2.32s/\u001b[A\n",
      "Average Metric: 14.683333333333334 / 29  (50.6):  93%|▉| 28/30 [01:36<00:04,  2.32s/\u001b[A\n",
      "Average Metric: 14.683333333333334 / 29  (50.6):  97%|▉| 29/30 [01:36<00:02,  2.44s/\u001b[A\n",
      "Average Metric: 15.183333333333334 / 30  (50.6):  97%|▉| 29/30 [01:39<00:02,  2.44s/\u001b[A\n",
      "Average Metric: 15.183333333333334 / 30  (50.6): 100%|█| 30/30 [01:39<00:00,  3.33s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.183333333333334 / 30  (50.6%)\n",
      "Score: 50.61 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7311111111111112\n",
      "Average of max per entry across top 3 scores: 0.8327777777777778\n",
      "Average of max per entry across top 5 scores: 0.9138888888888889\n",
      "Average of max per entry across top 8 scores: 0.9322222222222222\n",
      "Average of max per entry across top 9999 scores: 0.9322222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:31,  1.09s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:31,  1.13s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:06<01:06,  2.47s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:07<00:48,  1.85s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:08<00:40,  1.62s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:09<00:34,  1.45s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:13<00:50,  2.19s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:14<00:38,  1.77s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 9 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:50,  3.81s/it]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 2  (16.7):   3%| | 1/30 [00:03<01:50,  3.81s/it\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   7%| | 2/30 [00:06<01:46,  3.81s/it\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):  10%| | 3/30 [00:06<00:50,  1.86s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.1666666666666665 / 4  (29.2):  10%| | 3/30 [00:11<00:50,  1.86s/it\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 4  (29.2):  13%|▏| 4/30 [00:11<01:16,  2.94s/it\u001b[A\n",
      "Average Metric: 1.9166666666666665 / 5  (38.3):  13%|▏| 4/30 [00:12<01:16,  2.94s/it\u001b[A\n",
      "Average Metric: 1.9166666666666665 / 5  (38.3):  17%|▏| 5/30 [00:12<01:01,  2.46s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.25 / 6  (37.5):  17%|██▎           | 5/30 [00:13<01:01,  2.46s/it]\u001b[A\n",
      "Average Metric: 2.25 / 6  (37.5):  20%|██▊           | 6/30 [00:13<00:44,  1.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5833333333333335 / 7  (36.9):  20%|▏| 6/30 [00:14<00:44,  1.84s/it\u001b[A\n",
      "Average Metric: 2.5833333333333335 / 7  (36.9):  23%|▏| 7/30 [00:14<00:38,  1.67s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5833333333333335 / 8  (32.3):  23%|▏| 7/30 [00:25<00:38,  1.67s/it\u001b[A\n",
      "Average Metric: 2.5833333333333335 / 8  (32.3):  27%|▎| 8/30 [00:25<01:41,  4.60s/it\u001b[A\n",
      "Average Metric: 3.0833333333333335 / 9  (34.3):  27%|▎| 8/30 [00:25<01:41,  4.60s/it\u001b[A\n",
      "Average Metric: 3.0833333333333335 / 9  (34.3):  30%|▎| 9/30 [00:25<01:09,  3.29s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.416666666666667 / 10  (34.2):  30%|▎| 9/30 [00:28<01:09,  3.29s/it\u001b[A\n",
      "Average Metric: 3.416666666666667 / 10  (34.2):  33%|▎| 10/30 [00:28<01:02,  3.12s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.7500000000000004 / 11  (34.1):  33%|▎| 10/30 [00:33<01:02,  3.12s/\u001b[A\n",
      "Average Metric: 3.7500000000000004 / 11  (34.1):  37%|▎| 11/30 [00:33<01:08,  3.59s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.0 / 12  (33.3):  37%|████▊        | 11/30 [00:38<01:08,  3.59s/it]\u001b[A\n",
      "Average Metric: 4.0 / 12  (33.3):  40%|█████▏       | 12/30 [00:38<01:12,  4.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.75 / 13  (36.5):  40%|████▊       | 12/30 [00:40<01:12,  4.01s/it]\u001b[A\n",
      "Average Metric: 4.75 / 13  (36.5):  43%|█████▏      | 13/30 [00:40<00:59,  3.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.75 / 14  (41.1):  43%|█████▏      | 13/30 [00:41<00:59,  3.50s/it]\u001b[A\n",
      "Average Metric: 5.75 / 14  (41.1):  47%|█████▌      | 14/30 [00:41<00:43,  2.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.75 / 15  (45.0):  47%|█████▌      | 14/30 [00:47<00:43,  2.75s/it]\u001b[A\n",
      "Average Metric: 6.75 / 15  (45.0):  50%|██████      | 15/30 [00:47<00:53,  3.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.75 / 16  (48.4):  50%|██████      | 15/30 [00:52<00:53,  3.58s/it]\u001b[A\n",
      "Average Metric: 7.75 / 16  (48.4):  53%|██████▍     | 16/30 [00:52<00:58,  4.19s/it]\u001b[A\n",
      "Average Metric: 8.75 / 17  (51.5):  53%|██████▍     | 16/30 [00:53<00:58,  4.19s/it]\u001b[A\n",
      "Average Metric: 8.75 / 17  (51.5):  57%|██████▊     | 17/30 [00:53<00:41,  3.22s/it]\u001b[A\n",
      "Average Metric: 9.083333333333334 / 18  (50.5):  57%|▌| 17/30 [00:54<00:41,  3.22s/i\u001b[A\n",
      "Average Metric: 9.083333333333334 / 18  (50.5):  60%|▌| 18/30 [00:54<00:29,  2.44s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.583333333333334 / 19  (50.4):  60%|▌| 18/30 [00:58<00:29,  2.44s/i\u001b[A\n",
      "Average Metric: 9.583333333333334 / 19  (50.4):  63%|▋| 19/30 [00:58<00:31,  2.84s/i\u001b[A\n",
      "Average Metric: 9.583333333333334 / 20  (47.9):  63%|▋| 19/30 [00:59<00:31,  2.84s/i\u001b[A\n",
      "Average Metric: 9.583333333333334 / 20  (47.9):  67%|▋| 20/30 [00:59<00:24,  2.41s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.916666666666668 / 21  (47.2):  67%|▋| 20/30 [01:06<00:24,  2.41s/i\u001b[A\n",
      "Average Metric: 9.916666666666668 / 21  (47.2):  70%|▋| 21/30 [01:06<00:33,  3.72s/i\u001b[A\n",
      "Average Metric: 10.416666666666668 / 22  (47.3):  70%|▋| 21/30 [01:06<00:33,  3.72s/\u001b[A\n",
      "Average Metric: 10.416666666666668 / 22  (47.3):  73%|▋| 22/30 [01:06<00:22,  2.80s/\u001b[A\n",
      "Average Metric: 11.041666666666668 / 23  (48.0):  73%|▋| 22/30 [01:07<00:22,  2.80s/\u001b[A\n",
      "Average Metric: 11.041666666666668 / 23  (48.0):  77%|▊| 23/30 [01:07<00:15,  2.23s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.041666666666668 / 24  (46.0):  77%|▊| 23/30 [01:10<00:15,  2.23s/\u001b[A\n",
      "Average Metric: 11.041666666666668 / 24  (46.0):  80%|▊| 24/30 [01:10<00:14,  2.43s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.041666666666668 / 25  (48.2):  80%|▊| 24/30 [01:13<00:14,  2.43s/\u001b[A\n",
      "Average Metric: 12.041666666666668 / 25  (48.2):  83%|▊| 25/30 [01:13<00:12,  2.42s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.041666666666668 / 26  (50.2):  83%|▊| 25/30 [01:14<00:12,  2.42s/\u001b[A\n",
      "Average Metric: 13.041666666666668 / 26  (50.2):  87%|▊| 26/30 [01:14<00:08,  2.20s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.041666666666668 / 27  (48.3):  87%|▊| 26/30 [01:19<00:08,  2.20s/\u001b[A\n",
      "Average Metric: 13.041666666666668 / 27  (48.3):  90%|▉| 27/30 [01:19<00:08,  2.95s/\u001b[A\n",
      "Average Metric: 14.041666666666668 / 28  (50.1):  90%|▉| 27/30 [01:22<00:08,  2.95s/\u001b[A\n",
      "Average Metric: 14.041666666666668 / 28  (50.1):  93%|▉| 28/30 [01:22<00:06,  3.05s/\u001b[A\n",
      "Average Metric: 14.791666666666668 / 29  (51.0):  93%|▉| 28/30 [01:23<00:06,  3.05s/\u001b[A\n",
      "Average Metric: 14.791666666666668 / 29  (51.0):  97%|▉| 29/30 [01:23<00:02,  2.38s/\u001b[A\n",
      "Average Metric: 15.591666666666669 / 30  (52.0):  97%|▉| 29/30 [01:25<00:02,  2.38s/\u001b[A\n",
      "Average Metric: 15.591666666666669 / 30  (52.0): 100%|█| 30/30 [01:25<00:00,  2.86s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.591666666666669 / 30  (52.0%)\n",
      "Score: 51.97 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.8316666666666668\n",
      "Average of max per entry across top 5 scores: 0.9149999999999999\n",
      "Average of max per entry across top 8 scores: 0.9516666666666667\n",
      "Average of max per entry across top 9999 scores: 0.9516666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:40,  1.40s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:32,  1.15s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:31,  1.16s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:04<00:32,  1.24s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:05<00:28,  1.13s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:07<00:30,  1.29s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:08<00:29,  1.27s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:09<00:26,  1.21s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:11<00:25,  1.23s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:12<00:25,  1.29s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:13<00:23,  1.21s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 12 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 1  (33.3):   0%|        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.3333333333333333 / 1  (33.3):   3%| | 1/30 [00:00<00:27,  1.04it/s\u001b[A\n",
      "Average Metric: 1.3333333333333333 / 2  (66.7):   3%| | 1/30 [00:00<00:27,  1.04it/s\u001b[A\n",
      "Average Metric: 1.3333333333333333 / 3  (44.4):   7%| | 2/30 [00:00<00:26,  1.04it/s\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):  10%| | 3/30 [00:00<00:26,  1.04it/s\u001b[A\n",
      "Average Metric: 2.333333333333333 / 5  (46.7):  13%|▏| 4/30 [00:01<00:25,  1.04it/s]\u001b[A\n",
      "Average Metric: 2.333333333333333 / 6  (38.9):  17%|▏| 5/30 [00:01<00:24,  1.04it/s]\u001b[A\n",
      "Average Metric: 2.333333333333333 / 6  (38.9):  20%|▏| 6/30 [00:01<00:06,  3.70it/s]\u001b[A\n",
      "Average Metric: 2.833333333333333 / 7  (40.5):  20%|▏| 6/30 [00:01<00:06,  3.70it/s]\u001b[A\n",
      "Average Metric: 2.833333333333333 / 7  (40.5):  23%|▏| 7/30 [00:01<00:05,  4.12it/s]\u001b[A\n",
      "Average Metric: 3.333333333333333 / 8  (41.7):  23%|▏| 7/30 [00:02<00:05,  4.12it/s]\u001b[A\n",
      "Average Metric: 3.333333333333333 / 8  (41.7):  27%|▎| 8/30 [00:02<00:07,  2.88it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.333333333333333 / 9  (37.0):  27%|▎| 8/30 [00:05<00:07,  2.88it/s]\u001b[A\n",
      "Average Metric: 3.333333333333333 / 9  (37.0):  30%|▎| 9/30 [00:05<00:17,  1.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.083333333333333 / 10  (40.8):  30%|▎| 9/30 [00:06<00:17,  1.21it/s\u001b[A\n",
      "Average Metric: 4.083333333333333 / 10  (40.8):  33%|▎| 10/30 [00:06<00:17,  1.13it/\u001b[A\n",
      "Average Metric: 5.083333333333333 / 11  (46.2):  33%|▎| 10/30 [00:07<00:17,  1.13it/\u001b[A\n",
      "Average Metric: 5.083333333333333 / 11  (46.2):  37%|▎| 11/30 [00:07<00:17,  1.08it/\u001b[A\n",
      "Average Metric: 5.333333333333333 / 12  (44.4):  37%|▎| 11/30 [00:07<00:17,  1.08it/\u001b[A\n",
      "Average Metric: 5.333333333333333 / 12  (44.4):  40%|▍| 12/30 [00:07<00:12,  1.40it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.583333333333333 / 13  (42.9):  40%|▍| 12/30 [00:11<00:12,  1.40it/\u001b[A\n",
      "Average Metric: 5.583333333333333 / 13  (42.9):  43%|▍| 13/30 [00:11<00:27,  1.63s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.583333333333333 / 14  (47.0):  43%|▍| 13/30 [00:12<00:27,  1.63s/i\u001b[A\n",
      "Average Metric: 6.583333333333333 / 14  (47.0):  47%|▍| 14/30 [00:12<00:25,  1.62s/i\u001b[A\n",
      "Average Metric: 6.916666666666666 / 15  (46.1):  47%|▍| 14/30 [00:13<00:25,  1.62s/i\u001b[A\n",
      "Average Metric: 6.916666666666666 / 15  (46.1):  50%|▌| 15/30 [00:13<00:21,  1.42s/i\u001b[A\n",
      "Average Metric: 6.916666666666666 / 16  (43.2):  50%|▌| 15/30 [00:14<00:21,  1.42s/i\u001b[A\n",
      "Average Metric: 6.916666666666666 / 16  (43.2):  53%|▌| 16/30 [00:14<00:15,  1.12s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.316666666666666 / 17  (43.0):  53%|▌| 16/30 [00:17<00:15,  1.12s/i\u001b[A\n",
      "Average Metric: 7.316666666666666 / 17  (43.0):  57%|▌| 17/30 [00:17<00:23,  1.78s/i\u001b[A\n",
      "Average Metric: 7.816666666666666 / 18  (43.4):  57%|▌| 17/30 [00:17<00:23,  1.78s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.316666666666666 / 19  (43.8):  60%|▌| 18/30 [00:18<00:21,  1.78s/i\u001b[A\n",
      "Average Metric: 8.316666666666666 / 19  (43.8):  63%|▋| 19/30 [00:18<00:13,  1.20s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.316666666666666 / 20  (41.6):  63%|▋| 19/30 [00:20<00:13,  1.20s/i\u001b[A\n",
      "Average Metric: 8.316666666666666 / 20  (41.6):  67%|▋| 20/30 [00:20<00:13,  1.38s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.066666666666666 / 21  (43.2):  67%|▋| 20/30 [00:20<00:13,  1.38s/i\u001b[A\n",
      "Average Metric: 9.066666666666666 / 21  (43.2):  70%|▋| 21/30 [00:20<00:09,  1.09s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.066666666666666 / 22  (41.2):  70%|▋| 21/30 [00:21<00:09,  1.09s/i\u001b[A\n",
      "Average Metric: 9.066666666666666 / 22  (41.2):  73%|▋| 22/30 [00:21<00:08,  1.09s/i\u001b[A\n",
      "Average Metric: 10.066666666666666 / 23  (43.8):  73%|▋| 22/30 [00:22<00:08,  1.09s/\u001b[A\n",
      "Average Metric: 10.066666666666666 / 23  (43.8):  77%|▊| 23/30 [00:22<00:05,  1.18it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.066666666666666 / 24  (41.9):  77%|▊| 23/30 [00:23<00:05,  1.18it\u001b[A\n",
      "Average Metric: 10.066666666666666 / 24  (41.9):  80%|▊| 24/30 [00:23<00:06,  1.03s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.066666666666666 / 25  (40.3):  80%|▊| 24/30 [00:24<00:06,  1.03s/\u001b[A\n",
      "Average Metric: 10.066666666666666 / 25  (40.3):  83%|▊| 25/30 [00:24<00:05,  1.11s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.691666666666666 / 26  (41.1):  83%|▊| 25/30 [00:26<00:05,  1.11s/\u001b[A\n",
      "Average Metric: 10.691666666666666 / 26  (41.1):  87%|▊| 26/30 [00:26<00:04,  1.15s/\u001b[A\n",
      "Average Metric: 11.691666666666666 / 27  (43.3):  87%|▊| 26/30 [00:27<00:04,  1.15s/\u001b[A\n",
      "Average Metric: 11.691666666666666 / 27  (43.3):  90%|▉| 27/30 [00:27<00:03,  1.15s/\u001b[A\n",
      "Average Metric: 12.691666666666666 / 28  (45.3):  90%|▉| 27/30 [00:28<00:03,  1.15s/\u001b[A\n",
      "Average Metric: 12.691666666666666 / 28  (45.3):  93%|▉| 28/30 [00:28<00:02,  1.15s/\u001b[A\n",
      "Average Metric: 13.191666666666666 / 29  (45.5):  93%|▉| 28/30 [00:29<00:02,  1.15s/\u001b[A\n",
      "Average Metric: 13.191666666666666 / 29  (45.5):  97%|▉| 29/30 [00:29<00:01,  1.13s/\u001b[A\n",
      "Average Metric: 13.691666666666666 / 30  (45.6):  97%|▉| 29/30 [00:30<00:01,  1.13s/\u001b[A\n",
      "Average Metric: 13.691666666666666 / 30  (45.6): 100%|█| 30/30 [00:30<00:00,  1.02s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.691666666666666 / 30  (45.6%)\n",
      "Score: 45.64 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.8316666666666668\n",
      "Average of max per entry across top 5 scores: 0.9149999999999999\n",
      "Average of max per entry across top 8 scores: 0.935\n",
      "Average of max per entry across top 9999 scores: 0.9516666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:37,  1.28s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:34,  1.24s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:35,  1.33s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:05<00:32,  1.26s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:00<00:28,  1.03it/s]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:01<00:28,  1.03it/s]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   7%|▉             | 2/30 [00:01<00:17,  1.58it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5 / 3  (83.3):   7%|█              | 2/30 [00:05<00:17,  1.58it/s]\u001b[A\n",
      "Average Metric: 2.5 / 3  (83.3):  10%|█▌             | 3/30 [00:05<00:56,  2.07s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.5 / 4  (62.5):  10%|█▌             | 3/30 [00:06<00:56,  2.07s/it]\u001b[A\n",
      "Average Metric: 2.5 / 4  (62.5):  13%|██             | 4/30 [00:06<00:46,  1.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.625 / 5  (52.5):  13%|█▋           | 4/30 [00:07<00:46,  1.77s/it]\u001b[A\n",
      "Average Metric: 2.625 / 5  (52.5):  17%|██▏          | 5/30 [00:07<00:38,  1.55s/it]\u001b[A\n",
      "Average Metric: 2.625 / 6  (43.8):  17%|██▏          | 5/30 [00:07<00:38,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.625 / 7  (37.5):  20%|██▌          | 6/30 [00:08<00:37,  1.55s/it]\u001b[A\n",
      "Average Metric: 2.625 / 7  (37.5):  23%|███          | 7/30 [00:08<00:24,  1.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.9583333333333335 / 8  (37.0):  23%|▏| 7/30 [00:11<00:24,  1.06s/it\u001b[A\n",
      "Average Metric: 2.9583333333333335 / 8  (37.0):  27%|▎| 8/30 [00:11<00:30,  1.40s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.4583333333333335 / 9  (38.4):  27%|▎| 8/30 [00:11<00:30,  1.40s/it\u001b[A\n",
      "Average Metric: 3.4583333333333335 / 9  (38.4):  30%|▎| 9/30 [00:11<00:24,  1.15s/it\u001b[A\n",
      "Average Metric: 3.4583333333333335 / 10  (34.6):  30%|▎| 9/30 [00:11<00:24,  1.15s/i\u001b[A\n",
      "Average Metric: 3.4583333333333335 / 10  (34.6):  33%|▎| 10/30 [00:11<00:17,  1.17it\u001b[A\n",
      "Average Metric: 4.083333333333334 / 11  (37.1):  33%|▎| 10/30 [00:12<00:17,  1.17it/\u001b[A\n",
      "Average Metric: 4.083333333333334 / 11  (37.1):  37%|▎| 11/30 [00:12<00:13,  1.38it/\u001b[A\n",
      "Average Metric: 5.083333333333334 / 12  (42.4):  37%|▎| 11/30 [00:12<00:13,  1.38it/\u001b[A\n",
      "Average Metric: 5.083333333333334 / 12  (42.4):  40%|▍| 12/30 [00:12<00:11,  1.56it/\u001b[A\n",
      "Average Metric: 6.083333333333334 / 13  (46.8):  40%|▍| 12/30 [00:12<00:11,  1.56it/\u001b[A\n",
      "Average Metric: 7.083333333333334 / 14  (50.6):  43%|▍| 13/30 [00:13<00:10,  1.56it/\u001b[A\n",
      "Average Metric: 7.083333333333334 / 14  (50.6):  47%|▍| 14/30 [00:13<00:08,  1.96it/\u001b[A\n",
      "Average Metric: 7.083333333333334 / 15  (47.2):  47%|▍| 14/30 [00:13<00:08,  1.96it/\u001b[A\n",
      "Average Metric: 7.083333333333334 / 15  (47.2):  50%|▌| 15/30 [00:13<00:07,  1.88it/\u001b[A\n",
      "Average Metric: 7.416666666666667 / 16  (46.4):  50%|▌| 15/30 [00:13<00:07,  1.88it/\u001b[A\n",
      "Average Metric: 7.416666666666667 / 17  (43.6):  53%|▌| 16/30 [00:14<00:07,  1.88it/\u001b[A\n",
      "Average Metric: 7.416666666666667 / 17  (43.6):  57%|▌| 17/30 [00:14<00:05,  2.52it/\u001b[A\n",
      "Average Metric: 7.75 / 18  (43.1):  57%|██████▊     | 17/30 [00:14<00:05,  2.52it/s]\u001b[A\n",
      "Average Metric: 7.75 / 18  (43.1):  60%|███████▏    | 18/30 [00:14<00:05,  2.29it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.75 / 19  (40.8):  60%|███████▏    | 18/30 [00:15<00:05,  2.29it/s]\u001b[A\n",
      "Average Metric: 7.75 / 19  (40.8):  63%|███████▌    | 19/30 [00:15<00:04,  2.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.083333333333334 / 20  (40.4):  63%|▋| 19/30 [00:16<00:04,  2.42it/\u001b[A\n",
      "Average Metric: 8.083333333333334 / 20  (40.4):  67%|▋| 20/30 [00:16<00:07,  1.29it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.583333333333334 / 21  (40.9):  67%|▋| 20/30 [00:18<00:07,  1.29it/\u001b[A\n",
      "Average Metric: 8.583333333333334 / 21  (40.9):  70%|▋| 21/30 [00:18<00:07,  1.17it/\u001b[A\n",
      "Average Metric: 9.583333333333334 / 22  (43.6):  70%|▋| 21/30 [00:18<00:07,  1.17it/\u001b[A\n",
      "Average Metric: 9.583333333333334 / 22  (43.6):  73%|▋| 22/30 [00:18<00:06,  1.17it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.333333333333334 / 23  (44.9):  73%|▋| 22/30 [00:19<00:06,  1.17it\u001b[A\n",
      "Average Metric: 10.333333333333334 / 23  (44.9):  77%|▊| 23/30 [00:19<00:05,  1.19it\u001b[A\n",
      "Average Metric: 11.333333333333334 / 24  (47.2):  77%|▊| 23/30 [00:19<00:05,  1.19it\u001b[A\n",
      "Average Metric: 11.333333333333334 / 24  (47.2):  80%|▊| 24/30 [00:19<00:03,  1.53it\u001b[A\n",
      "Average Metric: 11.333333333333334 / 25  (45.3):  80%|▊| 24/30 [00:20<00:03,  1.53it\u001b[A\n",
      "Average Metric: 11.333333333333334 / 25  (45.3):  83%|▊| 25/30 [00:20<00:03,  1.54it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.333333333333334 / 26  (47.4):  83%|▊| 25/30 [00:21<00:03,  1.54it\u001b[A\n",
      "Average Metric: 12.333333333333334 / 26  (47.4):  87%|▊| 26/30 [00:21<00:02,  1.48it\u001b[A\n",
      "Average Metric: 13.333333333333334 / 27  (49.4):  87%|▊| 26/30 [00:22<00:02,  1.48it\u001b[A\n",
      "Average Metric: 13.333333333333334 / 27  (49.4):  90%|▉| 27/30 [00:22<00:02,  1.19it\u001b[A\n",
      "Average Metric: 13.333333333333334 / 28  (47.6):  90%|▉| 27/30 [00:24<00:02,  1.19it\u001b[A\n",
      "Average Metric: 13.333333333333334 / 28  (47.6):  93%|▉| 28/30 [00:24<00:02,  1.23s/\u001b[A\n",
      "Average Metric: 13.833333333333334 / 29  (47.7):  93%|▉| 28/30 [00:26<00:02,  1.23s/\u001b[A\n",
      "Average Metric: 13.833333333333334 / 29  (47.7):  97%|▉| 29/30 [00:26<00:01,  1.46s/\u001b[A\n",
      "Average Metric: 14.833333333333334 / 30  (49.4):  97%|▉| 29/30 [00:27<00:01,  1.46s/\u001b[A\n",
      "Average Metric: 14.833333333333334 / 30  (49.4): 100%|█| 30/30 [00:27<00:00,  1.08it\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.833333333333334 / 30  (49.4%)\n",
      "Score: 49.44 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.8316666666666668\n",
      "Average of max per entry across top 5 scores: 0.9333333333333333\n",
      "Average of max per entry across top 8 scores: 0.95\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:32,  1.11s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:32,  1.18s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:34,  1.27s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:04<00:31,  1.22s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:06<00:34,  1.39s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:07<00:29,  1.22s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:08<00:28,  1.22s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:09<00:27,  1.26s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:11<00:25,  1.23s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 10 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:03<01:42,  3.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:06<01:42,  3.52s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:06<01:32,  3.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:09<01:32,  3.29s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:09<01:18,  2.92s/it]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):  10%|█▌             | 3/30 [00:10<01:18,  2.92s/it]\u001b[A\n",
      "Average Metric: 1.0 / 4  (25.0):  13%|██             | 4/30 [00:10<00:57,  2.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.6666666666666665 / 5  (33.3):  13%|▏| 4/30 [00:20<00:57,  2.22s/it\u001b[A\n",
      "Average Metric: 1.6666666666666665 / 5  (33.3):  17%|▏| 5/30 [00:20<02:07,  5.10s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.4166666666666665 / 6  (40.3):  17%|▏| 5/30 [00:22<02:07,  5.10s/it\u001b[A\n",
      "Average Metric: 2.4166666666666665 / 6  (40.3):  20%|▏| 6/30 [00:22<01:35,  3.97s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.4166666666666665 / 7  (34.5):  20%|▏| 6/30 [00:24<01:35,  3.97s/it\u001b[A\n",
      "Average Metric: 2.4166666666666665 / 7  (34.5):  23%|▏| 7/30 [00:24<01:16,  3.33s/it\u001b[A\n",
      "Average Metric: 2.8166666666666664 / 8  (35.2):  23%|▏| 7/30 [00:24<01:16,  3.33s/it\u001b[A\n",
      "Average Metric: 2.8166666666666664 / 8  (35.2):  27%|▎| 8/30 [00:24<00:52,  2.39s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 8.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.15 / 9  (35.0):  27%|███▋          | 8/30 [00:33<00:52,  2.39s/it]\u001b[A\n",
      "Average Metric: 3.15 / 9  (35.0):  30%|████▏         | 9/30 [00:33<01:29,  4.26s/it]\u001b[A\n",
      "Average Metric: 3.4833333333333334 / 10  (34.8):  30%|▎| 9/30 [00:34<01:29,  4.26s/i\u001b[A\n",
      "Average Metric: 3.4833333333333334 / 10  (34.8):  33%|▎| 10/30 [00:34<01:06,  3.32s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.783333333333333 / 11  (34.4):  33%|▎| 10/30 [00:38<01:06,  3.32s/i\u001b[A\n",
      "Average Metric: 3.783333333333333 / 11  (34.4):  37%|▎| 11/30 [00:38<01:06,  3.51s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 10.7 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.783333333333333 / 12  (39.9):  37%|▎| 11/30 [00:42<01:06,  3.51s/i\u001b[A\n",
      "Average Metric: 4.783333333333333 / 12  (39.9):  40%|▍| 12/30 [00:42<01:06,  3.68s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.069047619047619 / 13  (39.0):  40%|▍| 12/30 [00:45<01:06,  3.68s/i\u001b[A\n",
      "Average Metric: 5.069047619047619 / 13  (39.0):  43%|▍| 13/30 [00:45<01:02,  3.68s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.069047619047619 / 14  (43.4):  43%|▍| 13/30 [00:48<01:02,  3.68s/i\u001b[A\n",
      "Average Metric: 6.069047619047619 / 14  (43.4):  47%|▍| 14/30 [00:48<00:52,  3.25s/i\u001b[A\n",
      "Average Metric: 6.735714285714286 / 15  (44.9):  47%|▍| 14/30 [00:48<00:52,  3.25s/i\u001b[A\n",
      "Average Metric: 6.735714285714286 / 15  (44.9):  50%|▌| 15/30 [00:48<00:34,  2.33s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.735714285714286 / 16  (42.1):  50%|▌| 15/30 [00:51<00:34,  2.33s/i\u001b[A\n",
      "Average Metric: 6.735714285714286 / 16  (42.1):  53%|▌| 16/30 [00:51<00:36,  2.60s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 42.6 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.735714285714286 / 17  (39.6):  53%|▌| 16/30 [00:54<00:36,  2.60s/i\u001b[A\n",
      "Average Metric: 6.735714285714286 / 17  (39.6):  57%|▌| 17/30 [00:54<00:35,  2.72s/i\u001b[A\n",
      "Average Metric: 6.735714285714286 / 18  (37.4):  57%|▌| 17/30 [00:55<00:35,  2.72s/i\u001b[A\n",
      "Average Metric: 6.735714285714286 / 18  (37.4):  60%|▌| 18/30 [00:55<00:26,  2.20s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.069047619047619 / 19  (37.2):  60%|▌| 18/30 [00:57<00:26,  2.20s/i\u001b[A\n",
      "Average Metric: 7.069047619047619 / 19  (37.2):  63%|▋| 19/30 [00:57<00:24,  2.24s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 9.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.069047619047619 / 20  (35.3):  63%|▋| 19/30 [01:02<00:24,  2.24s/i\u001b[A\n",
      "Average Metric: 7.069047619047619 / 20  (35.3):  67%|▋| 20/30 [01:02<00:28,  2.85s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 26.5 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.06904761904762 / 21  (38.4):  67%|▋| 20/30 [01:03<00:28,  2.85s/it\u001b[A\n",
      "Average Metric: 8.06904761904762 / 21  (38.4):  70%|▋| 21/30 [01:03<00:22,  2.51s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.06904761904762 / 22  (41.2):  70%|▋| 21/30 [01:07<00:22,  2.51s/it\u001b[A\n",
      "Average Metric: 9.06904761904762 / 22  (41.2):  73%|▋| 22/30 [01:07<00:21,  2.69s/it\u001b[A\n",
      "Average Metric: 9.56904761904762 / 23  (41.6):  73%|▋| 22/30 [01:07<00:21,  2.69s/it\u001b[A\n",
      "Average Metric: 9.56904761904762 / 23  (41.6):  77%|▊| 23/30 [01:07<00:14,  2.03s/it\u001b[A\n",
      "Average Metric: 10.56904761904762 / 24  (44.0):  77%|▊| 23/30 [01:12<00:14,  2.03s/i\u001b[A\n",
      "Average Metric: 10.56904761904762 / 24  (44.0):  80%|▊| 24/30 [01:12<00:17,  2.96s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.36904761904762 / 25  (45.5):  80%|▊| 24/30 [01:15<00:17,  2.96s/i\u001b[A\n",
      "Average Metric: 11.36904761904762 / 25  (45.5):  83%|▊| 25/30 [01:15<00:14,  2.97s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.36904761904762 / 26  (43.7):  83%|▊| 25/30 [01:17<00:14,  2.97s/i\u001b[A\n",
      "Average Metric: 11.36904761904762 / 26  (43.7):  87%|▊| 26/30 [01:17<00:10,  2.70s/i\u001b[A\n",
      "Average Metric: 11.56904761904762 / 27  (42.8):  87%|▊| 26/30 [01:20<00:10,  2.70s/i\u001b[A\n",
      "Average Metric: 11.56904761904762 / 27  (42.8):  90%|▉| 27/30 [01:20<00:08,  2.86s/i\u001b[A\n",
      "Average Metric: 12.56904761904762 / 28  (44.9):  90%|▉| 27/30 [01:24<00:08,  2.86s/i\u001b[A\n",
      "Average Metric: 12.56904761904762 / 28  (44.9):  93%|▉| 28/30 [01:24<00:06,  3.11s/i\u001b[A\n",
      "Average Metric: 13.31904761904762 / 29  (45.9):  93%|▉| 28/30 [01:42<00:06,  3.11s/i\u001b[A\n",
      "Average Metric: 13.31904761904762 / 29  (45.9):  97%|▉| 29/30 [01:42<00:07,  7.67s/i\u001b[A\n",
      "Average Metric: 13.985714285714286 / 30  (46.6):  97%|▉| 29/30 [01:44<00:07,  7.67s/\u001b[A\n",
      "Average Metric: 13.985714285714286 / 30  (46.6): 100%|█| 30/30 [01:44<00:00,  3.47s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.985714285714286 / 30  (46.6%)\n",
      "Score: 46.62 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.8316666666666668\n",
      "Average of max per entry across top 5 scores: 0.9333333333333333\n",
      "Average of max per entry across top 8 scores: 0.95\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:04<01:59,  4.13s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:05<01:02,  2.23s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:07<01:02,  2.31s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:08<00:46,  1.77s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:09<00:38,  1.55s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:10<00:30,  1.29s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:11<00:27,  1.21s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:12<00:26,  1.22s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:13<00:25,  1.20s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:18<00:42,  2.14s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:19<00:36,  1.91s/it]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:20<00:30,  1.70s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:07<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:07<03:36,  7.48s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:08<03:36,  7.48s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:08<01:49,  3.92s/it]\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   7%| | 2/30 [00:11<01:49,  3.92s/it\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):  10%| | 3/30 [00:11<01:25,  3.18s/it\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 4  (45.8):  10%| | 3/30 [00:11<01:25,  3.18s/it\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):  13%|▏| 4/30 [00:11<01:22,  3.18s/it\u001b[A\n",
      "Average Metric: 1.8333333333333333 / 5  (36.7):  17%|▏| 5/30 [00:11<00:37,  1.49s/it\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 6  (37.2):  17%|▏| 5/30 [00:15<00:37,  1.49s/it\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 6  (37.2):  20%|▏| 6/30 [00:15<00:53,  2.22s/it\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):  20%|▏| 6/30 [00:16<00:53,  2.22s/it\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 7  (31.9):  23%|▏| 7/30 [00:16<00:38,  1.68s/it\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 8  (27.9):  23%|▏| 7/30 [00:19<00:38,  1.68s/it\u001b[A\n",
      "Average Metric: 2.2333333333333334 / 8  (27.9):  27%|▎| 8/30 [00:19<00:46,  2.12s/it\u001b[A\n",
      "Average Metric: 2.566666666666667 / 9  (28.5):  27%|▎| 8/30 [00:23<00:46,  2.12s/it]\u001b[A\n",
      "Average Metric: 2.566666666666667 / 9  (28.5):  30%|▎| 9/30 [00:23<01:00,  2.88s/it]\u001b[A\n",
      "Average Metric: 3.066666666666667 / 10  (30.7):  30%|▎| 9/30 [00:24<01:00,  2.88s/it\u001b[A\n",
      "Average Metric: 3.066666666666667 / 10  (30.7):  33%|▎| 10/30 [00:24<00:42,  2.13s/i\u001b[A\n",
      "Average Metric: 3.316666666666667 / 11  (30.2):  33%|▎| 10/30 [00:27<00:42,  2.13s/i\u001b[A\n",
      "Average Metric: 3.316666666666667 / 11  (30.2):  37%|▎| 11/30 [00:27<00:45,  2.39s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.316666666666666 / 12  (36.0):  37%|▎| 11/30 [00:29<00:45,  2.39s/i\u001b[A\n",
      "Average Metric: 4.316666666666666 / 12  (36.0):  40%|▍| 12/30 [00:29<00:40,  2.26s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.941666666666666 / 13  (38.0):  40%|▍| 12/30 [00:40<00:40,  2.26s/i\u001b[A\n",
      "Average Metric: 4.941666666666666 / 13  (38.0):  43%|▍| 13/30 [00:40<01:25,  5.02s/i\u001b[A\n",
      "Average Metric: 5.941666666666666 / 14  (42.4):  43%|▍| 13/30 [00:41<01:25,  5.02s/i\u001b[A\n",
      "Average Metric: 5.941666666666666 / 14  (42.4):  47%|▍| 14/30 [00:41<01:00,  3.81s/i\u001b[A\n",
      "Average Metric: 6.066666666666666 / 15  (40.4):  47%|▍| 14/30 [00:41<01:00,  3.81s/i\u001b[A\n",
      "Average Metric: 6.066666666666666 / 15  (40.4):  50%|▌| 15/30 [00:41<00:40,  2.70s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.3999999999999995 / 16  (40.0):  50%|▌| 15/30 [00:43<00:40,  2.70s/\u001b[A\n",
      "Average Metric: 6.3999999999999995 / 16  (40.0):  53%|▌| 16/30 [00:43<00:34,  2.47s/\u001b[A\n",
      "Average Metric: 6.8999999999999995 / 17  (40.6):  53%|▌| 16/30 [00:45<00:34,  2.47s/\u001b[A\n",
      "Average Metric: 6.8999999999999995 / 17  (40.6):  57%|▌| 17/30 [00:45<00:30,  2.35s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.8999999999999995 / 18  (43.9):  57%|▌| 17/30 [00:47<00:30,  2.35s/\u001b[A\n",
      "Average Metric: 7.8999999999999995 / 18  (43.9):  60%|▌| 18/30 [00:47<00:27,  2.30s/\u001b[A\n",
      "Average Metric: 7.8999999999999995 / 19  (41.6):  60%|▌| 18/30 [00:48<00:27,  2.30s/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[A\n",
      "Average Metric: 7.8999999999999995 / 19  (41.6):  63%|▋| 19/30 [00:48<00:19,  1.74s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 27.0 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.8999999999999995 / 20  (39.5):  63%|▋| 19/30 [00:54<00:19,  1.74s/\u001b[A\n",
      "Average Metric: 7.8999999999999995 / 20  (39.5):  67%|▋| 20/30 [00:54<00:31,  3.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.8999999999999995 / 21  (37.6):  67%|▋| 20/30 [01:01<00:31,  3.17s/\u001b[A\n",
      "Average Metric: 7.8999999999999995 / 21  (37.6):  70%|▋| 21/30 [01:01<00:37,  4.19s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.233333333333333 / 22  (37.4):  70%|▋| 21/30 [01:02<00:37,  4.19s/i\u001b[A\n",
      "Average Metric: 8.233333333333333 / 22  (37.4):  73%|▋| 22/30 [01:02<00:25,  3.22s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.233333333333333 / 23  (40.1):  73%|▋| 22/30 [01:05<00:25,  3.22s/i\u001b[A\n",
      "Average Metric: 9.233333333333333 / 23  (40.1):  77%|▊| 23/30 [01:05<00:21,  3.06s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.983333333333333 / 24  (41.6):  77%|▊| 23/30 [01:07<00:21,  3.06s/i\u001b[A\n",
      "Average Metric: 9.983333333333333 / 24  (41.6):  80%|▊| 24/30 [01:07<00:18,  3.02s/i\u001b[A\n",
      "Average Metric: 10.649999999999999 / 25  (42.6):  80%|▊| 24/30 [01:09<00:18,  3.02s/\u001b[A\n",
      "Average Metric: 10.649999999999999 / 25  (42.6):  83%|▊| 25/30 [01:09<00:12,  2.53s/\u001b[A\n",
      "Average Metric: 11.149999999999999 / 26  (42.9):  83%|▊| 25/30 [01:11<00:12,  2.53s/\u001b[A\n",
      "Average Metric: 11.149999999999999 / 26  (42.9):  87%|▊| 26/30 [01:11<00:10,  2.51s/\u001b[A\n",
      "Average Metric: 12.149999999999999 / 27  (45.0):  87%|▊| 26/30 [01:12<00:10,  2.51s/\u001b[A\n",
      "Average Metric: 12.149999999999999 / 27  (45.0):  90%|▉| 27/30 [01:12<00:05,  1.98s/\u001b[A\n",
      "Average Metric: 13.149999999999999 / 28  (47.0):  90%|▉| 27/30 [01:15<00:05,  1.98s/\u001b[A\n",
      "Average Metric: 13.149999999999999 / 28  (47.0):  93%|▉| 28/30 [01:15<00:04,  2.27s/\u001b[A\n",
      "Average Metric: 14.149999999999999 / 29  (48.8):  93%|▉| 28/30 [01:18<00:04,  2.27s/\u001b[A\n",
      "Average Metric: 14.149999999999999 / 29  (48.8):  97%|▉| 29/30 [01:18<00:02,  2.62s/\u001b[A\n",
      "Average Metric: 14.483333333333333 / 30  (48.3):  97%|▉| 29/30 [01:28<00:02,  2.62s/\u001b[A\n",
      "Average Metric: 14.483333333333333 / 30  (48.3): 100%|█| 30/30 [01:28<00:00,  2.94s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 14.483333333333333 / 30  (48.3%)\n",
      "Score: 48.28 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.8316666666666668\n",
      "Average of max per entry across top 5 scores: 0.9333333333333333\n",
      "Average of max per entry across top 8 scores: 0.95\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:42,  1.47s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:33,  1.19s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:30,  1.11s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:04<00:28,  1.08s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:05<00:26,  1.04s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:06<00:27,  1.16s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:08<00:28,  1.26s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:09<00:25,  1.18s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:10<00:27,  1.29s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:12<00:27,  1.36s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:13<00:24,  1.31s/it]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:14<00:22,  1.22s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 13 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:33,  3.22s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:05<01:33,  3.22s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:05<01:09,  2.49s/it]\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 3  (38.9):   7%| | 2/30 [00:09<01:09,  2.49s/it\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 3  (38.9):  10%| | 3/30 [00:09<01:26,  3.19s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.4999999999999998 / 4  (37.5):  10%| | 3/30 [00:10<01:26,  3.19s/it\u001b[A\n",
      "Average Metric: 1.4999999999999998 / 4  (37.5):  13%|▏| 4/30 [00:10<01:01,  2.37s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.4999999999999998 / 5  (30.0):  13%|▏| 4/30 [00:15<01:01,  2.37s/it\u001b[A\n",
      "Average Metric: 1.4999999999999998 / 5  (30.0):  17%|▏| 5/30 [00:15<01:25,  3.41s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.9 / 6  (31.7):  17%|██▌            | 5/30 [00:20<01:25,  3.41s/it]\u001b[A\n",
      "Average Metric: 1.9 / 6  (31.7):  20%|███            | 6/30 [00:20<01:36,  4.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.4 / 7  (34.3):  20%|███            | 6/30 [00:24<01:36,  4.01s/it]\u001b[A\n",
      "Average Metric: 2.4 / 7  (34.3):  23%|███▌           | 7/30 [00:24<01:28,  3.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 12.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.4 / 8  (30.0):  23%|███▌           | 7/30 [00:30<01:28,  3.86s/it]\u001b[A\n",
      "Average Metric: 2.4 / 8  (30.0):  27%|████           | 8/30 [00:30<01:40,  4.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.8 / 9  (31.1):  27%|████           | 8/30 [00:34<01:40,  4.59s/it]\u001b[A\n",
      "Average Metric: 2.8 / 9  (31.1):  30%|████▌          | 9/30 [00:34<01:30,  4.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 5.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.1333333333333333 / 10  (31.3):  30%|▎| 9/30 [00:38<01:30,  4.33s/i\u001b[A\n",
      "Average Metric: 3.1333333333333333 / 10  (31.3):  33%|▎| 10/30 [00:38<01:25,  4.27s/\u001b[A\n",
      "Average Metric: 4.133333333333333 / 11  (37.6):  33%|▎| 10/30 [00:38<01:25,  4.27s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.883333333333333 / 12  (40.7):  37%|▎| 11/30 [00:45<01:21,  4.27s/i\u001b[A\n",
      "Average Metric: 4.883333333333333 / 12  (40.7):  40%|▍| 12/30 [00:45<01:09,  3.85s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.883333333333333 / 13  (45.3):  40%|▍| 12/30 [00:51<01:09,  3.85s/i\u001b[A\n",
      "Average Metric: 5.883333333333333 / 13  (45.3):  43%|▍| 13/30 [00:51<01:15,  4.43s/i\u001b[A\n",
      "Average Metric: 6.216666666666666 / 14  (44.4):  43%|▍| 13/30 [00:54<01:15,  4.43s/i\u001b[A\n",
      "Average Metric: 6.216666666666666 / 14  (44.4):  47%|▍| 14/30 [00:54<01:06,  4.14s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.216666666666666 / 15  (48.1):  47%|▍| 14/30 [00:55<01:06,  4.14s/i\u001b[A\n",
      "Average Metric: 7.216666666666666 / 15  (48.1):  50%|▌| 15/30 [00:55<00:50,  3.38s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.6 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.216666666666666 / 16  (45.1):  50%|▌| 15/30 [00:59<00:50,  3.38s/i\u001b[A\n",
      "Average Metric: 7.216666666666666 / 16  (45.1):  53%|▌| 16/30 [00:59<00:46,  3.34s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.216666666666665 / 17  (48.3):  53%|▌| 16/30 [01:01<00:46,  3.34s/i\u001b[A\n",
      "Average Metric: 8.216666666666665 / 17  (48.3):  57%|▌| 17/30 [01:01<00:41,  3.16s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 11.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.716666666666665 / 18  (48.4):  57%|▌| 17/30 [01:07<00:41,  3.16s/i\u001b[A\n",
      "Average Metric: 8.716666666666665 / 18  (48.4):  60%|▌| 18/30 [01:07<00:46,  3.85s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.049999999999999 / 19  (47.6):  60%|▌| 18/30 [01:08<00:46,  3.85s/i\u001b[A\n",
      "Average Metric: 9.049999999999999 / 19  (47.6):  63%|▋| 19/30 [01:08<00:32,  2.91s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.549999999999999 / 20  (47.7):  63%|▋| 19/30 [01:16<00:32,  2.91s/i\u001b[A\n",
      "Average Metric: 9.549999999999999 / 20  (47.7):  67%|▋| 20/30 [01:16<00:44,  4.47s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.549999999999999 / 21  (45.5):  67%|▋| 20/30 [01:18<00:44,  4.47s/i\u001b[A\n",
      "Average Metric: 9.549999999999999 / 21  (45.5):  70%|▋| 21/30 [01:18<00:33,  3.70s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 9.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.216666666666665 / 22  (46.4):  70%|▋| 21/30 [01:19<00:33,  3.70s/\u001b[A\n",
      "Average Metric: 10.216666666666665 / 22  (46.4):  73%|▋| 22/30 [01:19<00:23,  2.91s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.4 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.216666666666665 / 23  (48.8):  73%|▋| 22/30 [01:25<00:23,  2.91s/\u001b[A\n",
      "Average Metric: 11.216666666666665 / 23  (48.8):  77%|▊| 23/30 [01:25<00:27,  3.97s/\u001b[A\n",
      "Average Metric: 11.716666666666665 / 24  (48.8):  77%|▊| 23/30 [01:26<00:27,  3.97s/\u001b[A\n",
      "Average Metric: 11.716666666666665 / 24  (48.8):  80%|▊| 24/30 [01:26<00:18,  3.11s/\u001b[A\n",
      "Average Metric: 12.716666666666665 / 25  (50.9):  80%|▊| 24/30 [01:27<00:18,  3.11s/\u001b[A\n",
      "Average Metric: 12.716666666666665 / 25  (50.9):  83%|▊| 25/30 [01:27<00:12,  2.40s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.466666666666665 / 26  (51.8):  83%|▊| 25/30 [01:28<00:12,  2.40s/\u001b[A\n",
      "Average Metric: 13.466666666666665 / 26  (51.8):  87%|▊| 26/30 [01:28<00:08,  2.13s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.466666666666665 / 27  (49.9):  87%|▊| 26/30 [01:32<00:08,  2.13s/\u001b[A\n",
      "Average Metric: 13.466666666666665 / 27  (49.9):  90%|▉| 27/30 [01:32<00:07,  2.40s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.216666666666665 / 28  (50.8):  90%|▉| 27/30 [01:40<00:07,  2.40s/\u001b[A\n",
      "Average Metric: 14.216666666666665 / 28  (50.8):  93%|▉| 28/30 [01:40<00:08,  4.35s/\u001b[A\n",
      "Average Metric: 15.216666666666665 / 29  (52.5):  93%|▉| 28/30 [01:41<00:08,  4.35s/\u001b[A\n",
      "Average Metric: 15.216666666666665 / 29  (52.5):  97%|▉| 29/30 [01:41<00:03,  3.19s/\u001b[A\n",
      "Average Metric: 15.516666666666666 / 30  (51.7):  97%|▉| 29/30 [01:42<00:03,  3.19s/\u001b[A\n",
      "Average Metric: 15.516666666666666 / 30  (51.7): 100%|█| 30/30 [01:42<00:00,  3.40s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.516666666666666 / 30  (51.7%)\n",
      "Score: 51.72 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28, 51.72]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.7977777777777778\n",
      "Average of max per entry across top 5 scores: 0.9016666666666667\n",
      "Average of max per entry across top 8 scores: 0.95\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:42,  1.48s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:38,  1.38s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:04<00:36,  1.34s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:05<00:35,  1.38s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:04<01:57,  4.07s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   3%|▌              | 1/30 [00:04<01:57,  4.07s/it]\u001b[A\n",
      "Average Metric: 1.0 / 2  (50.0):   7%|█              | 2/30 [00:04<00:52,  1.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 3  (33.3):   7%|█              | 2/30 [00:08<00:52,  1.89s/it]\u001b[A\n",
      "Average Metric: 1.0 / 3  (33.3):  10%|█▌             | 3/30 [00:08<01:18,  2.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.3333333333333333 / 4  (33.3):  10%| | 3/30 [00:10<01:18,  2.92s/it\u001b[A\n",
      "Average Metric: 1.3333333333333333 / 4  (33.3):  13%|▏| 4/30 [00:10<01:04,  2.50s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.333333333333333 / 5  (46.7):  13%|▏| 4/30 [00:18<01:04,  2.50s/it]\u001b[A\n",
      "Average Metric: 2.333333333333333 / 5  (46.7):  17%|▏| 5/30 [00:18<01:54,  4.58s/it]\u001b[A\n",
      "Average Metric: 3.333333333333333 / 6  (55.6):  17%|▏| 5/30 [00:20<01:54,  4.58s/it]\u001b[A\n",
      "Average Metric: 3.333333333333333 / 6  (55.6):  20%|▏| 6/30 [00:20<01:26,  3.60s/it]\u001b[A\n",
      "Average Metric: 3.533333333333333 / 7  (50.5):  20%|▏| 6/30 [00:21<01:26,  3.60s/it]\u001b[A\n",
      "Average Metric: 3.533333333333333 / 7  (50.5):  23%|▏| 7/30 [00:21<01:01,  2.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8666666666666667 / 8  (48.3):  23%|▏| 7/30 [00:27<01:01,  2.69s/it\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 8  (48.3):  27%|▎| 8/30 [00:27<01:26,  3.94s/it\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 9  (43.0):  27%|▎| 8/30 [00:29<01:26,  3.94s/it\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 9  (43.0):  30%|▎| 9/30 [00:29<01:07,  3.21s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8666666666666667 / 10  (38.7):  30%|▎| 9/30 [00:33<01:07,  3.21s/i\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 10  (38.7):  33%|▎| 10/30 [00:33<01:06,  3.32s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.2 / 11  (38.2):  33%|████▎        | 10/30 [00:38<01:06,  3.32s/it]\u001b[A\n",
      "Average Metric: 4.2 / 11  (38.2):  37%|████▊        | 11/30 [00:38<01:15,  3.98s/it]\u001b[A\n",
      "Average Metric: 5.2 / 12  (43.3):  37%|████▊        | 11/30 [00:39<01:15,  3.98s/it]\u001b[A\n",
      "Average Metric: 5.2 / 12  (43.3):  40%|█████▏       | 12/30 [00:39<00:54,  3.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.3 / 13  (40.8):  40%|█████▏       | 12/30 [00:46<00:54,  3.04s/it]\u001b[A\n",
      "Average Metric: 5.3 / 13  (40.8):  43%|█████▋       | 13/30 [00:46<01:14,  4.37s/it]\u001b[A\n",
      "Average Metric: 6.3 / 14  (45.0):  43%|█████▋       | 13/30 [00:47<01:14,  4.37s/it]\u001b[A\n",
      "Average Metric: 6.3 / 14  (45.0):  47%|██████       | 14/30 [00:47<00:52,  3.25s/it]\u001b[A\n",
      "Average Metric: 6.663636363636363 / 15  (44.4):  47%|▍| 14/30 [00:48<00:52,  3.25s/i\u001b[A\n",
      "Average Metric: 6.663636363636363 / 15  (44.4):  50%|▌| 15/30 [00:48<00:37,  2.49s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.663636363636363 / 16  (41.6):  50%|▌| 15/30 [00:51<00:37,  2.49s/i\u001b[A\n",
      "Average Metric: 6.663636363636363 / 16  (41.6):  53%|▌| 16/30 [00:51<00:37,  2.70s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.663636363636363 / 17  (45.1):  53%|▌| 16/30 [00:54<00:37,  2.70s/i\u001b[A\n",
      "Average Metric: 7.663636363636363 / 17  (45.1):  57%|▌| 17/30 [00:54<00:35,  2.77s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.413636363636364 / 18  (46.7):  57%|▌| 17/30 [00:56<00:35,  2.77s/i\u001b[A\n",
      "Average Metric: 8.413636363636364 / 18  (46.7):  60%|▌| 18/30 [00:56<00:30,  2.53s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.413636363636364 / 19  (49.5):  60%|▌| 18/30 [00:57<00:30,  2.53s/i\u001b[A\n",
      "Average Metric: 9.413636363636364 / 19  (49.5):  63%|▋| 19/30 [00:57<00:22,  2.09s/i\u001b[A\n",
      "Average Metric: 9.413636363636364 / 20  (47.1):  63%|▋| 19/30 [00:58<00:22,  2.09s/i\u001b[A\n",
      "Average Metric: 9.413636363636364 / 20  (47.1):  67%|▋| 20/30 [00:58<00:17,  1.73s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.913636363636364 / 21  (47.2):  67%|▋| 20/30 [01:00<00:17,  1.73s/i\u001b[A\n",
      "Average Metric: 9.913636363636364 / 21  (47.2):  70%|▋| 21/30 [01:00<00:16,  1.80s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.413636363636364 / 22  (47.3):  70%|▋| 21/30 [01:02<00:16,  1.80s/\u001b[A\n",
      "Average Metric: 10.413636363636364 / 22  (47.3):  73%|▋| 22/30 [01:02<00:14,  1.87s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.913636363636364 / 23  (47.5):  73%|▋| 22/30 [01:05<00:14,  1.87s/\u001b[A\n",
      "Average Metric: 10.913636363636364 / 23  (47.5):  77%|▊| 23/30 [01:05<00:16,  2.43s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.913636363636364 / 24  (49.6):  77%|▊| 23/30 [01:08<00:16,  2.43s/\u001b[A\n",
      "Average Metric: 11.913636363636364 / 24  (49.6):  80%|▊| 24/30 [01:08<00:15,  2.59s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.913636363636364 / 25  (51.7):  80%|▊| 24/30 [01:11<00:15,  2.59s/\u001b[A\n",
      "Average Metric: 12.913636363636364 / 25  (51.7):  83%|▊| 25/30 [01:11<00:12,  2.43s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 13.913636363636364 / 26  (53.5):  83%|▊| 25/30 [01:11<00:12,  2.43s/\u001b[A\n",
      "Average Metric: 13.913636363636364 / 26  (53.5):  87%|▊| 26/30 [01:11<00:07,  1.91s/\u001b[A\n",
      "Average Metric: 14.663636363636364 / 27  (54.3):  87%|▊| 26/30 [01:14<00:07,  1.91s/\u001b[A\n",
      "Average Metric: 14.663636363636364 / 27  (54.3):  90%|▉| 27/30 [01:14<00:06,  2.05s/\u001b[A\n",
      "Average Metric: 14.663636363636364 / 28  (52.4):  90%|▉| 27/30 [01:15<00:06,  2.05s/\u001b[A\n",
      "Average Metric: 14.663636363636364 / 28  (52.4):  93%|▉| 28/30 [01:15<00:03,  1.89s/\u001b[A\n",
      "Average Metric: 14.663636363636364 / 29  (50.6):  93%|▉| 28/30 [01:16<00:03,  1.89s/\u001b[A\n",
      "Average Metric: 14.663636363636364 / 29  (50.6):  97%|▉| 29/30 [01:16<00:01,  1.47s/\u001b[A\n",
      "Average Metric: 15.413636363636364 / 30  (51.4):  97%|▉| 29/30 [01:20<00:01,  1.47s/\u001b[A\n",
      "Average Metric: 15.413636363636364 / 30  (51.4): 100%|█| 30/30 [01:20<00:00,  2.70s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.413636363636364 / 30  (51.4%)\n",
      "Score: 51.38 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28, 51.72, 51.38]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.7977777777777778\n",
      "Average of max per entry across top 5 scores: 0.9183333333333333\n",
      "Average of max per entry across top 8 scores: 0.95\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:32,  1.13s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:03<00:54,  1.94s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:04<00:41,  1.54s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:05<00:35,  1.35s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:07<00:34,  1.37s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:08<00:30,  1.28s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:09<00:26,  1.16s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:11<00:30,  1.38s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:12<00:28,  1.34s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:13<00:27,  1.37s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:14<00:24,  1.30s/it]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:16<00:27,  1.51s/it]\u001b[A\n",
      " 43%|████████████████████▎                          | 13/30 [00:17<00:23,  1.37s/it]\u001b[A\n",
      " 47%|█████████████████████▉                         | 14/30 [00:19<00:22,  1.42s/it]\u001b[A\n",
      " 50%|███████████████████████▌                       | 15/30 [00:21<00:22,  1.49s/it]\u001b[A\n",
      " 53%|█████████████████████████                      | 16/30 [00:21<00:19,  1.37s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 17 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:03<01:33,  3.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:09<01:33,  3.21s/it]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   7%|▉             | 2/30 [00:09<02:20,  5.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:12<02:20,  5.01s/it]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):  10%|█▌             | 3/30 [00:12<01:44,  3.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.3333333333333335 / 4  (58.3):  10%| | 3/30 [00:16<01:44,  3.88s/it\u001b[A\n",
      "Average Metric: 2.3333333333333335 / 4  (58.3):  13%|▏| 4/30 [00:16<01:47,  4.13s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.8333333333333335 / 5  (56.7):  13%|▏| 4/30 [00:17<01:47,  4.13s/it\u001b[A\n",
      "Average Metric: 2.8333333333333335 / 5  (56.7):  17%|▏| 5/30 [00:17<01:15,  3.04s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.8333333333333335 / 6  (47.2):  17%|▏| 5/30 [00:18<01:15,  3.04s/it\u001b[A\n",
      "Average Metric: 2.8333333333333335 / 6  (47.2):  20%|▏| 6/30 [00:18<00:53,  2.21s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.5 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.5 / 7  (50.0):  20%|███            | 6/30 [00:28<00:53,  2.21s/it]\u001b[A\n",
      "Average Metric: 3.5 / 7  (50.0):  23%|███▌           | 7/30 [00:28<01:51,  4.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.5 / 8  (43.8):  23%|███▌           | 7/30 [00:32<01:51,  4.87s/it]\u001b[A\n",
      "Average Metric: 3.5 / 8  (43.8):  27%|████           | 8/30 [00:32<01:43,  4.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 15.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.8333333333333335 / 9  (42.6):  27%|▎| 8/30 [00:33<01:43,  4.69s/it\u001b[A\n",
      "Average Metric: 3.8333333333333335 / 9  (42.6):  30%|▎| 9/30 [00:33<01:11,  3.39s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 23.4 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.833333333333334 / 10  (48.3):  30%|▎| 9/30 [00:45<01:11,  3.39s/it\u001b[A\n",
      "Average Metric: 4.833333333333334 / 10  (48.3):  33%|▎| 10/30 [00:45<02:00,  6.03s/i\u001b[A\n",
      "Average Metric: 5.196969696969697 / 11  (47.2):  33%|▎| 10/30 [00:47<02:00,  6.03s/i\u001b[A\n",
      "Average Metric: 5.196969696969697 / 11  (47.2):  37%|▎| 11/30 [00:47<01:34,  4.98s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.446969696969697 / 12  (45.4):  37%|▎| 11/30 [00:50<01:34,  4.98s/i\u001b[A\n",
      "Average Metric: 5.446969696969697 / 12  (45.4):  40%|▍| 12/30 [00:50<01:15,  4.17s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.78030303030303 / 13  (44.5):  40%|▍| 12/30 [01:02<01:15,  4.17s/it\u001b[A\n",
      "Average Metric: 5.78030303030303 / 13  (44.5):  43%|▍| 13/30 [01:02<01:54,  6.74s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.03030303030303 / 14  (43.1):  43%|▍| 13/30 [01:05<01:54,  6.74s/it\u001b[A\n",
      "Average Metric: 6.03030303030303 / 14  (43.1):  47%|▍| 14/30 [01:05<01:26,  5.43s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.03030303030303 / 15  (46.9):  47%|▍| 14/30 [01:09<01:26,  5.43s/it\u001b[A\n",
      "Average Metric: 7.03030303030303 / 15  (46.9):  50%|▌| 15/30 [01:09<01:16,  5.08s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.363636363636363 / 16  (46.0):  50%|▌| 15/30 [01:16<01:16,  5.08s/i\u001b[A\n",
      "Average Metric: 7.363636363636363 / 16  (46.0):  53%|▌| 16/30 [01:16<01:20,  5.74s/i\u001b[A\n",
      "Average Metric: 8.363636363636363 / 17  (49.2):  53%|▌| 16/30 [01:17<01:20,  5.74s/i\u001b[A\n",
      "Average Metric: 8.363636363636363 / 17  (49.2):  57%|▌| 17/30 [01:17<00:55,  4.25s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.696969696969697 / 18  (48.3):  57%|▌| 17/30 [01:20<00:55,  4.25s/i\u001b[A\n",
      "Average Metric: 8.696969696969697 / 18  (48.3):  60%|▌| 18/30 [01:20<00:44,  3.71s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.696969696969697 / 19  (45.8):  60%|▌| 18/30 [01:28<00:44,  3.71s/i\u001b[A\n",
      "Average Metric: 8.696969696969697 / 19  (45.8):  63%|▋| 19/30 [01:28<00:54,  5.00s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.030303030303031 / 20  (45.2):  63%|▋| 19/30 [01:30<00:54,  5.00s/i\u001b[A\n",
      "Average Metric: 9.030303030303031 / 20  (45.2):  67%|▋| 20/30 [01:30<00:41,  4.18s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.030303030303031 / 21  (47.8):  67%|▋| 20/30 [01:34<00:41,  4.18s/\u001b[A\n",
      "Average Metric: 10.030303030303031 / 21  (47.8):  70%|▋| 21/30 [01:34<00:36,  4.05s/\u001b[A\n",
      "Average Metric: 11.030303030303031 / 22  (50.1):  70%|▋| 21/30 [01:34<00:36,  4.05s/\u001b[A\n",
      "Average Metric: 11.030303030303031 / 22  (50.1):  73%|▋| 22/30 [01:34<00:24,  3.04s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.7 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.530303030303031 / 23  (50.1):  73%|▋| 22/30 [01:38<00:24,  3.04s/\u001b[A\n",
      "Average Metric: 11.530303030303031 / 23  (50.1):  77%|▊| 23/30 [01:38<00:22,  3.24s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.530303030303031 / 24  (48.0):  77%|▊| 23/30 [01:40<00:22,  3.24s/\u001b[A\n",
      "Average Metric: 11.530303030303031 / 24  (48.0):  80%|▊| 24/30 [01:40<00:17,  2.99s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.530303030303031 / 25  (46.1):  80%|▊| 24/30 [01:43<00:17,  2.99s/\u001b[A\n",
      "Average Metric: 11.530303030303031 / 25  (46.1):  83%|▊| 25/30 [01:43<00:14,  2.85s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.530303030303031 / 26  (48.2):  83%|▊| 25/30 [01:46<00:14,  2.85s/\u001b[A\n",
      "Average Metric: 12.530303030303031 / 26  (48.2):  87%|▊| 26/30 [01:46<00:11,  2.94s/\u001b[A\n",
      "Average Metric: 13.530303030303031 / 27  (50.1):  87%|▊| 26/30 [01:48<00:11,  2.94s/\u001b[A\n",
      "Average Metric: 13.530303030303031 / 27  (50.1):  90%|▉| 27/30 [01:48<00:07,  2.51s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 21.6 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 14.530303030303031 / 28  (51.9):  90%|▉| 27/30 [01:51<00:07,  2.51s/\u001b[A\n",
      "Average Metric: 14.530303030303031 / 28  (51.9):  93%|▉| 28/30 [01:51<00:05,  2.75s/\u001b[A\n",
      "Average Metric: 15.330303030303032 / 29  (52.9):  93%|▉| 28/30 [01:55<00:05,  2.75s/\u001b[A\n",
      "Average Metric: 15.330303030303032 / 29  (52.9):  97%|▉| 29/30 [01:55<00:03,  3.22s/\u001b[A\n",
      "Average Metric: 15.530303030303031 / 30  (51.8):  97%|▉| 29/30 [02:19<00:03,  3.22s/\u001b[A\n",
      "Average Metric: 15.530303030303031 / 30  (51.8): 100%|█| 30/30 [02:19<00:00,  4.67s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.530303030303031 / 30  (51.8%)\n",
      "Score: 51.77 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28, 51.72, 51.38, 51.77]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.7858333333333333\n",
      "Average of max per entry across top 5 scores: 0.9072222222222223\n",
      "Average of max per entry across top 8 scores: 0.9416666666666667\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:30,  1.04s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:01<00:25,  1.09it/s]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:02<00:26,  1.03it/s]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:03<00:26,  1.00s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:05<00:25,  1.03s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:06<00:27,  1.14s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:07<00:25,  1.10s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:08<00:25,  1.16s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:10<00:26,  1.27s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:12<00:29,  1.48s/it]\u001b[A\n",
      " 37%|█████████████████▏                             | 11/30 [00:13<00:25,  1.32s/it]\u001b[A\n",
      " 40%|██████████████████▊                            | 12/30 [00:14<00:22,  1.22s/it]\u001b[A\n",
      " 43%|████████████████████▎                          | 13/30 [00:18<00:36,  2.16s/it]\u001b[A\n",
      " 47%|█████████████████████▉                         | 14/30 [00:22<00:42,  2.66s/it]\u001b[A\n",
      " 50%|███████████████████████▌                       | 15/30 [00:23<00:32,  2.18s/it]\u001b[A\n",
      " 53%|█████████████████████████                      | 16/30 [00:24<00:24,  1.77s/it]\u001b[A\n",
      " 57%|██████████████████████████▋                    | 17/30 [00:26<00:23,  1.80s/it]\u001b[A\n",
      " 60%|████████████████████████████▏                  | 18/30 [00:27<00:21,  1.81s/it]\u001b[A\n",
      " 63%|█████████████████████████████▊                 | 19/30 [00:28<00:16,  1.51s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 20 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   0%|                        | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.0 / 1  (0.0):   3%|▌               | 1/30 [00:03<01:39,  3.43s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:06<01:39,  3.43s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:06<01:32,  3.32s/it]\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):   7%| | 2/30 [00:08<01:32,  3.32s/it\u001b[A\n",
      "Average Metric: 0.8333333333333333 / 3  (27.8):  10%| | 3/30 [00:08<01:12,  2.69s/it\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 4  (29.2):  10%| | 3/30 [00:09<01:12,  2.69s/it\u001b[A\n",
      "Average Metric: 1.1666666666666665 / 4  (29.2):  13%|▏| 4/30 [00:09<00:48,  1.86s/it\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 5  (43.3):  13%|▏| 4/30 [00:10<00:48,  1.86s/it\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 5  (43.3):  17%|▏| 5/30 [00:10<00:37,  1.50s/it\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 6  (36.1):  17%|▏| 5/30 [00:10<00:37,  1.50s/it\u001b[A\n",
      "Average Metric: 2.1666666666666665 / 6  (36.1):  20%|▏| 6/30 [00:10<00:29,  1.23s/it\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 7  (45.2):  20%|▏| 6/30 [00:13<00:29,  1.23s/it\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 7  (45.2):  23%|▏| 7/30 [00:13<00:36,  1.60s/it\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 8  (39.6):  23%|▏| 7/30 [00:18<00:36,  1.60s/it\u001b[A\n",
      "Average Metric: 3.1666666666666665 / 8  (39.6):  27%|▎| 8/30 [00:18<01:00,  2.74s/it\u001b[A\n",
      "Average Metric: 3.5 / 9  (38.9):  27%|████           | 8/30 [00:18<01:00,  2.74s/it]\u001b[A\n",
      "Average Metric: 3.5 / 9  (38.9):  30%|████▌          | 9/30 [00:18<00:43,  2.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.75 / 10  (37.5):  30%|███▉         | 9/30 [00:23<00:43,  2.05s/it]\u001b[A\n",
      "Average Metric: 3.75 / 10  (37.5):  33%|████        | 10/30 [00:23<00:58,  2.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.75 / 11  (43.2):  33%|████        | 10/30 [00:35<00:58,  2.93s/it]\u001b[A\n",
      "Average Metric: 4.75 / 11  (43.2):  37%|████▍       | 11/30 [00:35<01:44,  5.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.75 / 12  (39.6):  37%|████▍       | 11/30 [00:37<01:44,  5.51s/it]\u001b[A\n",
      "Average Metric: 4.75 / 12  (39.6):  40%|████▊       | 12/30 [00:37<01:22,  4.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.15 / 13  (39.6):  40%|████▊       | 12/30 [00:43<01:22,  4.57s/it]\u001b[A\n",
      "Average Metric: 5.15 / 13  (39.6):  43%|█████▏      | 13/30 [00:43<01:22,  4.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.15 / 14  (43.9):  43%|█████▏      | 13/30 [00:43<01:22,  4.86s/it]\u001b[A\n",
      "Average Metric: 6.15 / 14  (43.9):  47%|█████▌      | 14/30 [00:43<00:56,  3.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.15 / 15  (41.0):  47%|█████▌      | 14/30 [00:47<00:56,  3.52s/it]\u001b[A\n",
      "Average Metric: 6.15 / 15  (41.0):  50%|██████      | 15/30 [00:47<00:53,  3.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.4 / 16  (40.0):  50%|██████▌      | 15/30 [00:55<00:53,  3.55s/it]\u001b[A\n",
      "Average Metric: 6.4 / 16  (40.0):  53%|██████▉      | 16/30 [00:55<01:08,  4.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.9 / 17  (40.6):  53%|██████▉      | 16/30 [00:59<01:08,  4.87s/it]\u001b[A\n",
      "Average Metric: 6.9 / 17  (40.6):  57%|███████▎     | 17/30 [00:59<01:00,  4.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.2 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.9 / 18  (38.3):  57%|███████▎     | 17/30 [01:07<01:00,  4.69s/it]\u001b[A\n",
      "Average Metric: 6.9 / 18  (38.3):  60%|███████▊     | 18/30 [01:07<01:09,  5.76s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.15 / 19  (37.6):  60%|███████▏    | 18/30 [01:08<01:09,  5.76s/it]\u001b[A\n",
      "Average Metric: 7.15 / 19  (37.6):  63%|███████▌    | 19/30 [01:08<00:47,  4.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 15.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 10.8 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.816666666666667 / 20  (39.1):  63%|▋| 19/30 [01:15<00:47,  4.32s/i\u001b[A\n",
      "Average Metric: 7.816666666666667 / 20  (39.1):  67%|▋| 20/30 [01:15<00:49,  5.00s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.816666666666667 / 21  (37.2):  67%|▋| 20/30 [01:17<00:49,  5.00s/i\u001b[A\n",
      "Average Metric: 7.816666666666667 / 21  (37.2):  70%|▋| 21/30 [01:17<00:36,  4.08s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.816666666666666 / 22  (40.1):  70%|▋| 21/30 [01:20<00:36,  4.08s/i\u001b[A\n",
      "Average Metric: 8.816666666666666 / 22  (40.1):  73%|▋| 22/30 [01:20<00:32,  4.02s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.316666666666666 / 23  (40.5):  73%|▋| 22/30 [01:23<00:32,  4.02s/i\u001b[A\n",
      "Average Metric: 9.316666666666666 / 23  (40.5):  77%|▊| 23/30 [01:23<00:25,  3.63s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.316666666666666 / 24  (38.8):  77%|▊| 23/30 [01:27<00:25,  3.63s/i\u001b[A\n",
      "Average Metric: 9.316666666666666 / 24  (38.8):  80%|▊| 24/30 [01:27<00:21,  3.65s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.6 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 6.3 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.316666666666666 / 25  (41.3):  80%|▊| 24/30 [01:32<00:21,  3.65s/\u001b[A\n",
      "Average Metric: 10.316666666666666 / 25  (41.3):  83%|▊| 25/30 [01:32<00:20,  4.17s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 18.2 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.316666666666666 / 26  (39.7):  83%|▊| 25/30 [01:34<00:20,  4.17s/\u001b[A\n",
      "Average Metric: 10.316666666666666 / 26  (39.7):  87%|▊| 26/30 [01:34<00:14,  3.60s/\u001b[A\n",
      "Average Metric: 10.816666666666666 / 27  (40.1):  87%|▊| 26/30 [01:37<00:14,  3.60s/\u001b[A\n",
      "Average Metric: 10.816666666666666 / 27  (40.1):  90%|▉| 27/30 [01:37<00:09,  3.28s/\u001b[A\n",
      "Average Metric: 11.816666666666666 / 28  (42.2):  90%|▉| 27/30 [01:40<00:09,  3.28s/\u001b[A\n",
      "Average Metric: 11.816666666666666 / 28  (42.2):  93%|▉| 28/30 [01:40<00:06,  3.34s/\u001b[A\n",
      "Average Metric: 12.15 / 29  (41.9):  93%|██████████▎| 28/30 [01:41<00:06,  3.34s/it]\u001b[A\n",
      "Average Metric: 12.15 / 29  (41.9):  97%|██████████▋| 29/30 [01:41<00:02,  2.51s/it]\u001b[A\n",
      "Average Metric: 12.9 / 30  (43.0):  97%|███████████▌| 29/30 [01:58<00:02,  2.51s/it]\u001b[A\n",
      "Average Metric: 12.9 / 30  (43.0): 100%|████████████| 30/30 [01:58<00:00,  3.94s/it]\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 12.9 / 30  (43.0%)\n",
      "Score: 43.0 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28, 51.72, 51.38, 51.77, 43.0]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.7858333333333333\n",
      "Average of max per entry across top 5 scores: 0.9072222222222223\n",
      "Average of max per entry across top 8 scores: 0.9416666666666667\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:36,  1.27s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:36,  1.32s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:34,  1.26s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:04<00:31,  1.20s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:05<00:28,  1.15s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:07<00:28,  1.17s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:08<00:27,  1.19s/it]\u001b[A\n",
      " 27%|████████████▊                                   | 8/30 [00:09<00:24,  1.14s/it]\u001b[A\n",
      " 30%|██████████████▍                                 | 9/30 [00:10<00:23,  1.10s/it]\u001b[A\n",
      " 33%|███████████████▋                               | 10/30 [00:11<00:22,  1.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 11 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   0%|                       | 0/30 [00:03<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.5 / 1  (50.0):   3%|▌              | 1/30 [00:03<01:48,  3.75s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   3%|▌              | 1/30 [00:04<01:48,  3.75s/it]\u001b[A\n",
      "Average Metric: 0.5 / 2  (25.0):   7%|█              | 2/30 [00:04<00:47,  1.71s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):   7%|█              | 2/30 [00:08<00:47,  1.71s/it]\u001b[A\n",
      "Average Metric: 0.5 / 3  (16.7):  10%|█▌             | 3/30 [00:08<01:17,  2.87s/it]\u001b[A\n",
      "Average Metric: 0.5 / 4  (12.5):  10%|█▌             | 3/30 [00:10<01:17,  2.87s/it]\u001b[A\n",
      "Average Metric: 0.5 / 4  (12.5):  13%|██             | 4/30 [00:10<01:12,  2.80s/it]\u001b[A\n",
      "Average Metric: 1.0 / 5  (20.0):  13%|██             | 4/30 [00:11<01:12,  2.80s/it]\u001b[A\n",
      "Average Metric: 1.0 / 5  (20.0):  17%|██▌            | 5/30 [00:11<00:47,  1.89s/it]\u001b[A\n",
      "Average Metric: 2.0 / 6  (33.3):  17%|██▌            | 5/30 [00:11<00:47,  1.89s/it]\u001b[A\n",
      "Average Metric: 2.0 / 6  (33.3):  20%|███            | 6/30 [00:11<00:31,  1.30s/it]\u001b[A\n",
      "Average Metric: 3.0 / 7  (42.9):  20%|███            | 6/30 [00:14<00:31,  1.30s/it]\u001b[A\n",
      "Average Metric: 3.0 / 7  (42.9):  23%|███▌           | 7/30 [00:14<00:45,  1.98s/it]\u001b[A\n",
      "Average Metric: 3.0 / 8  (37.5):  23%|███▌           | 7/30 [00:15<00:45,  1.98s/it]\u001b[A\n",
      "Average Metric: 3.0 / 8  (37.5):  27%|████           | 8/30 [00:15<00:34,  1.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0 / 9  (33.3):  27%|████           | 8/30 [00:22<00:34,  1.57s/it]\u001b[A\n",
      "Average Metric: 3.0 / 9  (33.3):  30%|████▌          | 9/30 [00:22<01:07,  3.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0 / 10  (30.0):  30%|████▏         | 9/30 [00:25<01:07,  3.24s/it]\u001b[A\n",
      "Average Metric: 3.0 / 10  (30.0):  33%|████▎        | 10/30 [00:25<01:04,  3.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.0 / 11  (36.4):  33%|████▎        | 10/30 [00:26<01:04,  3.20s/it]\u001b[A\n",
      "Average Metric: 4.0 / 11  (36.4):  37%|████▊        | 11/30 [00:26<00:47,  2.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.0 / 12  (33.3):  37%|████▊        | 11/30 [00:28<00:47,  2.49s/it]\u001b[A\n",
      "Average Metric: 4.0 / 12  (33.3):  40%|█████▏       | 12/30 [00:28<00:44,  2.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.666666666666667 / 13  (35.9):  40%|▍| 12/30 [00:33<00:44,  2.49s/i\u001b[A\n",
      "Average Metric: 4.666666666666667 / 13  (35.9):  43%|▍| 13/30 [00:33<00:51,  3.02s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 7.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.866666666666667 / 14  (34.8):  43%|▍| 13/30 [00:41<00:51,  3.02s/i\u001b[A\n",
      "Average Metric: 4.866666666666667 / 14  (34.8):  47%|▍| 14/30 [00:41<01:12,  4.54s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.866666666666667 / 15  (39.1):  47%|▍| 14/30 [00:49<01:12,  4.54s/i\u001b[A\n",
      "Average Metric: 5.866666666666667 / 15  (39.1):  50%|▌| 15/30 [00:49<01:26,  5.77s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.866666666666667 / 16  (36.7):  50%|▌| 15/30 [00:50<01:26,  5.77s/i\u001b[A\n",
      "Average Metric: 5.866666666666667 / 16  (36.7):  53%|▌| 16/30 [00:50<00:58,  4.19s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.866666666666667 / 17  (34.5):  53%|▌| 16/30 [00:55<00:58,  4.19s/i\u001b[A\n",
      "Average Metric: 5.866666666666667 / 17  (34.5):  57%|▌| 17/30 [00:55<00:57,  4.40s/i\u001b[A\n",
      "Average Metric: 5.866666666666667 / 18  (32.6):  57%|▌| 17/30 [00:56<00:57,  4.40s/i\u001b[A\n",
      "Average Metric: 5.866666666666667 / 18  (32.6):  60%|▌| 18/30 [00:56<00:41,  3.43s/i\u001b[A\n",
      "Average Metric: 5.966666666666667 / 19  (31.4):  60%|▌| 18/30 [00:56<00:41,  3.43s/i\u001b[A\n",
      "Average Metric: 5.966666666666667 / 19  (31.4):  63%|▋| 19/30 [00:56<00:26,  2.44s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.966666666666667 / 20  (29.8):  63%|▋| 19/30 [00:58<00:26,  2.44s/i\u001b[A\n",
      "Average Metric: 5.966666666666667 / 20  (29.8):  67%|▋| 20/30 [00:58<00:21,  2.18s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.466666666666667 / 21  (30.8):  67%|▋| 20/30 [00:59<00:21,  2.18s/i\u001b[A\n",
      "Average Metric: 6.466666666666667 / 21  (30.8):  70%|▋| 21/30 [00:59<00:18,  2.01s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.466666666666667 / 22  (33.9):  70%|▋| 21/30 [01:03<00:18,  2.01s/i\u001b[A\n",
      "Average Metric: 7.466666666666667 / 22  (33.9):  73%|▋| 22/30 [01:03<00:19,  2.48s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.966666666666667 / 23  (34.6):  73%|▋| 22/30 [01:07<00:19,  2.48s/i\u001b[A\n",
      "Average Metric: 7.966666666666667 / 23  (34.6):  77%|▊| 23/30 [01:07<00:20,  2.93s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.966666666666667 / 24  (37.4):  77%|▊| 23/30 [01:10<00:20,  2.93s/i\u001b[A\n",
      "Average Metric: 8.966666666666667 / 24  (37.4):  80%|▊| 24/30 [01:10<00:19,  3.18s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.966666666666667 / 25  (35.9):  80%|▊| 24/30 [01:12<00:19,  3.18s/i\u001b[A\n",
      "Average Metric: 8.966666666666667 / 25  (35.9):  83%|▊| 25/30 [01:12<00:12,  2.58s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.966666666666667 / 26  (34.5):  83%|▊| 25/30 [01:14<00:12,  2.58s/i\u001b[A\n",
      "Average Metric: 8.966666666666667 / 26  (34.5):  87%|▊| 26/30 [01:14<00:10,  2.54s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.591666666666667 / 27  (35.5):  87%|▊| 26/30 [01:18<00:10,  2.54s/i\u001b[A\n",
      "Average Metric: 9.591666666666667 / 27  (35.5):  90%|▉| 27/30 [01:18<00:08,  2.97s/i\u001b[A\n",
      "Average Metric: 10.591666666666667 / 28  (37.8):  90%|▉| 27/30 [01:20<00:08,  2.97s/\u001b[A\n",
      "Average Metric: 10.591666666666667 / 28  (37.8):  93%|▉| 28/30 [01:20<00:05,  2.57s/\u001b[A\n",
      "Average Metric: 11.258333333333333 / 29  (38.8):  93%|▉| 28/30 [01:22<00:05,  2.57s/\u001b[A\n",
      "Average Metric: 11.258333333333333 / 29  (38.8):  97%|▉| 29/30 [01:22<00:02,  2.63s/\u001b[A\n",
      "Average Metric: 11.758333333333333 / 30  (39.2):  97%|▉| 29/30 [01:26<00:02,  2.63s/\u001b[A\n",
      "Average Metric: 11.758333333333333 / 30  (39.2): 100%|█| 30/30 [01:26<00:00,  2.89s/\u001b[A\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 11.758333333333333 / 30  (39.2%)\n",
      "Score: 39.19 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28, 51.72, 51.38, 51.77, 43.0, 39.19]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.7858333333333333\n",
      "Average of max per entry across top 5 scores: 0.9072222222222223\n",
      "Average of max per entry across top 8 scores: 0.9416666666666667\n",
      "Average of max per entry across top 9999 scores: 0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:00<00:25,  1.14it/s]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:29,  1.05s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:33,  1.24s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:04<00:29,  1.14s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.6666666666666666 / 1  (66.7):   0%|        | 0/30 [00:01<?, ?it/s]\u001b[A\n",
      "Average Metric: 0.6666666666666666 / 1  (66.7):   3%| | 1/30 [00:01<00:32,  1.13s/it\u001b[A\n",
      "Average Metric: 0.9166666666666666 / 2  (45.8):   3%| | 1/30 [00:01<00:32,  1.13s/it\u001b[A\n",
      "Average Metric: 1.3166666666666667 / 3  (43.9):   7%| | 2/30 [00:03<00:31,  1.13s/it\u001b[A\n",
      "Average Metric: 1.3166666666666667 / 3  (43.9):  10%| | 3/30 [00:03<00:27,  1.03s/it\u001b[A\n",
      "Average Metric: 2.1166666666666667 / 4  (52.9):  10%| | 3/30 [00:04<00:27,  1.03s/it\u001b[A\n",
      "Average Metric: 2.1166666666666667 / 4  (52.9):  13%|▏| 4/30 [00:04<00:25,  1.01it/s\u001b[A\n",
      "Average Metric: 2.6166666666666667 / 5  (52.3):  13%|▏| 4/30 [00:04<00:25,  1.01it/s\u001b[A\n",
      "Average Metric: 2.6166666666666667 / 5  (52.3):  17%|▏| 5/30 [00:04<00:18,  1.39it/s\u001b[A\n",
      "Average Metric: 2.6166666666666667 / 6  (43.6):  17%|▏| 5/30 [00:04<00:18,  1.39it/s\u001b[A\n",
      "Average Metric: 2.6166666666666667 / 6  (43.6):  20%|▏| 6/30 [00:04<00:17,  1.36it/s\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.6166666666666667 / 7  (37.4):  20%|▏| 6/30 [00:07<00:17,  1.36it/s\u001b[A\n",
      "Average Metric: 2.6166666666666667 / 7  (37.4):  23%|▏| 7/30 [00:07<00:28,  1.24s/it\u001b[A\n",
      "Average Metric: 2.6166666666666667 / 8  (32.7):  23%|▏| 7/30 [00:08<00:28,  1.24s/it\u001b[A\n",
      "Average Metric: 2.6166666666666667 / 8  (32.7):  27%|▎| 8/30 [00:08<00:30,  1.37s/it\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.6166666666666667 / 9  (40.2):  27%|▎| 8/30 [00:09<00:30,  1.37s/it\u001b[A\n",
      "Average Metric: 3.6166666666666667 / 9  (40.2):  30%|▎| 9/30 [00:09<00:20,  1.01it/s\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 10  (38.7):  30%|▎| 9/30 [00:10<00:20,  1.01it/\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 10  (38.7):  33%|▎| 10/30 [00:10<00:20,  1.04s/\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 11  (35.2):  33%|▎| 10/30 [00:11<00:20,  1.04s/\u001b[A\n",
      "Average Metric: 3.8666666666666667 / 11  (35.2):  37%|▎| 11/30 [00:11<00:19,  1.02s/\u001b[A\n",
      "Average Metric: 4.2 / 12  (35.0):  37%|████▊        | 11/30 [00:11<00:19,  1.02s/it]\u001b[A\n",
      "Average Metric: 5.2 / 13  (40.0):  40%|█████▏       | 12/30 [00:11<00:18,  1.02s/it]\u001b[A\n",
      "Average Metric: 5.45 / 14  (38.9):  43%|█████▏      | 13/30 [00:11<00:17,  1.02s/it]\u001b[A\n",
      "Average Metric: 5.45 / 14  (38.9):  47%|█████▌      | 14/30 [00:11<00:09,  1.76it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.45 / 15  (43.0):  47%|█████▌      | 14/30 [00:13<00:09,  1.76it/s]\u001b[A\n",
      "Average Metric: 6.45 / 15  (43.0):  50%|██████      | 15/30 [00:13<00:13,  1.15it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.8500000000000005 / 16  (42.8):  50%|▌| 15/30 [00:17<00:13,  1.15it\u001b[A\n",
      "Average Metric: 6.8500000000000005 / 16  (42.8):  53%|▌| 16/30 [00:17<00:22,  1.61s/\u001b[A\n",
      "Average Metric: 7.183333333333334 / 17  (42.3):  53%|▌| 16/30 [00:18<00:22,  1.61s/i\u001b[A\n",
      "Average Metric: 7.183333333333334 / 17  (42.3):  57%|▌| 17/30 [00:18<00:16,  1.28s/i\u001b[A\n",
      "Average Metric: 7.516666666666667 / 18  (41.8):  57%|▌| 17/30 [00:19<00:16,  1.28s/i\u001b[A\n",
      "Average Metric: 7.516666666666667 / 18  (41.8):  60%|▌| 18/30 [00:19<00:14,  1.20s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.016666666666666 / 19  (42.2):  60%|▌| 18/30 [00:19<00:14,  1.20s/i\u001b[A\n",
      "Average Metric: 8.016666666666666 / 19  (42.2):  63%|▋| 19/30 [00:19<00:11,  1.09s/i\u001b[A\n",
      "Average Metric: 8.016666666666666 / 20  (40.1):  63%|▋| 19/30 [00:20<00:11,  1.09s/i\u001b[A\n",
      "Average Metric: 8.016666666666666 / 20  (40.1):  67%|▋| 20/30 [00:20<00:10,  1.03s/i\u001b[A\n",
      "Average Metric: 8.016666666666666 / 21  (38.2):  67%|▋| 20/30 [00:21<00:10,  1.03s/i\u001b[A\n",
      "Average Metric: 8.016666666666666 / 21  (38.2):  70%|▋| 21/30 [00:21<00:08,  1.12it/\u001b[A\n",
      "Average Metric: 8.516666666666666 / 22  (38.7):  70%|▋| 21/30 [00:21<00:08,  1.12it/\u001b[A\n",
      "Average Metric: 8.516666666666666 / 22  (38.7):  73%|▋| 22/30 [00:21<00:05,  1.34it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.266666666666666 / 23  (40.3):  73%|▋| 22/30 [00:22<00:05,  1.34it/\u001b[A\n",
      "Average Metric: 9.266666666666666 / 23  (40.3):  77%|▊| 23/30 [00:22<00:05,  1.34it/\u001b[A\n",
      "Average Metric: 9.766666666666666 / 24  (40.7):  77%|▊| 23/30 [00:23<00:05,  1.34it/\u001b[A\n",
      "Average Metric: 9.766666666666666 / 24  (40.7):  80%|▊| 24/30 [00:23<00:04,  1.36it/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 10.766666666666666 / 25  (43.1):  80%|▊| 24/30 [00:24<00:04,  1.36it\u001b[A\n",
      "Average Metric: 10.766666666666666 / 25  (43.1):  83%|▊| 25/30 [00:24<00:03,  1.31it\u001b[A\n",
      "Average Metric: 11.1 / 26  (42.7):  83%|██████████  | 25/30 [00:24<00:03,  1.31it/s]\u001b[A\n",
      "Average Metric: 11.1 / 26  (42.7):  87%|██████████▍ | 26/30 [00:24<00:02,  1.45it/s]\u001b[A\n",
      "Average Metric: 11.1 / 27  (41.1):  87%|██████████▍ | 26/30 [00:25<00:02,  1.45it/s]\u001b[A\n",
      "Average Metric: 11.1 / 27  (41.1):  90%|██████████▊ | 27/30 [00:25<00:01,  1.53it/s]\u001b[A\n",
      "Average Metric: 12.1 / 28  (43.2):  90%|██████████▊ | 27/30 [00:25<00:01,  1.53it/s]\u001b[A\n",
      "Average Metric: 12.1 / 28  (43.2):  93%|███████████▏| 28/30 [00:25<00:01,  1.84it/s]\u001b[A\n",
      "Average Metric: 12.7 / 29  (43.8):  93%|███████████▏| 28/30 [00:26<00:01,  1.84it/s]\u001b[A\n",
      "Average Metric: 12.7 / 29  (43.8):  97%|███████████▌| 29/30 [00:26<00:00,  1.60it/s]\u001b[A\n",
      "Average Metric: 13.7 / 30  (45.7): 100%|████████████| 30/30 [00:26<00:00,  1.14it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 13.7 / 30  (45.7%)\n",
      "Score: 45.67 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28, 51.72, 51.38, 51.77, 43.0, 39.19, 45.67]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7269444444444445\n",
      "Average of max per entry across top 3 scores: 0.7858333333333333\n",
      "Average of max per entry across top 5 scores: 0.9072222222222223\n",
      "Average of max per entry across top 8 scores: 0.9416666666666667\n",
      "Average of max per entry across top 9999 scores: 0.9833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|█▌                                              | 1/30 [00:01<00:34,  1.19s/it]\u001b[A\n",
      "  7%|███▏                                            | 2/30 [00:02<00:31,  1.14s/it]\u001b[A\n",
      " 10%|████▊                                           | 3/30 [00:03<00:31,  1.18s/it]\u001b[A\n",
      " 13%|██████▍                                         | 4/30 [00:04<00:27,  1.07s/it]\u001b[A\n",
      " 17%|████████                                        | 5/30 [00:05<00:29,  1.18s/it]\u001b[A\n",
      " 20%|█████████▌                                      | 6/30 [00:07<00:31,  1.29s/it]\u001b[A\n",
      " 23%|███████████▏                                    | 7/30 [00:08<00:28,  1.25s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 8 examples in round 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                        | 0/30 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 1.0 / 1  (100.0):   0%|                      | 0/30 [00:04<?, ?it/s]\u001b[A\n",
      "Average Metric: 1.0 / 1  (100.0):   3%|▍             | 1/30 [00:04<02:21,  4.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 5.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0 / 2  (100.0):   3%|▍             | 1/30 [00:12<02:21,  4.88s/it]\u001b[A\n",
      "Average Metric: 2.0 / 2  (100.0):   7%|▉             | 2/30 [00:12<02:59,  6.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 2.0 / 3  (66.7):   7%|█              | 2/30 [00:13<02:59,  6.41s/it]\u001b[A\n",
      "Average Metric: 2.0 / 3  (66.7):  10%|█▌             | 3/30 [00:13<01:50,  4.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0 / 4  (75.0):  10%|█▌             | 3/30 [00:16<01:50,  4.10s/it]\u001b[A\n",
      "Average Metric: 3.0 / 4  (75.0):  13%|██             | 4/30 [00:16<01:29,  3.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.0 / 5  (60.0):  13%|██             | 4/30 [00:21<01:29,  3.44s/it]\u001b[A\n",
      "Average Metric: 3.0 / 5  (60.0):  17%|██▌            | 5/30 [00:21<01:43,  4.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.125 / 6  (52.1):  17%|██▏          | 5/30 [00:33<01:43,  4.15s/it]\u001b[A\n",
      "Average Metric: 3.125 / 6  (52.1):  20%|██▌          | 6/30 [00:33<02:47,  6.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 3.725 / 7  (53.2):  20%|██▌          | 6/30 [00:36<02:47,  6.97s/it]\u001b[A\n",
      "Average Metric: 3.725 / 7  (53.2):  23%|███          | 7/30 [00:36<02:07,  5.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.3 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.725 / 8  (59.1):  23%|███          | 7/30 [00:37<02:07,  5.56s/it]\u001b[A\n",
      "Average Metric: 4.725 / 8  (59.1):  27%|███▍         | 8/30 [00:37<01:29,  4.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 4.725 / 9  (52.5):  27%|███▍         | 8/30 [00:39<01:29,  4.08s/it]\u001b[A\n",
      "Average Metric: 4.725 / 9  (52.5):  30%|███▉         | 9/30 [00:39<01:13,  3.52s/it]\u001b[A\n",
      "Average Metric: 4.725 / 10  (47.2):  30%|███▌        | 9/30 [00:40<01:13,  3.52s/it]\u001b[A\n",
      "Average Metric: 4.725 / 10  (47.2):  33%|███▋       | 10/30 [00:40<00:53,  2.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 5.058333333333333 / 11  (46.0):  33%|▎| 10/30 [00:49<00:53,  2.69s/i\u001b[A\n",
      "Average Metric: 5.058333333333333 / 11  (46.0):  37%|▎| 11/30 [00:49<01:26,  4.53s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 6.058333333333333 / 12  (50.5):  37%|▎| 11/30 [00:53<01:26,  4.53s/i\u001b[A\n",
      "Average Metric: 6.058333333333333 / 12  (50.5):  40%|▍| 12/30 [00:53<01:19,  4.43s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.058333333333333 / 13  (54.3):  40%|▍| 12/30 [00:56<01:19,  4.43s/i\u001b[A\n",
      "Average Metric: 7.058333333333333 / 13  (54.3):  43%|▍| 13/30 [00:56<01:09,  4.07s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.458333333333333 / 14  (53.3):  43%|▍| 13/30 [01:00<01:09,  4.07s/i\u001b[A\n",
      "Average Metric: 7.458333333333333 / 14  (53.3):  47%|▍| 14/30 [01:00<01:02,  3.89s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.958333333333333 / 15  (53.1):  47%|▍| 14/30 [01:02<01:02,  3.89s/i\u001b[A\n",
      "Average Metric: 7.958333333333333 / 15  (53.1):  50%|▌| 15/30 [01:02<00:50,  3.35s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 7.958333333333333 / 16  (49.7):  50%|▌| 15/30 [01:05<00:50,  3.35s/i\u001b[A\n",
      "Average Metric: 7.958333333333333 / 16  (49.7):  53%|▌| 16/30 [01:05<00:45,  3.28s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.291666666666666 / 17  (48.8):  53%|▌| 16/30 [01:06<00:45,  3.28s/i\u001b[A\n",
      "Average Metric: 8.291666666666666 / 17  (48.8):  57%|▌| 17/30 [01:06<00:35,  2.73s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 3.1 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 8.791666666666666 / 18  (48.8):  57%|▌| 17/30 [01:09<00:35,  2.73s/i\u001b[A\n",
      "Average Metric: 8.791666666666666 / 18  (48.8):  60%|▌| 18/30 [01:09<00:30,  2.53s/i\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 9.458333333333332 / 19  (49.8):  60%|▌| 18/30 [01:09<00:30,  2.53s/i\u001b[A\n",
      "Average Metric: 9.458333333333332 / 19  (49.8):  63%|▋| 19/30 [01:09<00:21,  1.95s/i\u001b[A\n",
      "Average Metric: 10.458333333333332 / 20  (52.3):  63%|▋| 19/30 [01:10<00:21,  1.95s/\u001b[A\n",
      "Average Metric: 10.458333333333332 / 20  (52.3):  67%|▋| 20/30 [01:10<00:16,  1.68s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.458333333333332 / 21  (54.6):  67%|▋| 20/30 [01:12<00:16,  1.68s/\u001b[A\n",
      "Average Metric: 11.458333333333332 / 21  (54.6):  70%|▋| 21/30 [01:12<00:15,  1.74s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 4.2 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 23.6 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.458333333333332 / 22  (52.1):  70%|▋| 21/30 [01:18<00:15,  1.74s/\u001b[A\n",
      "Average Metric: 11.458333333333332 / 22  (52.1):  73%|▋| 22/30 [01:18<00:23,  2.97s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.458333333333332 / 23  (49.8):  73%|▋| 22/30 [01:20<00:23,  2.97s/\u001b[A\n",
      "Average Metric: 11.458333333333332 / 23  (49.8):  77%|▊| 23/30 [01:20<00:19,  2.76s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 11.958333333333332 / 24  (49.8):  77%|▊| 23/30 [01:22<00:19,  2.76s/\u001b[A\n",
      "Average Metric: 11.958333333333332 / 24  (49.8):  80%|▊| 24/30 [01:22<00:14,  2.42s/\u001b[A\n",
      "Average Metric: 12.958333333333332 / 25  (51.8):  80%|▊| 24/30 [01:23<00:14,  2.42s/\u001b[A\n",
      "Average Metric: 12.958333333333332 / 25  (51.8):  83%|▊| 25/30 [01:23<00:09,  1.93s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 12.958333333333332 / 26  (49.8):  83%|▊| 25/30 [01:30<00:09,  1.93s/\u001b[A\n",
      "Average Metric: 12.958333333333332 / 26  (49.8):  87%|▊| 26/30 [01:30<00:14,  3.51s/\u001b[A\n",
      "Average Metric: 13.624999999999998 / 27  (50.5):  87%|▊| 26/30 [01:31<00:14,  3.51s/\u001b[A\n",
      "Average Metric: 13.624999999999998 / 27  (50.5):  90%|▉| 27/30 [01:31<00:08,  2.76s/\u001b[A\n",
      "Average Metric: 14.624999999999998 / 28  (52.2):  90%|▉| 27/30 [01:33<00:08,  2.76s/\u001b[A\n",
      "Average Metric: 14.624999999999998 / 28  (52.2):  93%|▉| 28/30 [01:33<00:05,  2.55s/\u001b[A\n",
      "Average Metric: 15.374999999999998 / 29  (53.0):  93%|▉| 28/30 [01:38<00:05,  2.55s/\u001b[A\n",
      "Average Metric: 15.374999999999998 / 29  (53.0):  97%|▉| 29/30 [01:38<00:03,  3.26s/\u001b[A\n",
      "Average Metric: 15.708333333333332 / 30  (52.4):  97%|▉| 29/30 [01:52<00:03,  3.26s/\u001b[A\n",
      "Average Metric: 15.708333333333332 / 30  (52.4): 100%|█| 30/30 [01:52<00:00,  3.73s/\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 15.708333333333332 / 30  (52.4%)\n",
      "Score: 52.36 for set: [16, 16, 16]\n",
      "Scores so far: [37.56, 56.67, 47.49, 51.53, 46.28, 35.64, 50.61, 51.97, 45.64, 49.44, 46.62, 48.28, 51.72, 51.38, 51.77, 43.0, 39.19, 45.67, 52.36]\n",
      "Best score: 56.67\n",
      "Average of max per entry across top 1 scores: 0.5666666666666667\n",
      "Average of max per entry across top 2 scores: 0.7583333333333332\n",
      "Average of max per entry across top 3 scores: 0.8547222222222223\n",
      "Average of max per entry across top 5 scores: 0.8927777777777778\n",
      "Average of max per entry across top 8 scores: 0.9683333333333334\n",
      "Average of max per entry across top 9999 scores: 1.0\n",
      "19 candidate programs found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "optimizer = BootstrapFewShotWithRandomSearch(metric=validate_venn)\n",
    "compiled_pipeline_v3 = optimizer.compile(ABSAPipelineV3(), teacher=ABSAPipelineV3(), trainset=dspy_train[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "434498d0-a68e-465b-9b8b-a0b2f9f67e4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                                       | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0 / 1  (0.0):   0%|                         | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0 / 1  (0.0):   1%|▏                | 1/100 [00:00<00:12,  7.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   1%|▏              | 1/100 [00:00<00:12,  7.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 2  (0.0):   2%|▎              | 2/100 [00:00<00:11,  8.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 3  (0.0):   2%|▎              | 2/100 [00:00<00:11,  8.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 4  (0.0):   3%|▍              | 3/100 [00:00<00:11,  8.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.5 / 5  (10.0):   4%|▌             | 4/100 [00:00<00:11,  8.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.1666666666666665 / 6  (19.4):   5%| | 5/100 [00:00<00:11,  8.30it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.1666666666666665 / 6  (19.4):   6%| | 6/100 [00:00<00:05, 15.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 1.5666666666666664 / 7  (22.4):   6%| | 6/100 [00:00<00:05, 15.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 2.5666666666666664 / 8  (32.1):   7%| | 7/100 [00:00<00:05, 15.76it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.233333333333333 / 9  (35.9):   8%| | 8/100 [00:00<00:05, 15.76it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.233333333333333 / 9  (35.9):   9%| | 9/100 [00:00<00:04, 19.45it/s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.233333333333333 / 10  (32.3):   9%| | 9/100 [00:00<00:04, 19.45it/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 3.233333333333333 / 11  (29.4):  10%| | 10/100 [00:00<00:04, 19.45it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 4.2333333333333325 / 12  (35.3):  11%| | 11/100 [00:00<00:04, 19.45i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.2333333333333325 / 13  (40.3):  12%| | 12/100 [00:00<00:04, 19.45i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 5.519047619047618 / 14  (39.4):  13%|▏| 13/100 [00:00<00:04, 19.45it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.519047619047618 / 15  (43.5):  14%|▏| 14/100 [00:00<00:04, 19.45it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 6.519047619047618 / 15  (43.5):  15%|▏| 15/100 [00:00<00:03, 28.21it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.319047619047618 / 16  (45.7):  15%|▏| 15/100 [00:00<00:03, 28.21it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.319047619047618 / 17  (43.1):  16%|▏| 16/100 [00:00<00:02, 28.21it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.319047619047618 / 18  (40.7):  17%|▏| 17/100 [00:00<00:02, 28.21it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 7.319047619047618 / 18  (40.7):  18%|▏| 18/100 [00:00<00:03, 25.13it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 8.319047619047618 / 19  (43.8):  18%|▏| 18/100 [00:00<00:03, 25.13it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 9.319047619047618 / 20  (46.6):  19%|▏| 19/100 [00:00<00:03, 25.13it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.319047619047618 / 21  (49.1):  20%|▏| 20/100 [00:00<00:03, 25.13i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.319047619047618 / 22  (46.9):  21%|▏| 21/100 [00:00<00:03, 25.13i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.319047619047618 / 22  (46.9):  22%|▏| 22/100 [00:00<00:02, 28.48i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.319047619047618 / 23  (44.9):  22%|▏| 22/100 [00:00<00:02, 28.48i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 10.819047619047618 / 24  (45.1):  23%|▏| 23/100 [00:00<00:02, 28.48i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.819047619047618 / 25  (47.3):  24%|▏| 24/100 [00:00<00:02, 28.48i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 11.819047619047618 / 25  (47.3):  25%|▎| 25/100 [00:01<00:08,  9.09i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 0.0 / 9  (0.0):  30%|███▉         | 9/30 [44:25<1:43:39, 296.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Average Metric: 12.569047619047618 / 27  (46.6):  26%|▎| 26/100 [00:01<00:08,  9.09i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.569047619047618 / 28  (48.5):  27%|▎| 27/100 [00:01<00:08,  9.09i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.569047619047618 / 29  (46.8):  28%|▎| 28/100 [00:01<00:07,  9.09i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.569047619047618 / 29  (46.8):  29%|▎| 29/100 [00:01<00:05, 12.01i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 13.569047619047618 / 30  (45.2):  29%|▎| 29/100 [00:02<00:05, 12.01i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.235714285714284 / 31  (45.9):  30%|▎| 30/100 [00:02<00:05, 12.01i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.90238095238095 / 32  (46.6):  31%|▎| 31/100 [00:02<00:05, 12.01it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 14.90238095238095 / 33  (45.2):  32%|▎| 32/100 [00:02<00:05, 12.01it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.90238095238095 / 34  (46.8):  33%|▎| 33/100 [00:02<00:05, 12.01it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.90238095238095 / 34  (46.8):  34%|▎| 34/100 [00:02<00:04, 15.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.90238095238095 / 35  (45.4):  34%|▎| 34/100 [00:02<00:04, 15.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 15.90238095238095 / 36  (44.2):  35%|▎| 35/100 [00:02<00:04, 15.10it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.902380952380952 / 37  (45.7):  36%|▎| 36/100 [00:02<00:04, 15.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.902380952380952 / 38  (44.5):  37%|▎| 37/100 [00:02<00:04, 15.10i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 16.902380952380952 / 38  (44.5):  38%|▍| 38/100 [00:02<00:03, 17.83i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 17.56904761904762 / 39  (45.0):  38%|▍| 38/100 [00:02<00:03, 17.83it\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.235714285714288 / 40  (45.6):  39%|▍| 39/100 [00:02<00:03, 17.83i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 18.235714285714288 / 41  (44.5):  40%|▍| 40/100 [00:02<00:03, 17.83i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 19.235714285714288 / 42  (45.8):  41%|▍| 41/100 [00:02<00:03, 17.83i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 20.235714285714288 / 43  (47.1):  42%|▍| 42/100 [00:02<00:03, 17.83i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 20.235714285714288 / 43  (47.1):  43%|▍| 43/100 [00:02<00:02, 22.39i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 20.735714285714288 / 44  (47.1):  43%|▍| 43/100 [00:02<00:02, 22.39i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 21.402380952380955 / 45  (47.6):  44%|▍| 44/100 [00:02<00:02, 22.39i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.202380952380956 / 46  (48.3):  45%|▍| 45/100 [00:02<00:02, 22.39i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.202380952380956 / 47  (47.2):  46%|▍| 46/100 [00:02<00:02, 22.39i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.202380952380956 / 47  (47.2):  47%|▍| 47/100 [00:02<00:02, 24.81i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 22.869047619047624 / 48  (47.6):  47%|▍| 47/100 [00:02<00:02, 24.81i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 23.869047619047624 / 49  (48.7):  48%|▍| 48/100 [00:02<00:02, 24.81i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 23.869047619047624 / 50  (47.7):  49%|▍| 49/100 [00:02<00:02, 24.81i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 24.869047619047624 / 51  (48.8):  50%|▌| 50/100 [00:02<00:02, 24.81i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 52  (49.7):  51%|▌| 51/100 [00:02<00:01, 24.81i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 52  (49.7):  52%|▌| 52/100 [00:02<00:01, 29.17i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 53  (48.8):  52%|▌| 52/100 [00:02<00:01, 29.17i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 54  (47.9):  53%|▌| 53/100 [00:02<00:01, 29.17i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 55  (47.0):  54%|▌| 54/100 [00:02<00:01, 29.17i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 56  (46.2):  55%|▌| 55/100 [00:02<00:01, 29.17i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 57  (45.4):  56%|▌| 56/100 [00:02<00:01, 29.17i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 57  (45.4):  57%|▌| 57/100 [00:02<00:01, 29.31i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 58  (44.6):  57%|▌| 57/100 [00:02<00:01, 29.31i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 25.869047619047624 / 59  (43.8):  58%|▌| 58/100 [00:02<00:01, 29.31i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.369047619047624 / 60  (43.9):  59%|▌| 59/100 [00:02<00:01, 29.31i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.369047619047624 / 61  (43.2):  60%|▌| 60/100 [00:02<00:01, 29.31i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 26.369047619047624 / 62  (42.5):  61%|▌| 61/100 [00:02<00:01, 29.31i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.169047619047625 / 63  (43.1):  62%|▌| 62/100 [00:03<00:01, 29.31i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.169047619047625 / 63  (43.1):  63%|▋| 63/100 [00:03<00:01, 29.77i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.169047619047625 / 64  (42.5):  63%|▋| 63/100 [00:03<00:01, 29.77i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.169047619047625 / 65  (41.8):  64%|▋| 64/100 [00:03<00:01, 29.77i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 27.169047619047625 / 66  (41.2):  65%|▋| 65/100 [00:03<00:01, 29.77i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 28.169047619047625 / 67  (42.0):  66%|▋| 66/100 [00:03<00:01, 29.77i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 28.969047619047625 / 68  (42.6):  67%|▋| 67/100 [00:03<00:01, 29.77i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 28.969047619047625 / 69  (42.0):  68%|▋| 68/100 [00:03<00:01, 29.77i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 28.969047619047625 / 69  (42.0):  69%|▋| 69/100 [00:03<00:00, 35.45i\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 29.969047619047625 / 70  (42.8):  69%|▋| 69/100 [00:04<00:00, 35.45i\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 29.969047619047625 / 71  (42.2):  70%|▋| 70/100 [00:07<00:00, 35.45i\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.4 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.0 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 30.969047619047625 / 72  (43.0):  71%|▋| 71/100 [00:11<00:00, 35.45i\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 30.969047619047625 / 72  (43.0):  72%|▋| 72/100 [00:15<00:00, 35.45i\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 13.9 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 4.4 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 42.4 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.5 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 31.369047619047624 / 73  (43.0):  72%|▋| 72/100 [00:24<00:00, 35.45i\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 31.369047619047624 / 73  (43.0):  73%|▋| 73/100 [00:24<00:35,  1.30s\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 20.5 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.5 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 7.7 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 32.36904761904762 / 74  (43.7):  73%|▋| 73/100 [00:29<00:35,  1.30s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 32.36904761904762 / 74  (43.7):  74%|▋| 74/100 [00:29<00:42,  1.64s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.035714285714285 / 75  (44.0):  74%|▋| 74/100 [00:29<00:42,  1.64s\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 33.035714285714285 / 76  (43.5):  75%|▊| 75/100 [00:30<00:40,  1.64s\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 33.035714285714285 / 77  (42.9):  76%|▊| 76/100 [00:32<00:39,  1.64s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 33.035714285714285 / 77  (42.9):  77%|▊| 77/100 [00:32<00:33,  1.46s\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 19.0 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 33.43571428571428 / 78  (42.9):  77%|▊| 77/100 [00:32<00:33,  1.46s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 4.1 seconds after 5 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 34.43571428571428 / 79  (43.6):  78%|▊| 78/100 [00:40<00:32,  1.46s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 34.43571428571428 / 79  (43.6):  79%|▊| 79/100 [00:40<00:40,  1.92s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 18.1 seconds after 6 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 35.23571428571428 / 80  (44.0):  79%|▊| 79/100 [00:42<00:40,  1.92s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 35.569047619047616 / 81  (43.9):  80%|▊| 80/100 [00:43<00:38,  1.92s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 35.569047619047616 / 81  (43.9):  81%|▊| 81/100 [00:43<00:35,  1.89s\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 36.569047619047616 / 82  (44.6):  81%|▊| 81/100 [00:45<00:35,  1.89s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.569047619047616 / 82  (44.6):  82%|▊| 82/100 [00:45<00:33,  1.89s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.569047619047616 / 83  (44.1):  82%|▊| 82/100 [00:45<00:33,  1.89s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 36.569047619047616 / 83  (44.1):  83%|▊| 83/100 [00:45<00:27,  1.60s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 37.23571428571428 / 84  (44.3):  83%|▊| 83/100 [00:45<00:27,  1.60s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 37.23571428571428 / 84  (44.3):  84%|▊| 84/100 [00:45<00:21,  1.32s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {'max_tokens': 500, 'n': 1, 'temperature': 0.0}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.7 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 38.23571428571428 / 85  (45.0):  84%|▊| 84/100 [00:48<00:21,  1.32s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 38.23571428571428 / 85  (45.0):  85%|▊| 85/100 [00:48<00:24,  1.63s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.3 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.2 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 38.23571428571428 / 86  (44.5):  85%|▊| 85/100 [00:51<00:24,  1.63s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 38.23571428571428 / 86  (44.5):  86%|▊| 86/100 [00:51<00:27,  1.94s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 39.23571428571428 / 87  (45.1):  86%|▊| 86/100 [00:51<00:27,  1.94s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 39.23571428571428 / 87  (45.1):  87%|▊| 87/100 [00:51<00:19,  1.54s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.23571428571428 / 88  (45.7):  87%|▊| 87/100 [00:52<00:19,  1.54s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.23571428571428 / 88  (45.7):  88%|▉| 88/100 [00:52<00:15,  1.26s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 94.1 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.2 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.4 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.9 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 40.63571428571428 / 89  (45.7):  88%|▉| 88/100 [01:04<00:15,  1.26s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.63571428571428 / 89  (45.7):  89%|▉| 89/100 [01:04<00:45,  4.13s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.7 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.8 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.5 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 62.7 seconds after 7 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.6 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.7 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.1 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.6 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 2.0 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.8 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 53.4 seconds after 8 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.3 seconds after 2 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 1.0 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 40.63571428571428 / 90  (45.2):  89%|▉| 89/100 [01:05<00:45,  4.13s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 40.63571428571428 / 90  (45.2):  90%|▉| 90/100 [01:05<00:34,  3.41s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 41.30238095238094 / 91  (45.4):  90%|▉| 90/100 [01:06<00:34,  3.41s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 41.30238095238094 / 91  (45.4):  91%|▉| 91/100 [01:06<00:23,  2.66s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 2.9 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 3 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 0.1 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 41.96904761904761 / 92  (45.6):  91%|▉| 91/100 [01:09<00:23,  2.66s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 41.96904761904761 / 92  (45.6):  92%|▉| 92/100 [01:09<00:22,  2.86s/\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backing off 0.9 seconds after 1 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n",
      "Backing off 3.2 seconds after 4 tries calling function <function GPT3.request at 0x3106b0e00> with kwargs {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Average Metric: 42.82619047619046 / 93  (46.0):  92%|▉| 92/100 [01:12<00:22,  2.86s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 93  (46.0):  93%|▉| 93/100 [01:12<00:19,  2.81s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 94  (45.6):  93%|▉| 93/100 [01:13<00:19,  2.81s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 94  (45.6):  94%|▉| 94/100 [01:13<00:13,  2.30s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 95  (45.1):  94%|▉| 94/100 [01:14<00:13,  2.30s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 95  (45.1):  95%|▉| 95/100 [01:14<00:08,  1.76s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 96  (44.6):  95%|▉| 95/100 [01:15<00:08,  1.76s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 96  (44.6):  96%|▉| 96/100 [01:15<00:06,  1.72s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 97  (44.2):  96%|▉| 96/100 [01:23<00:06,  1.72s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 42.82619047619046 / 97  (44.2):  97%|▉| 97/100 [01:23<00:10,  3.62s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 43.82619047619046 / 98  (44.7):  97%|▉| 97/100 [01:59<00:10,  3.62s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 43.82619047619046 / 98  (44.7):  98%|▉| 98/100 [01:59<00:26, 13.14s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 44.32619047619046 / 99  (44.8):  98%|▉| 98/100 [02:03<00:26, 13.14s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 44.32619047619046 / 99  (44.8):  99%|▉| 99/100 [02:03<00:10, 10.59s/\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 44.32619047619046 / 100  (44.3):  99%|▉| 99/100 [02:27<00:10, 10.59s\u001b[A\u001b[A\n",
      "\n",
      "Average Metric: 44.32619047619046 / 100  (44.3): 100%|█| 100/100 [02:27<00:00,  1.48\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 44.32619047619046 / 100  (44.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:187: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(truncate_cell)\n",
      "/Users/richy/.pyenv/versions/3.11.7/envs/llm/lib/python3.11/site-packages/dspy/evaluate/evaluate.py:263: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0.0' '0.0' '0.6666666666666666' '0.0' '0.5']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, metric_name] = df[metric_name].apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_01702 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_01702 td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_01702_row0_col0, #T_01702_row0_col1, #T_01702_row0_col2, #T_01702_row0_col3, #T_01702_row0_col4, #T_01702_row1_col0, #T_01702_row1_col1, #T_01702_row1_col2, #T_01702_row1_col3, #T_01702_row1_col4, #T_01702_row2_col0, #T_01702_row2_col1, #T_01702_row2_col2, #T_01702_row2_col3, #T_01702_row2_col4, #T_01702_row3_col0, #T_01702_row3_col1, #T_01702_row3_col2, #T_01702_row3_col3, #T_01702_row3_col4, #T_01702_row4_col0, #T_01702_row4_col1, #T_01702_row4_col2, #T_01702_row4_col3, #T_01702_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_01702\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_01702_level0_col0\" class=\"col_heading level0 col0\" >review</th>\n",
       "      <th id=\"T_01702_level0_col1\" class=\"col_heading level0 col1\" >example_aspects_with_label</th>\n",
       "      <th id=\"T_01702_level0_col2\" class=\"col_heading level0 col2\" >aspects_list</th>\n",
       "      <th id=\"T_01702_level0_col3\" class=\"col_heading level0 col3\" >pred_aspects_with_label</th>\n",
       "      <th id=\"T_01702_level0_col4\" class=\"col_heading level0 col4\" >validate_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_01702_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_01702_row0_col0\" class=\"data row0 col0\" >\" The menu includes pub fare--burgers, steaks and shepherds pie--and even a portabella lasagna for those black sheep known as \"vegetarians.</td>\n",
       "      <td id=\"T_01702_row0_col1\" class=\"data row0 col1\" >{'menu': 0, 'burgers': 0, 'steaks': 0, 'shepherds pie': 0, 'portabella lasagna': 0, 'pub fare': 0}</td>\n",
       "      <td id=\"T_01702_row0_col2\" class=\"data row0 col2\" >dict_keys(['menu', 'burgers', 'steaks', 'shepherds pie', 'portabella lasagna', 'pub fare'])</td>\n",
       "      <td id=\"T_01702_row0_col3\" class=\"data row0 col3\" >{'menu': 1, 'pub fare': 0, 'burgers': 1, 'steaks': 1, 'shepherds pie': 1, 'portabella lasagna': 1, 'vegetarians': 0}</td>\n",
       "      <td id=\"T_01702_row0_col4\" class=\"data row0 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01702_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_01702_row1_col0\" class=\"data row1 col0\" >(The sashimi is cut a little thinly.</td>\n",
       "      <td id=\"T_01702_row1_col1\" class=\"data row1 col1\" >{'sashimi': -1}</td>\n",
       "      <td id=\"T_01702_row1_col2\" class=\"data row1 col2\" >dict_keys(['sashimi'])</td>\n",
       "      <td id=\"T_01702_row1_col3\" class=\"data row1 col3\" >{'sashimi': -1, 'thinly': -1}</td>\n",
       "      <td id=\"T_01702_row1_col4\" class=\"data row1 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01702_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_01702_row2_col0\" class=\"data row2 col0\" >) It's not the best Japanese restaurant in the East Village, but it's a pretty solid one for its modest prices, and worth repeat visits.</td>\n",
       "      <td id=\"T_01702_row2_col1\" class=\"data row2 col1\" >{'prices': 1}</td>\n",
       "      <td id=\"T_01702_row2_col2\" class=\"data row2 col2\" >dict_keys(['prices'])</td>\n",
       "      <td id=\"T_01702_row2_col3\" class=\"data row2 col3\" >{'Japanese restaurant': 0, 'East Village': 0, 'prices': 1, 'repeat visits': 1}</td>\n",
       "      <td id=\"T_01702_row2_col4\" class=\"data row2 col4\" >0.6666666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01702_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_01702_row3_col0\" class=\"data row3 col0\" >15% gratuity automatically added to the bill.</td>\n",
       "      <td id=\"T_01702_row3_col1\" class=\"data row3 col1\" >{'bill': -1, 'gratuity': -1}</td>\n",
       "      <td id=\"T_01702_row3_col2\" class=\"data row3 col2\" >dict_keys(['bill', 'gratuity'])</td>\n",
       "      <td id=\"T_01702_row3_col3\" class=\"data row3 col3\" >{'gratuity': -1, 'bill': -1}</td>\n",
       "      <td id=\"T_01702_row3_col4\" class=\"data row3 col4\" >0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_01702_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_01702_row4_col0\" class=\"data row4 col0\" >A beautiful atmosphere, perfect for drinks and/or appetizers.</td>\n",
       "      <td id=\"T_01702_row4_col1\" class=\"data row4 col1\" >{'atmosphere': 1, 'drinks': 0, 'appetizers': 0}</td>\n",
       "      <td id=\"T_01702_row4_col2\" class=\"data row4 col2\" >dict_keys(['atmosphere', 'drinks', 'appetizers'])</td>\n",
       "      <td id=\"T_01702_row4_col3\" class=\"data row4 col3\" >{'atmosphere': 1, 'drinks': 1, 'appetizers': 1}</td>\n",
       "      <td id=\"T_01702_row4_col4\" class=\"data row4 col4\" >0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x35db34410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 95 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "44.33"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " evaluate_test(compiled_pipeline_v3, metric=validate_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12cc5efe-104a-468f-8eaa-6b7ceb04a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_pipeline_v3.save(\"./ABSAPipelineV3venn.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6429b1c9-1f23-4faa-bbe3-fd72648c4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3 = ABSAPipelineV3()\n",
    "v3_venn = ABSAPipelineV3()\n",
    "v3 = ABSAPipelineV3.load(\"./ABSAPipelineV3venn.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
